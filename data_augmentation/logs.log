2023-11-04 13:09:13,664:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-04 13:09:13,664:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-04 13:09:13,664:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-04 13:09:13,664:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-04 13:09:47,292:INFO:PyCaret RegressionExperiment
2023-11-04 13:09:47,292:INFO:Logging name: reg-default-name
2023-11-04 13:09:47,292:INFO:ML Usecase: MLUsecase.REGRESSION
2023-11-04 13:09:47,292:INFO:version 3.1.0
2023-11-04 13:09:47,292:INFO:Initializing setup()
2023-11-04 13:09:47,292:INFO:self.USI: 886c
2023-11-04 13:09:47,292:INFO:self._variable_keys: {'USI', 'log_plots_param', 'gpu_param', 'fold_generator', 'X_test', 'html_param', '_ml_usecase', '_available_plots', 'exp_id', 'target_param', 'idx', 'fold_shuffle_param', 'n_jobs_param', 'seed', 'exp_name_log', 'X', 'y_train', 'transform_target_param', 'data', 'y_test', 'fold_groups_param', 'logging_param', 'gpu_n_jobs_param', 'y', 'X_train', 'memory', 'pipeline'}
2023-11-04 13:09:47,292:INFO:Checking environment
2023-11-04 13:09:47,292:INFO:python_version: 3.9.13
2023-11-04 13:09:47,292:INFO:python_build: ('main', 'Aug 25 2022 18:29:29')
2023-11-04 13:09:47,292:INFO:machine: x86_64
2023-11-04 13:09:47,292:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-11-04 13:09:47,292:INFO:Memory: svmem(total=17179869184, available=1581998080, percent=90.8, used=1851469824, free=198430720, active=1384419328, inactive=1339461632, wired=467050496)
2023-11-04 13:09:47,292:INFO:Physical Core: 8
2023-11-04 13:09:47,292:INFO:Logical Core: 8
2023-11-04 13:09:47,292:INFO:Checking libraries
2023-11-04 13:09:47,292:INFO:System:
2023-11-04 13:09:47,292:INFO:    python: 3.9.13 (main, Aug 25 2022, 18:29:29)  [Clang 12.0.0 ]
2023-11-04 13:09:47,292:INFO:executable: /Users/michal/opt/anaconda3/bin/python
2023-11-04 13:09:47,292:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-11-04 13:09:47,292:INFO:PyCaret required dependencies:
2023-11-04 13:09:47,293:INFO:                 pip: 22.2.2
2023-11-04 13:09:47,293:INFO:          setuptools: 63.4.1
2023-11-04 13:09:47,293:INFO:             pycaret: 3.1.0
2023-11-04 13:09:47,293:INFO:             IPython: 7.31.1
2023-11-04 13:09:47,293:INFO:          ipywidgets: 7.6.5
2023-11-04 13:09:47,294:INFO:                tqdm: 4.64.1
2023-11-04 13:09:47,294:INFO:               numpy: 1.21.5
2023-11-04 13:09:47,294:INFO:              pandas: 1.4.4
2023-11-04 13:09:47,294:INFO:              jinja2: 2.11.3
2023-11-04 13:09:47,294:INFO:               scipy: 1.10.1
2023-11-04 13:09:47,294:INFO:              joblib: 1.2.0
2023-11-04 13:09:47,294:INFO:             sklearn: 1.0.2
2023-11-04 13:09:47,294:INFO:                pyod: 1.1.1
2023-11-04 13:09:47,294:INFO:            imblearn: 0.10.1
2023-11-04 13:09:47,294:INFO:   category_encoders: 2.6.3
2023-11-04 13:09:47,294:INFO:            lightgbm: 3.3.5
2023-11-04 13:09:47,294:INFO:               numba: 0.55.1
2023-11-04 13:09:47,294:INFO:            requests: 2.28.1
2023-11-04 13:09:47,294:INFO:          matplotlib: 3.5.2
2023-11-04 13:09:47,294:INFO:          scikitplot: 0.3.7
2023-11-04 13:09:47,294:INFO:         yellowbrick: 1.5
2023-11-04 13:09:47,294:INFO:              plotly: 5.9.0
2023-11-04 13:09:47,294:INFO:    plotly-resampler: Not installed
2023-11-04 13:09:47,294:INFO:             kaleido: 0.2.1
2023-11-04 13:09:47,294:INFO:           schemdraw: 0.15
2023-11-04 13:09:47,294:INFO:         statsmodels: 0.13.2
2023-11-04 13:09:47,294:INFO:              sktime: 0.21.1
2023-11-04 13:09:47,294:INFO:               tbats: 1.1.3
2023-11-04 13:09:47,294:INFO:            pmdarima: 2.0.4
2023-11-04 13:09:47,294:INFO:              psutil: 5.9.0
2023-11-04 13:09:47,294:INFO:          markupsafe: 2.0.1
2023-11-04 13:09:47,294:INFO:             pickle5: Not installed
2023-11-04 13:09:47,294:INFO:         cloudpickle: 2.0.0
2023-11-04 13:09:47,294:INFO:         deprecation: 2.1.0
2023-11-04 13:09:47,294:INFO:              xxhash: 3.4.1
2023-11-04 13:09:47,294:INFO:           wurlitzer: 3.0.2
2023-11-04 13:09:47,294:INFO:PyCaret optional dependencies:
2023-11-04 13:09:47,303:INFO:                shap: 0.41.0
2023-11-04 13:09:47,303:INFO:           interpret: Not installed
2023-11-04 13:09:47,303:INFO:                umap: 0.5.3
2023-11-04 13:09:47,303:INFO:     ydata_profiling: Not installed
2023-11-04 13:09:47,303:INFO:  explainerdashboard: Not installed
2023-11-04 13:09:47,303:INFO:             autoviz: Not installed
2023-11-04 13:09:47,303:INFO:           fairlearn: Not installed
2023-11-04 13:09:47,303:INFO:          deepchecks: Not installed
2023-11-04 13:09:47,303:INFO:             xgboost: 1.7.4
2023-11-04 13:09:47,303:INFO:            catboost: 1.2
2023-11-04 13:09:47,303:INFO:              kmodes: Not installed
2023-11-04 13:09:47,303:INFO:             mlxtend: 0.21.0
2023-11-04 13:09:47,303:INFO:       statsforecast: Not installed
2023-11-04 13:09:47,303:INFO:        tune_sklearn: Not installed
2023-11-04 13:09:47,303:INFO:                 ray: Not installed
2023-11-04 13:09:47,303:INFO:            hyperopt: Not installed
2023-11-04 13:09:47,303:INFO:              optuna: Not installed
2023-11-04 13:09:47,303:INFO:               skopt: Not installed
2023-11-04 13:09:47,303:INFO:              mlflow: Not installed
2023-11-04 13:09:47,303:INFO:              gradio: Not installed
2023-11-04 13:09:47,303:INFO:             fastapi: Not installed
2023-11-04 13:09:47,303:INFO:             uvicorn: Not installed
2023-11-04 13:09:47,303:INFO:              m2cgen: Not installed
2023-11-04 13:09:47,303:INFO:           evidently: Not installed
2023-11-04 13:09:47,303:INFO:               fugue: Not installed
2023-11-04 13:09:47,303:INFO:           streamlit: Not installed
2023-11-04 13:09:47,303:INFO:             prophet: Not installed
2023-11-04 13:09:47,303:INFO:None
2023-11-04 13:09:47,303:INFO:Set up data.
2023-11-04 13:09:47,305:INFO:Set up folding strategy.
2023-11-04 13:09:47,305:INFO:Set up train/test split.
2023-11-04 13:09:47,307:INFO:Set up index.
2023-11-04 13:09:47,307:INFO:Assigning column types.
2023-11-04 13:09:47,308:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-04 13:09:47,308:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-04 13:09:47,311:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 13:09:47,313:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 13:09:47,346:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 13:09:47,372:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 13:09:47,372:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 13:09:47,472:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 13:09:47,485:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-04 13:09:47,487:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 13:09:47,490:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 13:09:47,524:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 13:09:47,550:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 13:09:47,551:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 13:09:47,552:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 13:09:47,552:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-11-04 13:09:47,555:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 13:09:47,558:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 13:09:47,590:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 13:09:47,616:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 13:09:47,616:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 13:09:47,617:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 13:09:47,620:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 13:09:47,623:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 13:09:47,655:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 13:09:47,680:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 13:09:47,681:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 13:09:47,682:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 13:09:47,682:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-11-04 13:09:47,687:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 13:09:47,719:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 13:09:47,746:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 13:09:47,746:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 13:09:47,747:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 13:09:47,753:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 13:09:47,785:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 13:09:47,811:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 13:09:47,811:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 13:09:47,812:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 13:09:47,813:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-11-04 13:09:47,850:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 13:09:47,876:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 13:09:47,876:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 13:09:47,877:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 13:09:47,915:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 13:09:47,940:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 13:09:47,940:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 13:09:47,942:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 13:09:47,942:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-04 13:09:47,979:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 13:09:48,005:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 13:09:48,006:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 13:09:48,043:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 13:09:48,069:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 13:09:48,070:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 13:09:48,071:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-11-04 13:09:48,133:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 13:09:48,134:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 13:09:48,196:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 13:09:48,198:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 13:09:48,200:INFO:Preparing preprocessing pipeline...
2023-11-04 13:09:48,200:INFO:Set up simple imputation.
2023-11-04 13:09:48,200:INFO:Set up variance threshold.
2023-11-04 13:09:48,200:INFO:Set up removing multicollinearity.
2023-11-04 13:09:48,200:INFO:Set up column name cleaning.
2023-11-04 13:09:48,216:INFO:Finished creating preprocessing pipeline.
2023-11-04 13:09:48,220:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/h9/5_75v3qs13x63s15wwxdrd000000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['sepal length (cm)',
                                             'sepal width (cm)',
                                             'petal length (cm)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.1))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-11-04 13:09:48,220:INFO:Creating final display dataframe.
2023-11-04 13:09:48,262:INFO:Setup _display_container:                     Description             Value
0                    Session id              1767
1                        Target  petal width (cm)
2                   Target type        Regression
3           Original data shape          (150, 4)
4        Transformed data shape          (150, 4)
5   Transformed train set shape          (105, 4)
6    Transformed test set shape           (45, 4)
7              Numeric features                 3
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12       Low variance threshold               0.1
13     Remove multicollinearity              True
14  Multicollinearity threshold              0.95
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              886c
2023-11-04 13:09:48,334:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 13:09:48,336:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 13:09:48,403:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 13:09:48,405:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 13:09:48,405:INFO:setup() successfully completed in 1.11s...............
2023-11-04 13:09:48,405:INFO:Initializing compare_models()
2023-11-04 13:09:48,405:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4357a6730>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fb4357a6730>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-11-04 13:09:48,405:INFO:Checking exceptions
2023-11-04 13:09:48,406:INFO:Preparing display monitor
2023-11-04 13:09:48,424:INFO:Initializing Linear Regression
2023-11-04 13:09:48,425:INFO:Total runtime is 1.700719197591146e-06 minutes
2023-11-04 13:09:48,426:INFO:SubProcess create_model() called ==================================
2023-11-04 13:09:48,426:INFO:Initializing create_model()
2023-11-04 13:09:48,426:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4357a6730>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb440dd8c40>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 13:09:48,427:INFO:Checking exceptions
2023-11-04 13:09:48,427:INFO:Importing libraries
2023-11-04 13:09:48,427:INFO:Copying training dataset
2023-11-04 13:09:48,429:INFO:Defining folds
2023-11-04 13:09:48,429:INFO:Declaring metric variables
2023-11-04 13:09:48,430:INFO:Importing untrained model
2023-11-04 13:09:48,432:INFO:Linear Regression Imported successfully
2023-11-04 13:09:48,436:INFO:Starting cross validation
2023-11-04 13:09:48,441:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 13:09:51,038:INFO:Calculating mean and std
2023-11-04 13:09:51,040:INFO:Creating metrics dataframe
2023-11-04 13:09:51,044:INFO:Uploading results into container
2023-11-04 13:09:51,044:INFO:Uploading model into container now
2023-11-04 13:09:51,045:INFO:_master_model_container: 1
2023-11-04 13:09:51,045:INFO:_display_container: 2
2023-11-04 13:09:51,045:INFO:LinearRegression(n_jobs=-1)
2023-11-04 13:09:51,045:INFO:create_model() successfully completed......................................
2023-11-04 13:09:51,163:INFO:SubProcess create_model() end ==================================
2023-11-04 13:09:51,163:INFO:Creating metrics dataframe
2023-11-04 13:09:51,168:INFO:Initializing Lasso Regression
2023-11-04 13:09:51,168:INFO:Total runtime is 0.04573088486989339 minutes
2023-11-04 13:09:51,170:INFO:SubProcess create_model() called ==================================
2023-11-04 13:09:51,170:INFO:Initializing create_model()
2023-11-04 13:09:51,170:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4357a6730>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb440dd8c40>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 13:09:51,170:INFO:Checking exceptions
2023-11-04 13:09:51,170:INFO:Importing libraries
2023-11-04 13:09:51,170:INFO:Copying training dataset
2023-11-04 13:09:51,173:INFO:Defining folds
2023-11-04 13:09:51,173:INFO:Declaring metric variables
2023-11-04 13:09:51,175:INFO:Importing untrained model
2023-11-04 13:09:51,176:INFO:Lasso Regression Imported successfully
2023-11-04 13:09:51,179:INFO:Starting cross validation
2023-11-04 13:09:51,180:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 13:09:51,230:INFO:Calculating mean and std
2023-11-04 13:09:51,230:INFO:Creating metrics dataframe
2023-11-04 13:09:51,232:INFO:Uploading results into container
2023-11-04 13:09:51,232:INFO:Uploading model into container now
2023-11-04 13:09:51,232:INFO:_master_model_container: 2
2023-11-04 13:09:51,232:INFO:_display_container: 2
2023-11-04 13:09:51,233:INFO:Lasso(random_state=1767)
2023-11-04 13:09:51,233:INFO:create_model() successfully completed......................................
2023-11-04 13:09:51,304:INFO:SubProcess create_model() end ==================================
2023-11-04 13:09:51,304:INFO:Creating metrics dataframe
2023-11-04 13:09:51,310:INFO:Initializing Ridge Regression
2023-11-04 13:09:51,310:INFO:Total runtime is 0.04808666706085205 minutes
2023-11-04 13:09:51,311:INFO:SubProcess create_model() called ==================================
2023-11-04 13:09:51,312:INFO:Initializing create_model()
2023-11-04 13:09:51,312:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4357a6730>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb440dd8c40>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 13:09:51,312:INFO:Checking exceptions
2023-11-04 13:09:51,312:INFO:Importing libraries
2023-11-04 13:09:51,312:INFO:Copying training dataset
2023-11-04 13:09:51,314:INFO:Defining folds
2023-11-04 13:09:51,314:INFO:Declaring metric variables
2023-11-04 13:09:51,316:INFO:Importing untrained model
2023-11-04 13:09:51,318:INFO:Ridge Regression Imported successfully
2023-11-04 13:09:51,321:INFO:Starting cross validation
2023-11-04 13:09:51,321:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 13:09:51,369:INFO:Calculating mean and std
2023-11-04 13:09:51,370:INFO:Creating metrics dataframe
2023-11-04 13:09:51,371:INFO:Uploading results into container
2023-11-04 13:09:51,371:INFO:Uploading model into container now
2023-11-04 13:09:51,372:INFO:_master_model_container: 3
2023-11-04 13:09:51,372:INFO:_display_container: 2
2023-11-04 13:09:51,372:INFO:Ridge(random_state=1767)
2023-11-04 13:09:51,372:INFO:create_model() successfully completed......................................
2023-11-04 13:09:51,444:INFO:SubProcess create_model() end ==================================
2023-11-04 13:09:51,444:INFO:Creating metrics dataframe
2023-11-04 13:09:51,449:INFO:Initializing Elastic Net
2023-11-04 13:09:51,449:INFO:Total runtime is 0.05041520198186239 minutes
2023-11-04 13:09:51,451:INFO:SubProcess create_model() called ==================================
2023-11-04 13:09:51,451:INFO:Initializing create_model()
2023-11-04 13:09:51,451:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4357a6730>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb440dd8c40>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 13:09:51,451:INFO:Checking exceptions
2023-11-04 13:09:51,451:INFO:Importing libraries
2023-11-04 13:09:51,451:INFO:Copying training dataset
2023-11-04 13:09:51,453:INFO:Defining folds
2023-11-04 13:09:51,454:INFO:Declaring metric variables
2023-11-04 13:09:51,455:INFO:Importing untrained model
2023-11-04 13:09:51,457:INFO:Elastic Net Imported successfully
2023-11-04 13:09:51,460:INFO:Starting cross validation
2023-11-04 13:09:51,461:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 13:09:51,510:INFO:Calculating mean and std
2023-11-04 13:09:51,510:INFO:Creating metrics dataframe
2023-11-04 13:09:51,512:INFO:Uploading results into container
2023-11-04 13:09:51,512:INFO:Uploading model into container now
2023-11-04 13:09:51,512:INFO:_master_model_container: 4
2023-11-04 13:09:51,513:INFO:_display_container: 2
2023-11-04 13:09:51,513:INFO:ElasticNet(random_state=1767)
2023-11-04 13:09:51,513:INFO:create_model() successfully completed......................................
2023-11-04 13:09:51,584:INFO:SubProcess create_model() end ==================================
2023-11-04 13:09:51,585:INFO:Creating metrics dataframe
2023-11-04 13:09:51,590:INFO:Initializing Least Angle Regression
2023-11-04 13:09:51,590:INFO:Total runtime is 0.052755848566691084 minutes
2023-11-04 13:09:51,591:INFO:SubProcess create_model() called ==================================
2023-11-04 13:09:51,592:INFO:Initializing create_model()
2023-11-04 13:09:51,592:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4357a6730>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb440dd8c40>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 13:09:51,592:INFO:Checking exceptions
2023-11-04 13:09:51,592:INFO:Importing libraries
2023-11-04 13:09:51,592:INFO:Copying training dataset
2023-11-04 13:09:51,594:INFO:Defining folds
2023-11-04 13:09:51,594:INFO:Declaring metric variables
2023-11-04 13:09:51,597:INFO:Importing untrained model
2023-11-04 13:09:51,599:INFO:Least Angle Regression Imported successfully
2023-11-04 13:09:51,604:INFO:Starting cross validation
2023-11-04 13:09:51,605:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 13:09:51,624:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 13:09:51,626:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 13:09:51,629:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 13:09:51,631:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 13:09:51,637:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 13:09:51,643:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 13:09:51,643:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 13:09:51,646:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 13:09:51,647:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 13:09:51,649:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 13:09:51,655:INFO:Calculating mean and std
2023-11-04 13:09:51,655:INFO:Creating metrics dataframe
2023-11-04 13:09:51,657:INFO:Uploading results into container
2023-11-04 13:09:51,657:INFO:Uploading model into container now
2023-11-04 13:09:51,657:INFO:_master_model_container: 5
2023-11-04 13:09:51,657:INFO:_display_container: 2
2023-11-04 13:09:51,657:INFO:Lars(random_state=1767)
2023-11-04 13:09:51,657:INFO:create_model() successfully completed......................................
2023-11-04 13:09:51,729:INFO:SubProcess create_model() end ==================================
2023-11-04 13:09:51,729:INFO:Creating metrics dataframe
2023-11-04 13:09:51,735:INFO:Initializing Lasso Least Angle Regression
2023-11-04 13:09:51,735:INFO:Total runtime is 0.055175979932149254 minutes
2023-11-04 13:09:51,737:INFO:SubProcess create_model() called ==================================
2023-11-04 13:09:51,737:INFO:Initializing create_model()
2023-11-04 13:09:51,737:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4357a6730>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb440dd8c40>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 13:09:51,737:INFO:Checking exceptions
2023-11-04 13:09:51,737:INFO:Importing libraries
2023-11-04 13:09:51,737:INFO:Copying training dataset
2023-11-04 13:09:51,739:INFO:Defining folds
2023-11-04 13:09:51,739:INFO:Declaring metric variables
2023-11-04 13:09:51,741:INFO:Importing untrained model
2023-11-04 13:09:51,743:INFO:Lasso Least Angle Regression Imported successfully
2023-11-04 13:09:51,746:INFO:Starting cross validation
2023-11-04 13:09:51,747:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 13:09:51,763:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 13:09:51,765:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 13:09:51,769:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 13:09:51,777:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 13:09:51,779:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 13:09:51,779:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 13:09:51,780:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 13:09:51,782:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 13:09:51,785:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 13:09:51,789:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 13:09:51,793:INFO:Calculating mean and std
2023-11-04 13:09:51,794:INFO:Creating metrics dataframe
2023-11-04 13:09:51,795:INFO:Uploading results into container
2023-11-04 13:09:51,795:INFO:Uploading model into container now
2023-11-04 13:09:51,796:INFO:_master_model_container: 6
2023-11-04 13:09:51,796:INFO:_display_container: 2
2023-11-04 13:09:51,796:INFO:LassoLars(random_state=1767)
2023-11-04 13:09:51,796:INFO:create_model() successfully completed......................................
2023-11-04 13:09:51,868:INFO:SubProcess create_model() end ==================================
2023-11-04 13:09:51,868:INFO:Creating metrics dataframe
2023-11-04 13:09:51,873:INFO:Initializing Orthogonal Matching Pursuit
2023-11-04 13:09:51,874:INFO:Total runtime is 0.057485298315684004 minutes
2023-11-04 13:09:51,875:INFO:SubProcess create_model() called ==================================
2023-11-04 13:09:51,876:INFO:Initializing create_model()
2023-11-04 13:09:51,876:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4357a6730>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb440dd8c40>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 13:09:51,876:INFO:Checking exceptions
2023-11-04 13:09:51,876:INFO:Importing libraries
2023-11-04 13:09:51,876:INFO:Copying training dataset
2023-11-04 13:09:51,878:INFO:Defining folds
2023-11-04 13:09:51,878:INFO:Declaring metric variables
2023-11-04 13:09:51,879:INFO:Importing untrained model
2023-11-04 13:09:51,881:INFO:Orthogonal Matching Pursuit Imported successfully
2023-11-04 13:09:51,884:INFO:Starting cross validation
2023-11-04 13:09:51,885:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 13:09:51,901:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 13:09:51,903:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 13:09:51,904:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 13:09:51,914:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 13:09:51,916:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 13:09:51,916:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 13:09:51,921:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 13:09:51,923:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 13:09:51,925:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 13:09:51,927:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 13:09:51,932:INFO:Calculating mean and std
2023-11-04 13:09:51,932:INFO:Creating metrics dataframe
2023-11-04 13:09:51,934:INFO:Uploading results into container
2023-11-04 13:09:51,934:INFO:Uploading model into container now
2023-11-04 13:09:51,935:INFO:_master_model_container: 7
2023-11-04 13:09:51,935:INFO:_display_container: 2
2023-11-04 13:09:51,935:INFO:OrthogonalMatchingPursuit()
2023-11-04 13:09:51,935:INFO:create_model() successfully completed......................................
2023-11-04 13:09:52,007:INFO:SubProcess create_model() end ==================================
2023-11-04 13:09:52,007:INFO:Creating metrics dataframe
2023-11-04 13:09:52,012:INFO:Initializing Bayesian Ridge
2023-11-04 13:09:52,012:INFO:Total runtime is 0.05979819695154826 minutes
2023-11-04 13:09:52,014:INFO:SubProcess create_model() called ==================================
2023-11-04 13:09:52,014:INFO:Initializing create_model()
2023-11-04 13:09:52,014:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4357a6730>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb440dd8c40>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 13:09:52,015:INFO:Checking exceptions
2023-11-04 13:09:52,015:INFO:Importing libraries
2023-11-04 13:09:52,015:INFO:Copying training dataset
2023-11-04 13:09:52,017:INFO:Defining folds
2023-11-04 13:09:52,017:INFO:Declaring metric variables
2023-11-04 13:09:52,018:INFO:Importing untrained model
2023-11-04 13:09:52,020:INFO:Bayesian Ridge Imported successfully
2023-11-04 13:09:52,023:INFO:Starting cross validation
2023-11-04 13:09:52,024:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 13:09:52,071:INFO:Calculating mean and std
2023-11-04 13:09:52,071:INFO:Creating metrics dataframe
2023-11-04 13:09:52,072:INFO:Uploading results into container
2023-11-04 13:09:52,073:INFO:Uploading model into container now
2023-11-04 13:09:52,073:INFO:_master_model_container: 8
2023-11-04 13:09:52,073:INFO:_display_container: 2
2023-11-04 13:09:52,073:INFO:BayesianRidge()
2023-11-04 13:09:52,073:INFO:create_model() successfully completed......................................
2023-11-04 13:09:52,145:INFO:SubProcess create_model() end ==================================
2023-11-04 13:09:52,145:INFO:Creating metrics dataframe
2023-11-04 13:09:52,151:INFO:Initializing Passive Aggressive Regressor
2023-11-04 13:09:52,151:INFO:Total runtime is 0.062116118272145596 minutes
2023-11-04 13:09:52,153:INFO:SubProcess create_model() called ==================================
2023-11-04 13:09:52,153:INFO:Initializing create_model()
2023-11-04 13:09:52,153:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4357a6730>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb440dd8c40>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 13:09:52,153:INFO:Checking exceptions
2023-11-04 13:09:52,153:INFO:Importing libraries
2023-11-04 13:09:52,153:INFO:Copying training dataset
2023-11-04 13:09:52,156:INFO:Defining folds
2023-11-04 13:09:52,156:INFO:Declaring metric variables
2023-11-04 13:09:52,157:INFO:Importing untrained model
2023-11-04 13:09:52,159:INFO:Passive Aggressive Regressor Imported successfully
2023-11-04 13:09:52,162:INFO:Starting cross validation
2023-11-04 13:09:52,163:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 13:09:52,211:INFO:Calculating mean and std
2023-11-04 13:09:52,211:INFO:Creating metrics dataframe
2023-11-04 13:09:52,213:INFO:Uploading results into container
2023-11-04 13:09:52,213:INFO:Uploading model into container now
2023-11-04 13:09:52,213:INFO:_master_model_container: 9
2023-11-04 13:09:52,213:INFO:_display_container: 2
2023-11-04 13:09:52,213:INFO:PassiveAggressiveRegressor(random_state=1767)
2023-11-04 13:09:52,213:INFO:create_model() successfully completed......................................
2023-11-04 13:09:52,286:INFO:SubProcess create_model() end ==================================
2023-11-04 13:09:52,286:INFO:Creating metrics dataframe
2023-11-04 13:09:52,292:INFO:Initializing Huber Regressor
2023-11-04 13:09:52,292:INFO:Total runtime is 0.06446436643600464 minutes
2023-11-04 13:09:52,294:INFO:SubProcess create_model() called ==================================
2023-11-04 13:09:52,294:INFO:Initializing create_model()
2023-11-04 13:09:52,294:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4357a6730>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb440dd8c40>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 13:09:52,294:INFO:Checking exceptions
2023-11-04 13:09:52,295:INFO:Importing libraries
2023-11-04 13:09:52,295:INFO:Copying training dataset
2023-11-04 13:09:52,297:INFO:Defining folds
2023-11-04 13:09:52,297:INFO:Declaring metric variables
2023-11-04 13:09:52,298:INFO:Importing untrained model
2023-11-04 13:09:52,300:INFO:Huber Regressor Imported successfully
2023-11-04 13:09:52,303:INFO:Starting cross validation
2023-11-04 13:09:52,304:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 13:09:52,360:INFO:Calculating mean and std
2023-11-04 13:09:52,361:INFO:Creating metrics dataframe
2023-11-04 13:09:52,362:INFO:Uploading results into container
2023-11-04 13:09:52,363:INFO:Uploading model into container now
2023-11-04 13:09:52,363:INFO:_master_model_container: 10
2023-11-04 13:09:52,363:INFO:_display_container: 2
2023-11-04 13:09:52,363:INFO:HuberRegressor()
2023-11-04 13:09:52,363:INFO:create_model() successfully completed......................................
2023-11-04 13:09:52,435:INFO:SubProcess create_model() end ==================================
2023-11-04 13:09:52,435:INFO:Creating metrics dataframe
2023-11-04 13:09:52,441:INFO:Initializing K Neighbors Regressor
2023-11-04 13:09:52,441:INFO:Total runtime is 0.06694614887237549 minutes
2023-11-04 13:09:52,443:INFO:SubProcess create_model() called ==================================
2023-11-04 13:09:52,443:INFO:Initializing create_model()
2023-11-04 13:09:52,443:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4357a6730>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb440dd8c40>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 13:09:52,443:INFO:Checking exceptions
2023-11-04 13:09:52,443:INFO:Importing libraries
2023-11-04 13:09:52,443:INFO:Copying training dataset
2023-11-04 13:09:52,445:INFO:Defining folds
2023-11-04 13:09:52,445:INFO:Declaring metric variables
2023-11-04 13:09:52,447:INFO:Importing untrained model
2023-11-04 13:09:52,449:INFO:K Neighbors Regressor Imported successfully
2023-11-04 13:09:52,453:INFO:Starting cross validation
2023-11-04 13:09:52,453:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 13:09:52,506:INFO:Calculating mean and std
2023-11-04 13:09:52,506:INFO:Creating metrics dataframe
2023-11-04 13:09:52,508:INFO:Uploading results into container
2023-11-04 13:09:52,508:INFO:Uploading model into container now
2023-11-04 13:09:52,508:INFO:_master_model_container: 11
2023-11-04 13:09:52,508:INFO:_display_container: 2
2023-11-04 13:09:52,509:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-04 13:09:52,509:INFO:create_model() successfully completed......................................
2023-11-04 13:09:52,581:INFO:SubProcess create_model() end ==================================
2023-11-04 13:09:52,581:INFO:Creating metrics dataframe
2023-11-04 13:09:52,587:INFO:Initializing Decision Tree Regressor
2023-11-04 13:09:52,587:INFO:Total runtime is 0.06937501827875774 minutes
2023-11-04 13:09:52,589:INFO:SubProcess create_model() called ==================================
2023-11-04 13:09:52,589:INFO:Initializing create_model()
2023-11-04 13:09:52,589:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4357a6730>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb440dd8c40>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 13:09:52,589:INFO:Checking exceptions
2023-11-04 13:09:52,589:INFO:Importing libraries
2023-11-04 13:09:52,589:INFO:Copying training dataset
2023-11-04 13:09:52,591:INFO:Defining folds
2023-11-04 13:09:52,591:INFO:Declaring metric variables
2023-11-04 13:09:52,593:INFO:Importing untrained model
2023-11-04 13:09:52,595:INFO:Decision Tree Regressor Imported successfully
2023-11-04 13:09:52,598:INFO:Starting cross validation
2023-11-04 13:09:52,598:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 13:09:52,646:INFO:Calculating mean and std
2023-11-04 13:09:52,647:INFO:Creating metrics dataframe
2023-11-04 13:09:52,648:INFO:Uploading results into container
2023-11-04 13:09:52,649:INFO:Uploading model into container now
2023-11-04 13:09:52,649:INFO:_master_model_container: 12
2023-11-04 13:09:52,649:INFO:_display_container: 2
2023-11-04 13:09:52,649:INFO:DecisionTreeRegressor(random_state=1767)
2023-11-04 13:09:52,649:INFO:create_model() successfully completed......................................
2023-11-04 13:09:52,721:INFO:SubProcess create_model() end ==================================
2023-11-04 13:09:52,721:INFO:Creating metrics dataframe
2023-11-04 13:09:52,727:INFO:Initializing Random Forest Regressor
2023-11-04 13:09:52,727:INFO:Total runtime is 0.0717164675394694 minutes
2023-11-04 13:09:52,729:INFO:SubProcess create_model() called ==================================
2023-11-04 13:09:52,729:INFO:Initializing create_model()
2023-11-04 13:09:52,730:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4357a6730>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb440dd8c40>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 13:09:52,730:INFO:Checking exceptions
2023-11-04 13:09:52,730:INFO:Importing libraries
2023-11-04 13:09:52,730:INFO:Copying training dataset
2023-11-04 13:09:52,732:INFO:Defining folds
2023-11-04 13:09:52,732:INFO:Declaring metric variables
2023-11-04 13:09:52,733:INFO:Importing untrained model
2023-11-04 13:09:52,735:INFO:Random Forest Regressor Imported successfully
2023-11-04 13:09:52,738:INFO:Starting cross validation
2023-11-04 13:09:52,739:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 13:09:52,977:INFO:Calculating mean and std
2023-11-04 13:09:52,977:INFO:Creating metrics dataframe
2023-11-04 13:09:52,979:INFO:Uploading results into container
2023-11-04 13:09:52,980:INFO:Uploading model into container now
2023-11-04 13:09:52,980:INFO:_master_model_container: 13
2023-11-04 13:09:52,980:INFO:_display_container: 2
2023-11-04 13:09:52,980:INFO:RandomForestRegressor(n_jobs=-1, random_state=1767)
2023-11-04 13:09:52,980:INFO:create_model() successfully completed......................................
2023-11-04 13:09:53,054:INFO:SubProcess create_model() end ==================================
2023-11-04 13:09:53,054:INFO:Creating metrics dataframe
2023-11-04 13:09:53,061:INFO:Initializing Extra Trees Regressor
2023-11-04 13:09:53,061:INFO:Total runtime is 0.07727558215459188 minutes
2023-11-04 13:09:53,063:INFO:SubProcess create_model() called ==================================
2023-11-04 13:09:53,063:INFO:Initializing create_model()
2023-11-04 13:09:53,063:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4357a6730>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb440dd8c40>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 13:09:53,063:INFO:Checking exceptions
2023-11-04 13:09:53,063:INFO:Importing libraries
2023-11-04 13:09:53,063:INFO:Copying training dataset
2023-11-04 13:09:53,065:INFO:Defining folds
2023-11-04 13:09:53,065:INFO:Declaring metric variables
2023-11-04 13:09:53,066:INFO:Importing untrained model
2023-11-04 13:09:53,068:INFO:Extra Trees Regressor Imported successfully
2023-11-04 13:09:53,071:INFO:Starting cross validation
2023-11-04 13:09:53,071:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 13:09:53,267:INFO:Calculating mean and std
2023-11-04 13:09:53,268:INFO:Creating metrics dataframe
2023-11-04 13:09:53,270:INFO:Uploading results into container
2023-11-04 13:09:53,270:INFO:Uploading model into container now
2023-11-04 13:09:53,270:INFO:_master_model_container: 14
2023-11-04 13:09:53,270:INFO:_display_container: 2
2023-11-04 13:09:53,271:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1767)
2023-11-04 13:09:53,271:INFO:create_model() successfully completed......................................
2023-11-04 13:09:53,343:INFO:SubProcess create_model() end ==================================
2023-11-04 13:09:53,343:INFO:Creating metrics dataframe
2023-11-04 13:09:53,350:INFO:Initializing AdaBoost Regressor
2023-11-04 13:09:53,350:INFO:Total runtime is 0.08209856748580932 minutes
2023-11-04 13:09:53,352:INFO:SubProcess create_model() called ==================================
2023-11-04 13:09:53,352:INFO:Initializing create_model()
2023-11-04 13:09:53,352:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4357a6730>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb440dd8c40>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 13:09:53,352:INFO:Checking exceptions
2023-11-04 13:09:53,352:INFO:Importing libraries
2023-11-04 13:09:53,352:INFO:Copying training dataset
2023-11-04 13:09:53,354:INFO:Defining folds
2023-11-04 13:09:53,354:INFO:Declaring metric variables
2023-11-04 13:09:53,355:INFO:Importing untrained model
2023-11-04 13:09:53,357:INFO:AdaBoost Regressor Imported successfully
2023-11-04 13:09:53,360:INFO:Starting cross validation
2023-11-04 13:09:53,361:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 13:09:53,428:INFO:Calculating mean and std
2023-11-04 13:09:53,429:INFO:Creating metrics dataframe
2023-11-04 13:09:53,431:INFO:Uploading results into container
2023-11-04 13:09:53,432:INFO:Uploading model into container now
2023-11-04 13:09:53,432:INFO:_master_model_container: 15
2023-11-04 13:09:53,432:INFO:_display_container: 2
2023-11-04 13:09:53,432:INFO:AdaBoostRegressor(random_state=1767)
2023-11-04 13:09:53,432:INFO:create_model() successfully completed......................................
2023-11-04 13:09:53,505:INFO:SubProcess create_model() end ==================================
2023-11-04 13:09:53,506:INFO:Creating metrics dataframe
2023-11-04 13:09:53,512:INFO:Initializing Gradient Boosting Regressor
2023-11-04 13:09:53,512:INFO:Total runtime is 0.08479881683985392 minutes
2023-11-04 13:09:53,514:INFO:SubProcess create_model() called ==================================
2023-11-04 13:09:53,514:INFO:Initializing create_model()
2023-11-04 13:09:53,514:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4357a6730>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb440dd8c40>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 13:09:53,514:INFO:Checking exceptions
2023-11-04 13:09:53,514:INFO:Importing libraries
2023-11-04 13:09:53,514:INFO:Copying training dataset
2023-11-04 13:09:53,516:INFO:Defining folds
2023-11-04 13:09:53,516:INFO:Declaring metric variables
2023-11-04 13:09:53,517:INFO:Importing untrained model
2023-11-04 13:09:53,519:INFO:Gradient Boosting Regressor Imported successfully
2023-11-04 13:09:53,522:INFO:Starting cross validation
2023-11-04 13:09:53,523:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 13:09:53,595:INFO:Calculating mean and std
2023-11-04 13:09:53,596:INFO:Creating metrics dataframe
2023-11-04 13:09:53,598:INFO:Uploading results into container
2023-11-04 13:09:53,598:INFO:Uploading model into container now
2023-11-04 13:09:53,599:INFO:_master_model_container: 16
2023-11-04 13:09:53,599:INFO:_display_container: 2
2023-11-04 13:09:53,599:INFO:GradientBoostingRegressor(random_state=1767)
2023-11-04 13:09:53,599:INFO:create_model() successfully completed......................................
2023-11-04 13:09:53,672:INFO:SubProcess create_model() end ==================================
2023-11-04 13:09:53,672:INFO:Creating metrics dataframe
2023-11-04 13:09:53,679:INFO:Initializing Extreme Gradient Boosting
2023-11-04 13:09:53,679:INFO:Total runtime is 0.08758081595102946 minutes
2023-11-04 13:09:53,681:INFO:SubProcess create_model() called ==================================
2023-11-04 13:09:53,681:INFO:Initializing create_model()
2023-11-04 13:09:53,681:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4357a6730>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb440dd8c40>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 13:09:53,681:INFO:Checking exceptions
2023-11-04 13:09:53,681:INFO:Importing libraries
2023-11-04 13:09:53,681:INFO:Copying training dataset
2023-11-04 13:09:53,683:INFO:Defining folds
2023-11-04 13:09:53,683:INFO:Declaring metric variables
2023-11-04 13:09:53,684:INFO:Importing untrained model
2023-11-04 13:09:53,686:INFO:Extreme Gradient Boosting Imported successfully
2023-11-04 13:09:53,689:INFO:Starting cross validation
2023-11-04 13:09:53,690:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 13:09:53,779:INFO:Calculating mean and std
2023-11-04 13:09:53,780:INFO:Creating metrics dataframe
2023-11-04 13:09:53,782:INFO:Uploading results into container
2023-11-04 13:09:53,782:INFO:Uploading model into container now
2023-11-04 13:09:53,783:INFO:_master_model_container: 17
2023-11-04 13:09:53,783:INFO:_display_container: 2
2023-11-04 13:09:53,783:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=1767, ...)
2023-11-04 13:09:53,783:INFO:create_model() successfully completed......................................
2023-11-04 13:09:53,856:INFO:SubProcess create_model() end ==================================
2023-11-04 13:09:53,856:INFO:Creating metrics dataframe
2023-11-04 13:09:53,863:INFO:Initializing Light Gradient Boosting Machine
2023-11-04 13:09:53,863:INFO:Total runtime is 0.09064931869506836 minutes
2023-11-04 13:09:53,865:INFO:SubProcess create_model() called ==================================
2023-11-04 13:09:53,865:INFO:Initializing create_model()
2023-11-04 13:09:53,865:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4357a6730>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb440dd8c40>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 13:09:53,865:INFO:Checking exceptions
2023-11-04 13:09:53,866:INFO:Importing libraries
2023-11-04 13:09:53,866:INFO:Copying training dataset
2023-11-04 13:09:53,867:INFO:Defining folds
2023-11-04 13:09:53,867:INFO:Declaring metric variables
2023-11-04 13:09:53,868:INFO:Importing untrained model
2023-11-04 13:09:53,870:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-04 13:09:53,873:INFO:Starting cross validation
2023-11-04 13:09:53,874:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 13:09:54,419:INFO:Calculating mean and std
2023-11-04 13:09:54,420:INFO:Creating metrics dataframe
2023-11-04 13:09:54,422:INFO:Uploading results into container
2023-11-04 13:09:54,422:INFO:Uploading model into container now
2023-11-04 13:09:54,422:INFO:_master_model_container: 18
2023-11-04 13:09:54,423:INFO:_display_container: 2
2023-11-04 13:09:54,423:INFO:LGBMRegressor(random_state=1767)
2023-11-04 13:09:54,423:INFO:create_model() successfully completed......................................
2023-11-04 13:09:54,495:INFO:SubProcess create_model() end ==================================
2023-11-04 13:09:54,495:INFO:Creating metrics dataframe
2023-11-04 13:09:54,502:INFO:Initializing CatBoost Regressor
2023-11-04 13:09:54,502:INFO:Total runtime is 0.10129568179448445 minutes
2023-11-04 13:09:54,504:INFO:SubProcess create_model() called ==================================
2023-11-04 13:09:54,504:INFO:Initializing create_model()
2023-11-04 13:09:54,504:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4357a6730>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb440dd8c40>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 13:09:54,504:INFO:Checking exceptions
2023-11-04 13:09:54,504:INFO:Importing libraries
2023-11-04 13:09:54,504:INFO:Copying training dataset
2023-11-04 13:09:54,506:INFO:Defining folds
2023-11-04 13:09:54,506:INFO:Declaring metric variables
2023-11-04 13:09:54,507:INFO:Importing untrained model
2023-11-04 13:09:54,509:INFO:CatBoost Regressor Imported successfully
2023-11-04 13:09:54,512:INFO:Starting cross validation
2023-11-04 13:09:54,512:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 13:09:55,413:INFO:Calculating mean and std
2023-11-04 13:09:55,414:INFO:Creating metrics dataframe
2023-11-04 13:09:55,416:INFO:Uploading results into container
2023-11-04 13:09:55,416:INFO:Uploading model into container now
2023-11-04 13:09:55,417:INFO:_master_model_container: 19
2023-11-04 13:09:55,417:INFO:_display_container: 2
2023-11-04 13:09:55,417:INFO:<catboost.core.CatBoostRegressor object at 0x7fb4233934c0>
2023-11-04 13:09:55,417:INFO:create_model() successfully completed......................................
2023-11-04 13:09:55,498:INFO:SubProcess create_model() end ==================================
2023-11-04 13:09:55,498:INFO:Creating metrics dataframe
2023-11-04 13:09:55,506:INFO:Initializing Dummy Regressor
2023-11-04 13:09:55,506:INFO:Total runtime is 0.11802156766255696 minutes
2023-11-04 13:09:55,507:INFO:SubProcess create_model() called ==================================
2023-11-04 13:09:55,508:INFO:Initializing create_model()
2023-11-04 13:09:55,508:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4357a6730>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb440dd8c40>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 13:09:55,508:INFO:Checking exceptions
2023-11-04 13:09:55,508:INFO:Importing libraries
2023-11-04 13:09:55,508:INFO:Copying training dataset
2023-11-04 13:09:55,509:INFO:Defining folds
2023-11-04 13:09:55,509:INFO:Declaring metric variables
2023-11-04 13:09:55,511:INFO:Importing untrained model
2023-11-04 13:09:55,512:INFO:Dummy Regressor Imported successfully
2023-11-04 13:09:55,515:INFO:Starting cross validation
2023-11-04 13:09:55,516:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 13:09:55,565:INFO:Calculating mean and std
2023-11-04 13:09:55,566:INFO:Creating metrics dataframe
2023-11-04 13:09:55,568:INFO:Uploading results into container
2023-11-04 13:09:55,569:INFO:Uploading model into container now
2023-11-04 13:09:55,569:INFO:_master_model_container: 20
2023-11-04 13:09:55,569:INFO:_display_container: 2
2023-11-04 13:09:55,569:INFO:DummyRegressor()
2023-11-04 13:09:55,569:INFO:create_model() successfully completed......................................
2023-11-04 13:09:55,648:INFO:SubProcess create_model() end ==================================
2023-11-04 13:09:55,648:INFO:Creating metrics dataframe
2023-11-04 13:09:55,660:INFO:Initializing create_model()
2023-11-04 13:09:55,660:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4357a6730>, estimator=KNeighborsRegressor(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-04 13:09:55,660:INFO:Checking exceptions
2023-11-04 13:09:55,661:INFO:Importing libraries
2023-11-04 13:09:55,661:INFO:Copying training dataset
2023-11-04 13:09:55,663:INFO:Defining folds
2023-11-04 13:09:55,663:INFO:Declaring metric variables
2023-11-04 13:09:55,663:INFO:Importing untrained model
2023-11-04 13:09:55,663:INFO:Declaring custom model
2023-11-04 13:09:55,663:INFO:K Neighbors Regressor Imported successfully
2023-11-04 13:09:55,664:INFO:Cross validation set to False
2023-11-04 13:09:55,664:INFO:Fitting Model
2023-11-04 13:09:55,671:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-04 13:09:55,671:INFO:create_model() successfully completed......................................
2023-11-04 13:09:55,767:INFO:_master_model_container: 20
2023-11-04 13:09:55,767:INFO:_display_container: 2
2023-11-04 13:09:55,767:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-04 13:09:55,767:INFO:compare_models() successfully completed......................................
2023-11-04 13:10:06,828:INFO:PyCaret RegressionExperiment
2023-11-04 13:10:06,828:INFO:Logging name: reg-default-name
2023-11-04 13:10:06,828:INFO:ML Usecase: MLUsecase.REGRESSION
2023-11-04 13:10:06,829:INFO:version 3.1.0
2023-11-04 13:10:06,829:INFO:Initializing setup()
2023-11-04 13:10:06,829:INFO:self.USI: 0556
2023-11-04 13:10:06,829:INFO:self._variable_keys: {'USI', 'log_plots_param', 'gpu_param', 'fold_generator', 'X_test', 'html_param', '_ml_usecase', '_available_plots', 'exp_id', 'target_param', 'idx', 'fold_shuffle_param', 'n_jobs_param', 'seed', 'exp_name_log', 'X', 'y_train', 'transform_target_param', 'data', 'y_test', 'fold_groups_param', 'logging_param', 'gpu_n_jobs_param', 'y', 'X_train', 'memory', 'pipeline'}
2023-11-04 13:10:06,829:INFO:Checking environment
2023-11-04 13:10:06,829:INFO:python_version: 3.9.13
2023-11-04 13:10:06,829:INFO:python_build: ('main', 'Aug 25 2022 18:29:29')
2023-11-04 13:10:06,829:INFO:machine: x86_64
2023-11-04 13:10:06,829:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-11-04 13:10:06,829:INFO:Memory: svmem(total=17179869184, available=1481179136, percent=91.4, used=1935462400, free=14536704, active=1471492096, inactive=1463660544, wired=463970304)
2023-11-04 13:10:06,829:INFO:Physical Core: 8
2023-11-04 13:10:06,829:INFO:Logical Core: 8
2023-11-04 13:10:06,829:INFO:Checking libraries
2023-11-04 13:10:06,830:INFO:System:
2023-11-04 13:10:06,830:INFO:    python: 3.9.13 (main, Aug 25 2022, 18:29:29)  [Clang 12.0.0 ]
2023-11-04 13:10:06,830:INFO:executable: /Users/michal/opt/anaconda3/bin/python
2023-11-04 13:10:06,830:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-11-04 13:10:06,830:INFO:PyCaret required dependencies:
2023-11-04 13:10:06,830:INFO:                 pip: 22.2.2
2023-11-04 13:10:06,830:INFO:          setuptools: 63.4.1
2023-11-04 13:10:06,830:INFO:             pycaret: 3.1.0
2023-11-04 13:10:06,830:INFO:             IPython: 7.31.1
2023-11-04 13:10:06,830:INFO:          ipywidgets: 7.6.5
2023-11-04 13:10:06,830:INFO:                tqdm: 4.64.1
2023-11-04 13:10:06,830:INFO:               numpy: 1.21.5
2023-11-04 13:10:06,830:INFO:              pandas: 1.4.4
2023-11-04 13:10:06,830:INFO:              jinja2: 2.11.3
2023-11-04 13:10:06,830:INFO:               scipy: 1.10.1
2023-11-04 13:10:06,830:INFO:              joblib: 1.2.0
2023-11-04 13:10:06,830:INFO:             sklearn: 1.0.2
2023-11-04 13:10:06,830:INFO:                pyod: 1.1.1
2023-11-04 13:10:06,830:INFO:            imblearn: 0.10.1
2023-11-04 13:10:06,831:INFO:   category_encoders: 2.6.3
2023-11-04 13:10:06,831:INFO:            lightgbm: 3.3.5
2023-11-04 13:10:06,831:INFO:               numba: 0.55.1
2023-11-04 13:10:06,831:INFO:            requests: 2.28.1
2023-11-04 13:10:06,831:INFO:          matplotlib: 3.5.2
2023-11-04 13:10:06,831:INFO:          scikitplot: 0.3.7
2023-11-04 13:10:06,831:INFO:         yellowbrick: 1.5
2023-11-04 13:10:06,831:INFO:              plotly: 5.9.0
2023-11-04 13:10:06,831:INFO:    plotly-resampler: Not installed
2023-11-04 13:10:06,831:INFO:             kaleido: 0.2.1
2023-11-04 13:10:06,831:INFO:           schemdraw: 0.15
2023-11-04 13:10:06,831:INFO:         statsmodels: 0.13.2
2023-11-04 13:10:06,831:INFO:              sktime: 0.21.1
2023-11-04 13:10:06,831:INFO:               tbats: 1.1.3
2023-11-04 13:10:06,831:INFO:            pmdarima: 2.0.4
2023-11-04 13:10:06,831:INFO:              psutil: 5.9.0
2023-11-04 13:10:06,831:INFO:          markupsafe: 2.0.1
2023-11-04 13:10:06,831:INFO:             pickle5: Not installed
2023-11-04 13:10:06,831:INFO:         cloudpickle: 2.0.0
2023-11-04 13:10:06,831:INFO:         deprecation: 2.1.0
2023-11-04 13:10:06,832:INFO:              xxhash: 3.4.1
2023-11-04 13:10:06,832:INFO:           wurlitzer: 3.0.2
2023-11-04 13:10:06,832:INFO:PyCaret optional dependencies:
2023-11-04 13:10:06,832:INFO:                shap: 0.41.0
2023-11-04 13:10:06,832:INFO:           interpret: Not installed
2023-11-04 13:10:06,832:INFO:                umap: 0.5.3
2023-11-04 13:10:06,832:INFO:     ydata_profiling: Not installed
2023-11-04 13:10:06,832:INFO:  explainerdashboard: Not installed
2023-11-04 13:10:06,832:INFO:             autoviz: Not installed
2023-11-04 13:10:06,832:INFO:           fairlearn: Not installed
2023-11-04 13:10:06,832:INFO:          deepchecks: Not installed
2023-11-04 13:10:06,832:INFO:             xgboost: 1.7.4
2023-11-04 13:10:06,832:INFO:            catboost: 1.2
2023-11-04 13:10:06,832:INFO:              kmodes: Not installed
2023-11-04 13:10:06,832:INFO:             mlxtend: 0.21.0
2023-11-04 13:10:06,833:INFO:       statsforecast: Not installed
2023-11-04 13:10:06,833:INFO:        tune_sklearn: Not installed
2023-11-04 13:10:06,833:INFO:                 ray: Not installed
2023-11-04 13:10:06,833:INFO:            hyperopt: Not installed
2023-11-04 13:10:06,833:INFO:              optuna: Not installed
2023-11-04 13:10:06,833:INFO:               skopt: Not installed
2023-11-04 13:10:06,833:INFO:              mlflow: Not installed
2023-11-04 13:10:06,833:INFO:              gradio: Not installed
2023-11-04 13:10:06,833:INFO:             fastapi: Not installed
2023-11-04 13:10:06,833:INFO:             uvicorn: Not installed
2023-11-04 13:10:06,833:INFO:              m2cgen: Not installed
2023-11-04 13:10:06,833:INFO:           evidently: Not installed
2023-11-04 13:10:06,833:INFO:               fugue: Not installed
2023-11-04 13:10:06,833:INFO:           streamlit: Not installed
2023-11-04 13:10:06,833:INFO:             prophet: Not installed
2023-11-04 13:10:06,833:INFO:None
2023-11-04 13:10:06,833:INFO:Set up data.
2023-11-04 13:10:06,838:INFO:Set up folding strategy.
2023-11-04 13:10:06,839:INFO:Set up train/test split.
2023-11-04 13:10:06,842:INFO:Set up index.
2023-11-04 13:10:06,842:INFO:Assigning column types.
2023-11-04 13:10:06,847:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-04 13:10:06,847:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-04 13:10:06,854:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 13:10:06,860:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 13:10:06,910:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 13:10:06,936:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 13:10:06,936:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 13:10:06,938:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 13:10:06,938:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-04 13:10:06,941:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 13:10:06,944:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 13:10:06,977:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 13:10:07,003:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 13:10:07,004:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 13:10:07,005:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 13:10:07,005:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-11-04 13:10:07,008:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 13:10:07,011:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 13:10:07,044:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 13:10:07,070:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 13:10:07,071:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 13:10:07,072:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 13:10:07,075:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 13:10:07,078:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 13:10:07,111:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 13:10:07,137:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 13:10:07,137:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 13:10:07,139:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 13:10:07,139:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-11-04 13:10:07,144:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 13:10:07,178:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 13:10:07,205:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 13:10:07,205:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 13:10:07,206:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 13:10:07,212:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 13:10:07,245:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 13:10:07,272:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 13:10:07,272:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 13:10:07,274:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 13:10:07,274:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-11-04 13:10:07,312:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 13:10:07,339:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 13:10:07,339:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 13:10:07,340:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 13:10:07,379:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 13:10:07,405:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 13:10:07,405:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 13:10:07,407:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 13:10:07,407:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-04 13:10:07,445:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 13:10:07,472:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 13:10:07,473:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 13:10:07,511:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 13:10:07,538:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 13:10:07,539:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 13:10:07,539:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-11-04 13:10:07,604:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 13:10:07,606:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 13:10:07,674:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 13:10:07,676:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 13:10:07,677:INFO:Preparing preprocessing pipeline...
2023-11-04 13:10:07,677:INFO:Set up simple imputation.
2023-11-04 13:10:07,677:INFO:Set up variance threshold.
2023-11-04 13:10:07,677:INFO:Set up removing multicollinearity.
2023-11-04 13:10:07,677:INFO:Set up column name cleaning.
2023-11-04 13:10:07,692:INFO:Finished creating preprocessing pipeline.
2023-11-04 13:10:07,695:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/h9/5_75v3qs13x63s15wwxdrd000000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['sepal length (cm)',
                                             'sepal width (cm)',
                                             'petal length (cm)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.1))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-11-04 13:10:07,695:INFO:Creating final display dataframe.
2023-11-04 13:10:07,736:INFO:Setup _display_container:                     Description             Value
0                    Session id              3497
1                        Target  petal width (cm)
2                   Target type        Regression
3           Original data shape          (207, 4)
4        Transformed data shape          (207, 4)
5   Transformed train set shape          (144, 4)
6    Transformed test set shape           (63, 4)
7              Numeric features                 3
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12       Low variance threshold               0.1
13     Remove multicollinearity              True
14  Multicollinearity threshold              0.95
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              0556
2023-11-04 13:10:07,808:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 13:10:07,810:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 13:10:07,877:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 13:10:07,879:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 13:10:07,879:INFO:setup() successfully completed in 1.05s...............
2023-11-04 13:10:07,879:INFO:Initializing compare_models()
2023-11-04 13:10:07,879:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb435d042b0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fb435d042b0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-11-04 13:10:07,879:INFO:Checking exceptions
2023-11-04 13:10:07,880:INFO:Preparing display monitor
2023-11-04 13:10:07,897:INFO:Initializing Linear Regression
2023-11-04 13:10:07,897:INFO:Total runtime is 2.018610636393229e-06 minutes
2023-11-04 13:10:07,899:INFO:SubProcess create_model() called ==================================
2023-11-04 13:10:07,899:INFO:Initializing create_model()
2023-11-04 13:10:07,899:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb435d042b0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb42335d2b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 13:10:07,900:INFO:Checking exceptions
2023-11-04 13:10:07,900:INFO:Importing libraries
2023-11-04 13:10:07,900:INFO:Copying training dataset
2023-11-04 13:10:07,902:INFO:Defining folds
2023-11-04 13:10:07,902:INFO:Declaring metric variables
2023-11-04 13:10:07,904:INFO:Importing untrained model
2023-11-04 13:10:07,905:INFO:Linear Regression Imported successfully
2023-11-04 13:10:07,909:INFO:Starting cross validation
2023-11-04 13:10:07,909:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 13:10:07,960:INFO:Calculating mean and std
2023-11-04 13:10:07,960:INFO:Creating metrics dataframe
2023-11-04 13:10:07,962:INFO:Uploading results into container
2023-11-04 13:10:07,962:INFO:Uploading model into container now
2023-11-04 13:10:07,962:INFO:_master_model_container: 1
2023-11-04 13:10:07,962:INFO:_display_container: 2
2023-11-04 13:10:07,962:INFO:LinearRegression(n_jobs=-1)
2023-11-04 13:10:07,962:INFO:create_model() successfully completed......................................
2023-11-04 13:10:08,043:INFO:SubProcess create_model() end ==================================
2023-11-04 13:10:08,043:INFO:Creating metrics dataframe
2023-11-04 13:10:08,047:INFO:Initializing Lasso Regression
2023-11-04 13:10:08,047:INFO:Total runtime is 0.002510400613149007 minutes
2023-11-04 13:10:08,049:INFO:SubProcess create_model() called ==================================
2023-11-04 13:10:08,049:INFO:Initializing create_model()
2023-11-04 13:10:08,049:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb435d042b0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb42335d2b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 13:10:08,050:INFO:Checking exceptions
2023-11-04 13:10:08,050:INFO:Importing libraries
2023-11-04 13:10:08,050:INFO:Copying training dataset
2023-11-04 13:10:08,051:INFO:Defining folds
2023-11-04 13:10:08,051:INFO:Declaring metric variables
2023-11-04 13:10:08,053:INFO:Importing untrained model
2023-11-04 13:10:08,055:INFO:Lasso Regression Imported successfully
2023-11-04 13:10:08,058:INFO:Starting cross validation
2023-11-04 13:10:08,058:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 13:10:08,106:INFO:Calculating mean and std
2023-11-04 13:10:08,107:INFO:Creating metrics dataframe
2023-11-04 13:10:08,108:INFO:Uploading results into container
2023-11-04 13:10:08,109:INFO:Uploading model into container now
2023-11-04 13:10:08,109:INFO:_master_model_container: 2
2023-11-04 13:10:08,109:INFO:_display_container: 2
2023-11-04 13:10:08,109:INFO:Lasso(random_state=3497)
2023-11-04 13:10:08,109:INFO:create_model() successfully completed......................................
2023-11-04 13:10:08,185:INFO:SubProcess create_model() end ==================================
2023-11-04 13:10:08,185:INFO:Creating metrics dataframe
2023-11-04 13:10:08,190:INFO:Initializing Ridge Regression
2023-11-04 13:10:08,190:INFO:Total runtime is 0.004884966214497884 minutes
2023-11-04 13:10:08,192:INFO:SubProcess create_model() called ==================================
2023-11-04 13:10:08,192:INFO:Initializing create_model()
2023-11-04 13:10:08,192:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb435d042b0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb42335d2b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 13:10:08,192:INFO:Checking exceptions
2023-11-04 13:10:08,192:INFO:Importing libraries
2023-11-04 13:10:08,192:INFO:Copying training dataset
2023-11-04 13:10:08,194:INFO:Defining folds
2023-11-04 13:10:08,194:INFO:Declaring metric variables
2023-11-04 13:10:08,195:INFO:Importing untrained model
2023-11-04 13:10:08,197:INFO:Ridge Regression Imported successfully
2023-11-04 13:10:08,200:INFO:Starting cross validation
2023-11-04 13:10:08,201:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 13:10:08,249:INFO:Calculating mean and std
2023-11-04 13:10:08,250:INFO:Creating metrics dataframe
2023-11-04 13:10:08,251:INFO:Uploading results into container
2023-11-04 13:10:08,252:INFO:Uploading model into container now
2023-11-04 13:10:08,252:INFO:_master_model_container: 3
2023-11-04 13:10:08,252:INFO:_display_container: 2
2023-11-04 13:10:08,252:INFO:Ridge(random_state=3497)
2023-11-04 13:10:08,252:INFO:create_model() successfully completed......................................
2023-11-04 13:10:08,325:INFO:SubProcess create_model() end ==================================
2023-11-04 13:10:08,325:INFO:Creating metrics dataframe
2023-11-04 13:10:08,331:INFO:Initializing Elastic Net
2023-11-04 13:10:08,331:INFO:Total runtime is 0.007231016953786214 minutes
2023-11-04 13:10:08,332:INFO:SubProcess create_model() called ==================================
2023-11-04 13:10:08,333:INFO:Initializing create_model()
2023-11-04 13:10:08,333:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb435d042b0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb42335d2b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 13:10:08,333:INFO:Checking exceptions
2023-11-04 13:10:08,333:INFO:Importing libraries
2023-11-04 13:10:08,333:INFO:Copying training dataset
2023-11-04 13:10:08,334:INFO:Defining folds
2023-11-04 13:10:08,334:INFO:Declaring metric variables
2023-11-04 13:10:08,336:INFO:Importing untrained model
2023-11-04 13:10:08,338:INFO:Elastic Net Imported successfully
2023-11-04 13:10:08,341:INFO:Starting cross validation
2023-11-04 13:10:08,341:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 13:10:08,390:INFO:Calculating mean and std
2023-11-04 13:10:08,391:INFO:Creating metrics dataframe
2023-11-04 13:10:08,392:INFO:Uploading results into container
2023-11-04 13:10:08,393:INFO:Uploading model into container now
2023-11-04 13:10:08,393:INFO:_master_model_container: 4
2023-11-04 13:10:08,393:INFO:_display_container: 2
2023-11-04 13:10:08,393:INFO:ElasticNet(random_state=3497)
2023-11-04 13:10:08,393:INFO:create_model() successfully completed......................................
2023-11-04 13:10:08,466:INFO:SubProcess create_model() end ==================================
2023-11-04 13:10:08,466:INFO:Creating metrics dataframe
2023-11-04 13:10:08,471:INFO:Initializing Least Angle Regression
2023-11-04 13:10:08,471:INFO:Total runtime is 0.009571484724680583 minutes
2023-11-04 13:10:08,473:INFO:SubProcess create_model() called ==================================
2023-11-04 13:10:08,473:INFO:Initializing create_model()
2023-11-04 13:10:08,473:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb435d042b0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb42335d2b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 13:10:08,473:INFO:Checking exceptions
2023-11-04 13:10:08,473:INFO:Importing libraries
2023-11-04 13:10:08,473:INFO:Copying training dataset
2023-11-04 13:10:08,475:INFO:Defining folds
2023-11-04 13:10:08,475:INFO:Declaring metric variables
2023-11-04 13:10:08,477:INFO:Importing untrained model
2023-11-04 13:10:08,478:INFO:Least Angle Regression Imported successfully
2023-11-04 13:10:08,481:INFO:Starting cross validation
2023-11-04 13:10:08,482:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 13:10:08,498:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 13:10:08,502:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 13:10:08,505:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 13:10:08,510:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 13:10:08,514:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 13:10:08,514:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 13:10:08,517:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 13:10:08,519:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 13:10:08,521:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 13:10:08,525:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 13:10:08,530:INFO:Calculating mean and std
2023-11-04 13:10:08,531:INFO:Creating metrics dataframe
2023-11-04 13:10:08,532:INFO:Uploading results into container
2023-11-04 13:10:08,533:INFO:Uploading model into container now
2023-11-04 13:10:08,533:INFO:_master_model_container: 5
2023-11-04 13:10:08,533:INFO:_display_container: 2
2023-11-04 13:10:08,533:INFO:Lars(random_state=3497)
2023-11-04 13:10:08,533:INFO:create_model() successfully completed......................................
2023-11-04 13:10:08,607:INFO:SubProcess create_model() end ==================================
2023-11-04 13:10:08,607:INFO:Creating metrics dataframe
2023-11-04 13:10:08,612:INFO:Initializing Lasso Least Angle Regression
2023-11-04 13:10:08,612:INFO:Total runtime is 0.01192473570505778 minutes
2023-11-04 13:10:08,614:INFO:SubProcess create_model() called ==================================
2023-11-04 13:10:08,614:INFO:Initializing create_model()
2023-11-04 13:10:08,614:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb435d042b0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb42335d2b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 13:10:08,614:INFO:Checking exceptions
2023-11-04 13:10:08,615:INFO:Importing libraries
2023-11-04 13:10:08,615:INFO:Copying training dataset
2023-11-04 13:10:08,616:INFO:Defining folds
2023-11-04 13:10:08,616:INFO:Declaring metric variables
2023-11-04 13:10:08,618:INFO:Importing untrained model
2023-11-04 13:10:08,620:INFO:Lasso Least Angle Regression Imported successfully
2023-11-04 13:10:08,623:INFO:Starting cross validation
2023-11-04 13:10:08,623:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 13:10:08,640:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 13:10:08,642:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 13:10:08,644:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 13:10:08,653:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 13:10:08,656:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 13:10:08,656:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 13:10:08,657:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 13:10:08,660:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 13:10:08,668:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 13:10:08,669:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 13:10:08,674:INFO:Calculating mean and std
2023-11-04 13:10:08,674:INFO:Creating metrics dataframe
2023-11-04 13:10:08,676:INFO:Uploading results into container
2023-11-04 13:10:08,676:INFO:Uploading model into container now
2023-11-04 13:10:08,677:INFO:_master_model_container: 6
2023-11-04 13:10:08,677:INFO:_display_container: 2
2023-11-04 13:10:08,677:INFO:LassoLars(random_state=3497)
2023-11-04 13:10:08,677:INFO:create_model() successfully completed......................................
2023-11-04 13:10:08,751:INFO:SubProcess create_model() end ==================================
2023-11-04 13:10:08,751:INFO:Creating metrics dataframe
2023-11-04 13:10:08,757:INFO:Initializing Orthogonal Matching Pursuit
2023-11-04 13:10:08,757:INFO:Total runtime is 0.014332918326059978 minutes
2023-11-04 13:10:08,759:INFO:SubProcess create_model() called ==================================
2023-11-04 13:10:08,759:INFO:Initializing create_model()
2023-11-04 13:10:08,759:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb435d042b0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb42335d2b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 13:10:08,759:INFO:Checking exceptions
2023-11-04 13:10:08,759:INFO:Importing libraries
2023-11-04 13:10:08,759:INFO:Copying training dataset
2023-11-04 13:10:08,761:INFO:Defining folds
2023-11-04 13:10:08,761:INFO:Declaring metric variables
2023-11-04 13:10:08,762:INFO:Importing untrained model
2023-11-04 13:10:08,764:INFO:Orthogonal Matching Pursuit Imported successfully
2023-11-04 13:10:08,767:INFO:Starting cross validation
2023-11-04 13:10:08,768:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 13:10:08,784:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 13:10:08,790:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 13:10:08,791:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 13:10:08,795:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 13:10:08,802:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 13:10:08,803:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 13:10:08,804:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 13:10:08,807:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 13:10:08,807:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 13:10:08,812:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 13:10:08,817:INFO:Calculating mean and std
2023-11-04 13:10:08,818:INFO:Creating metrics dataframe
2023-11-04 13:10:08,819:INFO:Uploading results into container
2023-11-04 13:10:08,820:INFO:Uploading model into container now
2023-11-04 13:10:08,820:INFO:_master_model_container: 7
2023-11-04 13:10:08,820:INFO:_display_container: 2
2023-11-04 13:10:08,820:INFO:OrthogonalMatchingPursuit()
2023-11-04 13:10:08,820:INFO:create_model() successfully completed......................................
2023-11-04 13:10:08,893:INFO:SubProcess create_model() end ==================================
2023-11-04 13:10:08,893:INFO:Creating metrics dataframe
2023-11-04 13:10:08,899:INFO:Initializing Bayesian Ridge
2023-11-04 13:10:08,899:INFO:Total runtime is 0.01670173406600952 minutes
2023-11-04 13:10:08,901:INFO:SubProcess create_model() called ==================================
2023-11-04 13:10:08,901:INFO:Initializing create_model()
2023-11-04 13:10:08,901:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb435d042b0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb42335d2b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 13:10:08,901:INFO:Checking exceptions
2023-11-04 13:10:08,901:INFO:Importing libraries
2023-11-04 13:10:08,901:INFO:Copying training dataset
2023-11-04 13:10:08,903:INFO:Defining folds
2023-11-04 13:10:08,903:INFO:Declaring metric variables
2023-11-04 13:10:08,905:INFO:Importing untrained model
2023-11-04 13:10:08,907:INFO:Bayesian Ridge Imported successfully
2023-11-04 13:10:08,910:INFO:Starting cross validation
2023-11-04 13:10:08,910:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 13:10:08,959:INFO:Calculating mean and std
2023-11-04 13:10:08,960:INFO:Creating metrics dataframe
2023-11-04 13:10:08,961:INFO:Uploading results into container
2023-11-04 13:10:08,962:INFO:Uploading model into container now
2023-11-04 13:10:08,962:INFO:_master_model_container: 8
2023-11-04 13:10:08,962:INFO:_display_container: 2
2023-11-04 13:10:08,962:INFO:BayesianRidge()
2023-11-04 13:10:08,962:INFO:create_model() successfully completed......................................
2023-11-04 13:10:09,036:INFO:SubProcess create_model() end ==================================
2023-11-04 13:10:09,036:INFO:Creating metrics dataframe
2023-11-04 13:10:09,042:INFO:Initializing Passive Aggressive Regressor
2023-11-04 13:10:09,042:INFO:Total runtime is 0.019081381956736247 minutes
2023-11-04 13:10:09,044:INFO:SubProcess create_model() called ==================================
2023-11-04 13:10:09,044:INFO:Initializing create_model()
2023-11-04 13:10:09,044:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb435d042b0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb42335d2b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 13:10:09,044:INFO:Checking exceptions
2023-11-04 13:10:09,044:INFO:Importing libraries
2023-11-04 13:10:09,044:INFO:Copying training dataset
2023-11-04 13:10:09,046:INFO:Defining folds
2023-11-04 13:10:09,046:INFO:Declaring metric variables
2023-11-04 13:10:09,048:INFO:Importing untrained model
2023-11-04 13:10:09,049:INFO:Passive Aggressive Regressor Imported successfully
2023-11-04 13:10:09,052:INFO:Starting cross validation
2023-11-04 13:10:09,053:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 13:10:09,101:INFO:Calculating mean and std
2023-11-04 13:10:09,101:INFO:Creating metrics dataframe
2023-11-04 13:10:09,103:INFO:Uploading results into container
2023-11-04 13:10:09,103:INFO:Uploading model into container now
2023-11-04 13:10:09,104:INFO:_master_model_container: 9
2023-11-04 13:10:09,104:INFO:_display_container: 2
2023-11-04 13:10:09,104:INFO:PassiveAggressiveRegressor(random_state=3497)
2023-11-04 13:10:09,104:INFO:create_model() successfully completed......................................
2023-11-04 13:10:09,177:INFO:SubProcess create_model() end ==================================
2023-11-04 13:10:09,177:INFO:Creating metrics dataframe
2023-11-04 13:10:09,183:INFO:Initializing Huber Regressor
2023-11-04 13:10:09,183:INFO:Total runtime is 0.021434330940246583 minutes
2023-11-04 13:10:09,185:INFO:SubProcess create_model() called ==================================
2023-11-04 13:10:09,185:INFO:Initializing create_model()
2023-11-04 13:10:09,185:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb435d042b0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb42335d2b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 13:10:09,185:INFO:Checking exceptions
2023-11-04 13:10:09,185:INFO:Importing libraries
2023-11-04 13:10:09,185:INFO:Copying training dataset
2023-11-04 13:10:09,187:INFO:Defining folds
2023-11-04 13:10:09,187:INFO:Declaring metric variables
2023-11-04 13:10:09,189:INFO:Importing untrained model
2023-11-04 13:10:09,190:INFO:Huber Regressor Imported successfully
2023-11-04 13:10:09,193:INFO:Starting cross validation
2023-11-04 13:10:09,194:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 13:10:09,249:INFO:Calculating mean and std
2023-11-04 13:10:09,250:INFO:Creating metrics dataframe
2023-11-04 13:10:09,252:INFO:Uploading results into container
2023-11-04 13:10:09,252:INFO:Uploading model into container now
2023-11-04 13:10:09,252:INFO:_master_model_container: 10
2023-11-04 13:10:09,252:INFO:_display_container: 2
2023-11-04 13:10:09,252:INFO:HuberRegressor()
2023-11-04 13:10:09,252:INFO:create_model() successfully completed......................................
2023-11-04 13:10:09,325:INFO:SubProcess create_model() end ==================================
2023-11-04 13:10:09,325:INFO:Creating metrics dataframe
2023-11-04 13:10:09,331:INFO:Initializing K Neighbors Regressor
2023-11-04 13:10:09,332:INFO:Total runtime is 0.02391261657079061 minutes
2023-11-04 13:10:09,333:INFO:SubProcess create_model() called ==================================
2023-11-04 13:10:09,334:INFO:Initializing create_model()
2023-11-04 13:10:09,334:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb435d042b0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb42335d2b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 13:10:09,334:INFO:Checking exceptions
2023-11-04 13:10:09,334:INFO:Importing libraries
2023-11-04 13:10:09,334:INFO:Copying training dataset
2023-11-04 13:10:09,336:INFO:Defining folds
2023-11-04 13:10:09,336:INFO:Declaring metric variables
2023-11-04 13:10:09,337:INFO:Importing untrained model
2023-11-04 13:10:09,339:INFO:K Neighbors Regressor Imported successfully
2023-11-04 13:10:09,342:INFO:Starting cross validation
2023-11-04 13:10:09,343:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 13:10:09,397:INFO:Calculating mean and std
2023-11-04 13:10:09,398:INFO:Creating metrics dataframe
2023-11-04 13:10:09,399:INFO:Uploading results into container
2023-11-04 13:10:09,400:INFO:Uploading model into container now
2023-11-04 13:10:09,400:INFO:_master_model_container: 11
2023-11-04 13:10:09,400:INFO:_display_container: 2
2023-11-04 13:10:09,400:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-04 13:10:09,400:INFO:create_model() successfully completed......................................
2023-11-04 13:10:09,473:INFO:SubProcess create_model() end ==================================
2023-11-04 13:10:09,473:INFO:Creating metrics dataframe
2023-11-04 13:10:09,479:INFO:Initializing Decision Tree Regressor
2023-11-04 13:10:09,480:INFO:Total runtime is 0.026378631591796875 minutes
2023-11-04 13:10:09,481:INFO:SubProcess create_model() called ==================================
2023-11-04 13:10:09,482:INFO:Initializing create_model()
2023-11-04 13:10:09,482:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb435d042b0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb42335d2b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 13:10:09,482:INFO:Checking exceptions
2023-11-04 13:10:09,482:INFO:Importing libraries
2023-11-04 13:10:09,482:INFO:Copying training dataset
2023-11-04 13:10:09,484:INFO:Defining folds
2023-11-04 13:10:09,484:INFO:Declaring metric variables
2023-11-04 13:10:09,485:INFO:Importing untrained model
2023-11-04 13:10:09,487:INFO:Decision Tree Regressor Imported successfully
2023-11-04 13:10:09,490:INFO:Starting cross validation
2023-11-04 13:10:09,491:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 13:10:09,540:INFO:Calculating mean and std
2023-11-04 13:10:09,540:INFO:Creating metrics dataframe
2023-11-04 13:10:09,542:INFO:Uploading results into container
2023-11-04 13:10:09,542:INFO:Uploading model into container now
2023-11-04 13:10:09,542:INFO:_master_model_container: 12
2023-11-04 13:10:09,542:INFO:_display_container: 2
2023-11-04 13:10:09,542:INFO:DecisionTreeRegressor(random_state=3497)
2023-11-04 13:10:09,542:INFO:create_model() successfully completed......................................
2023-11-04 13:10:09,615:INFO:SubProcess create_model() end ==================================
2023-11-04 13:10:09,616:INFO:Creating metrics dataframe
2023-11-04 13:10:09,622:INFO:Initializing Random Forest Regressor
2023-11-04 13:10:09,622:INFO:Total runtime is 0.028757115205128986 minutes
2023-11-04 13:10:09,624:INFO:SubProcess create_model() called ==================================
2023-11-04 13:10:09,624:INFO:Initializing create_model()
2023-11-04 13:10:09,624:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb435d042b0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb42335d2b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 13:10:09,624:INFO:Checking exceptions
2023-11-04 13:10:09,624:INFO:Importing libraries
2023-11-04 13:10:09,624:INFO:Copying training dataset
2023-11-04 13:10:09,627:INFO:Defining folds
2023-11-04 13:10:09,627:INFO:Declaring metric variables
2023-11-04 13:10:09,628:INFO:Importing untrained model
2023-11-04 13:10:09,630:INFO:Random Forest Regressor Imported successfully
2023-11-04 13:10:09,633:INFO:Starting cross validation
2023-11-04 13:10:09,633:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 13:10:09,884:INFO:Calculating mean and std
2023-11-04 13:10:09,885:INFO:Creating metrics dataframe
2023-11-04 13:10:09,887:INFO:Uploading results into container
2023-11-04 13:10:09,888:INFO:Uploading model into container now
2023-11-04 13:10:09,888:INFO:_master_model_container: 13
2023-11-04 13:10:09,888:INFO:_display_container: 2
2023-11-04 13:10:09,888:INFO:RandomForestRegressor(n_jobs=-1, random_state=3497)
2023-11-04 13:10:09,888:INFO:create_model() successfully completed......................................
2023-11-04 13:10:09,963:INFO:SubProcess create_model() end ==================================
2023-11-04 13:10:09,963:INFO:Creating metrics dataframe
2023-11-04 13:10:09,970:INFO:Initializing Extra Trees Regressor
2023-11-04 13:10:09,970:INFO:Total runtime is 0.034552347660064694 minutes
2023-11-04 13:10:09,972:INFO:SubProcess create_model() called ==================================
2023-11-04 13:10:09,972:INFO:Initializing create_model()
2023-11-04 13:10:09,972:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb435d042b0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb42335d2b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 13:10:09,972:INFO:Checking exceptions
2023-11-04 13:10:09,972:INFO:Importing libraries
2023-11-04 13:10:09,972:INFO:Copying training dataset
2023-11-04 13:10:09,973:INFO:Defining folds
2023-11-04 13:10:09,973:INFO:Declaring metric variables
2023-11-04 13:10:09,975:INFO:Importing untrained model
2023-11-04 13:10:09,976:INFO:Extra Trees Regressor Imported successfully
2023-11-04 13:10:09,979:INFO:Starting cross validation
2023-11-04 13:10:09,980:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 13:10:10,181:INFO:Calculating mean and std
2023-11-04 13:10:10,182:INFO:Creating metrics dataframe
2023-11-04 13:10:10,184:INFO:Uploading results into container
2023-11-04 13:10:10,184:INFO:Uploading model into container now
2023-11-04 13:10:10,184:INFO:_master_model_container: 14
2023-11-04 13:10:10,184:INFO:_display_container: 2
2023-11-04 13:10:10,185:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=3497)
2023-11-04 13:10:10,185:INFO:create_model() successfully completed......................................
2023-11-04 13:10:10,255:INFO:SubProcess create_model() end ==================================
2023-11-04 13:10:10,255:INFO:Creating metrics dataframe
2023-11-04 13:10:10,262:INFO:Initializing AdaBoost Regressor
2023-11-04 13:10:10,262:INFO:Total runtime is 0.039415597915649414 minutes
2023-11-04 13:10:10,263:INFO:SubProcess create_model() called ==================================
2023-11-04 13:10:10,264:INFO:Initializing create_model()
2023-11-04 13:10:10,264:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb435d042b0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb42335d2b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 13:10:10,264:INFO:Checking exceptions
2023-11-04 13:10:10,264:INFO:Importing libraries
2023-11-04 13:10:10,264:INFO:Copying training dataset
2023-11-04 13:10:10,265:INFO:Defining folds
2023-11-04 13:10:10,265:INFO:Declaring metric variables
2023-11-04 13:10:10,267:INFO:Importing untrained model
2023-11-04 13:10:10,268:INFO:AdaBoost Regressor Imported successfully
2023-11-04 13:10:10,271:INFO:Starting cross validation
2023-11-04 13:10:10,272:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 13:10:10,363:INFO:Calculating mean and std
2023-11-04 13:10:10,364:INFO:Creating metrics dataframe
2023-11-04 13:10:10,366:INFO:Uploading results into container
2023-11-04 13:10:10,366:INFO:Uploading model into container now
2023-11-04 13:10:10,366:INFO:_master_model_container: 15
2023-11-04 13:10:10,366:INFO:_display_container: 2
2023-11-04 13:10:10,366:INFO:AdaBoostRegressor(random_state=3497)
2023-11-04 13:10:10,366:INFO:create_model() successfully completed......................................
2023-11-04 13:10:10,436:INFO:SubProcess create_model() end ==================================
2023-11-04 13:10:10,436:INFO:Creating metrics dataframe
2023-11-04 13:10:10,443:INFO:Initializing Gradient Boosting Regressor
2023-11-04 13:10:10,443:INFO:Total runtime is 0.04244241714477539 minutes
2023-11-04 13:10:10,445:INFO:SubProcess create_model() called ==================================
2023-11-04 13:10:10,445:INFO:Initializing create_model()
2023-11-04 13:10:10,445:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb435d042b0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb42335d2b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 13:10:10,445:INFO:Checking exceptions
2023-11-04 13:10:10,445:INFO:Importing libraries
2023-11-04 13:10:10,446:INFO:Copying training dataset
2023-11-04 13:10:10,447:INFO:Defining folds
2023-11-04 13:10:10,447:INFO:Declaring metric variables
2023-11-04 13:10:10,449:INFO:Importing untrained model
2023-11-04 13:10:10,451:INFO:Gradient Boosting Regressor Imported successfully
2023-11-04 13:10:10,454:INFO:Starting cross validation
2023-11-04 13:10:10,454:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 13:10:10,523:INFO:Calculating mean and std
2023-11-04 13:10:10,524:INFO:Creating metrics dataframe
2023-11-04 13:10:10,526:INFO:Uploading results into container
2023-11-04 13:10:10,527:INFO:Uploading model into container now
2023-11-04 13:10:10,527:INFO:_master_model_container: 16
2023-11-04 13:10:10,527:INFO:_display_container: 2
2023-11-04 13:10:10,527:INFO:GradientBoostingRegressor(random_state=3497)
2023-11-04 13:10:10,527:INFO:create_model() successfully completed......................................
2023-11-04 13:10:10,599:INFO:SubProcess create_model() end ==================================
2023-11-04 13:10:10,599:INFO:Creating metrics dataframe
2023-11-04 13:10:10,606:INFO:Initializing Extreme Gradient Boosting
2023-11-04 13:10:10,606:INFO:Total runtime is 0.04515261650085449 minutes
2023-11-04 13:10:10,608:INFO:SubProcess create_model() called ==================================
2023-11-04 13:10:10,608:INFO:Initializing create_model()
2023-11-04 13:10:10,608:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb435d042b0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb42335d2b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 13:10:10,608:INFO:Checking exceptions
2023-11-04 13:10:10,608:INFO:Importing libraries
2023-11-04 13:10:10,608:INFO:Copying training dataset
2023-11-04 13:10:10,609:INFO:Defining folds
2023-11-04 13:10:10,610:INFO:Declaring metric variables
2023-11-04 13:10:10,611:INFO:Importing untrained model
2023-11-04 13:10:10,613:INFO:Extreme Gradient Boosting Imported successfully
2023-11-04 13:10:10,616:INFO:Starting cross validation
2023-11-04 13:10:10,616:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 13:10:10,695:INFO:Calculating mean and std
2023-11-04 13:10:10,696:INFO:Creating metrics dataframe
2023-11-04 13:10:10,698:INFO:Uploading results into container
2023-11-04 13:10:10,698:INFO:Uploading model into container now
2023-11-04 13:10:10,698:INFO:_master_model_container: 17
2023-11-04 13:10:10,698:INFO:_display_container: 2
2023-11-04 13:10:10,699:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=3497, ...)
2023-11-04 13:10:10,699:INFO:create_model() successfully completed......................................
2023-11-04 13:10:10,769:INFO:SubProcess create_model() end ==================================
2023-11-04 13:10:10,769:INFO:Creating metrics dataframe
2023-11-04 13:10:10,776:INFO:Initializing Light Gradient Boosting Machine
2023-11-04 13:10:10,776:INFO:Total runtime is 0.04799251556396484 minutes
2023-11-04 13:10:10,778:INFO:SubProcess create_model() called ==================================
2023-11-04 13:10:10,778:INFO:Initializing create_model()
2023-11-04 13:10:10,778:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb435d042b0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb42335d2b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 13:10:10,778:INFO:Checking exceptions
2023-11-04 13:10:10,779:INFO:Importing libraries
2023-11-04 13:10:10,779:INFO:Copying training dataset
2023-11-04 13:10:10,780:INFO:Defining folds
2023-11-04 13:10:10,780:INFO:Declaring metric variables
2023-11-04 13:10:10,782:INFO:Importing untrained model
2023-11-04 13:10:10,783:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-04 13:10:10,786:INFO:Starting cross validation
2023-11-04 13:10:10,787:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 13:10:10,843:INFO:Calculating mean and std
2023-11-04 13:10:10,843:INFO:Creating metrics dataframe
2023-11-04 13:10:10,845:INFO:Uploading results into container
2023-11-04 13:10:10,846:INFO:Uploading model into container now
2023-11-04 13:10:10,846:INFO:_master_model_container: 18
2023-11-04 13:10:10,846:INFO:_display_container: 2
2023-11-04 13:10:10,847:INFO:LGBMRegressor(random_state=3497)
2023-11-04 13:10:10,847:INFO:create_model() successfully completed......................................
2023-11-04 13:10:10,919:INFO:SubProcess create_model() end ==================================
2023-11-04 13:10:10,919:INFO:Creating metrics dataframe
2023-11-04 13:10:10,926:INFO:Initializing CatBoost Regressor
2023-11-04 13:10:10,926:INFO:Total runtime is 0.050490367412567135 minutes
2023-11-04 13:10:10,928:INFO:SubProcess create_model() called ==================================
2023-11-04 13:10:10,928:INFO:Initializing create_model()
2023-11-04 13:10:10,928:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb435d042b0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb42335d2b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 13:10:10,928:INFO:Checking exceptions
2023-11-04 13:10:10,928:INFO:Importing libraries
2023-11-04 13:10:10,928:INFO:Copying training dataset
2023-11-04 13:10:10,930:INFO:Defining folds
2023-11-04 13:10:10,930:INFO:Declaring metric variables
2023-11-04 13:10:10,931:INFO:Importing untrained model
2023-11-04 13:10:10,933:INFO:CatBoost Regressor Imported successfully
2023-11-04 13:10:10,936:INFO:Starting cross validation
2023-11-04 13:10:10,937:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 13:10:11,578:INFO:Calculating mean and std
2023-11-04 13:10:11,579:INFO:Creating metrics dataframe
2023-11-04 13:10:11,581:INFO:Uploading results into container
2023-11-04 13:10:11,581:INFO:Uploading model into container now
2023-11-04 13:10:11,581:INFO:_master_model_container: 19
2023-11-04 13:10:11,582:INFO:_display_container: 2
2023-11-04 13:10:11,582:INFO:<catboost.core.CatBoostRegressor object at 0x7fb42335d940>
2023-11-04 13:10:11,582:INFO:create_model() successfully completed......................................
2023-11-04 13:10:11,653:INFO:SubProcess create_model() end ==================================
2023-11-04 13:10:11,653:INFO:Creating metrics dataframe
2023-11-04 13:10:11,661:INFO:Initializing Dummy Regressor
2023-11-04 13:10:11,661:INFO:Total runtime is 0.06274205048878988 minutes
2023-11-04 13:10:11,663:INFO:SubProcess create_model() called ==================================
2023-11-04 13:10:11,663:INFO:Initializing create_model()
2023-11-04 13:10:11,663:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb435d042b0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb42335d2b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 13:10:11,663:INFO:Checking exceptions
2023-11-04 13:10:11,663:INFO:Importing libraries
2023-11-04 13:10:11,664:INFO:Copying training dataset
2023-11-04 13:10:11,665:INFO:Defining folds
2023-11-04 13:10:11,665:INFO:Declaring metric variables
2023-11-04 13:10:11,667:INFO:Importing untrained model
2023-11-04 13:10:11,668:INFO:Dummy Regressor Imported successfully
2023-11-04 13:10:11,671:INFO:Starting cross validation
2023-11-04 13:10:11,672:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 13:10:11,718:INFO:Calculating mean and std
2023-11-04 13:10:11,719:INFO:Creating metrics dataframe
2023-11-04 13:10:11,721:INFO:Uploading results into container
2023-11-04 13:10:11,721:INFO:Uploading model into container now
2023-11-04 13:10:11,722:INFO:_master_model_container: 20
2023-11-04 13:10:11,722:INFO:_display_container: 2
2023-11-04 13:10:11,722:INFO:DummyRegressor()
2023-11-04 13:10:11,722:INFO:create_model() successfully completed......................................
2023-11-04 13:10:11,795:INFO:SubProcess create_model() end ==================================
2023-11-04 13:10:11,795:INFO:Creating metrics dataframe
2023-11-04 13:10:11,806:INFO:Initializing create_model()
2023-11-04 13:10:11,806:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb435d042b0>, estimator=AdaBoostRegressor(random_state=3497), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-04 13:10:11,806:INFO:Checking exceptions
2023-11-04 13:10:11,807:INFO:Importing libraries
2023-11-04 13:10:11,807:INFO:Copying training dataset
2023-11-04 13:10:11,809:INFO:Defining folds
2023-11-04 13:10:11,809:INFO:Declaring metric variables
2023-11-04 13:10:11,809:INFO:Importing untrained model
2023-11-04 13:10:11,809:INFO:Declaring custom model
2023-11-04 13:10:11,809:INFO:AdaBoost Regressor Imported successfully
2023-11-04 13:10:11,810:INFO:Cross validation set to False
2023-11-04 13:10:11,810:INFO:Fitting Model
2023-11-04 13:10:11,842:INFO:AdaBoostRegressor(random_state=3497)
2023-11-04 13:10:11,842:INFO:create_model() successfully completed......................................
2023-11-04 13:10:11,930:INFO:_master_model_container: 20
2023-11-04 13:10:11,930:INFO:_display_container: 2
2023-11-04 13:10:11,930:INFO:AdaBoostRegressor(random_state=3497)
2023-11-04 13:10:11,930:INFO:compare_models() successfully completed......................................
2023-11-04 19:28:40,019:INFO:PyCaret RegressionExperiment
2023-11-04 19:28:40,019:INFO:Logging name: reg-default-name
2023-11-04 19:28:40,019:INFO:ML Usecase: MLUsecase.REGRESSION
2023-11-04 19:28:40,019:INFO:version 3.1.0
2023-11-04 19:28:40,019:INFO:Initializing setup()
2023-11-04 19:28:40,019:INFO:self.USI: bf91
2023-11-04 19:28:40,019:INFO:self._variable_keys: {'USI', 'log_plots_param', 'gpu_param', 'fold_generator', 'X_test', 'html_param', '_ml_usecase', '_available_plots', 'exp_id', 'target_param', 'idx', 'fold_shuffle_param', 'n_jobs_param', 'seed', 'exp_name_log', 'X', 'y_train', 'transform_target_param', 'data', 'y_test', 'fold_groups_param', 'logging_param', 'gpu_n_jobs_param', 'y', 'X_train', 'memory', 'pipeline'}
2023-11-04 19:28:40,019:INFO:Checking environment
2023-11-04 19:28:40,019:INFO:python_version: 3.9.13
2023-11-04 19:28:40,019:INFO:python_build: ('main', 'Aug 25 2022 18:29:29')
2023-11-04 19:28:40,019:INFO:machine: x86_64
2023-11-04 19:28:40,019:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-11-04 19:28:40,019:INFO:Memory: svmem(total=17179869184, available=1441005568, percent=91.6, used=1905586176, free=48566272, active=1395683328, inactive=1368813568, wired=509902848)
2023-11-04 19:28:40,019:INFO:Physical Core: 8
2023-11-04 19:28:40,019:INFO:Logical Core: 8
2023-11-04 19:28:40,019:INFO:Checking libraries
2023-11-04 19:28:40,019:INFO:System:
2023-11-04 19:28:40,019:INFO:    python: 3.9.13 (main, Aug 25 2022, 18:29:29)  [Clang 12.0.0 ]
2023-11-04 19:28:40,019:INFO:executable: /Users/michal/opt/anaconda3/bin/python
2023-11-04 19:28:40,019:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-11-04 19:28:40,019:INFO:PyCaret required dependencies:
2023-11-04 19:28:40,019:INFO:                 pip: 22.2.2
2023-11-04 19:28:40,019:INFO:          setuptools: 63.4.1
2023-11-04 19:28:40,019:INFO:             pycaret: 3.1.0
2023-11-04 19:28:40,019:INFO:             IPython: 7.31.1
2023-11-04 19:28:40,019:INFO:          ipywidgets: 7.6.5
2023-11-04 19:28:40,019:INFO:                tqdm: 4.64.1
2023-11-04 19:28:40,019:INFO:               numpy: 1.21.5
2023-11-04 19:28:40,019:INFO:              pandas: 1.4.4
2023-11-04 19:28:40,019:INFO:              jinja2: 2.11.3
2023-11-04 19:28:40,019:INFO:               scipy: 1.10.1
2023-11-04 19:28:40,019:INFO:              joblib: 1.2.0
2023-11-04 19:28:40,019:INFO:             sklearn: 1.0.2
2023-11-04 19:28:40,019:INFO:                pyod: 1.1.1
2023-11-04 19:28:40,019:INFO:            imblearn: 0.10.1
2023-11-04 19:28:40,019:INFO:   category_encoders: 2.6.3
2023-11-04 19:28:40,019:INFO:            lightgbm: 3.3.5
2023-11-04 19:28:40,019:INFO:               numba: 0.55.1
2023-11-04 19:28:40,019:INFO:            requests: 2.28.1
2023-11-04 19:28:40,019:INFO:          matplotlib: 3.5.2
2023-11-04 19:28:40,019:INFO:          scikitplot: 0.3.7
2023-11-04 19:28:40,020:INFO:         yellowbrick: 1.5
2023-11-04 19:28:40,020:INFO:              plotly: 5.9.0
2023-11-04 19:28:40,020:INFO:    plotly-resampler: Not installed
2023-11-04 19:28:40,020:INFO:             kaleido: 0.2.1
2023-11-04 19:28:40,020:INFO:           schemdraw: 0.15
2023-11-04 19:28:40,020:INFO:         statsmodels: 0.13.2
2023-11-04 19:28:40,020:INFO:              sktime: 0.21.1
2023-11-04 19:28:40,020:INFO:               tbats: 1.1.3
2023-11-04 19:28:40,020:INFO:            pmdarima: 2.0.4
2023-11-04 19:28:40,020:INFO:              psutil: 5.9.0
2023-11-04 19:28:40,020:INFO:          markupsafe: 2.0.1
2023-11-04 19:28:40,020:INFO:             pickle5: Not installed
2023-11-04 19:28:40,020:INFO:         cloudpickle: 2.0.0
2023-11-04 19:28:40,020:INFO:         deprecation: 2.1.0
2023-11-04 19:28:40,020:INFO:              xxhash: 3.4.1
2023-11-04 19:28:40,020:INFO:           wurlitzer: 3.0.2
2023-11-04 19:28:40,020:INFO:PyCaret optional dependencies:
2023-11-04 19:28:40,020:INFO:                shap: 0.41.0
2023-11-04 19:28:40,020:INFO:           interpret: Not installed
2023-11-04 19:28:40,020:INFO:                umap: 0.5.3
2023-11-04 19:28:40,020:INFO:     ydata_profiling: Not installed
2023-11-04 19:28:40,020:INFO:  explainerdashboard: Not installed
2023-11-04 19:28:40,020:INFO:             autoviz: Not installed
2023-11-04 19:28:40,020:INFO:           fairlearn: Not installed
2023-11-04 19:28:40,020:INFO:          deepchecks: Not installed
2023-11-04 19:28:40,020:INFO:             xgboost: 1.7.4
2023-11-04 19:28:40,020:INFO:            catboost: 1.2
2023-11-04 19:28:40,020:INFO:              kmodes: Not installed
2023-11-04 19:28:40,020:INFO:             mlxtend: 0.21.0
2023-11-04 19:28:40,020:INFO:       statsforecast: Not installed
2023-11-04 19:28:40,020:INFO:        tune_sklearn: Not installed
2023-11-04 19:28:40,020:INFO:                 ray: Not installed
2023-11-04 19:28:40,020:INFO:            hyperopt: Not installed
2023-11-04 19:28:40,020:INFO:              optuna: Not installed
2023-11-04 19:28:40,020:INFO:               skopt: Not installed
2023-11-04 19:28:40,020:INFO:              mlflow: Not installed
2023-11-04 19:28:40,020:INFO:              gradio: Not installed
2023-11-04 19:28:40,020:INFO:             fastapi: Not installed
2023-11-04 19:28:40,020:INFO:             uvicorn: Not installed
2023-11-04 19:28:40,020:INFO:              m2cgen: Not installed
2023-11-04 19:28:40,020:INFO:           evidently: Not installed
2023-11-04 19:28:40,020:INFO:               fugue: Not installed
2023-11-04 19:28:40,020:INFO:           streamlit: Not installed
2023-11-04 19:28:40,020:INFO:             prophet: Not installed
2023-11-04 19:28:40,020:INFO:None
2023-11-04 19:28:40,020:INFO:Set up data.
2023-11-04 19:29:26,703:INFO:PyCaret RegressionExperiment
2023-11-04 19:29:26,703:INFO:Logging name: reg-default-name
2023-11-04 19:29:26,703:INFO:ML Usecase: MLUsecase.REGRESSION
2023-11-04 19:29:26,703:INFO:version 3.1.0
2023-11-04 19:29:26,703:INFO:Initializing setup()
2023-11-04 19:29:26,703:INFO:self.USI: f539
2023-11-04 19:29:26,703:INFO:self._variable_keys: {'USI', 'log_plots_param', 'gpu_param', 'fold_generator', 'X_test', 'html_param', '_ml_usecase', '_available_plots', 'exp_id', 'target_param', 'idx', 'fold_shuffle_param', 'n_jobs_param', 'seed', 'exp_name_log', 'X', 'y_train', 'transform_target_param', 'data', 'y_test', 'fold_groups_param', 'logging_param', 'gpu_n_jobs_param', 'y', 'X_train', 'memory', 'pipeline'}
2023-11-04 19:29:26,703:INFO:Checking environment
2023-11-04 19:29:26,703:INFO:python_version: 3.9.13
2023-11-04 19:29:26,703:INFO:python_build: ('main', 'Aug 25 2022 18:29:29')
2023-11-04 19:29:26,703:INFO:machine: x86_64
2023-11-04 19:29:26,703:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-11-04 19:29:26,703:INFO:Memory: svmem(total=17179869184, available=1438011392, percent=91.6, used=1910267904, free=30240768, active=1409875968, inactive=1382514688, wired=500391936)
2023-11-04 19:29:26,703:INFO:Physical Core: 8
2023-11-04 19:29:26,703:INFO:Logical Core: 8
2023-11-04 19:29:26,703:INFO:Checking libraries
2023-11-04 19:29:26,703:INFO:System:
2023-11-04 19:29:26,703:INFO:    python: 3.9.13 (main, Aug 25 2022, 18:29:29)  [Clang 12.0.0 ]
2023-11-04 19:29:26,703:INFO:executable: /Users/michal/opt/anaconda3/bin/python
2023-11-04 19:29:26,703:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-11-04 19:29:26,704:INFO:PyCaret required dependencies:
2023-11-04 19:29:26,704:INFO:                 pip: 22.2.2
2023-11-04 19:29:26,704:INFO:          setuptools: 63.4.1
2023-11-04 19:29:26,704:INFO:             pycaret: 3.1.0
2023-11-04 19:29:26,704:INFO:             IPython: 7.31.1
2023-11-04 19:29:26,704:INFO:          ipywidgets: 7.6.5
2023-11-04 19:29:26,704:INFO:                tqdm: 4.64.1
2023-11-04 19:29:26,704:INFO:               numpy: 1.21.5
2023-11-04 19:29:26,704:INFO:              pandas: 1.4.4
2023-11-04 19:29:26,704:INFO:              jinja2: 2.11.3
2023-11-04 19:29:26,704:INFO:               scipy: 1.10.1
2023-11-04 19:29:26,704:INFO:              joblib: 1.2.0
2023-11-04 19:29:26,704:INFO:             sklearn: 1.0.2
2023-11-04 19:29:26,704:INFO:                pyod: 1.1.1
2023-11-04 19:29:26,704:INFO:            imblearn: 0.10.1
2023-11-04 19:29:26,704:INFO:   category_encoders: 2.6.3
2023-11-04 19:29:26,704:INFO:            lightgbm: 3.3.5
2023-11-04 19:29:26,704:INFO:               numba: 0.55.1
2023-11-04 19:29:26,704:INFO:            requests: 2.28.1
2023-11-04 19:29:26,704:INFO:          matplotlib: 3.5.2
2023-11-04 19:29:26,704:INFO:          scikitplot: 0.3.7
2023-11-04 19:29:26,704:INFO:         yellowbrick: 1.5
2023-11-04 19:29:26,704:INFO:              plotly: 5.9.0
2023-11-04 19:29:26,704:INFO:    plotly-resampler: Not installed
2023-11-04 19:29:26,704:INFO:             kaleido: 0.2.1
2023-11-04 19:29:26,704:INFO:           schemdraw: 0.15
2023-11-04 19:29:26,704:INFO:         statsmodels: 0.13.2
2023-11-04 19:29:26,704:INFO:              sktime: 0.21.1
2023-11-04 19:29:26,704:INFO:               tbats: 1.1.3
2023-11-04 19:29:26,704:INFO:            pmdarima: 2.0.4
2023-11-04 19:29:26,704:INFO:              psutil: 5.9.0
2023-11-04 19:29:26,704:INFO:          markupsafe: 2.0.1
2023-11-04 19:29:26,704:INFO:             pickle5: Not installed
2023-11-04 19:29:26,704:INFO:         cloudpickle: 2.0.0
2023-11-04 19:29:26,704:INFO:         deprecation: 2.1.0
2023-11-04 19:29:26,704:INFO:              xxhash: 3.4.1
2023-11-04 19:29:26,704:INFO:           wurlitzer: 3.0.2
2023-11-04 19:29:26,704:INFO:PyCaret optional dependencies:
2023-11-04 19:29:26,704:INFO:                shap: 0.41.0
2023-11-04 19:29:26,704:INFO:           interpret: Not installed
2023-11-04 19:29:26,704:INFO:                umap: 0.5.3
2023-11-04 19:29:26,704:INFO:     ydata_profiling: Not installed
2023-11-04 19:29:26,704:INFO:  explainerdashboard: Not installed
2023-11-04 19:29:26,704:INFO:             autoviz: Not installed
2023-11-04 19:29:26,704:INFO:           fairlearn: Not installed
2023-11-04 19:29:26,704:INFO:          deepchecks: Not installed
2023-11-04 19:29:26,704:INFO:             xgboost: 1.7.4
2023-11-04 19:29:26,704:INFO:            catboost: 1.2
2023-11-04 19:29:26,704:INFO:              kmodes: Not installed
2023-11-04 19:29:26,704:INFO:             mlxtend: 0.21.0
2023-11-04 19:29:26,704:INFO:       statsforecast: Not installed
2023-11-04 19:29:26,704:INFO:        tune_sklearn: Not installed
2023-11-04 19:29:26,704:INFO:                 ray: Not installed
2023-11-04 19:29:26,704:INFO:            hyperopt: Not installed
2023-11-04 19:29:26,704:INFO:              optuna: Not installed
2023-11-04 19:29:26,704:INFO:               skopt: Not installed
2023-11-04 19:29:26,704:INFO:              mlflow: Not installed
2023-11-04 19:29:26,704:INFO:              gradio: Not installed
2023-11-04 19:29:26,704:INFO:             fastapi: Not installed
2023-11-04 19:29:26,704:INFO:             uvicorn: Not installed
2023-11-04 19:29:26,704:INFO:              m2cgen: Not installed
2023-11-04 19:29:26,704:INFO:           evidently: Not installed
2023-11-04 19:29:26,704:INFO:               fugue: Not installed
2023-11-04 19:29:26,705:INFO:           streamlit: Not installed
2023-11-04 19:29:26,705:INFO:             prophet: Not installed
2023-11-04 19:29:26,705:INFO:None
2023-11-04 19:29:26,705:INFO:Set up data.
2023-11-04 19:29:26,708:INFO:Set up folding strategy.
2023-11-04 19:29:26,708:INFO:Set up train/test split.
2023-11-04 19:29:26,709:INFO:Set up index.
2023-11-04 19:29:26,709:INFO:Assigning column types.
2023-11-04 19:29:26,710:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-04 19:29:26,710:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-04 19:29:26,713:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 19:29:26,716:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:29:26,750:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:29:26,777:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:29:26,777:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:29:26,778:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:29:26,779:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-04 19:29:26,782:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 19:29:26,784:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:29:26,818:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:29:26,845:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:29:26,845:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:29:26,847:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:29:26,847:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-11-04 19:29:26,850:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 19:29:26,852:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:29:26,886:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:29:26,912:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:29:26,913:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:29:26,915:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:29:26,918:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 19:29:26,920:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:29:26,954:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:29:26,981:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:29:26,981:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:29:26,982:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:29:26,983:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-11-04 19:29:26,988:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:29:27,022:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:29:27,048:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:29:27,049:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:29:27,050:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:29:27,056:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:29:27,089:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:29:27,115:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:29:27,115:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:29:27,116:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:29:27,117:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-11-04 19:29:27,155:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:29:27,181:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:29:27,181:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:29:27,183:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:29:27,221:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:29:27,246:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:29:27,247:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:29:27,248:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:29:27,248:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-04 19:29:27,286:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:29:27,312:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:29:27,314:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:29:27,352:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:29:27,380:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:29:27,382:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:29:27,382:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-11-04 19:29:27,445:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:29:27,446:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:29:27,509:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:29:27,511:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:29:27,511:INFO:Preparing preprocessing pipeline...
2023-11-04 19:29:27,511:INFO:Set up simple imputation.
2023-11-04 19:29:27,511:INFO:Set up variance threshold.
2023-11-04 19:29:27,511:INFO:Set up removing multicollinearity.
2023-11-04 19:29:27,512:INFO:Set up column name cleaning.
2023-11-04 19:29:27,532:INFO:Finished creating preprocessing pipeline.
2023-11-04 19:29:27,535:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/h9/5_75v3qs13x63s15wwxdrd000000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['solv_dG [kcal/mol]',
                                             'Bond dissociation entalphy',
                                             'water_ads [kcal/mol]', 'Coating',
                                             'Organic Matter Conc.', 'pH',
                                             'Primary Size', 'Initial Conc.',
                                             'Temp.', 'Ionic Strenght', 'Light',
                                             'MW', 'Noxy', 'χ', 'χox',
                                             'Z_metal', 'Zv...
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.1))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-11-04 19:29:27,535:INFO:Creating final display dataframe.
2023-11-04 19:29:27,583:INFO:Setup _display_container:                     Description             Value
0                    Session id              2529
1                        Target  %dissolved solid
2                   Target type        Regression
3           Original data shape         (115, 21)
4        Transformed data shape         (115, 19)
5   Transformed train set shape          (80, 19)
6    Transformed test set shape          (35, 19)
7              Numeric features                20
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12       Low variance threshold               0.1
13     Remove multicollinearity              True
14  Multicollinearity threshold              0.95
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              f539
2023-11-04 19:29:27,652:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:29:27,654:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:29:27,720:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:29:27,722:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:29:27,722:INFO:setup() successfully completed in 1.02s...............
2023-11-04 19:29:27,722:INFO:Initializing compare_models()
2023-11-04 19:29:27,722:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb43617f400>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fb43617f400>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-11-04 19:29:27,722:INFO:Checking exceptions
2023-11-04 19:29:27,723:INFO:Preparing display monitor
2023-11-04 19:29:27,739:INFO:Initializing Linear Regression
2023-11-04 19:29:27,740:INFO:Total runtime is 1.8517176310221354e-06 minutes
2023-11-04 19:29:27,741:INFO:SubProcess create_model() called ==================================
2023-11-04 19:29:27,741:INFO:Initializing create_model()
2023-11-04 19:29:27,741:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb43617f400>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4356cea30>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:29:27,741:INFO:Checking exceptions
2023-11-04 19:29:27,742:INFO:Importing libraries
2023-11-04 19:29:27,742:INFO:Copying training dataset
2023-11-04 19:29:27,743:INFO:Defining folds
2023-11-04 19:29:27,743:INFO:Declaring metric variables
2023-11-04 19:29:27,745:INFO:Importing untrained model
2023-11-04 19:29:27,747:INFO:Linear Regression Imported successfully
2023-11-04 19:29:27,750:INFO:Starting cross validation
2023-11-04 19:29:27,751:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:29:30,417:INFO:Calculating mean and std
2023-11-04 19:29:30,420:INFO:Creating metrics dataframe
2023-11-04 19:29:30,424:INFO:Uploading results into container
2023-11-04 19:29:30,425:INFO:Uploading model into container now
2023-11-04 19:29:30,426:INFO:_master_model_container: 1
2023-11-04 19:29:30,426:INFO:_display_container: 2
2023-11-04 19:29:30,426:INFO:LinearRegression(n_jobs=-1)
2023-11-04 19:29:30,426:INFO:create_model() successfully completed......................................
2023-11-04 19:29:30,580:INFO:SubProcess create_model() end ==================================
2023-11-04 19:29:30,580:INFO:Creating metrics dataframe
2023-11-04 19:29:30,585:INFO:Initializing Lasso Regression
2023-11-04 19:29:30,585:INFO:Total runtime is 0.04742106596628825 minutes
2023-11-04 19:29:30,587:INFO:SubProcess create_model() called ==================================
2023-11-04 19:29:30,587:INFO:Initializing create_model()
2023-11-04 19:29:30,587:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb43617f400>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4356cea30>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:29:30,587:INFO:Checking exceptions
2023-11-04 19:29:30,587:INFO:Importing libraries
2023-11-04 19:29:30,587:INFO:Copying training dataset
2023-11-04 19:29:30,589:INFO:Defining folds
2023-11-04 19:29:30,589:INFO:Declaring metric variables
2023-11-04 19:29:30,591:INFO:Importing untrained model
2023-11-04 19:29:30,593:INFO:Lasso Regression Imported successfully
2023-11-04 19:29:30,596:INFO:Starting cross validation
2023-11-04 19:29:30,597:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:29:30,657:INFO:Calculating mean and std
2023-11-04 19:29:30,658:INFO:Creating metrics dataframe
2023-11-04 19:29:30,659:INFO:Uploading results into container
2023-11-04 19:29:30,659:INFO:Uploading model into container now
2023-11-04 19:29:30,660:INFO:_master_model_container: 2
2023-11-04 19:29:30,660:INFO:_display_container: 2
2023-11-04 19:29:30,660:INFO:Lasso(random_state=2529)
2023-11-04 19:29:30,660:INFO:create_model() successfully completed......................................
2023-11-04 19:29:30,774:INFO:SubProcess create_model() end ==================================
2023-11-04 19:29:30,774:INFO:Creating metrics dataframe
2023-11-04 19:29:30,779:INFO:Initializing Ridge Regression
2023-11-04 19:29:30,779:INFO:Total runtime is 0.050662684440612796 minutes
2023-11-04 19:29:30,781:INFO:SubProcess create_model() called ==================================
2023-11-04 19:29:30,781:INFO:Initializing create_model()
2023-11-04 19:29:30,781:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb43617f400>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4356cea30>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:29:30,781:INFO:Checking exceptions
2023-11-04 19:29:30,781:INFO:Importing libraries
2023-11-04 19:29:30,782:INFO:Copying training dataset
2023-11-04 19:29:30,784:INFO:Defining folds
2023-11-04 19:29:30,784:INFO:Declaring metric variables
2023-11-04 19:29:30,785:INFO:Importing untrained model
2023-11-04 19:29:30,787:INFO:Ridge Regression Imported successfully
2023-11-04 19:29:30,791:INFO:Starting cross validation
2023-11-04 19:29:30,791:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:29:30,850:INFO:Calculating mean and std
2023-11-04 19:29:30,850:INFO:Creating metrics dataframe
2023-11-04 19:29:30,852:INFO:Uploading results into container
2023-11-04 19:29:30,852:INFO:Uploading model into container now
2023-11-04 19:29:30,852:INFO:_master_model_container: 3
2023-11-04 19:29:30,852:INFO:_display_container: 2
2023-11-04 19:29:30,852:INFO:Ridge(random_state=2529)
2023-11-04 19:29:30,852:INFO:create_model() successfully completed......................................
2023-11-04 19:29:30,962:INFO:SubProcess create_model() end ==================================
2023-11-04 19:29:30,962:INFO:Creating metrics dataframe
2023-11-04 19:29:30,967:INFO:Initializing Elastic Net
2023-11-04 19:29:30,967:INFO:Total runtime is 0.05379658142725627 minutes
2023-11-04 19:29:30,969:INFO:SubProcess create_model() called ==================================
2023-11-04 19:29:30,969:INFO:Initializing create_model()
2023-11-04 19:29:30,969:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb43617f400>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4356cea30>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:29:30,969:INFO:Checking exceptions
2023-11-04 19:29:30,969:INFO:Importing libraries
2023-11-04 19:29:30,969:INFO:Copying training dataset
2023-11-04 19:29:30,971:INFO:Defining folds
2023-11-04 19:29:30,972:INFO:Declaring metric variables
2023-11-04 19:29:30,973:INFO:Importing untrained model
2023-11-04 19:29:30,975:INFO:Elastic Net Imported successfully
2023-11-04 19:29:30,978:INFO:Starting cross validation
2023-11-04 19:29:30,979:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:29:31,034:INFO:Calculating mean and std
2023-11-04 19:29:31,034:INFO:Creating metrics dataframe
2023-11-04 19:29:31,036:INFO:Uploading results into container
2023-11-04 19:29:31,036:INFO:Uploading model into container now
2023-11-04 19:29:31,036:INFO:_master_model_container: 4
2023-11-04 19:29:31,036:INFO:_display_container: 2
2023-11-04 19:29:31,037:INFO:ElasticNet(random_state=2529)
2023-11-04 19:29:31,037:INFO:create_model() successfully completed......................................
2023-11-04 19:29:31,147:INFO:SubProcess create_model() end ==================================
2023-11-04 19:29:31,147:INFO:Creating metrics dataframe
2023-11-04 19:29:31,152:INFO:Initializing Least Angle Regression
2023-11-04 19:29:31,153:INFO:Total runtime is 0.05688676436742147 minutes
2023-11-04 19:29:31,154:INFO:SubProcess create_model() called ==================================
2023-11-04 19:29:31,155:INFO:Initializing create_model()
2023-11-04 19:29:31,155:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb43617f400>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4356cea30>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:29:31,155:INFO:Checking exceptions
2023-11-04 19:29:31,155:INFO:Importing libraries
2023-11-04 19:29:31,155:INFO:Copying training dataset
2023-11-04 19:29:31,157:INFO:Defining folds
2023-11-04 19:29:31,157:INFO:Declaring metric variables
2023-11-04 19:29:31,159:INFO:Importing untrained model
2023-11-04 19:29:31,161:INFO:Least Angle Regression Imported successfully
2023-11-04 19:29:31,163:INFO:Starting cross validation
2023-11-04 19:29:31,164:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:29:31,185:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:29:31,187:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:29:31,202:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:29:31,205:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:29:31,205:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:29:31,207:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:29:31,207:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:29:31,208:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:29:31,208:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:29:31,209:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.627e+02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-04 19:29:31,219:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:29:31,226:INFO:Calculating mean and std
2023-11-04 19:29:31,226:INFO:Creating metrics dataframe
2023-11-04 19:29:31,228:INFO:Uploading results into container
2023-11-04 19:29:31,228:INFO:Uploading model into container now
2023-11-04 19:29:31,228:INFO:_master_model_container: 5
2023-11-04 19:29:31,228:INFO:_display_container: 2
2023-11-04 19:29:31,228:INFO:Lars(random_state=2529)
2023-11-04 19:29:31,228:INFO:create_model() successfully completed......................................
2023-11-04 19:29:31,338:INFO:SubProcess create_model() end ==================================
2023-11-04 19:29:31,338:INFO:Creating metrics dataframe
2023-11-04 19:29:31,344:INFO:Initializing Lasso Least Angle Regression
2023-11-04 19:29:31,344:INFO:Total runtime is 0.06007051865259806 minutes
2023-11-04 19:29:31,345:INFO:SubProcess create_model() called ==================================
2023-11-04 19:29:31,346:INFO:Initializing create_model()
2023-11-04 19:29:31,346:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb43617f400>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4356cea30>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:29:31,346:INFO:Checking exceptions
2023-11-04 19:29:31,346:INFO:Importing libraries
2023-11-04 19:29:31,346:INFO:Copying training dataset
2023-11-04 19:29:31,348:INFO:Defining folds
2023-11-04 19:29:31,348:INFO:Declaring metric variables
2023-11-04 19:29:31,350:INFO:Importing untrained model
2023-11-04 19:29:31,351:INFO:Lasso Least Angle Regression Imported successfully
2023-11-04 19:29:31,354:INFO:Starting cross validation
2023-11-04 19:29:31,355:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:29:31,376:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:29:31,383:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:29:31,386:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:29:31,393:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:29:31,396:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:29:31,397:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:29:31,400:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:29:31,408:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:29:31,410:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:29:31,412:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:29:31,417:INFO:Calculating mean and std
2023-11-04 19:29:31,418:INFO:Creating metrics dataframe
2023-11-04 19:29:31,419:INFO:Uploading results into container
2023-11-04 19:29:31,420:INFO:Uploading model into container now
2023-11-04 19:29:31,420:INFO:_master_model_container: 6
2023-11-04 19:29:31,420:INFO:_display_container: 2
2023-11-04 19:29:31,420:INFO:LassoLars(random_state=2529)
2023-11-04 19:29:31,420:INFO:create_model() successfully completed......................................
2023-11-04 19:29:31,531:INFO:SubProcess create_model() end ==================================
2023-11-04 19:29:31,531:INFO:Creating metrics dataframe
2023-11-04 19:29:31,536:INFO:Initializing Orthogonal Matching Pursuit
2023-11-04 19:29:31,536:INFO:Total runtime is 0.06328486601511638 minutes
2023-11-04 19:29:31,538:INFO:SubProcess create_model() called ==================================
2023-11-04 19:29:31,539:INFO:Initializing create_model()
2023-11-04 19:29:31,539:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb43617f400>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4356cea30>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:29:31,539:INFO:Checking exceptions
2023-11-04 19:29:31,539:INFO:Importing libraries
2023-11-04 19:29:31,539:INFO:Copying training dataset
2023-11-04 19:29:31,541:INFO:Defining folds
2023-11-04 19:29:31,541:INFO:Declaring metric variables
2023-11-04 19:29:31,543:INFO:Importing untrained model
2023-11-04 19:29:31,544:INFO:Orthogonal Matching Pursuit Imported successfully
2023-11-04 19:29:31,548:INFO:Starting cross validation
2023-11-04 19:29:31,548:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:29:31,569:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:29:31,571:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:29:31,577:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:29:31,579:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:29:31,587:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:29:31,588:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:29:31,591:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:29:31,595:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:29:31,597:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:29:31,597:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:29:31,603:INFO:Calculating mean and std
2023-11-04 19:29:31,603:INFO:Creating metrics dataframe
2023-11-04 19:29:31,605:INFO:Uploading results into container
2023-11-04 19:29:31,605:INFO:Uploading model into container now
2023-11-04 19:29:31,606:INFO:_master_model_container: 7
2023-11-04 19:29:31,606:INFO:_display_container: 2
2023-11-04 19:29:31,606:INFO:OrthogonalMatchingPursuit()
2023-11-04 19:29:31,606:INFO:create_model() successfully completed......................................
2023-11-04 19:29:31,716:INFO:SubProcess create_model() end ==================================
2023-11-04 19:29:31,716:INFO:Creating metrics dataframe
2023-11-04 19:29:31,721:INFO:Initializing Bayesian Ridge
2023-11-04 19:29:31,722:INFO:Total runtime is 0.0663690169652303 minutes
2023-11-04 19:29:31,723:INFO:SubProcess create_model() called ==================================
2023-11-04 19:29:31,724:INFO:Initializing create_model()
2023-11-04 19:29:31,724:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb43617f400>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4356cea30>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:29:31,724:INFO:Checking exceptions
2023-11-04 19:29:31,724:INFO:Importing libraries
2023-11-04 19:29:31,724:INFO:Copying training dataset
2023-11-04 19:29:31,726:INFO:Defining folds
2023-11-04 19:29:31,726:INFO:Declaring metric variables
2023-11-04 19:29:31,728:INFO:Importing untrained model
2023-11-04 19:29:31,729:INFO:Bayesian Ridge Imported successfully
2023-11-04 19:29:31,733:INFO:Starting cross validation
2023-11-04 19:29:31,733:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:29:31,791:INFO:Calculating mean and std
2023-11-04 19:29:31,792:INFO:Creating metrics dataframe
2023-11-04 19:29:31,793:INFO:Uploading results into container
2023-11-04 19:29:31,793:INFO:Uploading model into container now
2023-11-04 19:29:31,794:INFO:_master_model_container: 8
2023-11-04 19:29:31,794:INFO:_display_container: 2
2023-11-04 19:29:31,794:INFO:BayesianRidge()
2023-11-04 19:29:31,794:INFO:create_model() successfully completed......................................
2023-11-04 19:29:31,905:INFO:SubProcess create_model() end ==================================
2023-11-04 19:29:31,905:INFO:Creating metrics dataframe
2023-11-04 19:29:31,910:INFO:Initializing Passive Aggressive Regressor
2023-11-04 19:29:31,911:INFO:Total runtime is 0.06951926549275715 minutes
2023-11-04 19:29:31,912:INFO:SubProcess create_model() called ==================================
2023-11-04 19:29:31,913:INFO:Initializing create_model()
2023-11-04 19:29:31,913:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb43617f400>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4356cea30>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:29:31,913:INFO:Checking exceptions
2023-11-04 19:29:31,913:INFO:Importing libraries
2023-11-04 19:29:31,913:INFO:Copying training dataset
2023-11-04 19:29:31,915:INFO:Defining folds
2023-11-04 19:29:31,915:INFO:Declaring metric variables
2023-11-04 19:29:31,916:INFO:Importing untrained model
2023-11-04 19:29:31,918:INFO:Passive Aggressive Regressor Imported successfully
2023-11-04 19:29:31,921:INFO:Starting cross validation
2023-11-04 19:29:31,922:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:29:31,980:INFO:Calculating mean and std
2023-11-04 19:29:31,980:INFO:Creating metrics dataframe
2023-11-04 19:29:31,982:INFO:Uploading results into container
2023-11-04 19:29:31,982:INFO:Uploading model into container now
2023-11-04 19:29:31,982:INFO:_master_model_container: 9
2023-11-04 19:29:31,982:INFO:_display_container: 2
2023-11-04 19:29:31,982:INFO:PassiveAggressiveRegressor(random_state=2529)
2023-11-04 19:29:31,982:INFO:create_model() successfully completed......................................
2023-11-04 19:29:32,093:INFO:SubProcess create_model() end ==================================
2023-11-04 19:29:32,093:INFO:Creating metrics dataframe
2023-11-04 19:29:32,099:INFO:Initializing Huber Regressor
2023-11-04 19:29:32,099:INFO:Total runtime is 0.07266501188278197 minutes
2023-11-04 19:29:32,101:INFO:SubProcess create_model() called ==================================
2023-11-04 19:29:32,101:INFO:Initializing create_model()
2023-11-04 19:29:32,101:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb43617f400>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4356cea30>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:29:32,101:INFO:Checking exceptions
2023-11-04 19:29:32,101:INFO:Importing libraries
2023-11-04 19:29:32,101:INFO:Copying training dataset
2023-11-04 19:29:32,104:INFO:Defining folds
2023-11-04 19:29:32,104:INFO:Declaring metric variables
2023-11-04 19:29:32,105:INFO:Importing untrained model
2023-11-04 19:29:32,107:INFO:Huber Regressor Imported successfully
2023-11-04 19:29:32,110:INFO:Starting cross validation
2023-11-04 19:29:32,111:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:29:32,142:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:29:32,149:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:29:32,150:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:29:32,161:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:29:32,164:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:29:32,166:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:29:32,173:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:29:32,173:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:29:32,176:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:29:32,178:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:29:32,183:INFO:Calculating mean and std
2023-11-04 19:29:32,183:INFO:Creating metrics dataframe
2023-11-04 19:29:32,185:INFO:Uploading results into container
2023-11-04 19:29:32,185:INFO:Uploading model into container now
2023-11-04 19:29:32,185:INFO:_master_model_container: 10
2023-11-04 19:29:32,185:INFO:_display_container: 2
2023-11-04 19:29:32,185:INFO:HuberRegressor()
2023-11-04 19:29:32,185:INFO:create_model() successfully completed......................................
2023-11-04 19:29:32,295:INFO:SubProcess create_model() end ==================================
2023-11-04 19:29:32,295:INFO:Creating metrics dataframe
2023-11-04 19:29:32,301:INFO:Initializing K Neighbors Regressor
2023-11-04 19:29:32,302:INFO:Total runtime is 0.07603556315104165 minutes
2023-11-04 19:29:32,303:INFO:SubProcess create_model() called ==================================
2023-11-04 19:29:32,303:INFO:Initializing create_model()
2023-11-04 19:29:32,303:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb43617f400>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4356cea30>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:29:32,304:INFO:Checking exceptions
2023-11-04 19:29:32,304:INFO:Importing libraries
2023-11-04 19:29:32,304:INFO:Copying training dataset
2023-11-04 19:29:32,306:INFO:Defining folds
2023-11-04 19:29:32,306:INFO:Declaring metric variables
2023-11-04 19:29:32,308:INFO:Importing untrained model
2023-11-04 19:29:32,310:INFO:K Neighbors Regressor Imported successfully
2023-11-04 19:29:32,313:INFO:Starting cross validation
2023-11-04 19:29:32,314:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:29:32,379:INFO:Calculating mean and std
2023-11-04 19:29:32,380:INFO:Creating metrics dataframe
2023-11-04 19:29:32,381:INFO:Uploading results into container
2023-11-04 19:29:32,382:INFO:Uploading model into container now
2023-11-04 19:29:32,382:INFO:_master_model_container: 11
2023-11-04 19:29:32,382:INFO:_display_container: 2
2023-11-04 19:29:32,382:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-04 19:29:32,382:INFO:create_model() successfully completed......................................
2023-11-04 19:29:32,495:INFO:SubProcess create_model() end ==================================
2023-11-04 19:29:32,495:INFO:Creating metrics dataframe
2023-11-04 19:29:32,501:INFO:Initializing Decision Tree Regressor
2023-11-04 19:29:32,501:INFO:Total runtime is 0.07936714887619017 minutes
2023-11-04 19:29:32,503:INFO:SubProcess create_model() called ==================================
2023-11-04 19:29:32,503:INFO:Initializing create_model()
2023-11-04 19:29:32,504:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb43617f400>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4356cea30>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:29:32,504:INFO:Checking exceptions
2023-11-04 19:29:32,504:INFO:Importing libraries
2023-11-04 19:29:32,504:INFO:Copying training dataset
2023-11-04 19:29:32,506:INFO:Defining folds
2023-11-04 19:29:32,506:INFO:Declaring metric variables
2023-11-04 19:29:32,508:INFO:Importing untrained model
2023-11-04 19:29:32,509:INFO:Decision Tree Regressor Imported successfully
2023-11-04 19:29:32,512:INFO:Starting cross validation
2023-11-04 19:29:32,513:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:29:32,569:INFO:Calculating mean and std
2023-11-04 19:29:32,570:INFO:Creating metrics dataframe
2023-11-04 19:29:32,571:INFO:Uploading results into container
2023-11-04 19:29:32,572:INFO:Uploading model into container now
2023-11-04 19:29:32,572:INFO:_master_model_container: 12
2023-11-04 19:29:32,572:INFO:_display_container: 2
2023-11-04 19:29:32,572:INFO:DecisionTreeRegressor(random_state=2529)
2023-11-04 19:29:32,572:INFO:create_model() successfully completed......................................
2023-11-04 19:29:32,682:INFO:SubProcess create_model() end ==================================
2023-11-04 19:29:32,682:INFO:Creating metrics dataframe
2023-11-04 19:29:32,688:INFO:Initializing Random Forest Regressor
2023-11-04 19:29:32,688:INFO:Total runtime is 0.08248451550801594 minutes
2023-11-04 19:29:32,690:INFO:SubProcess create_model() called ==================================
2023-11-04 19:29:32,690:INFO:Initializing create_model()
2023-11-04 19:29:32,690:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb43617f400>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4356cea30>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:29:32,691:INFO:Checking exceptions
2023-11-04 19:29:32,691:INFO:Importing libraries
2023-11-04 19:29:32,691:INFO:Copying training dataset
2023-11-04 19:29:32,693:INFO:Defining folds
2023-11-04 19:29:32,693:INFO:Declaring metric variables
2023-11-04 19:29:32,694:INFO:Importing untrained model
2023-11-04 19:29:32,696:INFO:Random Forest Regressor Imported successfully
2023-11-04 19:29:32,699:INFO:Starting cross validation
2023-11-04 19:29:32,700:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:29:32,952:INFO:Calculating mean and std
2023-11-04 19:29:32,952:INFO:Creating metrics dataframe
2023-11-04 19:29:32,955:INFO:Uploading results into container
2023-11-04 19:29:32,955:INFO:Uploading model into container now
2023-11-04 19:29:32,955:INFO:_master_model_container: 13
2023-11-04 19:29:32,955:INFO:_display_container: 2
2023-11-04 19:29:32,956:INFO:RandomForestRegressor(n_jobs=-1, random_state=2529)
2023-11-04 19:29:32,956:INFO:create_model() successfully completed......................................
2023-11-04 19:29:33,069:INFO:SubProcess create_model() end ==================================
2023-11-04 19:29:33,069:INFO:Creating metrics dataframe
2023-11-04 19:29:33,076:INFO:Initializing Extra Trees Regressor
2023-11-04 19:29:33,076:INFO:Total runtime is 0.08895089626312255 minutes
2023-11-04 19:29:33,078:INFO:SubProcess create_model() called ==================================
2023-11-04 19:29:33,078:INFO:Initializing create_model()
2023-11-04 19:29:33,078:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb43617f400>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4356cea30>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:29:33,078:INFO:Checking exceptions
2023-11-04 19:29:33,079:INFO:Importing libraries
2023-11-04 19:29:33,079:INFO:Copying training dataset
2023-11-04 19:29:33,080:INFO:Defining folds
2023-11-04 19:29:33,080:INFO:Declaring metric variables
2023-11-04 19:29:33,082:INFO:Importing untrained model
2023-11-04 19:29:33,083:INFO:Extra Trees Regressor Imported successfully
2023-11-04 19:29:33,087:INFO:Starting cross validation
2023-11-04 19:29:33,088:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:29:33,298:INFO:Calculating mean and std
2023-11-04 19:29:33,298:INFO:Creating metrics dataframe
2023-11-04 19:29:33,300:INFO:Uploading results into container
2023-11-04 19:29:33,301:INFO:Uploading model into container now
2023-11-04 19:29:33,301:INFO:_master_model_container: 14
2023-11-04 19:29:33,301:INFO:_display_container: 2
2023-11-04 19:29:33,301:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=2529)
2023-11-04 19:29:33,301:INFO:create_model() successfully completed......................................
2023-11-04 19:29:33,411:INFO:SubProcess create_model() end ==================================
2023-11-04 19:29:33,412:INFO:Creating metrics dataframe
2023-11-04 19:29:33,418:INFO:Initializing AdaBoost Regressor
2023-11-04 19:29:33,418:INFO:Total runtime is 0.09464814662933349 minutes
2023-11-04 19:29:33,420:INFO:SubProcess create_model() called ==================================
2023-11-04 19:29:33,420:INFO:Initializing create_model()
2023-11-04 19:29:33,420:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb43617f400>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4356cea30>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:29:33,420:INFO:Checking exceptions
2023-11-04 19:29:33,420:INFO:Importing libraries
2023-11-04 19:29:33,420:INFO:Copying training dataset
2023-11-04 19:29:33,422:INFO:Defining folds
2023-11-04 19:29:33,422:INFO:Declaring metric variables
2023-11-04 19:29:33,423:INFO:Importing untrained model
2023-11-04 19:29:33,425:INFO:AdaBoost Regressor Imported successfully
2023-11-04 19:29:33,429:INFO:Starting cross validation
2023-11-04 19:29:33,429:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:29:33,545:INFO:Calculating mean and std
2023-11-04 19:29:33,545:INFO:Creating metrics dataframe
2023-11-04 19:29:33,547:INFO:Uploading results into container
2023-11-04 19:29:33,548:INFO:Uploading model into container now
2023-11-04 19:29:33,548:INFO:_master_model_container: 15
2023-11-04 19:29:33,548:INFO:_display_container: 2
2023-11-04 19:29:33,548:INFO:AdaBoostRegressor(random_state=2529)
2023-11-04 19:29:33,548:INFO:create_model() successfully completed......................................
2023-11-04 19:29:33,659:INFO:SubProcess create_model() end ==================================
2023-11-04 19:29:33,659:INFO:Creating metrics dataframe
2023-11-04 19:29:33,665:INFO:Initializing Gradient Boosting Regressor
2023-11-04 19:29:33,665:INFO:Total runtime is 0.09876761436462402 minutes
2023-11-04 19:29:33,667:INFO:SubProcess create_model() called ==================================
2023-11-04 19:29:33,667:INFO:Initializing create_model()
2023-11-04 19:29:33,667:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb43617f400>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4356cea30>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:29:33,667:INFO:Checking exceptions
2023-11-04 19:29:33,667:INFO:Importing libraries
2023-11-04 19:29:33,667:INFO:Copying training dataset
2023-11-04 19:29:33,669:INFO:Defining folds
2023-11-04 19:29:33,669:INFO:Declaring metric variables
2023-11-04 19:29:33,670:INFO:Importing untrained model
2023-11-04 19:29:33,672:INFO:Gradient Boosting Regressor Imported successfully
2023-11-04 19:29:33,676:INFO:Starting cross validation
2023-11-04 19:29:33,677:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:29:33,756:INFO:Calculating mean and std
2023-11-04 19:29:33,756:INFO:Creating metrics dataframe
2023-11-04 19:29:33,758:INFO:Uploading results into container
2023-11-04 19:29:33,758:INFO:Uploading model into container now
2023-11-04 19:29:33,759:INFO:_master_model_container: 16
2023-11-04 19:29:33,759:INFO:_display_container: 2
2023-11-04 19:29:33,759:INFO:GradientBoostingRegressor(random_state=2529)
2023-11-04 19:29:33,759:INFO:create_model() successfully completed......................................
2023-11-04 19:29:33,869:INFO:SubProcess create_model() end ==================================
2023-11-04 19:29:33,869:INFO:Creating metrics dataframe
2023-11-04 19:29:33,876:INFO:Initializing Extreme Gradient Boosting
2023-11-04 19:29:33,876:INFO:Total runtime is 0.10227226813634235 minutes
2023-11-04 19:29:33,877:INFO:SubProcess create_model() called ==================================
2023-11-04 19:29:33,878:INFO:Initializing create_model()
2023-11-04 19:29:33,878:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb43617f400>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4356cea30>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:29:33,878:INFO:Checking exceptions
2023-11-04 19:29:33,878:INFO:Importing libraries
2023-11-04 19:29:33,878:INFO:Copying training dataset
2023-11-04 19:29:33,880:INFO:Defining folds
2023-11-04 19:29:33,880:INFO:Declaring metric variables
2023-11-04 19:29:33,881:INFO:Importing untrained model
2023-11-04 19:29:33,883:INFO:Extreme Gradient Boosting Imported successfully
2023-11-04 19:29:33,886:INFO:Starting cross validation
2023-11-04 19:29:33,887:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:29:34,006:INFO:Calculating mean and std
2023-11-04 19:29:34,007:INFO:Creating metrics dataframe
2023-11-04 19:29:34,009:INFO:Uploading results into container
2023-11-04 19:29:34,009:INFO:Uploading model into container now
2023-11-04 19:29:34,010:INFO:_master_model_container: 17
2023-11-04 19:29:34,010:INFO:_display_container: 2
2023-11-04 19:29:34,010:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=2529, ...)
2023-11-04 19:29:34,010:INFO:create_model() successfully completed......................................
2023-11-04 19:29:34,120:INFO:SubProcess create_model() end ==================================
2023-11-04 19:29:34,120:INFO:Creating metrics dataframe
2023-11-04 19:29:34,127:INFO:Initializing Light Gradient Boosting Machine
2023-11-04 19:29:34,127:INFO:Total runtime is 0.10645840167999267 minutes
2023-11-04 19:29:34,129:INFO:SubProcess create_model() called ==================================
2023-11-04 19:29:34,129:INFO:Initializing create_model()
2023-11-04 19:29:34,129:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb43617f400>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4356cea30>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:29:34,129:INFO:Checking exceptions
2023-11-04 19:29:34,129:INFO:Importing libraries
2023-11-04 19:29:34,129:INFO:Copying training dataset
2023-11-04 19:29:34,131:INFO:Defining folds
2023-11-04 19:29:34,131:INFO:Declaring metric variables
2023-11-04 19:29:34,133:INFO:Importing untrained model
2023-11-04 19:29:34,135:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-04 19:29:34,138:INFO:Starting cross validation
2023-11-04 19:29:34,139:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:29:34,705:INFO:Calculating mean and std
2023-11-04 19:29:34,706:INFO:Creating metrics dataframe
2023-11-04 19:29:34,707:INFO:Uploading results into container
2023-11-04 19:29:34,708:INFO:Uploading model into container now
2023-11-04 19:29:34,708:INFO:_master_model_container: 18
2023-11-04 19:29:34,708:INFO:_display_container: 2
2023-11-04 19:29:34,708:INFO:LGBMRegressor(random_state=2529)
2023-11-04 19:29:34,708:INFO:create_model() successfully completed......................................
2023-11-04 19:29:34,819:INFO:SubProcess create_model() end ==================================
2023-11-04 19:29:34,819:INFO:Creating metrics dataframe
2023-11-04 19:29:34,826:INFO:Initializing CatBoost Regressor
2023-11-04 19:29:34,826:INFO:Total runtime is 0.11810721556345621 minutes
2023-11-04 19:29:34,828:INFO:SubProcess create_model() called ==================================
2023-11-04 19:29:34,828:INFO:Initializing create_model()
2023-11-04 19:29:34,828:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb43617f400>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4356cea30>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:29:34,828:INFO:Checking exceptions
2023-11-04 19:29:34,828:INFO:Importing libraries
2023-11-04 19:29:34,828:INFO:Copying training dataset
2023-11-04 19:29:34,830:INFO:Defining folds
2023-11-04 19:29:34,830:INFO:Declaring metric variables
2023-11-04 19:29:34,832:INFO:Importing untrained model
2023-11-04 19:29:34,834:INFO:CatBoost Regressor Imported successfully
2023-11-04 19:29:34,837:INFO:Starting cross validation
2023-11-04 19:29:34,837:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:29:35,959:INFO:Calculating mean and std
2023-11-04 19:29:35,960:INFO:Creating metrics dataframe
2023-11-04 19:29:35,962:INFO:Uploading results into container
2023-11-04 19:29:35,963:INFO:Uploading model into container now
2023-11-04 19:29:35,963:INFO:_master_model_container: 19
2023-11-04 19:29:35,963:INFO:_display_container: 2
2023-11-04 19:29:35,963:INFO:<catboost.core.CatBoostRegressor object at 0x7fb4246023a0>
2023-11-04 19:29:35,963:INFO:create_model() successfully completed......................................
2023-11-04 19:29:36,075:INFO:SubProcess create_model() end ==================================
2023-11-04 19:29:36,075:INFO:Creating metrics dataframe
2023-11-04 19:29:36,082:INFO:Initializing Dummy Regressor
2023-11-04 19:29:36,082:INFO:Total runtime is 0.13904661734898885 minutes
2023-11-04 19:29:36,084:INFO:SubProcess create_model() called ==================================
2023-11-04 19:29:36,084:INFO:Initializing create_model()
2023-11-04 19:29:36,084:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb43617f400>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4356cea30>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:29:36,084:INFO:Checking exceptions
2023-11-04 19:29:36,084:INFO:Importing libraries
2023-11-04 19:29:36,085:INFO:Copying training dataset
2023-11-04 19:29:36,087:INFO:Defining folds
2023-11-04 19:29:36,087:INFO:Declaring metric variables
2023-11-04 19:29:36,088:INFO:Importing untrained model
2023-11-04 19:29:36,090:INFO:Dummy Regressor Imported successfully
2023-11-04 19:29:36,093:INFO:Starting cross validation
2023-11-04 19:29:36,094:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:29:36,146:INFO:Calculating mean and std
2023-11-04 19:29:36,147:INFO:Creating metrics dataframe
2023-11-04 19:29:36,148:INFO:Uploading results into container
2023-11-04 19:29:36,149:INFO:Uploading model into container now
2023-11-04 19:29:36,149:INFO:_master_model_container: 20
2023-11-04 19:29:36,149:INFO:_display_container: 2
2023-11-04 19:29:36,149:INFO:DummyRegressor()
2023-11-04 19:29:36,149:INFO:create_model() successfully completed......................................
2023-11-04 19:29:36,260:INFO:SubProcess create_model() end ==================================
2023-11-04 19:29:36,260:INFO:Creating metrics dataframe
2023-11-04 19:29:36,272:INFO:Initializing create_model()
2023-11-04 19:29:36,272:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb43617f400>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=2529), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:29:36,272:INFO:Checking exceptions
2023-11-04 19:29:36,273:INFO:Importing libraries
2023-11-04 19:29:36,274:INFO:Copying training dataset
2023-11-04 19:29:36,275:INFO:Defining folds
2023-11-04 19:29:36,275:INFO:Declaring metric variables
2023-11-04 19:29:36,276:INFO:Importing untrained model
2023-11-04 19:29:36,276:INFO:Declaring custom model
2023-11-04 19:29:36,276:INFO:Extra Trees Regressor Imported successfully
2023-11-04 19:29:36,277:INFO:Cross validation set to False
2023-11-04 19:29:36,277:INFO:Fitting Model
2023-11-04 19:29:36,337:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=2529)
2023-11-04 19:29:36,337:INFO:create_model() successfully completed......................................
2023-11-04 19:29:36,463:INFO:_master_model_container: 20
2023-11-04 19:29:36,463:INFO:_display_container: 2
2023-11-04 19:29:36,464:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=2529)
2023-11-04 19:29:36,464:INFO:compare_models() successfully completed......................................
2023-11-04 19:29:51,680:INFO:PyCaret RegressionExperiment
2023-11-04 19:29:51,680:INFO:Logging name: reg-default-name
2023-11-04 19:29:51,680:INFO:ML Usecase: MLUsecase.REGRESSION
2023-11-04 19:29:51,680:INFO:version 3.1.0
2023-11-04 19:29:51,681:INFO:Initializing setup()
2023-11-04 19:29:51,681:INFO:self.USI: f671
2023-11-04 19:29:51,681:INFO:self._variable_keys: {'USI', 'log_plots_param', 'gpu_param', 'fold_generator', 'X_test', 'html_param', '_ml_usecase', '_available_plots', 'exp_id', 'target_param', 'idx', 'fold_shuffle_param', 'n_jobs_param', 'seed', 'exp_name_log', 'X', 'y_train', 'transform_target_param', 'data', 'y_test', 'fold_groups_param', 'logging_param', 'gpu_n_jobs_param', 'y', 'X_train', 'memory', 'pipeline'}
2023-11-04 19:29:51,681:INFO:Checking environment
2023-11-04 19:29:51,681:INFO:python_version: 3.9.13
2023-11-04 19:29:51,681:INFO:python_build: ('main', 'Aug 25 2022 18:29:29')
2023-11-04 19:29:51,681:INFO:machine: x86_64
2023-11-04 19:29:51,681:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-11-04 19:29:51,681:INFO:Memory: svmem(total=17179869184, available=1433333760, percent=91.7, used=1921175552, free=18280448, active=1416077312, inactive=1412681728, wired=505098240)
2023-11-04 19:29:51,681:INFO:Physical Core: 8
2023-11-04 19:29:51,681:INFO:Logical Core: 8
2023-11-04 19:29:51,681:INFO:Checking libraries
2023-11-04 19:29:51,682:INFO:System:
2023-11-04 19:29:51,682:INFO:    python: 3.9.13 (main, Aug 25 2022, 18:29:29)  [Clang 12.0.0 ]
2023-11-04 19:29:51,682:INFO:executable: /Users/michal/opt/anaconda3/bin/python
2023-11-04 19:29:51,682:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-11-04 19:29:51,682:INFO:PyCaret required dependencies:
2023-11-04 19:29:51,682:INFO:                 pip: 22.2.2
2023-11-04 19:29:51,682:INFO:          setuptools: 63.4.1
2023-11-04 19:29:51,682:INFO:             pycaret: 3.1.0
2023-11-04 19:29:51,682:INFO:             IPython: 7.31.1
2023-11-04 19:29:51,682:INFO:          ipywidgets: 7.6.5
2023-11-04 19:29:51,682:INFO:                tqdm: 4.64.1
2023-11-04 19:29:51,682:INFO:               numpy: 1.21.5
2023-11-04 19:29:51,682:INFO:              pandas: 1.4.4
2023-11-04 19:29:51,682:INFO:              jinja2: 2.11.3
2023-11-04 19:29:51,682:INFO:               scipy: 1.10.1
2023-11-04 19:29:51,683:INFO:              joblib: 1.2.0
2023-11-04 19:29:51,683:INFO:             sklearn: 1.0.2
2023-11-04 19:29:51,683:INFO:                pyod: 1.1.1
2023-11-04 19:29:51,683:INFO:            imblearn: 0.10.1
2023-11-04 19:29:51,683:INFO:   category_encoders: 2.6.3
2023-11-04 19:29:51,683:INFO:            lightgbm: 3.3.5
2023-11-04 19:29:51,683:INFO:               numba: 0.55.1
2023-11-04 19:29:51,683:INFO:            requests: 2.28.1
2023-11-04 19:29:51,683:INFO:          matplotlib: 3.5.2
2023-11-04 19:29:51,683:INFO:          scikitplot: 0.3.7
2023-11-04 19:29:51,683:INFO:         yellowbrick: 1.5
2023-11-04 19:29:51,683:INFO:              plotly: 5.9.0
2023-11-04 19:29:51,683:INFO:    plotly-resampler: Not installed
2023-11-04 19:29:51,683:INFO:             kaleido: 0.2.1
2023-11-04 19:29:51,683:INFO:           schemdraw: 0.15
2023-11-04 19:29:51,683:INFO:         statsmodels: 0.13.2
2023-11-04 19:29:51,683:INFO:              sktime: 0.21.1
2023-11-04 19:29:51,683:INFO:               tbats: 1.1.3
2023-11-04 19:29:51,683:INFO:            pmdarima: 2.0.4
2023-11-04 19:29:51,684:INFO:              psutil: 5.9.0
2023-11-04 19:29:51,684:INFO:          markupsafe: 2.0.1
2023-11-04 19:29:51,684:INFO:             pickle5: Not installed
2023-11-04 19:29:51,684:INFO:         cloudpickle: 2.0.0
2023-11-04 19:29:51,684:INFO:         deprecation: 2.1.0
2023-11-04 19:29:51,684:INFO:              xxhash: 3.4.1
2023-11-04 19:29:51,684:INFO:           wurlitzer: 3.0.2
2023-11-04 19:29:51,684:INFO:PyCaret optional dependencies:
2023-11-04 19:29:51,684:INFO:                shap: 0.41.0
2023-11-04 19:29:51,684:INFO:           interpret: Not installed
2023-11-04 19:29:51,684:INFO:                umap: 0.5.3
2023-11-04 19:29:51,684:INFO:     ydata_profiling: Not installed
2023-11-04 19:29:51,684:INFO:  explainerdashboard: Not installed
2023-11-04 19:29:51,684:INFO:             autoviz: Not installed
2023-11-04 19:29:51,684:INFO:           fairlearn: Not installed
2023-11-04 19:29:51,684:INFO:          deepchecks: Not installed
2023-11-04 19:29:51,684:INFO:             xgboost: 1.7.4
2023-11-04 19:29:51,685:INFO:            catboost: 1.2
2023-11-04 19:29:51,685:INFO:              kmodes: Not installed
2023-11-04 19:29:51,685:INFO:             mlxtend: 0.21.0
2023-11-04 19:29:51,685:INFO:       statsforecast: Not installed
2023-11-04 19:29:51,685:INFO:        tune_sklearn: Not installed
2023-11-04 19:29:51,685:INFO:                 ray: Not installed
2023-11-04 19:29:51,685:INFO:            hyperopt: Not installed
2023-11-04 19:29:51,685:INFO:              optuna: Not installed
2023-11-04 19:29:51,685:INFO:               skopt: Not installed
2023-11-04 19:29:51,685:INFO:              mlflow: Not installed
2023-11-04 19:29:51,685:INFO:              gradio: Not installed
2023-11-04 19:29:51,685:INFO:             fastapi: Not installed
2023-11-04 19:29:51,685:INFO:             uvicorn: Not installed
2023-11-04 19:29:51,685:INFO:              m2cgen: Not installed
2023-11-04 19:29:51,685:INFO:           evidently: Not installed
2023-11-04 19:29:51,685:INFO:               fugue: Not installed
2023-11-04 19:29:51,685:INFO:           streamlit: Not installed
2023-11-04 19:29:51,686:INFO:             prophet: Not installed
2023-11-04 19:29:51,686:INFO:None
2023-11-04 19:29:51,686:INFO:Set up data.
2023-11-04 19:29:51,695:INFO:Set up folding strategy.
2023-11-04 19:29:51,695:INFO:Set up train/test split.
2023-11-04 19:29:51,699:INFO:Set up index.
2023-11-04 19:29:51,699:INFO:Assigning column types.
2023-11-04 19:29:51,701:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-04 19:29:51,702:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-04 19:29:51,707:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 19:29:51,713:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:29:51,760:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:29:51,786:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:29:51,786:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:29:51,788:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:29:51,789:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-04 19:29:51,791:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 19:29:51,794:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:29:51,827:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:29:51,853:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:29:51,853:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:29:51,855:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:29:51,855:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-11-04 19:29:51,858:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 19:29:51,861:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:29:51,893:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:29:51,919:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:29:51,920:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:29:51,921:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:29:51,924:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 19:29:51,927:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:29:51,959:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:29:51,985:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:29:51,985:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:29:51,987:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:29:51,987:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-11-04 19:29:51,992:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:29:52,025:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:29:52,051:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:29:52,051:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:29:52,053:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:29:52,058:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:29:52,090:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:29:52,115:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:29:52,116:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:29:52,117:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:29:52,117:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-11-04 19:29:52,155:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:29:52,180:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:29:52,181:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:29:52,182:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:29:52,219:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:29:52,245:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:29:52,245:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:29:52,247:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:29:52,247:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-04 19:29:52,284:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:29:52,310:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:29:52,311:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:29:52,349:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:29:52,375:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:29:52,376:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:29:52,377:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-11-04 19:29:52,439:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:29:52,441:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:29:52,507:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:29:52,509:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:29:52,509:INFO:Preparing preprocessing pipeline...
2023-11-04 19:29:52,509:INFO:Set up simple imputation.
2023-11-04 19:29:52,509:INFO:Set up variance threshold.
2023-11-04 19:29:52,509:INFO:Set up removing multicollinearity.
2023-11-04 19:29:52,510:INFO:Set up column name cleaning.
2023-11-04 19:29:52,530:INFO:Finished creating preprocessing pipeline.
2023-11-04 19:29:52,533:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/h9/5_75v3qs13x63s15wwxdrd000000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['solv_dG [kcal/mol]',
                                             'Bond dissociation entalphy',
                                             'water_ads [kcal/mol]', 'Coating',
                                             'Organic Matter Conc.', 'pH',
                                             'Primary Size', 'Initial Conc.',
                                             'Temp.', 'Ionic Strenght', 'Light',
                                             'MW', 'Noxy', 'χ', 'χox',
                                             'Z_metal', 'Zv...
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.1))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-11-04 19:29:52,533:INFO:Creating final display dataframe.
2023-11-04 19:29:52,579:INFO:Setup _display_container:                     Description             Value
0                    Session id              1598
1                        Target  %dissolved solid
2                   Target type        Regression
3           Original data shape         (246, 21)
4        Transformed data shape         (246, 19)
5   Transformed train set shape         (172, 19)
6    Transformed test set shape          (74, 19)
7              Numeric features                20
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12       Low variance threshold               0.1
13     Remove multicollinearity              True
14  Multicollinearity threshold              0.95
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              f671
2023-11-04 19:29:52,648:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:29:52,650:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:29:52,714:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:29:52,715:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:29:52,716:INFO:setup() successfully completed in 1.04s...............
2023-11-04 19:29:52,716:INFO:Initializing compare_models()
2023-11-04 19:29:52,716:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4243c1dc0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fb4243c1dc0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-11-04 19:29:52,716:INFO:Checking exceptions
2023-11-04 19:29:52,717:INFO:Preparing display monitor
2023-11-04 19:29:52,733:INFO:Initializing Linear Regression
2023-11-04 19:29:52,733:INFO:Total runtime is 2.7179718017578126e-06 minutes
2023-11-04 19:29:52,735:INFO:SubProcess create_model() called ==================================
2023-11-04 19:29:52,735:INFO:Initializing create_model()
2023-11-04 19:29:52,735:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4243c1dc0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb424522b20>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:29:52,735:INFO:Checking exceptions
2023-11-04 19:29:52,735:INFO:Importing libraries
2023-11-04 19:29:52,735:INFO:Copying training dataset
2023-11-04 19:29:52,737:INFO:Defining folds
2023-11-04 19:29:52,737:INFO:Declaring metric variables
2023-11-04 19:29:52,739:INFO:Importing untrained model
2023-11-04 19:29:52,741:INFO:Linear Regression Imported successfully
2023-11-04 19:29:52,744:INFO:Starting cross validation
2023-11-04 19:29:52,745:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:29:52,804:INFO:Calculating mean and std
2023-11-04 19:29:52,805:INFO:Creating metrics dataframe
2023-11-04 19:29:52,806:INFO:Uploading results into container
2023-11-04 19:29:52,807:INFO:Uploading model into container now
2023-11-04 19:29:52,807:INFO:_master_model_container: 1
2023-11-04 19:29:52,807:INFO:_display_container: 2
2023-11-04 19:29:52,807:INFO:LinearRegression(n_jobs=-1)
2023-11-04 19:29:52,807:INFO:create_model() successfully completed......................................
2023-11-04 19:29:52,921:INFO:SubProcess create_model() end ==================================
2023-11-04 19:29:52,922:INFO:Creating metrics dataframe
2023-11-04 19:29:52,926:INFO:Initializing Lasso Regression
2023-11-04 19:29:52,926:INFO:Total runtime is 0.0032150824864705402 minutes
2023-11-04 19:29:52,928:INFO:SubProcess create_model() called ==================================
2023-11-04 19:29:52,928:INFO:Initializing create_model()
2023-11-04 19:29:52,928:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4243c1dc0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb424522b20>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:29:52,928:INFO:Checking exceptions
2023-11-04 19:29:52,928:INFO:Importing libraries
2023-11-04 19:29:52,928:INFO:Copying training dataset
2023-11-04 19:29:52,930:INFO:Defining folds
2023-11-04 19:29:52,930:INFO:Declaring metric variables
2023-11-04 19:29:52,931:INFO:Importing untrained model
2023-11-04 19:29:52,933:INFO:Lasso Regression Imported successfully
2023-11-04 19:29:52,936:INFO:Starting cross validation
2023-11-04 19:29:52,936:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:29:53,001:INFO:Calculating mean and std
2023-11-04 19:29:53,002:INFO:Creating metrics dataframe
2023-11-04 19:29:53,003:INFO:Uploading results into container
2023-11-04 19:29:53,004:INFO:Uploading model into container now
2023-11-04 19:29:53,004:INFO:_master_model_container: 2
2023-11-04 19:29:53,004:INFO:_display_container: 2
2023-11-04 19:29:53,004:INFO:Lasso(random_state=1598)
2023-11-04 19:29:53,004:INFO:create_model() successfully completed......................................
2023-11-04 19:29:53,112:INFO:SubProcess create_model() end ==================================
2023-11-04 19:29:53,112:INFO:Creating metrics dataframe
2023-11-04 19:29:53,117:INFO:Initializing Ridge Regression
2023-11-04 19:29:53,117:INFO:Total runtime is 0.006399683157602946 minutes
2023-11-04 19:29:53,119:INFO:SubProcess create_model() called ==================================
2023-11-04 19:29:53,119:INFO:Initializing create_model()
2023-11-04 19:29:53,119:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4243c1dc0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb424522b20>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:29:53,119:INFO:Checking exceptions
2023-11-04 19:29:53,119:INFO:Importing libraries
2023-11-04 19:29:53,119:INFO:Copying training dataset
2023-11-04 19:29:53,121:INFO:Defining folds
2023-11-04 19:29:53,121:INFO:Declaring metric variables
2023-11-04 19:29:53,122:INFO:Importing untrained model
2023-11-04 19:29:53,124:INFO:Ridge Regression Imported successfully
2023-11-04 19:29:53,127:INFO:Starting cross validation
2023-11-04 19:29:53,127:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:29:53,181:INFO:Calculating mean and std
2023-11-04 19:29:53,181:INFO:Creating metrics dataframe
2023-11-04 19:29:53,183:INFO:Uploading results into container
2023-11-04 19:29:53,183:INFO:Uploading model into container now
2023-11-04 19:29:53,183:INFO:_master_model_container: 3
2023-11-04 19:29:53,183:INFO:_display_container: 2
2023-11-04 19:29:53,184:INFO:Ridge(random_state=1598)
2023-11-04 19:29:53,184:INFO:create_model() successfully completed......................................
2023-11-04 19:29:53,295:INFO:SubProcess create_model() end ==================================
2023-11-04 19:29:53,295:INFO:Creating metrics dataframe
2023-11-04 19:29:53,300:INFO:Initializing Elastic Net
2023-11-04 19:29:53,301:INFO:Total runtime is 0.009459849198659262 minutes
2023-11-04 19:29:53,302:INFO:SubProcess create_model() called ==================================
2023-11-04 19:29:53,303:INFO:Initializing create_model()
2023-11-04 19:29:53,303:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4243c1dc0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb424522b20>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:29:53,303:INFO:Checking exceptions
2023-11-04 19:29:53,303:INFO:Importing libraries
2023-11-04 19:29:53,303:INFO:Copying training dataset
2023-11-04 19:29:53,305:INFO:Defining folds
2023-11-04 19:29:53,305:INFO:Declaring metric variables
2023-11-04 19:29:53,306:INFO:Importing untrained model
2023-11-04 19:29:53,308:INFO:Elastic Net Imported successfully
2023-11-04 19:29:53,311:INFO:Starting cross validation
2023-11-04 19:29:53,311:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:29:53,368:INFO:Calculating mean and std
2023-11-04 19:29:53,368:INFO:Creating metrics dataframe
2023-11-04 19:29:53,370:INFO:Uploading results into container
2023-11-04 19:29:53,370:INFO:Uploading model into container now
2023-11-04 19:29:53,370:INFO:_master_model_container: 4
2023-11-04 19:29:53,370:INFO:_display_container: 2
2023-11-04 19:29:53,371:INFO:ElasticNet(random_state=1598)
2023-11-04 19:29:53,371:INFO:create_model() successfully completed......................................
2023-11-04 19:29:53,484:INFO:SubProcess create_model() end ==================================
2023-11-04 19:29:53,484:INFO:Creating metrics dataframe
2023-11-04 19:29:53,489:INFO:Initializing Least Angle Regression
2023-11-04 19:29:53,489:INFO:Total runtime is 0.012598733107248943 minutes
2023-11-04 19:29:53,491:INFO:SubProcess create_model() called ==================================
2023-11-04 19:29:53,491:INFO:Initializing create_model()
2023-11-04 19:29:53,491:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4243c1dc0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb424522b20>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:29:53,491:INFO:Checking exceptions
2023-11-04 19:29:53,491:INFO:Importing libraries
2023-11-04 19:29:53,491:INFO:Copying training dataset
2023-11-04 19:29:53,493:INFO:Defining folds
2023-11-04 19:29:53,493:INFO:Declaring metric variables
2023-11-04 19:29:53,494:INFO:Importing untrained model
2023-11-04 19:29:53,496:INFO:Least Angle Regression Imported successfully
2023-11-04 19:29:53,499:INFO:Starting cross validation
2023-11-04 19:29:53,499:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:29:53,519:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:29:53,522:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:29:53,525:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:29:53,531:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:29:53,533:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:29:53,543:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:29:53,546:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:29:53,548:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:29:53,551:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:29:53,551:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:29:53,558:INFO:Calculating mean and std
2023-11-04 19:29:53,559:INFO:Creating metrics dataframe
2023-11-04 19:29:53,560:INFO:Uploading results into container
2023-11-04 19:29:53,560:INFO:Uploading model into container now
2023-11-04 19:29:53,561:INFO:_master_model_container: 5
2023-11-04 19:29:53,561:INFO:_display_container: 2
2023-11-04 19:29:53,561:INFO:Lars(random_state=1598)
2023-11-04 19:29:53,561:INFO:create_model() successfully completed......................................
2023-11-04 19:29:53,673:INFO:SubProcess create_model() end ==================================
2023-11-04 19:29:53,673:INFO:Creating metrics dataframe
2023-11-04 19:29:53,679:INFO:Initializing Lasso Least Angle Regression
2023-11-04 19:29:53,679:INFO:Total runtime is 0.015762964884440105 minutes
2023-11-04 19:29:53,681:INFO:SubProcess create_model() called ==================================
2023-11-04 19:29:53,681:INFO:Initializing create_model()
2023-11-04 19:29:53,681:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4243c1dc0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb424522b20>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:29:53,681:INFO:Checking exceptions
2023-11-04 19:29:53,681:INFO:Importing libraries
2023-11-04 19:29:53,681:INFO:Copying training dataset
2023-11-04 19:29:53,682:INFO:Defining folds
2023-11-04 19:29:53,683:INFO:Declaring metric variables
2023-11-04 19:29:53,684:INFO:Importing untrained model
2023-11-04 19:29:53,686:INFO:Lasso Least Angle Regression Imported successfully
2023-11-04 19:29:53,689:INFO:Starting cross validation
2023-11-04 19:29:53,689:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:29:53,712:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:29:53,717:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:29:53,718:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:29:53,727:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:29:53,728:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:29:53,732:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:29:53,734:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:29:53,735:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:29:53,736:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:29:53,743:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:29:53,748:INFO:Calculating mean and std
2023-11-04 19:29:53,749:INFO:Creating metrics dataframe
2023-11-04 19:29:53,751:INFO:Uploading results into container
2023-11-04 19:29:53,751:INFO:Uploading model into container now
2023-11-04 19:29:53,752:INFO:_master_model_container: 6
2023-11-04 19:29:53,752:INFO:_display_container: 2
2023-11-04 19:29:53,752:INFO:LassoLars(random_state=1598)
2023-11-04 19:29:53,752:INFO:create_model() successfully completed......................................
2023-11-04 19:29:53,867:INFO:SubProcess create_model() end ==================================
2023-11-04 19:29:53,867:INFO:Creating metrics dataframe
2023-11-04 19:29:53,873:INFO:Initializing Orthogonal Matching Pursuit
2023-11-04 19:29:53,874:INFO:Total runtime is 0.019009947776794434 minutes
2023-11-04 19:29:53,875:INFO:SubProcess create_model() called ==================================
2023-11-04 19:29:53,876:INFO:Initializing create_model()
2023-11-04 19:29:53,876:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4243c1dc0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb424522b20>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:29:53,876:INFO:Checking exceptions
2023-11-04 19:29:53,876:INFO:Importing libraries
2023-11-04 19:29:53,876:INFO:Copying training dataset
2023-11-04 19:29:53,877:INFO:Defining folds
2023-11-04 19:29:53,877:INFO:Declaring metric variables
2023-11-04 19:29:53,879:INFO:Importing untrained model
2023-11-04 19:29:53,880:INFO:Orthogonal Matching Pursuit Imported successfully
2023-11-04 19:29:53,884:INFO:Starting cross validation
2023-11-04 19:29:53,885:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:29:53,905:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:29:53,913:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:29:53,918:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:29:53,922:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:29:53,927:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:29:53,928:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:29:53,929:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:29:53,934:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:29:53,938:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:29:53,944:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:29:53,949:INFO:Calculating mean and std
2023-11-04 19:29:53,950:INFO:Creating metrics dataframe
2023-11-04 19:29:53,951:INFO:Uploading results into container
2023-11-04 19:29:53,951:INFO:Uploading model into container now
2023-11-04 19:29:53,952:INFO:_master_model_container: 7
2023-11-04 19:29:53,952:INFO:_display_container: 2
2023-11-04 19:29:53,952:INFO:OrthogonalMatchingPursuit()
2023-11-04 19:29:53,952:INFO:create_model() successfully completed......................................
2023-11-04 19:29:54,062:INFO:SubProcess create_model() end ==================================
2023-11-04 19:29:54,062:INFO:Creating metrics dataframe
2023-11-04 19:29:54,068:INFO:Initializing Bayesian Ridge
2023-11-04 19:29:54,068:INFO:Total runtime is 0.022251200675964356 minutes
2023-11-04 19:29:54,070:INFO:SubProcess create_model() called ==================================
2023-11-04 19:29:54,070:INFO:Initializing create_model()
2023-11-04 19:29:54,070:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4243c1dc0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb424522b20>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:29:54,070:INFO:Checking exceptions
2023-11-04 19:29:54,070:INFO:Importing libraries
2023-11-04 19:29:54,070:INFO:Copying training dataset
2023-11-04 19:29:54,073:INFO:Defining folds
2023-11-04 19:29:54,073:INFO:Declaring metric variables
2023-11-04 19:29:54,074:INFO:Importing untrained model
2023-11-04 19:29:54,076:INFO:Bayesian Ridge Imported successfully
2023-11-04 19:29:54,079:INFO:Starting cross validation
2023-11-04 19:29:54,079:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:29:54,136:INFO:Calculating mean and std
2023-11-04 19:29:54,136:INFO:Creating metrics dataframe
2023-11-04 19:29:54,138:INFO:Uploading results into container
2023-11-04 19:29:54,138:INFO:Uploading model into container now
2023-11-04 19:29:54,138:INFO:_master_model_container: 8
2023-11-04 19:29:54,139:INFO:_display_container: 2
2023-11-04 19:29:54,139:INFO:BayesianRidge()
2023-11-04 19:29:54,139:INFO:create_model() successfully completed......................................
2023-11-04 19:29:54,247:INFO:SubProcess create_model() end ==================================
2023-11-04 19:29:54,247:INFO:Creating metrics dataframe
2023-11-04 19:29:54,252:INFO:Initializing Passive Aggressive Regressor
2023-11-04 19:29:54,252:INFO:Total runtime is 0.02532338301340739 minutes
2023-11-04 19:29:54,254:INFO:SubProcess create_model() called ==================================
2023-11-04 19:29:54,254:INFO:Initializing create_model()
2023-11-04 19:29:54,254:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4243c1dc0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb424522b20>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:29:54,254:INFO:Checking exceptions
2023-11-04 19:29:54,254:INFO:Importing libraries
2023-11-04 19:29:54,255:INFO:Copying training dataset
2023-11-04 19:29:54,257:INFO:Defining folds
2023-11-04 19:29:54,257:INFO:Declaring metric variables
2023-11-04 19:29:54,258:INFO:Importing untrained model
2023-11-04 19:29:54,260:INFO:Passive Aggressive Regressor Imported successfully
2023-11-04 19:29:54,263:INFO:Starting cross validation
2023-11-04 19:29:54,264:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:29:54,327:INFO:Calculating mean and std
2023-11-04 19:29:54,327:INFO:Creating metrics dataframe
2023-11-04 19:29:54,329:INFO:Uploading results into container
2023-11-04 19:29:54,329:INFO:Uploading model into container now
2023-11-04 19:29:54,329:INFO:_master_model_container: 9
2023-11-04 19:29:54,329:INFO:_display_container: 2
2023-11-04 19:29:54,330:INFO:PassiveAggressiveRegressor(random_state=1598)
2023-11-04 19:29:54,330:INFO:create_model() successfully completed......................................
2023-11-04 19:29:54,440:INFO:SubProcess create_model() end ==================================
2023-11-04 19:29:54,440:INFO:Creating metrics dataframe
2023-11-04 19:29:54,446:INFO:Initializing Huber Regressor
2023-11-04 19:29:54,446:INFO:Total runtime is 0.02854423522949219 minutes
2023-11-04 19:29:54,447:INFO:SubProcess create_model() called ==================================
2023-11-04 19:29:54,448:INFO:Initializing create_model()
2023-11-04 19:29:54,448:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4243c1dc0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb424522b20>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:29:54,448:INFO:Checking exceptions
2023-11-04 19:29:54,448:INFO:Importing libraries
2023-11-04 19:29:54,448:INFO:Copying training dataset
2023-11-04 19:29:54,450:INFO:Defining folds
2023-11-04 19:29:54,450:INFO:Declaring metric variables
2023-11-04 19:29:54,452:INFO:Importing untrained model
2023-11-04 19:29:54,453:INFO:Huber Regressor Imported successfully
2023-11-04 19:29:54,456:INFO:Starting cross validation
2023-11-04 19:29:54,457:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:29:54,490:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:29:54,492:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:29:54,493:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:29:54,504:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:29:54,506:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:29:54,514:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:29:54,521:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:29:54,524:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:29:54,527:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:29:54,530:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:29:54,535:INFO:Calculating mean and std
2023-11-04 19:29:54,535:INFO:Creating metrics dataframe
2023-11-04 19:29:54,537:INFO:Uploading results into container
2023-11-04 19:29:54,537:INFO:Uploading model into container now
2023-11-04 19:29:54,537:INFO:_master_model_container: 10
2023-11-04 19:29:54,537:INFO:_display_container: 2
2023-11-04 19:29:54,537:INFO:HuberRegressor()
2023-11-04 19:29:54,537:INFO:create_model() successfully completed......................................
2023-11-04 19:29:54,645:INFO:SubProcess create_model() end ==================================
2023-11-04 19:29:54,645:INFO:Creating metrics dataframe
2023-11-04 19:29:54,651:INFO:Initializing K Neighbors Regressor
2023-11-04 19:29:54,651:INFO:Total runtime is 0.03196709950764974 minutes
2023-11-04 19:29:54,653:INFO:SubProcess create_model() called ==================================
2023-11-04 19:29:54,653:INFO:Initializing create_model()
2023-11-04 19:29:54,653:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4243c1dc0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb424522b20>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:29:54,653:INFO:Checking exceptions
2023-11-04 19:29:54,653:INFO:Importing libraries
2023-11-04 19:29:54,653:INFO:Copying training dataset
2023-11-04 19:29:54,656:INFO:Defining folds
2023-11-04 19:29:54,656:INFO:Declaring metric variables
2023-11-04 19:29:54,657:INFO:Importing untrained model
2023-11-04 19:29:54,659:INFO:K Neighbors Regressor Imported successfully
2023-11-04 19:29:54,662:INFO:Starting cross validation
2023-11-04 19:29:54,663:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:29:54,728:INFO:Calculating mean and std
2023-11-04 19:29:54,728:INFO:Creating metrics dataframe
2023-11-04 19:29:54,730:INFO:Uploading results into container
2023-11-04 19:29:54,730:INFO:Uploading model into container now
2023-11-04 19:29:54,730:INFO:_master_model_container: 11
2023-11-04 19:29:54,730:INFO:_display_container: 2
2023-11-04 19:29:54,730:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-04 19:29:54,730:INFO:create_model() successfully completed......................................
2023-11-04 19:29:54,838:INFO:SubProcess create_model() end ==================================
2023-11-04 19:29:54,838:INFO:Creating metrics dataframe
2023-11-04 19:29:54,844:INFO:Initializing Decision Tree Regressor
2023-11-04 19:29:54,844:INFO:Total runtime is 0.03518508275349935 minutes
2023-11-04 19:29:54,846:INFO:SubProcess create_model() called ==================================
2023-11-04 19:29:54,846:INFO:Initializing create_model()
2023-11-04 19:29:54,846:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4243c1dc0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb424522b20>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:29:54,846:INFO:Checking exceptions
2023-11-04 19:29:54,846:INFO:Importing libraries
2023-11-04 19:29:54,846:INFO:Copying training dataset
2023-11-04 19:29:54,848:INFO:Defining folds
2023-11-04 19:29:54,848:INFO:Declaring metric variables
2023-11-04 19:29:54,850:INFO:Importing untrained model
2023-11-04 19:29:54,852:INFO:Decision Tree Regressor Imported successfully
2023-11-04 19:29:54,855:INFO:Starting cross validation
2023-11-04 19:29:54,855:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:29:54,914:INFO:Calculating mean and std
2023-11-04 19:29:54,914:INFO:Creating metrics dataframe
2023-11-04 19:29:54,916:INFO:Uploading results into container
2023-11-04 19:29:54,916:INFO:Uploading model into container now
2023-11-04 19:29:54,916:INFO:_master_model_container: 12
2023-11-04 19:29:54,916:INFO:_display_container: 2
2023-11-04 19:29:54,916:INFO:DecisionTreeRegressor(random_state=1598)
2023-11-04 19:29:54,916:INFO:create_model() successfully completed......................................
2023-11-04 19:29:55,024:INFO:SubProcess create_model() end ==================================
2023-11-04 19:29:55,025:INFO:Creating metrics dataframe
2023-11-04 19:29:55,031:INFO:Initializing Random Forest Regressor
2023-11-04 19:29:55,031:INFO:Total runtime is 0.038299481074015304 minutes
2023-11-04 19:29:55,033:INFO:SubProcess create_model() called ==================================
2023-11-04 19:29:55,033:INFO:Initializing create_model()
2023-11-04 19:29:55,033:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4243c1dc0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb424522b20>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:29:55,033:INFO:Checking exceptions
2023-11-04 19:29:55,033:INFO:Importing libraries
2023-11-04 19:29:55,033:INFO:Copying training dataset
2023-11-04 19:29:55,035:INFO:Defining folds
2023-11-04 19:29:55,035:INFO:Declaring metric variables
2023-11-04 19:29:55,037:INFO:Importing untrained model
2023-11-04 19:29:55,039:INFO:Random Forest Regressor Imported successfully
2023-11-04 19:29:55,042:INFO:Starting cross validation
2023-11-04 19:29:55,042:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:29:55,350:INFO:Calculating mean and std
2023-11-04 19:29:55,350:INFO:Creating metrics dataframe
2023-11-04 19:29:55,352:INFO:Uploading results into container
2023-11-04 19:29:55,353:INFO:Uploading model into container now
2023-11-04 19:29:55,353:INFO:_master_model_container: 13
2023-11-04 19:29:55,353:INFO:_display_container: 2
2023-11-04 19:29:55,353:INFO:RandomForestRegressor(n_jobs=-1, random_state=1598)
2023-11-04 19:29:55,353:INFO:create_model() successfully completed......................................
2023-11-04 19:29:55,462:INFO:SubProcess create_model() end ==================================
2023-11-04 19:29:55,462:INFO:Creating metrics dataframe
2023-11-04 19:29:55,468:INFO:Initializing Extra Trees Regressor
2023-11-04 19:29:55,468:INFO:Total runtime is 0.0455894152323405 minutes
2023-11-04 19:29:55,470:INFO:SubProcess create_model() called ==================================
2023-11-04 19:29:55,470:INFO:Initializing create_model()
2023-11-04 19:29:55,470:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4243c1dc0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb424522b20>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:29:55,470:INFO:Checking exceptions
2023-11-04 19:29:55,470:INFO:Importing libraries
2023-11-04 19:29:55,470:INFO:Copying training dataset
2023-11-04 19:29:55,472:INFO:Defining folds
2023-11-04 19:29:55,472:INFO:Declaring metric variables
2023-11-04 19:29:55,473:INFO:Importing untrained model
2023-11-04 19:29:55,475:INFO:Extra Trees Regressor Imported successfully
2023-11-04 19:29:55,479:INFO:Starting cross validation
2023-11-04 19:29:55,480:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:29:55,724:INFO:Calculating mean and std
2023-11-04 19:29:55,724:INFO:Creating metrics dataframe
2023-11-04 19:29:55,726:INFO:Uploading results into container
2023-11-04 19:29:55,727:INFO:Uploading model into container now
2023-11-04 19:29:55,727:INFO:_master_model_container: 14
2023-11-04 19:29:55,727:INFO:_display_container: 2
2023-11-04 19:29:55,727:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1598)
2023-11-04 19:29:55,727:INFO:create_model() successfully completed......................................
2023-11-04 19:29:55,836:INFO:SubProcess create_model() end ==================================
2023-11-04 19:29:55,836:INFO:Creating metrics dataframe
2023-11-04 19:29:55,842:INFO:Initializing AdaBoost Regressor
2023-11-04 19:29:55,842:INFO:Total runtime is 0.051824613412221276 minutes
2023-11-04 19:29:55,844:INFO:SubProcess create_model() called ==================================
2023-11-04 19:29:55,844:INFO:Initializing create_model()
2023-11-04 19:29:55,844:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4243c1dc0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb424522b20>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:29:55,845:INFO:Checking exceptions
2023-11-04 19:29:55,845:INFO:Importing libraries
2023-11-04 19:29:55,845:INFO:Copying training dataset
2023-11-04 19:29:55,846:INFO:Defining folds
2023-11-04 19:29:55,846:INFO:Declaring metric variables
2023-11-04 19:29:55,848:INFO:Importing untrained model
2023-11-04 19:29:55,849:INFO:AdaBoost Regressor Imported successfully
2023-11-04 19:29:55,853:INFO:Starting cross validation
2023-11-04 19:29:55,854:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:29:55,990:INFO:Calculating mean and std
2023-11-04 19:29:55,990:INFO:Creating metrics dataframe
2023-11-04 19:29:55,993:INFO:Uploading results into container
2023-11-04 19:29:55,993:INFO:Uploading model into container now
2023-11-04 19:29:55,993:INFO:_master_model_container: 15
2023-11-04 19:29:55,993:INFO:_display_container: 2
2023-11-04 19:29:55,993:INFO:AdaBoostRegressor(random_state=1598)
2023-11-04 19:29:55,994:INFO:create_model() successfully completed......................................
2023-11-04 19:29:56,107:INFO:SubProcess create_model() end ==================================
2023-11-04 19:29:56,107:INFO:Creating metrics dataframe
2023-11-04 19:29:56,115:INFO:Initializing Gradient Boosting Regressor
2023-11-04 19:29:56,115:INFO:Total runtime is 0.05636347929636638 minutes
2023-11-04 19:29:56,116:INFO:SubProcess create_model() called ==================================
2023-11-04 19:29:56,117:INFO:Initializing create_model()
2023-11-04 19:29:56,117:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4243c1dc0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb424522b20>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:29:56,117:INFO:Checking exceptions
2023-11-04 19:29:56,117:INFO:Importing libraries
2023-11-04 19:29:56,117:INFO:Copying training dataset
2023-11-04 19:29:56,118:INFO:Defining folds
2023-11-04 19:29:56,118:INFO:Declaring metric variables
2023-11-04 19:29:56,120:INFO:Importing untrained model
2023-11-04 19:29:56,122:INFO:Gradient Boosting Regressor Imported successfully
2023-11-04 19:29:56,126:INFO:Starting cross validation
2023-11-04 19:29:56,126:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:29:56,259:INFO:Calculating mean and std
2023-11-04 19:29:56,259:INFO:Creating metrics dataframe
2023-11-04 19:29:56,261:INFO:Uploading results into container
2023-11-04 19:29:56,262:INFO:Uploading model into container now
2023-11-04 19:29:56,262:INFO:_master_model_container: 16
2023-11-04 19:29:56,262:INFO:_display_container: 2
2023-11-04 19:29:56,263:INFO:GradientBoostingRegressor(random_state=1598)
2023-11-04 19:29:56,263:INFO:create_model() successfully completed......................................
2023-11-04 19:29:56,376:INFO:SubProcess create_model() end ==================================
2023-11-04 19:29:56,376:INFO:Creating metrics dataframe
2023-11-04 19:29:56,384:INFO:Initializing Extreme Gradient Boosting
2023-11-04 19:29:56,384:INFO:Total runtime is 0.060845883687337246 minutes
2023-11-04 19:29:56,385:INFO:SubProcess create_model() called ==================================
2023-11-04 19:29:56,386:INFO:Initializing create_model()
2023-11-04 19:29:56,386:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4243c1dc0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb424522b20>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:29:56,386:INFO:Checking exceptions
2023-11-04 19:29:56,386:INFO:Importing libraries
2023-11-04 19:29:56,386:INFO:Copying training dataset
2023-11-04 19:29:56,387:INFO:Defining folds
2023-11-04 19:29:56,387:INFO:Declaring metric variables
2023-11-04 19:29:56,389:INFO:Importing untrained model
2023-11-04 19:29:56,391:INFO:Extreme Gradient Boosting Imported successfully
2023-11-04 19:29:56,395:INFO:Starting cross validation
2023-11-04 19:29:56,395:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:29:56,549:INFO:Calculating mean and std
2023-11-04 19:29:56,550:INFO:Creating metrics dataframe
2023-11-04 19:29:56,552:INFO:Uploading results into container
2023-11-04 19:29:56,552:INFO:Uploading model into container now
2023-11-04 19:29:56,553:INFO:_master_model_container: 17
2023-11-04 19:29:56,553:INFO:_display_container: 2
2023-11-04 19:29:56,553:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=1598, ...)
2023-11-04 19:29:56,553:INFO:create_model() successfully completed......................................
2023-11-04 19:29:56,665:INFO:SubProcess create_model() end ==================================
2023-11-04 19:29:56,665:INFO:Creating metrics dataframe
2023-11-04 19:29:56,672:INFO:Initializing Light Gradient Boosting Machine
2023-11-04 19:29:56,672:INFO:Total runtime is 0.06565036773681641 minutes
2023-11-04 19:29:56,674:INFO:SubProcess create_model() called ==================================
2023-11-04 19:29:56,674:INFO:Initializing create_model()
2023-11-04 19:29:56,674:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4243c1dc0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb424522b20>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:29:56,674:INFO:Checking exceptions
2023-11-04 19:29:56,674:INFO:Importing libraries
2023-11-04 19:29:56,674:INFO:Copying training dataset
2023-11-04 19:29:56,676:INFO:Defining folds
2023-11-04 19:29:56,676:INFO:Declaring metric variables
2023-11-04 19:29:56,677:INFO:Importing untrained model
2023-11-04 19:29:56,679:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-04 19:29:56,683:INFO:Starting cross validation
2023-11-04 19:29:56,683:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:29:56,760:INFO:Calculating mean and std
2023-11-04 19:29:56,760:INFO:Creating metrics dataframe
2023-11-04 19:29:56,762:INFO:Uploading results into container
2023-11-04 19:29:56,762:INFO:Uploading model into container now
2023-11-04 19:29:56,762:INFO:_master_model_container: 18
2023-11-04 19:29:56,762:INFO:_display_container: 2
2023-11-04 19:29:56,763:INFO:LGBMRegressor(random_state=1598)
2023-11-04 19:29:56,763:INFO:create_model() successfully completed......................................
2023-11-04 19:29:56,875:INFO:SubProcess create_model() end ==================================
2023-11-04 19:29:56,875:INFO:Creating metrics dataframe
2023-11-04 19:29:56,882:INFO:Initializing CatBoost Regressor
2023-11-04 19:29:56,882:INFO:Total runtime is 0.06915349562962851 minutes
2023-11-04 19:29:56,884:INFO:SubProcess create_model() called ==================================
2023-11-04 19:29:56,884:INFO:Initializing create_model()
2023-11-04 19:29:56,884:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4243c1dc0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb424522b20>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:29:56,884:INFO:Checking exceptions
2023-11-04 19:29:56,884:INFO:Importing libraries
2023-11-04 19:29:56,884:INFO:Copying training dataset
2023-11-04 19:29:56,887:INFO:Defining folds
2023-11-04 19:29:56,887:INFO:Declaring metric variables
2023-11-04 19:29:56,888:INFO:Importing untrained model
2023-11-04 19:29:56,890:INFO:CatBoost Regressor Imported successfully
2023-11-04 19:29:56,893:INFO:Starting cross validation
2023-11-04 19:29:56,894:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:29:59,722:INFO:Calculating mean and std
2023-11-04 19:29:59,724:INFO:Creating metrics dataframe
2023-11-04 19:29:59,726:INFO:Uploading results into container
2023-11-04 19:29:59,726:INFO:Uploading model into container now
2023-11-04 19:29:59,727:INFO:_master_model_container: 19
2023-11-04 19:29:59,727:INFO:_display_container: 2
2023-11-04 19:29:59,727:INFO:<catboost.core.CatBoostRegressor object at 0x7fb435748580>
2023-11-04 19:29:59,727:INFO:create_model() successfully completed......................................
2023-11-04 19:29:59,841:INFO:SubProcess create_model() end ==================================
2023-11-04 19:29:59,842:INFO:Creating metrics dataframe
2023-11-04 19:29:59,849:INFO:Initializing Dummy Regressor
2023-11-04 19:29:59,849:INFO:Total runtime is 0.11860403219858806 minutes
2023-11-04 19:29:59,851:INFO:SubProcess create_model() called ==================================
2023-11-04 19:29:59,851:INFO:Initializing create_model()
2023-11-04 19:29:59,851:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4243c1dc0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb424522b20>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:29:59,851:INFO:Checking exceptions
2023-11-04 19:29:59,851:INFO:Importing libraries
2023-11-04 19:29:59,852:INFO:Copying training dataset
2023-11-04 19:29:59,854:INFO:Defining folds
2023-11-04 19:29:59,854:INFO:Declaring metric variables
2023-11-04 19:29:59,855:INFO:Importing untrained model
2023-11-04 19:29:59,857:INFO:Dummy Regressor Imported successfully
2023-11-04 19:29:59,860:INFO:Starting cross validation
2023-11-04 19:29:59,861:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:29:59,922:INFO:Calculating mean and std
2023-11-04 19:29:59,922:INFO:Creating metrics dataframe
2023-11-04 19:29:59,924:INFO:Uploading results into container
2023-11-04 19:29:59,924:INFO:Uploading model into container now
2023-11-04 19:29:59,924:INFO:_master_model_container: 20
2023-11-04 19:29:59,924:INFO:_display_container: 2
2023-11-04 19:29:59,924:INFO:DummyRegressor()
2023-11-04 19:29:59,924:INFO:create_model() successfully completed......................................
2023-11-04 19:30:00,037:INFO:SubProcess create_model() end ==================================
2023-11-04 19:30:00,037:INFO:Creating metrics dataframe
2023-11-04 19:30:00,049:INFO:Initializing create_model()
2023-11-04 19:30:00,050:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4243c1dc0>, estimator=<catboost.core.CatBoostRegressor object at 0x7fb435748580>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:30:00,050:INFO:Checking exceptions
2023-11-04 19:30:00,051:INFO:Importing libraries
2023-11-04 19:30:00,051:INFO:Copying training dataset
2023-11-04 19:30:00,052:INFO:Defining folds
2023-11-04 19:30:00,052:INFO:Declaring metric variables
2023-11-04 19:30:00,053:INFO:Importing untrained model
2023-11-04 19:30:00,053:INFO:Declaring custom model
2023-11-04 19:30:00,053:INFO:CatBoost Regressor Imported successfully
2023-11-04 19:30:00,054:INFO:Cross validation set to False
2023-11-04 19:30:00,054:INFO:Fitting Model
2023-11-04 19:30:00,696:INFO:<catboost.core.CatBoostRegressor object at 0x7fb423efbf70>
2023-11-04 19:30:00,696:INFO:create_model() successfully completed......................................
2023-11-04 19:30:00,828:INFO:_master_model_container: 20
2023-11-04 19:30:00,828:INFO:_display_container: 2
2023-11-04 19:30:00,828:INFO:<catboost.core.CatBoostRegressor object at 0x7fb423efbf70>
2023-11-04 19:30:00,828:INFO:compare_models() successfully completed......................................
2023-11-04 19:31:08,913:INFO:PyCaret RegressionExperiment
2023-11-04 19:31:08,914:INFO:Logging name: reg-default-name
2023-11-04 19:31:08,914:INFO:ML Usecase: MLUsecase.REGRESSION
2023-11-04 19:31:08,914:INFO:version 3.1.0
2023-11-04 19:31:08,914:INFO:Initializing setup()
2023-11-04 19:31:08,914:INFO:self.USI: 14ff
2023-11-04 19:31:08,914:INFO:self._variable_keys: {'USI', 'log_plots_param', 'gpu_param', 'fold_generator', 'X_test', 'html_param', '_ml_usecase', '_available_plots', 'exp_id', 'target_param', 'idx', 'fold_shuffle_param', 'n_jobs_param', 'seed', 'exp_name_log', 'X', 'y_train', 'transform_target_param', 'data', 'y_test', 'fold_groups_param', 'logging_param', 'gpu_n_jobs_param', 'y', 'X_train', 'memory', 'pipeline'}
2023-11-04 19:31:08,914:INFO:Checking environment
2023-11-04 19:31:08,915:INFO:python_version: 3.9.13
2023-11-04 19:31:08,915:INFO:python_build: ('main', 'Aug 25 2022 18:29:29')
2023-11-04 19:31:08,915:INFO:machine: x86_64
2023-11-04 19:31:08,915:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-11-04 19:31:08,915:INFO:Memory: svmem(total=17179869184, available=1437212672, percent=91.6, used=1915334656, free=33538048, active=1408270336, inactive=1401720832, wired=507064320)
2023-11-04 19:31:08,915:INFO:Physical Core: 8
2023-11-04 19:31:08,915:INFO:Logical Core: 8
2023-11-04 19:31:08,915:INFO:Checking libraries
2023-11-04 19:31:08,915:INFO:System:
2023-11-04 19:31:08,915:INFO:    python: 3.9.13 (main, Aug 25 2022, 18:29:29)  [Clang 12.0.0 ]
2023-11-04 19:31:08,915:INFO:executable: /Users/michal/opt/anaconda3/bin/python
2023-11-04 19:31:08,915:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-11-04 19:31:08,915:INFO:PyCaret required dependencies:
2023-11-04 19:31:08,915:INFO:                 pip: 22.2.2
2023-11-04 19:31:08,915:INFO:          setuptools: 63.4.1
2023-11-04 19:31:08,915:INFO:             pycaret: 3.1.0
2023-11-04 19:31:08,915:INFO:             IPython: 7.31.1
2023-11-04 19:31:08,915:INFO:          ipywidgets: 7.6.5
2023-11-04 19:31:08,915:INFO:                tqdm: 4.64.1
2023-11-04 19:31:08,915:INFO:               numpy: 1.21.5
2023-11-04 19:31:08,915:INFO:              pandas: 1.4.4
2023-11-04 19:31:08,915:INFO:              jinja2: 2.11.3
2023-11-04 19:31:08,915:INFO:               scipy: 1.10.1
2023-11-04 19:31:08,915:INFO:              joblib: 1.2.0
2023-11-04 19:31:08,915:INFO:             sklearn: 1.0.2
2023-11-04 19:31:08,915:INFO:                pyod: 1.1.1
2023-11-04 19:31:08,915:INFO:            imblearn: 0.10.1
2023-11-04 19:31:08,915:INFO:   category_encoders: 2.6.3
2023-11-04 19:31:08,915:INFO:            lightgbm: 3.3.5
2023-11-04 19:31:08,915:INFO:               numba: 0.55.1
2023-11-04 19:31:08,915:INFO:            requests: 2.28.1
2023-11-04 19:31:08,915:INFO:          matplotlib: 3.5.2
2023-11-04 19:31:08,915:INFO:          scikitplot: 0.3.7
2023-11-04 19:31:08,915:INFO:         yellowbrick: 1.5
2023-11-04 19:31:08,915:INFO:              plotly: 5.9.0
2023-11-04 19:31:08,915:INFO:    plotly-resampler: Not installed
2023-11-04 19:31:08,915:INFO:             kaleido: 0.2.1
2023-11-04 19:31:08,915:INFO:           schemdraw: 0.15
2023-11-04 19:31:08,915:INFO:         statsmodels: 0.13.2
2023-11-04 19:31:08,915:INFO:              sktime: 0.21.1
2023-11-04 19:31:08,915:INFO:               tbats: 1.1.3
2023-11-04 19:31:08,915:INFO:            pmdarima: 2.0.4
2023-11-04 19:31:08,915:INFO:              psutil: 5.9.0
2023-11-04 19:31:08,915:INFO:          markupsafe: 2.0.1
2023-11-04 19:31:08,915:INFO:             pickle5: Not installed
2023-11-04 19:31:08,915:INFO:         cloudpickle: 2.0.0
2023-11-04 19:31:08,915:INFO:         deprecation: 2.1.0
2023-11-04 19:31:08,915:INFO:              xxhash: 3.4.1
2023-11-04 19:31:08,915:INFO:           wurlitzer: 3.0.2
2023-11-04 19:31:08,915:INFO:PyCaret optional dependencies:
2023-11-04 19:31:08,915:INFO:                shap: 0.41.0
2023-11-04 19:31:08,915:INFO:           interpret: Not installed
2023-11-04 19:31:08,915:INFO:                umap: 0.5.3
2023-11-04 19:31:08,915:INFO:     ydata_profiling: Not installed
2023-11-04 19:31:08,915:INFO:  explainerdashboard: Not installed
2023-11-04 19:31:08,915:INFO:             autoviz: Not installed
2023-11-04 19:31:08,915:INFO:           fairlearn: Not installed
2023-11-04 19:31:08,915:INFO:          deepchecks: Not installed
2023-11-04 19:31:08,916:INFO:             xgboost: 1.7.4
2023-11-04 19:31:08,916:INFO:            catboost: 1.2
2023-11-04 19:31:08,916:INFO:              kmodes: Not installed
2023-11-04 19:31:08,916:INFO:             mlxtend: 0.21.0
2023-11-04 19:31:08,916:INFO:       statsforecast: Not installed
2023-11-04 19:31:08,916:INFO:        tune_sklearn: Not installed
2023-11-04 19:31:08,916:INFO:                 ray: Not installed
2023-11-04 19:31:08,916:INFO:            hyperopt: Not installed
2023-11-04 19:31:08,916:INFO:              optuna: Not installed
2023-11-04 19:31:08,916:INFO:               skopt: Not installed
2023-11-04 19:31:08,916:INFO:              mlflow: Not installed
2023-11-04 19:31:08,916:INFO:              gradio: Not installed
2023-11-04 19:31:08,916:INFO:             fastapi: Not installed
2023-11-04 19:31:08,916:INFO:             uvicorn: Not installed
2023-11-04 19:31:08,916:INFO:              m2cgen: Not installed
2023-11-04 19:31:08,916:INFO:           evidently: Not installed
2023-11-04 19:31:08,916:INFO:               fugue: Not installed
2023-11-04 19:31:08,916:INFO:           streamlit: Not installed
2023-11-04 19:31:08,916:INFO:             prophet: Not installed
2023-11-04 19:31:08,916:INFO:None
2023-11-04 19:31:08,916:INFO:Set up data.
2023-11-04 19:31:08,919:INFO:Set up folding strategy.
2023-11-04 19:31:08,919:INFO:Set up train/test split.
2023-11-04 19:31:08,920:INFO:Set up index.
2023-11-04 19:31:08,920:INFO:Assigning column types.
2023-11-04 19:31:08,921:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-04 19:31:08,921:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-04 19:31:08,924:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 19:31:08,927:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:31:08,960:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:31:08,987:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:31:08,987:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:31:08,988:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:31:08,989:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-04 19:31:08,992:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 19:31:08,994:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:31:09,027:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:31:09,054:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:31:09,054:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:31:09,056:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:31:09,056:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-11-04 19:31:09,058:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 19:31:09,061:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:31:09,094:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:31:09,121:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:31:09,121:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:31:09,123:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:31:09,125:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 19:31:09,128:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:31:09,162:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:31:09,188:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:31:09,188:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:31:09,190:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:31:09,190:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-11-04 19:31:09,195:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:31:09,227:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:31:09,253:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:31:09,253:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:31:09,255:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:31:09,260:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:31:09,293:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:31:09,320:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:31:09,320:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:31:09,322:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:31:09,322:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-11-04 19:31:09,360:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:31:09,386:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:31:09,387:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:31:09,388:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:31:09,426:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:31:09,452:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:31:09,452:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:31:09,454:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:31:09,454:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-04 19:31:09,492:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:31:09,519:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:31:09,520:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:31:09,559:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:31:09,586:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:31:09,587:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:31:09,587:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-11-04 19:31:09,651:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:31:09,653:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:31:09,717:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:31:09,718:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:31:09,719:INFO:Preparing preprocessing pipeline...
2023-11-04 19:31:09,719:INFO:Set up simple imputation.
2023-11-04 19:31:09,719:INFO:Set up variance threshold.
2023-11-04 19:31:09,719:INFO:Set up removing multicollinearity.
2023-11-04 19:31:09,719:INFO:Set up column name cleaning.
2023-11-04 19:31:09,743:INFO:Finished creating preprocessing pipeline.
2023-11-04 19:31:09,746:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/h9/5_75v3qs13x63s15wwxdrd000000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['solv_dG [kcal/mol]',
                                             'Bond dissociation entalphy',
                                             'water_ads [kcal/mol]', 'Coating',
                                             'Organic Matter Conc.', 'pH',
                                             'Primary Size', 'Initial Conc.',
                                             'Temp.', 'Ionic Strenght', 'Light',
                                             'MW', 'Noxy', 'χ', 'χox',
                                             'Z_metal', 'Zv...
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.1))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-11-04 19:31:09,746:INFO:Creating final display dataframe.
2023-11-04 19:31:09,792:INFO:Setup _display_container:                     Description             Value
0                    Session id              5305
1                        Target  %dissolved solid
2                   Target type        Regression
3           Original data shape         (115, 21)
4        Transformed data shape         (115, 19)
5   Transformed train set shape          (80, 19)
6    Transformed test set shape          (35, 19)
7              Numeric features                20
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12       Low variance threshold               0.1
13     Remove multicollinearity              True
14  Multicollinearity threshold              0.95
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              14ff
2023-11-04 19:31:09,861:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:31:09,862:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:31:09,929:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:31:09,930:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:31:09,931:INFO:setup() successfully completed in 1.02s...............
2023-11-04 19:31:09,931:INFO:Initializing compare_models()
2023-11-04 19:31:09,931:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb440b03550>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fb440b03550>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-11-04 19:31:09,931:INFO:Checking exceptions
2023-11-04 19:31:09,932:INFO:Preparing display monitor
2023-11-04 19:31:09,948:INFO:Initializing Linear Regression
2023-11-04 19:31:09,949:INFO:Total runtime is 1.9510587056477865e-06 minutes
2023-11-04 19:31:09,950:INFO:SubProcess create_model() called ==================================
2023-11-04 19:31:09,950:INFO:Initializing create_model()
2023-11-04 19:31:09,950:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb440b03550>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb41119bb50>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:31:09,950:INFO:Checking exceptions
2023-11-04 19:31:09,951:INFO:Importing libraries
2023-11-04 19:31:09,951:INFO:Copying training dataset
2023-11-04 19:31:09,952:INFO:Defining folds
2023-11-04 19:31:09,952:INFO:Declaring metric variables
2023-11-04 19:31:09,954:INFO:Importing untrained model
2023-11-04 19:31:09,956:INFO:Linear Regression Imported successfully
2023-11-04 19:31:09,959:INFO:Starting cross validation
2023-11-04 19:31:09,960:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:31:10,016:INFO:Calculating mean and std
2023-11-04 19:31:10,017:INFO:Creating metrics dataframe
2023-11-04 19:31:10,019:INFO:Uploading results into container
2023-11-04 19:31:10,019:INFO:Uploading model into container now
2023-11-04 19:31:10,019:INFO:_master_model_container: 1
2023-11-04 19:31:10,019:INFO:_display_container: 2
2023-11-04 19:31:10,019:INFO:LinearRegression(n_jobs=-1)
2023-11-04 19:31:10,019:INFO:create_model() successfully completed......................................
2023-11-04 19:31:10,177:INFO:SubProcess create_model() end ==================================
2023-11-04 19:31:10,177:INFO:Creating metrics dataframe
2023-11-04 19:31:10,181:INFO:Initializing Lasso Regression
2023-11-04 19:31:10,181:INFO:Total runtime is 0.0038776834805806476 minutes
2023-11-04 19:31:10,183:INFO:SubProcess create_model() called ==================================
2023-11-04 19:31:10,183:INFO:Initializing create_model()
2023-11-04 19:31:10,183:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb440b03550>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb41119bb50>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:31:10,183:INFO:Checking exceptions
2023-11-04 19:31:10,183:INFO:Importing libraries
2023-11-04 19:31:10,183:INFO:Copying training dataset
2023-11-04 19:31:10,185:INFO:Defining folds
2023-11-04 19:31:10,185:INFO:Declaring metric variables
2023-11-04 19:31:10,187:INFO:Importing untrained model
2023-11-04 19:31:10,188:INFO:Lasso Regression Imported successfully
2023-11-04 19:31:10,191:INFO:Starting cross validation
2023-11-04 19:31:10,192:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:31:10,246:INFO:Calculating mean and std
2023-11-04 19:31:10,246:INFO:Creating metrics dataframe
2023-11-04 19:31:10,248:INFO:Uploading results into container
2023-11-04 19:31:10,248:INFO:Uploading model into container now
2023-11-04 19:31:10,249:INFO:_master_model_container: 2
2023-11-04 19:31:10,249:INFO:_display_container: 2
2023-11-04 19:31:10,249:INFO:Lasso(random_state=5305)
2023-11-04 19:31:10,249:INFO:create_model() successfully completed......................................
2023-11-04 19:31:10,364:INFO:SubProcess create_model() end ==================================
2023-11-04 19:31:10,364:INFO:Creating metrics dataframe
2023-11-04 19:31:10,369:INFO:Initializing Ridge Regression
2023-11-04 19:31:10,369:INFO:Total runtime is 0.00701226790746053 minutes
2023-11-04 19:31:10,371:INFO:SubProcess create_model() called ==================================
2023-11-04 19:31:10,371:INFO:Initializing create_model()
2023-11-04 19:31:10,371:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb440b03550>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb41119bb50>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:31:10,371:INFO:Checking exceptions
2023-11-04 19:31:10,372:INFO:Importing libraries
2023-11-04 19:31:10,372:INFO:Copying training dataset
2023-11-04 19:31:10,373:INFO:Defining folds
2023-11-04 19:31:10,373:INFO:Declaring metric variables
2023-11-04 19:31:10,374:INFO:Importing untrained model
2023-11-04 19:31:10,376:INFO:Ridge Regression Imported successfully
2023-11-04 19:31:10,379:INFO:Starting cross validation
2023-11-04 19:31:10,380:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:31:10,437:INFO:Calculating mean and std
2023-11-04 19:31:10,438:INFO:Creating metrics dataframe
2023-11-04 19:31:10,439:INFO:Uploading results into container
2023-11-04 19:31:10,439:INFO:Uploading model into container now
2023-11-04 19:31:10,440:INFO:_master_model_container: 3
2023-11-04 19:31:10,440:INFO:_display_container: 2
2023-11-04 19:31:10,440:INFO:Ridge(random_state=5305)
2023-11-04 19:31:10,440:INFO:create_model() successfully completed......................................
2023-11-04 19:31:10,551:INFO:SubProcess create_model() end ==================================
2023-11-04 19:31:10,551:INFO:Creating metrics dataframe
2023-11-04 19:31:10,556:INFO:Initializing Elastic Net
2023-11-04 19:31:10,556:INFO:Total runtime is 0.010132686297098795 minutes
2023-11-04 19:31:10,558:INFO:SubProcess create_model() called ==================================
2023-11-04 19:31:10,558:INFO:Initializing create_model()
2023-11-04 19:31:10,558:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb440b03550>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb41119bb50>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:31:10,559:INFO:Checking exceptions
2023-11-04 19:31:10,559:INFO:Importing libraries
2023-11-04 19:31:10,559:INFO:Copying training dataset
2023-11-04 19:31:10,560:INFO:Defining folds
2023-11-04 19:31:10,560:INFO:Declaring metric variables
2023-11-04 19:31:10,562:INFO:Importing untrained model
2023-11-04 19:31:10,563:INFO:Elastic Net Imported successfully
2023-11-04 19:31:10,566:INFO:Starting cross validation
2023-11-04 19:31:10,567:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:31:10,620:INFO:Calculating mean and std
2023-11-04 19:31:10,620:INFO:Creating metrics dataframe
2023-11-04 19:31:10,622:INFO:Uploading results into container
2023-11-04 19:31:10,622:INFO:Uploading model into container now
2023-11-04 19:31:10,622:INFO:_master_model_container: 4
2023-11-04 19:31:10,622:INFO:_display_container: 2
2023-11-04 19:31:10,622:INFO:ElasticNet(random_state=5305)
2023-11-04 19:31:10,622:INFO:create_model() successfully completed......................................
2023-11-04 19:31:10,734:INFO:SubProcess create_model() end ==================================
2023-11-04 19:31:10,734:INFO:Creating metrics dataframe
2023-11-04 19:31:10,739:INFO:Initializing Least Angle Regression
2023-11-04 19:31:10,739:INFO:Total runtime is 0.013179532686869304 minutes
2023-11-04 19:31:10,741:INFO:SubProcess create_model() called ==================================
2023-11-04 19:31:10,741:INFO:Initializing create_model()
2023-11-04 19:31:10,741:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb440b03550>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb41119bb50>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:31:10,741:INFO:Checking exceptions
2023-11-04 19:31:10,741:INFO:Importing libraries
2023-11-04 19:31:10,742:INFO:Copying training dataset
2023-11-04 19:31:10,743:INFO:Defining folds
2023-11-04 19:31:10,743:INFO:Declaring metric variables
2023-11-04 19:31:10,744:INFO:Importing untrained model
2023-11-04 19:31:10,746:INFO:Least Angle Regression Imported successfully
2023-11-04 19:31:10,749:INFO:Starting cross validation
2023-11-04 19:31:10,750:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:31:10,768:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:31:10,780:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:31:10,781:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:31:10,782:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:31:10,786:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:31:10,791:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:31:10,792:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:31:10,798:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:31:10,798:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=2.473e-02, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-04 19:31:10,799:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:31:10,800:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:31:10,806:INFO:Calculating mean and std
2023-11-04 19:31:10,806:INFO:Creating metrics dataframe
2023-11-04 19:31:10,808:INFO:Uploading results into container
2023-11-04 19:31:10,808:INFO:Uploading model into container now
2023-11-04 19:31:10,808:INFO:_master_model_container: 5
2023-11-04 19:31:10,808:INFO:_display_container: 2
2023-11-04 19:31:10,809:INFO:Lars(random_state=5305)
2023-11-04 19:31:10,809:INFO:create_model() successfully completed......................................
2023-11-04 19:31:10,920:INFO:SubProcess create_model() end ==================================
2023-11-04 19:31:10,920:INFO:Creating metrics dataframe
2023-11-04 19:31:10,925:INFO:Initializing Lasso Least Angle Regression
2023-11-04 19:31:10,925:INFO:Total runtime is 0.016279852390289305 minutes
2023-11-04 19:31:10,927:INFO:SubProcess create_model() called ==================================
2023-11-04 19:31:10,927:INFO:Initializing create_model()
2023-11-04 19:31:10,927:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb440b03550>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb41119bb50>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:31:10,927:INFO:Checking exceptions
2023-11-04 19:31:10,927:INFO:Importing libraries
2023-11-04 19:31:10,928:INFO:Copying training dataset
2023-11-04 19:31:10,929:INFO:Defining folds
2023-11-04 19:31:10,929:INFO:Declaring metric variables
2023-11-04 19:31:10,930:INFO:Importing untrained model
2023-11-04 19:31:10,932:INFO:Lasso Least Angle Regression Imported successfully
2023-11-04 19:31:10,935:INFO:Starting cross validation
2023-11-04 19:31:10,936:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:31:10,957:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:31:10,959:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:31:10,962:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:31:10,968:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:31:10,976:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:31:10,976:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:31:10,978:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:31:10,979:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:31:10,981:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:31:10,989:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:31:10,994:INFO:Calculating mean and std
2023-11-04 19:31:10,995:INFO:Creating metrics dataframe
2023-11-04 19:31:10,997:INFO:Uploading results into container
2023-11-04 19:31:10,998:INFO:Uploading model into container now
2023-11-04 19:31:10,998:INFO:_master_model_container: 6
2023-11-04 19:31:10,998:INFO:_display_container: 2
2023-11-04 19:31:10,998:INFO:LassoLars(random_state=5305)
2023-11-04 19:31:10,998:INFO:create_model() successfully completed......................................
2023-11-04 19:31:11,111:INFO:SubProcess create_model() end ==================================
2023-11-04 19:31:11,111:INFO:Creating metrics dataframe
2023-11-04 19:31:11,116:INFO:Initializing Orthogonal Matching Pursuit
2023-11-04 19:31:11,116:INFO:Total runtime is 0.019463098049163817 minutes
2023-11-04 19:31:11,118:INFO:SubProcess create_model() called ==================================
2023-11-04 19:31:11,118:INFO:Initializing create_model()
2023-11-04 19:31:11,118:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb440b03550>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb41119bb50>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:31:11,118:INFO:Checking exceptions
2023-11-04 19:31:11,118:INFO:Importing libraries
2023-11-04 19:31:11,118:INFO:Copying training dataset
2023-11-04 19:31:11,120:INFO:Defining folds
2023-11-04 19:31:11,120:INFO:Declaring metric variables
2023-11-04 19:31:11,122:INFO:Importing untrained model
2023-11-04 19:31:11,123:INFO:Orthogonal Matching Pursuit Imported successfully
2023-11-04 19:31:11,127:INFO:Starting cross validation
2023-11-04 19:31:11,128:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:31:11,146:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:31:11,149:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:31:11,159:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:31:11,163:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:31:11,166:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:31:11,168:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:31:11,176:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:31:11,177:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:31:11,177:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:31:11,181:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:31:11,187:INFO:Calculating mean and std
2023-11-04 19:31:11,187:INFO:Creating metrics dataframe
2023-11-04 19:31:11,189:INFO:Uploading results into container
2023-11-04 19:31:11,189:INFO:Uploading model into container now
2023-11-04 19:31:11,189:INFO:_master_model_container: 7
2023-11-04 19:31:11,189:INFO:_display_container: 2
2023-11-04 19:31:11,189:INFO:OrthogonalMatchingPursuit()
2023-11-04 19:31:11,189:INFO:create_model() successfully completed......................................
2023-11-04 19:31:11,306:INFO:SubProcess create_model() end ==================================
2023-11-04 19:31:11,306:INFO:Creating metrics dataframe
2023-11-04 19:31:11,311:INFO:Initializing Bayesian Ridge
2023-11-04 19:31:11,312:INFO:Total runtime is 0.02271763483683268 minutes
2023-11-04 19:31:11,313:INFO:SubProcess create_model() called ==================================
2023-11-04 19:31:11,314:INFO:Initializing create_model()
2023-11-04 19:31:11,314:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb440b03550>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb41119bb50>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:31:11,314:INFO:Checking exceptions
2023-11-04 19:31:11,314:INFO:Importing libraries
2023-11-04 19:31:11,314:INFO:Copying training dataset
2023-11-04 19:31:11,316:INFO:Defining folds
2023-11-04 19:31:11,316:INFO:Declaring metric variables
2023-11-04 19:31:11,318:INFO:Importing untrained model
2023-11-04 19:31:11,319:INFO:Bayesian Ridge Imported successfully
2023-11-04 19:31:11,323:INFO:Starting cross validation
2023-11-04 19:31:11,323:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:31:11,383:INFO:Calculating mean and std
2023-11-04 19:31:11,384:INFO:Creating metrics dataframe
2023-11-04 19:31:11,385:INFO:Uploading results into container
2023-11-04 19:31:11,386:INFO:Uploading model into container now
2023-11-04 19:31:11,386:INFO:_master_model_container: 8
2023-11-04 19:31:11,386:INFO:_display_container: 2
2023-11-04 19:31:11,386:INFO:BayesianRidge()
2023-11-04 19:31:11,386:INFO:create_model() successfully completed......................................
2023-11-04 19:31:11,498:INFO:SubProcess create_model() end ==================================
2023-11-04 19:31:11,498:INFO:Creating metrics dataframe
2023-11-04 19:31:11,504:INFO:Initializing Passive Aggressive Regressor
2023-11-04 19:31:11,504:INFO:Total runtime is 0.02592518329620361 minutes
2023-11-04 19:31:11,506:INFO:SubProcess create_model() called ==================================
2023-11-04 19:31:11,506:INFO:Initializing create_model()
2023-11-04 19:31:11,506:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb440b03550>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb41119bb50>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:31:11,506:INFO:Checking exceptions
2023-11-04 19:31:11,506:INFO:Importing libraries
2023-11-04 19:31:11,506:INFO:Copying training dataset
2023-11-04 19:31:11,508:INFO:Defining folds
2023-11-04 19:31:11,508:INFO:Declaring metric variables
2023-11-04 19:31:11,510:INFO:Importing untrained model
2023-11-04 19:31:11,512:INFO:Passive Aggressive Regressor Imported successfully
2023-11-04 19:31:11,515:INFO:Starting cross validation
2023-11-04 19:31:11,516:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:31:11,574:INFO:Calculating mean and std
2023-11-04 19:31:11,574:INFO:Creating metrics dataframe
2023-11-04 19:31:11,576:INFO:Uploading results into container
2023-11-04 19:31:11,576:INFO:Uploading model into container now
2023-11-04 19:31:11,576:INFO:_master_model_container: 9
2023-11-04 19:31:11,576:INFO:_display_container: 2
2023-11-04 19:31:11,577:INFO:PassiveAggressiveRegressor(random_state=5305)
2023-11-04 19:31:11,577:INFO:create_model() successfully completed......................................
2023-11-04 19:31:11,688:INFO:SubProcess create_model() end ==================================
2023-11-04 19:31:11,688:INFO:Creating metrics dataframe
2023-11-04 19:31:11,694:INFO:Initializing Huber Regressor
2023-11-04 19:31:11,694:INFO:Total runtime is 0.02908731698989868 minutes
2023-11-04 19:31:11,695:INFO:SubProcess create_model() called ==================================
2023-11-04 19:31:11,696:INFO:Initializing create_model()
2023-11-04 19:31:11,696:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb440b03550>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb41119bb50>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:31:11,696:INFO:Checking exceptions
2023-11-04 19:31:11,696:INFO:Importing libraries
2023-11-04 19:31:11,696:INFO:Copying training dataset
2023-11-04 19:31:11,698:INFO:Defining folds
2023-11-04 19:31:11,698:INFO:Declaring metric variables
2023-11-04 19:31:11,700:INFO:Importing untrained model
2023-11-04 19:31:11,702:INFO:Huber Regressor Imported successfully
2023-11-04 19:31:11,705:INFO:Starting cross validation
2023-11-04 19:31:11,705:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:31:11,737:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:31:11,738:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:31:11,742:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:31:11,752:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:31:11,754:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:31:11,760:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:31:11,762:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:31:11,771:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:31:11,773:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:31:11,774:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:31:11,779:INFO:Calculating mean and std
2023-11-04 19:31:11,779:INFO:Creating metrics dataframe
2023-11-04 19:31:11,781:INFO:Uploading results into container
2023-11-04 19:31:11,781:INFO:Uploading model into container now
2023-11-04 19:31:11,781:INFO:_master_model_container: 10
2023-11-04 19:31:11,781:INFO:_display_container: 2
2023-11-04 19:31:11,781:INFO:HuberRegressor()
2023-11-04 19:31:11,781:INFO:create_model() successfully completed......................................
2023-11-04 19:31:11,893:INFO:SubProcess create_model() end ==================================
2023-11-04 19:31:11,893:INFO:Creating metrics dataframe
2023-11-04 19:31:11,899:INFO:Initializing K Neighbors Regressor
2023-11-04 19:31:11,899:INFO:Total runtime is 0.032506950696309406 minutes
2023-11-04 19:31:11,901:INFO:SubProcess create_model() called ==================================
2023-11-04 19:31:11,901:INFO:Initializing create_model()
2023-11-04 19:31:11,901:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb440b03550>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb41119bb50>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:31:11,901:INFO:Checking exceptions
2023-11-04 19:31:11,901:INFO:Importing libraries
2023-11-04 19:31:11,901:INFO:Copying training dataset
2023-11-04 19:31:11,903:INFO:Defining folds
2023-11-04 19:31:11,903:INFO:Declaring metric variables
2023-11-04 19:31:11,905:INFO:Importing untrained model
2023-11-04 19:31:11,907:INFO:K Neighbors Regressor Imported successfully
2023-11-04 19:31:11,910:INFO:Starting cross validation
2023-11-04 19:31:11,910:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:31:11,971:INFO:Calculating mean and std
2023-11-04 19:31:11,971:INFO:Creating metrics dataframe
2023-11-04 19:31:11,973:INFO:Uploading results into container
2023-11-04 19:31:11,973:INFO:Uploading model into container now
2023-11-04 19:31:11,973:INFO:_master_model_container: 11
2023-11-04 19:31:11,973:INFO:_display_container: 2
2023-11-04 19:31:11,973:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-04 19:31:11,973:INFO:create_model() successfully completed......................................
2023-11-04 19:31:12,087:INFO:SubProcess create_model() end ==================================
2023-11-04 19:31:12,087:INFO:Creating metrics dataframe
2023-11-04 19:31:12,094:INFO:Initializing Decision Tree Regressor
2023-11-04 19:31:12,094:INFO:Total runtime is 0.03575296799341837 minutes
2023-11-04 19:31:12,095:INFO:SubProcess create_model() called ==================================
2023-11-04 19:31:12,096:INFO:Initializing create_model()
2023-11-04 19:31:12,096:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb440b03550>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb41119bb50>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:31:12,096:INFO:Checking exceptions
2023-11-04 19:31:12,096:INFO:Importing libraries
2023-11-04 19:31:12,096:INFO:Copying training dataset
2023-11-04 19:31:12,098:INFO:Defining folds
2023-11-04 19:31:12,098:INFO:Declaring metric variables
2023-11-04 19:31:12,100:INFO:Importing untrained model
2023-11-04 19:31:12,102:INFO:Decision Tree Regressor Imported successfully
2023-11-04 19:31:12,105:INFO:Starting cross validation
2023-11-04 19:31:12,105:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:31:12,159:INFO:Calculating mean and std
2023-11-04 19:31:12,159:INFO:Creating metrics dataframe
2023-11-04 19:31:12,161:INFO:Uploading results into container
2023-11-04 19:31:12,161:INFO:Uploading model into container now
2023-11-04 19:31:12,161:INFO:_master_model_container: 12
2023-11-04 19:31:12,161:INFO:_display_container: 2
2023-11-04 19:31:12,162:INFO:DecisionTreeRegressor(random_state=5305)
2023-11-04 19:31:12,162:INFO:create_model() successfully completed......................................
2023-11-04 19:31:12,282:INFO:SubProcess create_model() end ==================================
2023-11-04 19:31:12,282:INFO:Creating metrics dataframe
2023-11-04 19:31:12,289:INFO:Initializing Random Forest Regressor
2023-11-04 19:31:12,289:INFO:Total runtime is 0.039011303583780924 minutes
2023-11-04 19:31:12,291:INFO:SubProcess create_model() called ==================================
2023-11-04 19:31:12,291:INFO:Initializing create_model()
2023-11-04 19:31:12,291:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb440b03550>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb41119bb50>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:31:12,291:INFO:Checking exceptions
2023-11-04 19:31:12,291:INFO:Importing libraries
2023-11-04 19:31:12,292:INFO:Copying training dataset
2023-11-04 19:31:12,294:INFO:Defining folds
2023-11-04 19:31:12,294:INFO:Declaring metric variables
2023-11-04 19:31:12,296:INFO:Importing untrained model
2023-11-04 19:31:12,297:INFO:Random Forest Regressor Imported successfully
2023-11-04 19:31:12,301:INFO:Starting cross validation
2023-11-04 19:31:12,301:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:31:12,563:INFO:Calculating mean and std
2023-11-04 19:31:12,564:INFO:Creating metrics dataframe
2023-11-04 19:31:12,566:INFO:Uploading results into container
2023-11-04 19:31:12,566:INFO:Uploading model into container now
2023-11-04 19:31:12,567:INFO:_master_model_container: 13
2023-11-04 19:31:12,567:INFO:_display_container: 2
2023-11-04 19:31:12,567:INFO:RandomForestRegressor(n_jobs=-1, random_state=5305)
2023-11-04 19:31:12,567:INFO:create_model() successfully completed......................................
2023-11-04 19:31:12,678:INFO:SubProcess create_model() end ==================================
2023-11-04 19:31:12,678:INFO:Creating metrics dataframe
2023-11-04 19:31:12,684:INFO:Initializing Extra Trees Regressor
2023-11-04 19:31:12,684:INFO:Total runtime is 0.045593849817911786 minutes
2023-11-04 19:31:12,686:INFO:SubProcess create_model() called ==================================
2023-11-04 19:31:12,686:INFO:Initializing create_model()
2023-11-04 19:31:12,686:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb440b03550>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb41119bb50>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:31:12,686:INFO:Checking exceptions
2023-11-04 19:31:12,686:INFO:Importing libraries
2023-11-04 19:31:12,686:INFO:Copying training dataset
2023-11-04 19:31:12,688:INFO:Defining folds
2023-11-04 19:31:12,688:INFO:Declaring metric variables
2023-11-04 19:31:12,689:INFO:Importing untrained model
2023-11-04 19:31:12,691:INFO:Extra Trees Regressor Imported successfully
2023-11-04 19:31:12,695:INFO:Starting cross validation
2023-11-04 19:31:12,696:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:31:12,903:INFO:Calculating mean and std
2023-11-04 19:31:12,903:INFO:Creating metrics dataframe
2023-11-04 19:31:12,905:INFO:Uploading results into container
2023-11-04 19:31:12,906:INFO:Uploading model into container now
2023-11-04 19:31:12,906:INFO:_master_model_container: 14
2023-11-04 19:31:12,906:INFO:_display_container: 2
2023-11-04 19:31:12,906:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=5305)
2023-11-04 19:31:12,906:INFO:create_model() successfully completed......................................
2023-11-04 19:31:13,017:INFO:SubProcess create_model() end ==================================
2023-11-04 19:31:13,017:INFO:Creating metrics dataframe
2023-11-04 19:31:13,023:INFO:Initializing AdaBoost Regressor
2023-11-04 19:31:13,023:INFO:Total runtime is 0.051248284180959065 minutes
2023-11-04 19:31:13,025:INFO:SubProcess create_model() called ==================================
2023-11-04 19:31:13,025:INFO:Initializing create_model()
2023-11-04 19:31:13,025:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb440b03550>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb41119bb50>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:31:13,025:INFO:Checking exceptions
2023-11-04 19:31:13,026:INFO:Importing libraries
2023-11-04 19:31:13,026:INFO:Copying training dataset
2023-11-04 19:31:13,027:INFO:Defining folds
2023-11-04 19:31:13,027:INFO:Declaring metric variables
2023-11-04 19:31:13,028:INFO:Importing untrained model
2023-11-04 19:31:13,030:INFO:AdaBoost Regressor Imported successfully
2023-11-04 19:31:13,034:INFO:Starting cross validation
2023-11-04 19:31:13,034:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:31:13,147:INFO:Calculating mean and std
2023-11-04 19:31:13,147:INFO:Creating metrics dataframe
2023-11-04 19:31:13,149:INFO:Uploading results into container
2023-11-04 19:31:13,150:INFO:Uploading model into container now
2023-11-04 19:31:13,150:INFO:_master_model_container: 15
2023-11-04 19:31:13,150:INFO:_display_container: 2
2023-11-04 19:31:13,150:INFO:AdaBoostRegressor(random_state=5305)
2023-11-04 19:31:13,150:INFO:create_model() successfully completed......................................
2023-11-04 19:31:13,261:INFO:SubProcess create_model() end ==================================
2023-11-04 19:31:13,261:INFO:Creating metrics dataframe
2023-11-04 19:31:13,268:INFO:Initializing Gradient Boosting Regressor
2023-11-04 19:31:13,268:INFO:Total runtime is 0.05532654921213786 minutes
2023-11-04 19:31:13,270:INFO:SubProcess create_model() called ==================================
2023-11-04 19:31:13,270:INFO:Initializing create_model()
2023-11-04 19:31:13,270:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb440b03550>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb41119bb50>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:31:13,270:INFO:Checking exceptions
2023-11-04 19:31:13,270:INFO:Importing libraries
2023-11-04 19:31:13,270:INFO:Copying training dataset
2023-11-04 19:31:13,272:INFO:Defining folds
2023-11-04 19:31:13,272:INFO:Declaring metric variables
2023-11-04 19:31:13,273:INFO:Importing untrained model
2023-11-04 19:31:13,275:INFO:Gradient Boosting Regressor Imported successfully
2023-11-04 19:31:13,279:INFO:Starting cross validation
2023-11-04 19:31:13,279:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:31:13,359:INFO:Calculating mean and std
2023-11-04 19:31:13,359:INFO:Creating metrics dataframe
2023-11-04 19:31:13,361:INFO:Uploading results into container
2023-11-04 19:31:13,361:INFO:Uploading model into container now
2023-11-04 19:31:13,361:INFO:_master_model_container: 16
2023-11-04 19:31:13,361:INFO:_display_container: 2
2023-11-04 19:31:13,361:INFO:GradientBoostingRegressor(random_state=5305)
2023-11-04 19:31:13,361:INFO:create_model() successfully completed......................................
2023-11-04 19:31:13,473:INFO:SubProcess create_model() end ==================================
2023-11-04 19:31:13,473:INFO:Creating metrics dataframe
2023-11-04 19:31:13,480:INFO:Initializing Extreme Gradient Boosting
2023-11-04 19:31:13,480:INFO:Total runtime is 0.058859602610270186 minutes
2023-11-04 19:31:13,482:INFO:SubProcess create_model() called ==================================
2023-11-04 19:31:13,482:INFO:Initializing create_model()
2023-11-04 19:31:13,482:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb440b03550>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb41119bb50>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:31:13,482:INFO:Checking exceptions
2023-11-04 19:31:13,482:INFO:Importing libraries
2023-11-04 19:31:13,482:INFO:Copying training dataset
2023-11-04 19:31:13,484:INFO:Defining folds
2023-11-04 19:31:13,484:INFO:Declaring metric variables
2023-11-04 19:31:13,486:INFO:Importing untrained model
2023-11-04 19:31:13,488:INFO:Extreme Gradient Boosting Imported successfully
2023-11-04 19:31:13,491:INFO:Starting cross validation
2023-11-04 19:31:13,492:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:31:13,592:INFO:Calculating mean and std
2023-11-04 19:31:13,593:INFO:Creating metrics dataframe
2023-11-04 19:31:13,594:INFO:Uploading results into container
2023-11-04 19:31:13,595:INFO:Uploading model into container now
2023-11-04 19:31:13,595:INFO:_master_model_container: 17
2023-11-04 19:31:13,595:INFO:_display_container: 2
2023-11-04 19:31:13,596:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=5305, ...)
2023-11-04 19:31:13,596:INFO:create_model() successfully completed......................................
2023-11-04 19:31:13,711:INFO:SubProcess create_model() end ==================================
2023-11-04 19:31:13,711:INFO:Creating metrics dataframe
2023-11-04 19:31:13,718:INFO:Initializing Light Gradient Boosting Machine
2023-11-04 19:31:13,719:INFO:Total runtime is 0.06283516486485799 minutes
2023-11-04 19:31:13,720:INFO:SubProcess create_model() called ==================================
2023-11-04 19:31:13,721:INFO:Initializing create_model()
2023-11-04 19:31:13,721:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb440b03550>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb41119bb50>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:31:13,721:INFO:Checking exceptions
2023-11-04 19:31:13,721:INFO:Importing libraries
2023-11-04 19:31:13,721:INFO:Copying training dataset
2023-11-04 19:31:13,723:INFO:Defining folds
2023-11-04 19:31:13,723:INFO:Declaring metric variables
2023-11-04 19:31:13,725:INFO:Importing untrained model
2023-11-04 19:31:13,727:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-04 19:31:13,730:INFO:Starting cross validation
2023-11-04 19:31:13,730:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:31:13,799:INFO:Calculating mean and std
2023-11-04 19:31:13,800:INFO:Creating metrics dataframe
2023-11-04 19:31:13,801:INFO:Uploading results into container
2023-11-04 19:31:13,802:INFO:Uploading model into container now
2023-11-04 19:31:13,802:INFO:_master_model_container: 18
2023-11-04 19:31:13,802:INFO:_display_container: 2
2023-11-04 19:31:13,802:INFO:LGBMRegressor(random_state=5305)
2023-11-04 19:31:13,802:INFO:create_model() successfully completed......................................
2023-11-04 19:31:13,914:INFO:SubProcess create_model() end ==================================
2023-11-04 19:31:13,914:INFO:Creating metrics dataframe
2023-11-04 19:31:13,921:INFO:Initializing CatBoost Regressor
2023-11-04 19:31:13,921:INFO:Total runtime is 0.0662067174911499 minutes
2023-11-04 19:31:13,923:INFO:SubProcess create_model() called ==================================
2023-11-04 19:31:13,923:INFO:Initializing create_model()
2023-11-04 19:31:13,923:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb440b03550>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb41119bb50>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:31:13,923:INFO:Checking exceptions
2023-11-04 19:31:13,923:INFO:Importing libraries
2023-11-04 19:31:13,923:INFO:Copying training dataset
2023-11-04 19:31:13,925:INFO:Defining folds
2023-11-04 19:31:13,925:INFO:Declaring metric variables
2023-11-04 19:31:13,927:INFO:Importing untrained model
2023-11-04 19:31:13,929:INFO:CatBoost Regressor Imported successfully
2023-11-04 19:31:13,932:INFO:Starting cross validation
2023-11-04 19:31:13,932:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:31:14,644:INFO:Calculating mean and std
2023-11-04 19:31:14,645:INFO:Creating metrics dataframe
2023-11-04 19:31:14,646:INFO:Uploading results into container
2023-11-04 19:31:14,647:INFO:Uploading model into container now
2023-11-04 19:31:14,647:INFO:_master_model_container: 19
2023-11-04 19:31:14,647:INFO:_display_container: 2
2023-11-04 19:31:14,647:INFO:<catboost.core.CatBoostRegressor object at 0x7fb441288f10>
2023-11-04 19:31:14,647:INFO:create_model() successfully completed......................................
2023-11-04 19:31:14,758:INFO:SubProcess create_model() end ==================================
2023-11-04 19:31:14,758:INFO:Creating metrics dataframe
2023-11-04 19:31:14,765:INFO:Initializing Dummy Regressor
2023-11-04 19:31:14,765:INFO:Total runtime is 0.08028268416722614 minutes
2023-11-04 19:31:14,767:INFO:SubProcess create_model() called ==================================
2023-11-04 19:31:14,767:INFO:Initializing create_model()
2023-11-04 19:31:14,767:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb440b03550>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb41119bb50>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:31:14,768:INFO:Checking exceptions
2023-11-04 19:31:14,768:INFO:Importing libraries
2023-11-04 19:31:14,768:INFO:Copying training dataset
2023-11-04 19:31:14,770:INFO:Defining folds
2023-11-04 19:31:14,770:INFO:Declaring metric variables
2023-11-04 19:31:14,771:INFO:Importing untrained model
2023-11-04 19:31:14,773:INFO:Dummy Regressor Imported successfully
2023-11-04 19:31:14,776:INFO:Starting cross validation
2023-11-04 19:31:14,777:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:31:14,828:INFO:Calculating mean and std
2023-11-04 19:31:14,828:INFO:Creating metrics dataframe
2023-11-04 19:31:14,830:INFO:Uploading results into container
2023-11-04 19:31:14,830:INFO:Uploading model into container now
2023-11-04 19:31:14,830:INFO:_master_model_container: 20
2023-11-04 19:31:14,830:INFO:_display_container: 2
2023-11-04 19:31:14,831:INFO:DummyRegressor()
2023-11-04 19:31:14,831:INFO:create_model() successfully completed......................................
2023-11-04 19:31:14,942:INFO:SubProcess create_model() end ==================================
2023-11-04 19:31:14,942:INFO:Creating metrics dataframe
2023-11-04 19:31:14,954:INFO:Initializing create_model()
2023-11-04 19:31:14,954:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb440b03550>, estimator=DummyRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:31:14,954:INFO:Checking exceptions
2023-11-04 19:31:14,955:INFO:Importing libraries
2023-11-04 19:31:14,955:INFO:Copying training dataset
2023-11-04 19:31:14,956:INFO:Defining folds
2023-11-04 19:31:14,956:INFO:Declaring metric variables
2023-11-04 19:31:14,957:INFO:Importing untrained model
2023-11-04 19:31:14,957:INFO:Declaring custom model
2023-11-04 19:31:14,957:INFO:Dummy Regressor Imported successfully
2023-11-04 19:31:14,958:INFO:Cross validation set to False
2023-11-04 19:31:14,958:INFO:Fitting Model
2023-11-04 19:31:14,967:INFO:DummyRegressor()
2023-11-04 19:31:14,967:INFO:create_model() successfully completed......................................
2023-11-04 19:31:15,100:INFO:_master_model_container: 20
2023-11-04 19:31:15,100:INFO:_display_container: 2
2023-11-04 19:31:15,101:INFO:DummyRegressor()
2023-11-04 19:31:15,101:INFO:compare_models() successfully completed......................................
2023-11-04 19:31:23,478:INFO:PyCaret RegressionExperiment
2023-11-04 19:31:23,478:INFO:Logging name: reg-default-name
2023-11-04 19:31:23,478:INFO:ML Usecase: MLUsecase.REGRESSION
2023-11-04 19:31:23,478:INFO:version 3.1.0
2023-11-04 19:31:23,478:INFO:Initializing setup()
2023-11-04 19:31:23,478:INFO:self.USI: 27b4
2023-11-04 19:31:23,478:INFO:self._variable_keys: {'USI', 'log_plots_param', 'gpu_param', 'fold_generator', 'X_test', 'html_param', '_ml_usecase', '_available_plots', 'exp_id', 'target_param', 'idx', 'fold_shuffle_param', 'n_jobs_param', 'seed', 'exp_name_log', 'X', 'y_train', 'transform_target_param', 'data', 'y_test', 'fold_groups_param', 'logging_param', 'gpu_n_jobs_param', 'y', 'X_train', 'memory', 'pipeline'}
2023-11-04 19:31:23,479:INFO:Checking environment
2023-11-04 19:31:23,479:INFO:python_version: 3.9.13
2023-11-04 19:31:23,479:INFO:python_build: ('main', 'Aug 25 2022 18:29:29')
2023-11-04 19:31:23,479:INFO:machine: x86_64
2023-11-04 19:31:23,479:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-11-04 19:31:23,479:INFO:Memory: svmem(total=17179869184, available=1429286912, percent=91.7, used=1921257472, free=20193280, active=1412845568, inactive=1407721472, wired=508411904)
2023-11-04 19:31:23,479:INFO:Physical Core: 8
2023-11-04 19:31:23,479:INFO:Logical Core: 8
2023-11-04 19:31:23,479:INFO:Checking libraries
2023-11-04 19:31:23,479:INFO:System:
2023-11-04 19:31:23,479:INFO:    python: 3.9.13 (main, Aug 25 2022, 18:29:29)  [Clang 12.0.0 ]
2023-11-04 19:31:23,479:INFO:executable: /Users/michal/opt/anaconda3/bin/python
2023-11-04 19:31:23,480:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-11-04 19:31:23,480:INFO:PyCaret required dependencies:
2023-11-04 19:31:23,480:INFO:                 pip: 22.2.2
2023-11-04 19:31:23,480:INFO:          setuptools: 63.4.1
2023-11-04 19:31:23,480:INFO:             pycaret: 3.1.0
2023-11-04 19:31:23,480:INFO:             IPython: 7.31.1
2023-11-04 19:31:23,480:INFO:          ipywidgets: 7.6.5
2023-11-04 19:31:23,480:INFO:                tqdm: 4.64.1
2023-11-04 19:31:23,480:INFO:               numpy: 1.21.5
2023-11-04 19:31:23,480:INFO:              pandas: 1.4.4
2023-11-04 19:31:23,480:INFO:              jinja2: 2.11.3
2023-11-04 19:31:23,480:INFO:               scipy: 1.10.1
2023-11-04 19:31:23,480:INFO:              joblib: 1.2.0
2023-11-04 19:31:23,480:INFO:             sklearn: 1.0.2
2023-11-04 19:31:23,480:INFO:                pyod: 1.1.1
2023-11-04 19:31:23,480:INFO:            imblearn: 0.10.1
2023-11-04 19:31:23,481:INFO:   category_encoders: 2.6.3
2023-11-04 19:31:23,481:INFO:            lightgbm: 3.3.5
2023-11-04 19:31:23,481:INFO:               numba: 0.55.1
2023-11-04 19:31:23,481:INFO:            requests: 2.28.1
2023-11-04 19:31:23,481:INFO:          matplotlib: 3.5.2
2023-11-04 19:31:23,481:INFO:          scikitplot: 0.3.7
2023-11-04 19:31:23,481:INFO:         yellowbrick: 1.5
2023-11-04 19:31:23,481:INFO:              plotly: 5.9.0
2023-11-04 19:31:23,481:INFO:    plotly-resampler: Not installed
2023-11-04 19:31:23,481:INFO:             kaleido: 0.2.1
2023-11-04 19:31:23,481:INFO:           schemdraw: 0.15
2023-11-04 19:31:23,481:INFO:         statsmodels: 0.13.2
2023-11-04 19:31:23,481:INFO:              sktime: 0.21.1
2023-11-04 19:31:23,481:INFO:               tbats: 1.1.3
2023-11-04 19:31:23,481:INFO:            pmdarima: 2.0.4
2023-11-04 19:31:23,481:INFO:              psutil: 5.9.0
2023-11-04 19:31:23,481:INFO:          markupsafe: 2.0.1
2023-11-04 19:31:23,481:INFO:             pickle5: Not installed
2023-11-04 19:31:23,481:INFO:         cloudpickle: 2.0.0
2023-11-04 19:31:23,482:INFO:         deprecation: 2.1.0
2023-11-04 19:31:23,482:INFO:              xxhash: 3.4.1
2023-11-04 19:31:23,482:INFO:           wurlitzer: 3.0.2
2023-11-04 19:31:23,482:INFO:PyCaret optional dependencies:
2023-11-04 19:31:23,482:INFO:                shap: 0.41.0
2023-11-04 19:31:23,482:INFO:           interpret: Not installed
2023-11-04 19:31:23,482:INFO:                umap: 0.5.3
2023-11-04 19:31:23,482:INFO:     ydata_profiling: Not installed
2023-11-04 19:31:23,482:INFO:  explainerdashboard: Not installed
2023-11-04 19:31:23,482:INFO:             autoviz: Not installed
2023-11-04 19:31:23,482:INFO:           fairlearn: Not installed
2023-11-04 19:31:23,482:INFO:          deepchecks: Not installed
2023-11-04 19:31:23,482:INFO:             xgboost: 1.7.4
2023-11-04 19:31:23,482:INFO:            catboost: 1.2
2023-11-04 19:31:23,482:INFO:              kmodes: Not installed
2023-11-04 19:31:23,482:INFO:             mlxtend: 0.21.0
2023-11-04 19:31:23,482:INFO:       statsforecast: Not installed
2023-11-04 19:31:23,482:INFO:        tune_sklearn: Not installed
2023-11-04 19:31:23,482:INFO:                 ray: Not installed
2023-11-04 19:31:23,482:INFO:            hyperopt: Not installed
2023-11-04 19:31:23,482:INFO:              optuna: Not installed
2023-11-04 19:31:23,482:INFO:               skopt: Not installed
2023-11-04 19:31:23,483:INFO:              mlflow: Not installed
2023-11-04 19:31:23,483:INFO:              gradio: Not installed
2023-11-04 19:31:23,483:INFO:             fastapi: Not installed
2023-11-04 19:31:23,483:INFO:             uvicorn: Not installed
2023-11-04 19:31:23,483:INFO:              m2cgen: Not installed
2023-11-04 19:31:23,483:INFO:           evidently: Not installed
2023-11-04 19:31:23,483:INFO:               fugue: Not installed
2023-11-04 19:31:23,483:INFO:           streamlit: Not installed
2023-11-04 19:31:23,483:INFO:             prophet: Not installed
2023-11-04 19:31:23,483:INFO:None
2023-11-04 19:31:23,483:INFO:Set up data.
2023-11-04 19:31:23,491:INFO:Set up folding strategy.
2023-11-04 19:31:23,492:INFO:Set up train/test split.
2023-11-04 19:31:23,494:INFO:Set up index.
2023-11-04 19:31:23,494:INFO:Assigning column types.
2023-11-04 19:31:23,497:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-04 19:31:23,497:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-04 19:31:23,501:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 19:31:23,508:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:31:23,556:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:31:23,583:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:31:23,583:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:31:23,584:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:31:23,585:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-04 19:31:23,588:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 19:31:23,590:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:31:23,623:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:31:23,649:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:31:23,649:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:31:23,651:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:31:23,651:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-11-04 19:31:23,654:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 19:31:23,656:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:31:23,688:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:31:23,715:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:31:23,715:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:31:23,717:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:31:23,719:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 19:31:23,722:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:31:23,755:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:31:23,781:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:31:23,781:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:31:23,782:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:31:23,782:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-11-04 19:31:23,788:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:31:23,822:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:31:23,848:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:31:23,848:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:31:23,850:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:31:23,855:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:31:23,888:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:31:23,914:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:31:23,914:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:31:23,915:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:31:23,916:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-11-04 19:31:23,953:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:31:23,979:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:31:23,979:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:31:23,981:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:31:24,018:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:31:24,044:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:31:24,044:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:31:24,045:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:31:24,045:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-04 19:31:24,083:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:31:24,108:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:31:24,110:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:31:24,147:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:31:24,173:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:31:24,174:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:31:24,175:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-11-04 19:31:24,239:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:31:24,240:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:31:24,304:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:31:24,309:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:31:24,310:INFO:Preparing preprocessing pipeline...
2023-11-04 19:31:24,310:INFO:Set up simple imputation.
2023-11-04 19:31:24,310:INFO:Set up variance threshold.
2023-11-04 19:31:24,310:INFO:Set up removing multicollinearity.
2023-11-04 19:31:24,310:INFO:Set up column name cleaning.
2023-11-04 19:31:24,329:INFO:Finished creating preprocessing pipeline.
2023-11-04 19:31:24,333:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/h9/5_75v3qs13x63s15wwxdrd000000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['solv_dG [kcal/mol]',
                                             'Bond dissociation entalphy',
                                             'water_ads [kcal/mol]', 'Coating',
                                             'Organic Matter Conc.', 'pH',
                                             'Primary Size', 'Initial Conc.',
                                             'Temp.', 'Ionic Strenght', 'Light',
                                             'MW', 'Noxy', 'χ', 'χox',
                                             'Z_metal', 'Zv...
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.1))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-11-04 19:31:24,333:INFO:Creating final display dataframe.
2023-11-04 19:31:24,379:INFO:Setup _display_container:                     Description             Value
0                    Session id              2587
1                        Target  %dissolved solid
2                   Target type        Regression
3           Original data shape         (248, 21)
4        Transformed data shape         (248, 20)
5   Transformed train set shape         (173, 20)
6    Transformed test set shape          (75, 20)
7              Numeric features                20
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12       Low variance threshold               0.1
13     Remove multicollinearity              True
14  Multicollinearity threshold              0.95
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              27b4
2023-11-04 19:31:24,448:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:31:24,450:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:31:24,517:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:31:24,518:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:31:24,519:INFO:setup() successfully completed in 1.04s...............
2023-11-04 19:31:24,519:INFO:Initializing compare_models()
2023-11-04 19:31:24,519:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412a4940>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fb4412a4940>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-11-04 19:31:24,519:INFO:Checking exceptions
2023-11-04 19:31:24,520:INFO:Preparing display monitor
2023-11-04 19:31:24,537:INFO:Initializing Linear Regression
2023-11-04 19:31:24,537:INFO:Total runtime is 3.0517578125e-06 minutes
2023-11-04 19:31:24,538:INFO:SubProcess create_model() called ==================================
2023-11-04 19:31:24,538:INFO:Initializing create_model()
2023-11-04 19:31:24,539:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412a4940>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb436a4ed60>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:31:24,539:INFO:Checking exceptions
2023-11-04 19:31:24,539:INFO:Importing libraries
2023-11-04 19:31:24,539:INFO:Copying training dataset
2023-11-04 19:31:24,540:INFO:Defining folds
2023-11-04 19:31:24,541:INFO:Declaring metric variables
2023-11-04 19:31:24,542:INFO:Importing untrained model
2023-11-04 19:31:24,544:INFO:Linear Regression Imported successfully
2023-11-04 19:31:24,547:INFO:Starting cross validation
2023-11-04 19:31:24,548:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:31:24,604:INFO:Calculating mean and std
2023-11-04 19:31:24,605:INFO:Creating metrics dataframe
2023-11-04 19:31:24,606:INFO:Uploading results into container
2023-11-04 19:31:24,607:INFO:Uploading model into container now
2023-11-04 19:31:24,607:INFO:_master_model_container: 1
2023-11-04 19:31:24,607:INFO:_display_container: 2
2023-11-04 19:31:24,607:INFO:LinearRegression(n_jobs=-1)
2023-11-04 19:31:24,607:INFO:create_model() successfully completed......................................
2023-11-04 19:31:24,722:INFO:SubProcess create_model() end ==================================
2023-11-04 19:31:24,722:INFO:Creating metrics dataframe
2023-11-04 19:31:24,726:INFO:Initializing Lasso Regression
2023-11-04 19:31:24,726:INFO:Total runtime is 0.0031638701756795244 minutes
2023-11-04 19:31:24,728:INFO:SubProcess create_model() called ==================================
2023-11-04 19:31:24,728:INFO:Initializing create_model()
2023-11-04 19:31:24,728:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412a4940>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb436a4ed60>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:31:24,729:INFO:Checking exceptions
2023-11-04 19:31:24,729:INFO:Importing libraries
2023-11-04 19:31:24,729:INFO:Copying training dataset
2023-11-04 19:31:24,730:INFO:Defining folds
2023-11-04 19:31:24,730:INFO:Declaring metric variables
2023-11-04 19:31:24,732:INFO:Importing untrained model
2023-11-04 19:31:24,733:INFO:Lasso Regression Imported successfully
2023-11-04 19:31:24,736:INFO:Starting cross validation
2023-11-04 19:31:24,737:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:31:24,797:INFO:Calculating mean and std
2023-11-04 19:31:24,798:INFO:Creating metrics dataframe
2023-11-04 19:31:24,799:INFO:Uploading results into container
2023-11-04 19:31:24,799:INFO:Uploading model into container now
2023-11-04 19:31:24,800:INFO:_master_model_container: 2
2023-11-04 19:31:24,800:INFO:_display_container: 2
2023-11-04 19:31:24,800:INFO:Lasso(random_state=2587)
2023-11-04 19:31:24,800:INFO:create_model() successfully completed......................................
2023-11-04 19:31:24,911:INFO:SubProcess create_model() end ==================================
2023-11-04 19:31:24,911:INFO:Creating metrics dataframe
2023-11-04 19:31:24,915:INFO:Initializing Ridge Regression
2023-11-04 19:31:24,916:INFO:Total runtime is 0.006315950552622476 minutes
2023-11-04 19:31:24,917:INFO:SubProcess create_model() called ==================================
2023-11-04 19:31:24,918:INFO:Initializing create_model()
2023-11-04 19:31:24,918:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412a4940>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb436a4ed60>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:31:24,918:INFO:Checking exceptions
2023-11-04 19:31:24,918:INFO:Importing libraries
2023-11-04 19:31:24,918:INFO:Copying training dataset
2023-11-04 19:31:24,919:INFO:Defining folds
2023-11-04 19:31:24,919:INFO:Declaring metric variables
2023-11-04 19:31:24,921:INFO:Importing untrained model
2023-11-04 19:31:24,922:INFO:Ridge Regression Imported successfully
2023-11-04 19:31:24,925:INFO:Starting cross validation
2023-11-04 19:31:24,926:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:31:24,978:INFO:Calculating mean and std
2023-11-04 19:31:24,978:INFO:Creating metrics dataframe
2023-11-04 19:31:24,980:INFO:Uploading results into container
2023-11-04 19:31:24,980:INFO:Uploading model into container now
2023-11-04 19:31:24,981:INFO:_master_model_container: 3
2023-11-04 19:31:24,981:INFO:_display_container: 2
2023-11-04 19:31:24,981:INFO:Ridge(random_state=2587)
2023-11-04 19:31:24,981:INFO:create_model() successfully completed......................................
2023-11-04 19:31:25,091:INFO:SubProcess create_model() end ==================================
2023-11-04 19:31:25,091:INFO:Creating metrics dataframe
2023-11-04 19:31:25,096:INFO:Initializing Elastic Net
2023-11-04 19:31:25,096:INFO:Total runtime is 0.009325134754180908 minutes
2023-11-04 19:31:25,098:INFO:SubProcess create_model() called ==================================
2023-11-04 19:31:25,098:INFO:Initializing create_model()
2023-11-04 19:31:25,098:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412a4940>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb436a4ed60>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:31:25,098:INFO:Checking exceptions
2023-11-04 19:31:25,098:INFO:Importing libraries
2023-11-04 19:31:25,098:INFO:Copying training dataset
2023-11-04 19:31:25,100:INFO:Defining folds
2023-11-04 19:31:25,100:INFO:Declaring metric variables
2023-11-04 19:31:25,101:INFO:Importing untrained model
2023-11-04 19:31:25,103:INFO:Elastic Net Imported successfully
2023-11-04 19:31:25,106:INFO:Starting cross validation
2023-11-04 19:31:25,107:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:31:25,161:INFO:Calculating mean and std
2023-11-04 19:31:25,162:INFO:Creating metrics dataframe
2023-11-04 19:31:25,163:INFO:Uploading results into container
2023-11-04 19:31:25,164:INFO:Uploading model into container now
2023-11-04 19:31:25,164:INFO:_master_model_container: 4
2023-11-04 19:31:25,164:INFO:_display_container: 2
2023-11-04 19:31:25,164:INFO:ElasticNet(random_state=2587)
2023-11-04 19:31:25,164:INFO:create_model() successfully completed......................................
2023-11-04 19:31:25,273:INFO:SubProcess create_model() end ==================================
2023-11-04 19:31:25,274:INFO:Creating metrics dataframe
2023-11-04 19:31:25,279:INFO:Initializing Least Angle Regression
2023-11-04 19:31:25,279:INFO:Total runtime is 0.012368881702423095 minutes
2023-11-04 19:31:25,280:INFO:SubProcess create_model() called ==================================
2023-11-04 19:31:25,281:INFO:Initializing create_model()
2023-11-04 19:31:25,281:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412a4940>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb436a4ed60>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:31:25,281:INFO:Checking exceptions
2023-11-04 19:31:25,281:INFO:Importing libraries
2023-11-04 19:31:25,281:INFO:Copying training dataset
2023-11-04 19:31:25,282:INFO:Defining folds
2023-11-04 19:31:25,282:INFO:Declaring metric variables
2023-11-04 19:31:25,284:INFO:Importing untrained model
2023-11-04 19:31:25,286:INFO:Least Angle Regression Imported successfully
2023-11-04 19:31:25,289:INFO:Starting cross validation
2023-11-04 19:31:25,289:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:31:25,309:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:31:25,313:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:31:25,316:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:31:25,322:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:31:25,328:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:31:25,330:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:31:25,332:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:31:25,333:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:31:25,337:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:31:25,339:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:31:25,346:INFO:Calculating mean and std
2023-11-04 19:31:25,346:INFO:Creating metrics dataframe
2023-11-04 19:31:25,348:INFO:Uploading results into container
2023-11-04 19:31:25,348:INFO:Uploading model into container now
2023-11-04 19:31:25,348:INFO:_master_model_container: 5
2023-11-04 19:31:25,348:INFO:_display_container: 2
2023-11-04 19:31:25,348:INFO:Lars(random_state=2587)
2023-11-04 19:31:25,348:INFO:create_model() successfully completed......................................
2023-11-04 19:31:25,459:INFO:SubProcess create_model() end ==================================
2023-11-04 19:31:25,459:INFO:Creating metrics dataframe
2023-11-04 19:31:25,464:INFO:Initializing Lasso Least Angle Regression
2023-11-04 19:31:25,464:INFO:Total runtime is 0.015465188026428222 minutes
2023-11-04 19:31:25,466:INFO:SubProcess create_model() called ==================================
2023-11-04 19:31:25,467:INFO:Initializing create_model()
2023-11-04 19:31:25,467:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412a4940>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb436a4ed60>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:31:25,467:INFO:Checking exceptions
2023-11-04 19:31:25,467:INFO:Importing libraries
2023-11-04 19:31:25,467:INFO:Copying training dataset
2023-11-04 19:31:25,468:INFO:Defining folds
2023-11-04 19:31:25,468:INFO:Declaring metric variables
2023-11-04 19:31:25,470:INFO:Importing untrained model
2023-11-04 19:31:25,471:INFO:Lasso Least Angle Regression Imported successfully
2023-11-04 19:31:25,474:INFO:Starting cross validation
2023-11-04 19:31:25,475:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:31:25,494:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:31:25,497:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:31:25,502:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:31:25,505:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:31:25,510:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:31:25,511:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:31:25,518:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:31:25,524:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:31:25,525:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:31:25,526:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:31:25,531:INFO:Calculating mean and std
2023-11-04 19:31:25,532:INFO:Creating metrics dataframe
2023-11-04 19:31:25,534:INFO:Uploading results into container
2023-11-04 19:31:25,535:INFO:Uploading model into container now
2023-11-04 19:31:25,535:INFO:_master_model_container: 6
2023-11-04 19:31:25,535:INFO:_display_container: 2
2023-11-04 19:31:25,535:INFO:LassoLars(random_state=2587)
2023-11-04 19:31:25,535:INFO:create_model() successfully completed......................................
2023-11-04 19:31:25,659:INFO:SubProcess create_model() end ==================================
2023-11-04 19:31:25,659:INFO:Creating metrics dataframe
2023-11-04 19:31:25,665:INFO:Initializing Orthogonal Matching Pursuit
2023-11-04 19:31:25,665:INFO:Total runtime is 0.018812302748362222 minutes
2023-11-04 19:31:25,667:INFO:SubProcess create_model() called ==================================
2023-11-04 19:31:25,667:INFO:Initializing create_model()
2023-11-04 19:31:25,667:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412a4940>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb436a4ed60>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:31:25,667:INFO:Checking exceptions
2023-11-04 19:31:25,667:INFO:Importing libraries
2023-11-04 19:31:25,668:INFO:Copying training dataset
2023-11-04 19:31:25,669:INFO:Defining folds
2023-11-04 19:31:25,669:INFO:Declaring metric variables
2023-11-04 19:31:25,671:INFO:Importing untrained model
2023-11-04 19:31:25,672:INFO:Orthogonal Matching Pursuit Imported successfully
2023-11-04 19:31:25,676:INFO:Starting cross validation
2023-11-04 19:31:25,677:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:31:25,700:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:31:25,701:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:31:25,705:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:31:25,715:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:31:25,716:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:31:25,720:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:31:25,720:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:31:25,727:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:31:25,729:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:31:25,735:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:31:25,740:INFO:Calculating mean and std
2023-11-04 19:31:25,741:INFO:Creating metrics dataframe
2023-11-04 19:31:25,742:INFO:Uploading results into container
2023-11-04 19:31:25,743:INFO:Uploading model into container now
2023-11-04 19:31:25,743:INFO:_master_model_container: 7
2023-11-04 19:31:25,743:INFO:_display_container: 2
2023-11-04 19:31:25,743:INFO:OrthogonalMatchingPursuit()
2023-11-04 19:31:25,743:INFO:create_model() successfully completed......................................
2023-11-04 19:31:25,865:INFO:SubProcess create_model() end ==================================
2023-11-04 19:31:25,865:INFO:Creating metrics dataframe
2023-11-04 19:31:25,871:INFO:Initializing Bayesian Ridge
2023-11-04 19:31:25,871:INFO:Total runtime is 0.022238234678904213 minutes
2023-11-04 19:31:25,873:INFO:SubProcess create_model() called ==================================
2023-11-04 19:31:25,873:INFO:Initializing create_model()
2023-11-04 19:31:25,873:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412a4940>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb436a4ed60>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:31:25,873:INFO:Checking exceptions
2023-11-04 19:31:25,873:INFO:Importing libraries
2023-11-04 19:31:25,873:INFO:Copying training dataset
2023-11-04 19:31:25,875:INFO:Defining folds
2023-11-04 19:31:25,875:INFO:Declaring metric variables
2023-11-04 19:31:25,877:INFO:Importing untrained model
2023-11-04 19:31:25,879:INFO:Bayesian Ridge Imported successfully
2023-11-04 19:31:25,882:INFO:Starting cross validation
2023-11-04 19:31:25,883:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:31:25,954:INFO:Calculating mean and std
2023-11-04 19:31:25,955:INFO:Creating metrics dataframe
2023-11-04 19:31:25,956:INFO:Uploading results into container
2023-11-04 19:31:25,957:INFO:Uploading model into container now
2023-11-04 19:31:25,957:INFO:_master_model_container: 8
2023-11-04 19:31:25,957:INFO:_display_container: 2
2023-11-04 19:31:25,957:INFO:BayesianRidge()
2023-11-04 19:31:25,957:INFO:create_model() successfully completed......................................
2023-11-04 19:31:26,080:INFO:SubProcess create_model() end ==================================
2023-11-04 19:31:26,080:INFO:Creating metrics dataframe
2023-11-04 19:31:26,086:INFO:Initializing Passive Aggressive Regressor
2023-11-04 19:31:26,086:INFO:Total runtime is 0.02582451502482096 minutes
2023-11-04 19:31:26,088:INFO:SubProcess create_model() called ==================================
2023-11-04 19:31:26,088:INFO:Initializing create_model()
2023-11-04 19:31:26,088:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412a4940>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb436a4ed60>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:31:26,088:INFO:Checking exceptions
2023-11-04 19:31:26,088:INFO:Importing libraries
2023-11-04 19:31:26,088:INFO:Copying training dataset
2023-11-04 19:31:26,090:INFO:Defining folds
2023-11-04 19:31:26,090:INFO:Declaring metric variables
2023-11-04 19:31:26,092:INFO:Importing untrained model
2023-11-04 19:31:26,094:INFO:Passive Aggressive Regressor Imported successfully
2023-11-04 19:31:26,097:INFO:Starting cross validation
2023-11-04 19:31:26,097:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:31:26,163:INFO:Calculating mean and std
2023-11-04 19:31:26,163:INFO:Creating metrics dataframe
2023-11-04 19:31:26,165:INFO:Uploading results into container
2023-11-04 19:31:26,165:INFO:Uploading model into container now
2023-11-04 19:31:26,166:INFO:_master_model_container: 9
2023-11-04 19:31:26,166:INFO:_display_container: 2
2023-11-04 19:31:26,166:INFO:PassiveAggressiveRegressor(random_state=2587)
2023-11-04 19:31:26,166:INFO:create_model() successfully completed......................................
2023-11-04 19:31:26,290:INFO:SubProcess create_model() end ==================================
2023-11-04 19:31:26,290:INFO:Creating metrics dataframe
2023-11-04 19:31:26,296:INFO:Initializing Huber Regressor
2023-11-04 19:31:26,296:INFO:Total runtime is 0.02932623227437337 minutes
2023-11-04 19:31:26,298:INFO:SubProcess create_model() called ==================================
2023-11-04 19:31:26,298:INFO:Initializing create_model()
2023-11-04 19:31:26,298:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412a4940>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb436a4ed60>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:31:26,298:INFO:Checking exceptions
2023-11-04 19:31:26,299:INFO:Importing libraries
2023-11-04 19:31:26,299:INFO:Copying training dataset
2023-11-04 19:31:26,301:INFO:Defining folds
2023-11-04 19:31:26,301:INFO:Declaring metric variables
2023-11-04 19:31:26,302:INFO:Importing untrained model
2023-11-04 19:31:26,304:INFO:Huber Regressor Imported successfully
2023-11-04 19:31:26,307:INFO:Starting cross validation
2023-11-04 19:31:26,308:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:31:26,341:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:31:26,350:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:31:26,374:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:31:26,375:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:31:26,379:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:31:26,386:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:31:26,388:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:31:26,393:INFO:Calculating mean and std
2023-11-04 19:31:26,393:INFO:Creating metrics dataframe
2023-11-04 19:31:26,395:INFO:Uploading results into container
2023-11-04 19:31:26,396:INFO:Uploading model into container now
2023-11-04 19:31:26,396:INFO:_master_model_container: 10
2023-11-04 19:31:26,396:INFO:_display_container: 2
2023-11-04 19:31:26,396:INFO:HuberRegressor()
2023-11-04 19:31:26,396:INFO:create_model() successfully completed......................................
2023-11-04 19:31:26,520:INFO:SubProcess create_model() end ==================================
2023-11-04 19:31:26,520:INFO:Creating metrics dataframe
2023-11-04 19:31:26,527:INFO:Initializing K Neighbors Regressor
2023-11-04 19:31:26,527:INFO:Total runtime is 0.03316775163014729 minutes
2023-11-04 19:31:26,528:INFO:SubProcess create_model() called ==================================
2023-11-04 19:31:26,529:INFO:Initializing create_model()
2023-11-04 19:31:26,529:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412a4940>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb436a4ed60>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:31:26,529:INFO:Checking exceptions
2023-11-04 19:31:26,529:INFO:Importing libraries
2023-11-04 19:31:26,529:INFO:Copying training dataset
2023-11-04 19:31:26,531:INFO:Defining folds
2023-11-04 19:31:26,531:INFO:Declaring metric variables
2023-11-04 19:31:26,533:INFO:Importing untrained model
2023-11-04 19:31:26,535:INFO:K Neighbors Regressor Imported successfully
2023-11-04 19:31:26,537:INFO:Starting cross validation
2023-11-04 19:31:26,538:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:31:26,614:INFO:Calculating mean and std
2023-11-04 19:31:26,614:INFO:Creating metrics dataframe
2023-11-04 19:31:26,616:INFO:Uploading results into container
2023-11-04 19:31:26,616:INFO:Uploading model into container now
2023-11-04 19:31:26,616:INFO:_master_model_container: 11
2023-11-04 19:31:26,616:INFO:_display_container: 2
2023-11-04 19:31:26,616:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-04 19:31:26,616:INFO:create_model() successfully completed......................................
2023-11-04 19:31:26,743:INFO:SubProcess create_model() end ==================================
2023-11-04 19:31:26,743:INFO:Creating metrics dataframe
2023-11-04 19:31:26,749:INFO:Initializing Decision Tree Regressor
2023-11-04 19:31:26,750:INFO:Total runtime is 0.036883433659871415 minutes
2023-11-04 19:31:26,751:INFO:SubProcess create_model() called ==================================
2023-11-04 19:31:26,752:INFO:Initializing create_model()
2023-11-04 19:31:26,752:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412a4940>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb436a4ed60>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:31:26,752:INFO:Checking exceptions
2023-11-04 19:31:26,752:INFO:Importing libraries
2023-11-04 19:31:26,752:INFO:Copying training dataset
2023-11-04 19:31:26,754:INFO:Defining folds
2023-11-04 19:31:26,754:INFO:Declaring metric variables
2023-11-04 19:31:26,756:INFO:Importing untrained model
2023-11-04 19:31:26,758:INFO:Decision Tree Regressor Imported successfully
2023-11-04 19:31:26,761:INFO:Starting cross validation
2023-11-04 19:31:26,762:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:31:26,818:INFO:Calculating mean and std
2023-11-04 19:31:26,819:INFO:Creating metrics dataframe
2023-11-04 19:31:26,820:INFO:Uploading results into container
2023-11-04 19:31:26,821:INFO:Uploading model into container now
2023-11-04 19:31:26,821:INFO:_master_model_container: 12
2023-11-04 19:31:26,821:INFO:_display_container: 2
2023-11-04 19:31:26,821:INFO:DecisionTreeRegressor(random_state=2587)
2023-11-04 19:31:26,821:INFO:create_model() successfully completed......................................
2023-11-04 19:31:26,931:INFO:SubProcess create_model() end ==================================
2023-11-04 19:31:26,931:INFO:Creating metrics dataframe
2023-11-04 19:31:26,937:INFO:Initializing Random Forest Regressor
2023-11-04 19:31:26,937:INFO:Total runtime is 0.040010269482930495 minutes
2023-11-04 19:31:26,939:INFO:SubProcess create_model() called ==================================
2023-11-04 19:31:26,939:INFO:Initializing create_model()
2023-11-04 19:31:26,939:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412a4940>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb436a4ed60>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:31:26,939:INFO:Checking exceptions
2023-11-04 19:31:26,939:INFO:Importing libraries
2023-11-04 19:31:26,939:INFO:Copying training dataset
2023-11-04 19:31:26,941:INFO:Defining folds
2023-11-04 19:31:26,941:INFO:Declaring metric variables
2023-11-04 19:31:26,943:INFO:Importing untrained model
2023-11-04 19:31:26,945:INFO:Random Forest Regressor Imported successfully
2023-11-04 19:31:26,948:INFO:Starting cross validation
2023-11-04 19:31:26,949:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:31:27,258:INFO:Calculating mean and std
2023-11-04 19:31:27,259:INFO:Creating metrics dataframe
2023-11-04 19:31:27,261:INFO:Uploading results into container
2023-11-04 19:31:27,261:INFO:Uploading model into container now
2023-11-04 19:31:27,261:INFO:_master_model_container: 13
2023-11-04 19:31:27,261:INFO:_display_container: 2
2023-11-04 19:31:27,262:INFO:RandomForestRegressor(n_jobs=-1, random_state=2587)
2023-11-04 19:31:27,262:INFO:create_model() successfully completed......................................
2023-11-04 19:31:27,371:INFO:SubProcess create_model() end ==================================
2023-11-04 19:31:27,371:INFO:Creating metrics dataframe
2023-11-04 19:31:27,378:INFO:Initializing Extra Trees Regressor
2023-11-04 19:31:27,378:INFO:Total runtime is 0.047356168429056794 minutes
2023-11-04 19:31:27,380:INFO:SubProcess create_model() called ==================================
2023-11-04 19:31:27,380:INFO:Initializing create_model()
2023-11-04 19:31:27,380:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412a4940>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb436a4ed60>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:31:27,380:INFO:Checking exceptions
2023-11-04 19:31:27,380:INFO:Importing libraries
2023-11-04 19:31:27,380:INFO:Copying training dataset
2023-11-04 19:31:27,382:INFO:Defining folds
2023-11-04 19:31:27,382:INFO:Declaring metric variables
2023-11-04 19:31:27,384:INFO:Importing untrained model
2023-11-04 19:31:27,385:INFO:Extra Trees Regressor Imported successfully
2023-11-04 19:31:27,389:INFO:Starting cross validation
2023-11-04 19:31:27,389:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:31:27,634:INFO:Calculating mean and std
2023-11-04 19:31:27,635:INFO:Creating metrics dataframe
2023-11-04 19:31:27,637:INFO:Uploading results into container
2023-11-04 19:31:27,637:INFO:Uploading model into container now
2023-11-04 19:31:27,637:INFO:_master_model_container: 14
2023-11-04 19:31:27,637:INFO:_display_container: 2
2023-11-04 19:31:27,638:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=2587)
2023-11-04 19:31:27,638:INFO:create_model() successfully completed......................................
2023-11-04 19:31:27,747:INFO:SubProcess create_model() end ==================================
2023-11-04 19:31:27,747:INFO:Creating metrics dataframe
2023-11-04 19:31:27,754:INFO:Initializing AdaBoost Regressor
2023-11-04 19:31:27,754:INFO:Total runtime is 0.05361996889114379 minutes
2023-11-04 19:31:27,756:INFO:SubProcess create_model() called ==================================
2023-11-04 19:31:27,756:INFO:Initializing create_model()
2023-11-04 19:31:27,756:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412a4940>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb436a4ed60>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:31:27,756:INFO:Checking exceptions
2023-11-04 19:31:27,756:INFO:Importing libraries
2023-11-04 19:31:27,756:INFO:Copying training dataset
2023-11-04 19:31:27,758:INFO:Defining folds
2023-11-04 19:31:27,758:INFO:Declaring metric variables
2023-11-04 19:31:27,760:INFO:Importing untrained model
2023-11-04 19:31:27,762:INFO:AdaBoost Regressor Imported successfully
2023-11-04 19:31:27,765:INFO:Starting cross validation
2023-11-04 19:31:27,765:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:31:27,900:INFO:Calculating mean and std
2023-11-04 19:31:27,901:INFO:Creating metrics dataframe
2023-11-04 19:31:27,903:INFO:Uploading results into container
2023-11-04 19:31:27,904:INFO:Uploading model into container now
2023-11-04 19:31:27,904:INFO:_master_model_container: 15
2023-11-04 19:31:27,904:INFO:_display_container: 2
2023-11-04 19:31:27,904:INFO:AdaBoostRegressor(random_state=2587)
2023-11-04 19:31:27,905:INFO:create_model() successfully completed......................................
2023-11-04 19:31:28,020:INFO:SubProcess create_model() end ==================================
2023-11-04 19:31:28,020:INFO:Creating metrics dataframe
2023-11-04 19:31:28,027:INFO:Initializing Gradient Boosting Regressor
2023-11-04 19:31:28,027:INFO:Total runtime is 0.058167719841003405 minutes
2023-11-04 19:31:28,028:INFO:SubProcess create_model() called ==================================
2023-11-04 19:31:28,029:INFO:Initializing create_model()
2023-11-04 19:31:28,029:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412a4940>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb436a4ed60>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:31:28,029:INFO:Checking exceptions
2023-11-04 19:31:28,029:INFO:Importing libraries
2023-11-04 19:31:28,029:INFO:Copying training dataset
2023-11-04 19:31:28,031:INFO:Defining folds
2023-11-04 19:31:28,031:INFO:Declaring metric variables
2023-11-04 19:31:28,033:INFO:Importing untrained model
2023-11-04 19:31:28,035:INFO:Gradient Boosting Regressor Imported successfully
2023-11-04 19:31:28,038:INFO:Starting cross validation
2023-11-04 19:31:28,038:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:31:28,176:INFO:Calculating mean and std
2023-11-04 19:31:28,177:INFO:Creating metrics dataframe
2023-11-04 19:31:28,179:INFO:Uploading results into container
2023-11-04 19:31:28,180:INFO:Uploading model into container now
2023-11-04 19:31:28,180:INFO:_master_model_container: 16
2023-11-04 19:31:28,180:INFO:_display_container: 2
2023-11-04 19:31:28,180:INFO:GradientBoostingRegressor(random_state=2587)
2023-11-04 19:31:28,180:INFO:create_model() successfully completed......................................
2023-11-04 19:31:28,290:INFO:SubProcess create_model() end ==================================
2023-11-04 19:31:28,290:INFO:Creating metrics dataframe
2023-11-04 19:31:28,297:INFO:Initializing Extreme Gradient Boosting
2023-11-04 19:31:28,297:INFO:Total runtime is 0.06266982158025104 minutes
2023-11-04 19:31:28,298:INFO:SubProcess create_model() called ==================================
2023-11-04 19:31:28,299:INFO:Initializing create_model()
2023-11-04 19:31:28,299:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412a4940>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb436a4ed60>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:31:28,299:INFO:Checking exceptions
2023-11-04 19:31:28,299:INFO:Importing libraries
2023-11-04 19:31:28,299:INFO:Copying training dataset
2023-11-04 19:31:28,301:INFO:Defining folds
2023-11-04 19:31:28,301:INFO:Declaring metric variables
2023-11-04 19:31:28,303:INFO:Importing untrained model
2023-11-04 19:31:28,305:INFO:Extreme Gradient Boosting Imported successfully
2023-11-04 19:31:28,308:INFO:Starting cross validation
2023-11-04 19:31:28,309:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:31:28,460:INFO:Calculating mean and std
2023-11-04 19:31:28,461:INFO:Creating metrics dataframe
2023-11-04 19:31:28,463:INFO:Uploading results into container
2023-11-04 19:31:28,463:INFO:Uploading model into container now
2023-11-04 19:31:28,463:INFO:_master_model_container: 17
2023-11-04 19:31:28,464:INFO:_display_container: 2
2023-11-04 19:31:28,464:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=2587, ...)
2023-11-04 19:31:28,464:INFO:create_model() successfully completed......................................
2023-11-04 19:31:28,574:INFO:SubProcess create_model() end ==================================
2023-11-04 19:31:28,574:INFO:Creating metrics dataframe
2023-11-04 19:31:28,581:INFO:Initializing Light Gradient Boosting Machine
2023-11-04 19:31:28,581:INFO:Total runtime is 0.0674064517021179 minutes
2023-11-04 19:31:28,583:INFO:SubProcess create_model() called ==================================
2023-11-04 19:31:28,583:INFO:Initializing create_model()
2023-11-04 19:31:28,583:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412a4940>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb436a4ed60>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:31:28,583:INFO:Checking exceptions
2023-11-04 19:31:28,583:INFO:Importing libraries
2023-11-04 19:31:28,583:INFO:Copying training dataset
2023-11-04 19:31:28,585:INFO:Defining folds
2023-11-04 19:31:28,585:INFO:Declaring metric variables
2023-11-04 19:31:28,587:INFO:Importing untrained model
2023-11-04 19:31:28,589:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-04 19:31:28,592:INFO:Starting cross validation
2023-11-04 19:31:28,592:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:31:28,663:INFO:Calculating mean and std
2023-11-04 19:31:28,663:INFO:Creating metrics dataframe
2023-11-04 19:31:28,665:INFO:Uploading results into container
2023-11-04 19:31:28,665:INFO:Uploading model into container now
2023-11-04 19:31:28,665:INFO:_master_model_container: 18
2023-11-04 19:31:28,665:INFO:_display_container: 2
2023-11-04 19:31:28,666:INFO:LGBMRegressor(random_state=2587)
2023-11-04 19:31:28,666:INFO:create_model() successfully completed......................................
2023-11-04 19:31:28,775:INFO:SubProcess create_model() end ==================================
2023-11-04 19:31:28,775:INFO:Creating metrics dataframe
2023-11-04 19:31:28,782:INFO:Initializing CatBoost Regressor
2023-11-04 19:31:28,783:INFO:Total runtime is 0.07076685428619382 minutes
2023-11-04 19:31:28,784:INFO:SubProcess create_model() called ==================================
2023-11-04 19:31:28,785:INFO:Initializing create_model()
2023-11-04 19:31:28,785:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412a4940>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb436a4ed60>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:31:28,785:INFO:Checking exceptions
2023-11-04 19:31:28,785:INFO:Importing libraries
2023-11-04 19:31:28,785:INFO:Copying training dataset
2023-11-04 19:31:28,787:INFO:Defining folds
2023-11-04 19:31:28,787:INFO:Declaring metric variables
2023-11-04 19:31:28,788:INFO:Importing untrained model
2023-11-04 19:31:28,790:INFO:CatBoost Regressor Imported successfully
2023-11-04 19:31:28,793:INFO:Starting cross validation
2023-11-04 19:31:28,794:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:31:31,585:INFO:Calculating mean and std
2023-11-04 19:31:31,586:INFO:Creating metrics dataframe
2023-11-04 19:31:31,588:INFO:Uploading results into container
2023-11-04 19:31:31,589:INFO:Uploading model into container now
2023-11-04 19:31:31,589:INFO:_master_model_container: 19
2023-11-04 19:31:31,589:INFO:_display_container: 2
2023-11-04 19:31:31,589:INFO:<catboost.core.CatBoostRegressor object at 0x7fb44130e1f0>
2023-11-04 19:31:31,589:INFO:create_model() successfully completed......................................
2023-11-04 19:31:31,703:INFO:SubProcess create_model() end ==================================
2023-11-04 19:31:31,703:INFO:Creating metrics dataframe
2023-11-04 19:31:31,710:INFO:Initializing Dummy Regressor
2023-11-04 19:31:31,711:INFO:Total runtime is 0.11956686973571776 minutes
2023-11-04 19:31:31,712:INFO:SubProcess create_model() called ==================================
2023-11-04 19:31:31,713:INFO:Initializing create_model()
2023-11-04 19:31:31,713:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412a4940>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb436a4ed60>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:31:31,713:INFO:Checking exceptions
2023-11-04 19:31:31,713:INFO:Importing libraries
2023-11-04 19:31:31,713:INFO:Copying training dataset
2023-11-04 19:31:31,715:INFO:Defining folds
2023-11-04 19:31:31,715:INFO:Declaring metric variables
2023-11-04 19:31:31,717:INFO:Importing untrained model
2023-11-04 19:31:31,718:INFO:Dummy Regressor Imported successfully
2023-11-04 19:31:31,721:INFO:Starting cross validation
2023-11-04 19:31:31,722:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:31:31,778:INFO:Calculating mean and std
2023-11-04 19:31:31,779:INFO:Creating metrics dataframe
2023-11-04 19:31:31,781:INFO:Uploading results into container
2023-11-04 19:31:31,781:INFO:Uploading model into container now
2023-11-04 19:31:31,781:INFO:_master_model_container: 20
2023-11-04 19:31:31,781:INFO:_display_container: 2
2023-11-04 19:31:31,781:INFO:DummyRegressor()
2023-11-04 19:31:31,781:INFO:create_model() successfully completed......................................
2023-11-04 19:31:31,892:INFO:SubProcess create_model() end ==================================
2023-11-04 19:31:31,892:INFO:Creating metrics dataframe
2023-11-04 19:31:31,904:INFO:Initializing create_model()
2023-11-04 19:31:31,904:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412a4940>, estimator=<catboost.core.CatBoostRegressor object at 0x7fb44130e1f0>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:31:31,904:INFO:Checking exceptions
2023-11-04 19:31:31,905:INFO:Importing libraries
2023-11-04 19:31:31,905:INFO:Copying training dataset
2023-11-04 19:31:31,907:INFO:Defining folds
2023-11-04 19:31:31,907:INFO:Declaring metric variables
2023-11-04 19:31:31,907:INFO:Importing untrained model
2023-11-04 19:31:31,907:INFO:Declaring custom model
2023-11-04 19:31:31,908:INFO:CatBoost Regressor Imported successfully
2023-11-04 19:31:31,908:INFO:Cross validation set to False
2023-11-04 19:31:31,908:INFO:Fitting Model
2023-11-04 19:31:32,543:INFO:<catboost.core.CatBoostRegressor object at 0x7fb4413269a0>
2023-11-04 19:31:32,543:INFO:create_model() successfully completed......................................
2023-11-04 19:31:32,673:INFO:_master_model_container: 20
2023-11-04 19:31:32,673:INFO:_display_container: 2
2023-11-04 19:31:32,673:INFO:<catboost.core.CatBoostRegressor object at 0x7fb4413269a0>
2023-11-04 19:31:32,673:INFO:compare_models() successfully completed......................................
2023-11-04 19:32:18,090:INFO:PyCaret RegressionExperiment
2023-11-04 19:32:18,091:INFO:Logging name: reg-default-name
2023-11-04 19:32:18,091:INFO:ML Usecase: MLUsecase.REGRESSION
2023-11-04 19:32:18,091:INFO:version 3.1.0
2023-11-04 19:32:18,091:INFO:Initializing setup()
2023-11-04 19:32:18,091:INFO:self.USI: 8273
2023-11-04 19:32:18,091:INFO:self._variable_keys: {'USI', 'log_plots_param', 'gpu_param', 'fold_generator', 'X_test', 'html_param', '_ml_usecase', '_available_plots', 'exp_id', 'target_param', 'idx', 'fold_shuffle_param', 'n_jobs_param', 'seed', 'exp_name_log', 'X', 'y_train', 'transform_target_param', 'data', 'y_test', 'fold_groups_param', 'logging_param', 'gpu_n_jobs_param', 'y', 'X_train', 'memory', 'pipeline'}
2023-11-04 19:32:18,091:INFO:Checking environment
2023-11-04 19:32:18,091:INFO:python_version: 3.9.13
2023-11-04 19:32:18,091:INFO:python_build: ('main', 'Aug 25 2022 18:29:29')
2023-11-04 19:32:18,091:INFO:machine: x86_64
2023-11-04 19:32:18,091:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-11-04 19:32:18,091:INFO:Memory: svmem(total=17179869184, available=1435860992, percent=91.6, used=1912631296, free=38346752, active=1398710272, inactive=1391697920, wired=513921024)
2023-11-04 19:32:18,091:INFO:Physical Core: 8
2023-11-04 19:32:18,091:INFO:Logical Core: 8
2023-11-04 19:32:18,091:INFO:Checking libraries
2023-11-04 19:32:18,091:INFO:System:
2023-11-04 19:32:18,091:INFO:    python: 3.9.13 (main, Aug 25 2022, 18:29:29)  [Clang 12.0.0 ]
2023-11-04 19:32:18,091:INFO:executable: /Users/michal/opt/anaconda3/bin/python
2023-11-04 19:32:18,091:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-11-04 19:32:18,091:INFO:PyCaret required dependencies:
2023-11-04 19:32:18,091:INFO:                 pip: 22.2.2
2023-11-04 19:32:18,091:INFO:          setuptools: 63.4.1
2023-11-04 19:32:18,091:INFO:             pycaret: 3.1.0
2023-11-04 19:32:18,091:INFO:             IPython: 7.31.1
2023-11-04 19:32:18,091:INFO:          ipywidgets: 7.6.5
2023-11-04 19:32:18,091:INFO:                tqdm: 4.64.1
2023-11-04 19:32:18,091:INFO:               numpy: 1.21.5
2023-11-04 19:32:18,091:INFO:              pandas: 1.4.4
2023-11-04 19:32:18,091:INFO:              jinja2: 2.11.3
2023-11-04 19:32:18,091:INFO:               scipy: 1.10.1
2023-11-04 19:32:18,091:INFO:              joblib: 1.2.0
2023-11-04 19:32:18,091:INFO:             sklearn: 1.0.2
2023-11-04 19:32:18,091:INFO:                pyod: 1.1.1
2023-11-04 19:32:18,091:INFO:            imblearn: 0.10.1
2023-11-04 19:32:18,091:INFO:   category_encoders: 2.6.3
2023-11-04 19:32:18,091:INFO:            lightgbm: 3.3.5
2023-11-04 19:32:18,091:INFO:               numba: 0.55.1
2023-11-04 19:32:18,091:INFO:            requests: 2.28.1
2023-11-04 19:32:18,091:INFO:          matplotlib: 3.5.2
2023-11-04 19:32:18,091:INFO:          scikitplot: 0.3.7
2023-11-04 19:32:18,091:INFO:         yellowbrick: 1.5
2023-11-04 19:32:18,092:INFO:              plotly: 5.9.0
2023-11-04 19:32:18,092:INFO:    plotly-resampler: Not installed
2023-11-04 19:32:18,092:INFO:             kaleido: 0.2.1
2023-11-04 19:32:18,092:INFO:           schemdraw: 0.15
2023-11-04 19:32:18,092:INFO:         statsmodels: 0.13.2
2023-11-04 19:32:18,092:INFO:              sktime: 0.21.1
2023-11-04 19:32:18,092:INFO:               tbats: 1.1.3
2023-11-04 19:32:18,092:INFO:            pmdarima: 2.0.4
2023-11-04 19:32:18,092:INFO:              psutil: 5.9.0
2023-11-04 19:32:18,092:INFO:          markupsafe: 2.0.1
2023-11-04 19:32:18,092:INFO:             pickle5: Not installed
2023-11-04 19:32:18,092:INFO:         cloudpickle: 2.0.0
2023-11-04 19:32:18,092:INFO:         deprecation: 2.1.0
2023-11-04 19:32:18,092:INFO:              xxhash: 3.4.1
2023-11-04 19:32:18,092:INFO:           wurlitzer: 3.0.2
2023-11-04 19:32:18,092:INFO:PyCaret optional dependencies:
2023-11-04 19:32:18,092:INFO:                shap: 0.41.0
2023-11-04 19:32:18,092:INFO:           interpret: Not installed
2023-11-04 19:32:18,092:INFO:                umap: 0.5.3
2023-11-04 19:32:18,092:INFO:     ydata_profiling: Not installed
2023-11-04 19:32:18,092:INFO:  explainerdashboard: Not installed
2023-11-04 19:32:18,092:INFO:             autoviz: Not installed
2023-11-04 19:32:18,092:INFO:           fairlearn: Not installed
2023-11-04 19:32:18,092:INFO:          deepchecks: Not installed
2023-11-04 19:32:18,092:INFO:             xgboost: 1.7.4
2023-11-04 19:32:18,092:INFO:            catboost: 1.2
2023-11-04 19:32:18,092:INFO:              kmodes: Not installed
2023-11-04 19:32:18,092:INFO:             mlxtend: 0.21.0
2023-11-04 19:32:18,092:INFO:       statsforecast: Not installed
2023-11-04 19:32:18,092:INFO:        tune_sklearn: Not installed
2023-11-04 19:32:18,092:INFO:                 ray: Not installed
2023-11-04 19:32:18,092:INFO:            hyperopt: Not installed
2023-11-04 19:32:18,092:INFO:              optuna: Not installed
2023-11-04 19:32:18,092:INFO:               skopt: Not installed
2023-11-04 19:32:18,092:INFO:              mlflow: Not installed
2023-11-04 19:32:18,092:INFO:              gradio: Not installed
2023-11-04 19:32:18,092:INFO:             fastapi: Not installed
2023-11-04 19:32:18,092:INFO:             uvicorn: Not installed
2023-11-04 19:32:18,092:INFO:              m2cgen: Not installed
2023-11-04 19:32:18,092:INFO:           evidently: Not installed
2023-11-04 19:32:18,092:INFO:               fugue: Not installed
2023-11-04 19:32:18,092:INFO:           streamlit: Not installed
2023-11-04 19:32:18,092:INFO:             prophet: Not installed
2023-11-04 19:32:18,092:INFO:None
2023-11-04 19:32:18,092:INFO:Set up data.
2023-11-04 19:32:18,095:INFO:Set up folding strategy.
2023-11-04 19:32:18,095:INFO:Set up train/test split.
2023-11-04 19:32:18,098:INFO:Set up index.
2023-11-04 19:32:18,098:INFO:Assigning column types.
2023-11-04 19:32:18,099:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-04 19:32:18,099:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-04 19:32:18,102:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 19:32:18,105:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:32:18,139:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:32:18,165:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:32:18,165:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:32:18,166:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:32:18,167:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-04 19:32:18,169:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 19:32:18,172:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:32:18,205:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:32:18,231:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:32:18,231:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:32:18,233:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:32:18,233:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-11-04 19:32:18,236:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 19:32:18,239:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:32:18,272:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:32:18,298:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:32:18,298:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:32:18,300:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:32:18,302:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 19:32:18,305:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:32:18,338:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:32:18,365:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:32:18,365:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:32:18,366:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:32:18,367:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-11-04 19:32:18,372:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:32:18,405:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:32:18,431:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:32:18,431:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:32:18,432:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:32:18,438:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:32:18,471:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:32:18,497:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:32:18,497:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:32:18,498:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:32:18,499:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-11-04 19:32:18,537:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:32:18,563:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:32:18,564:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:32:18,565:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:32:18,604:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:32:18,630:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:32:18,630:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:32:18,632:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:32:18,632:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-04 19:32:18,670:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:32:18,696:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:32:18,698:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:32:18,736:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:32:18,762:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:32:18,764:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:32:18,764:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-11-04 19:32:18,829:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:32:18,830:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:32:18,898:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:32:18,900:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:32:18,900:INFO:Preparing preprocessing pipeline...
2023-11-04 19:32:18,900:INFO:Set up simple imputation.
2023-11-04 19:32:18,900:INFO:Set up variance threshold.
2023-11-04 19:32:18,900:INFO:Set up removing multicollinearity.
2023-11-04 19:32:18,901:INFO:Set up column name cleaning.
2023-11-04 19:32:18,920:INFO:Finished creating preprocessing pipeline.
2023-11-04 19:32:18,924:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/h9/5_75v3qs13x63s15wwxdrd000000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['solv_dG [kcal/mol]',
                                             'Bond dissociation entalphy',
                                             'water_ads [kcal/mol]', 'Coating',
                                             'Organic Matter Conc.', 'pH',
                                             'Primary Size', 'Initial Conc.',
                                             'Temp.', 'Ionic Strenght', 'Light',
                                             'MW', 'Noxy', 'χ', 'χox',
                                             'Z_metal', 'Zv...
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.1))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-11-04 19:32:18,924:INFO:Creating final display dataframe.
2023-11-04 19:32:18,971:INFO:Setup _display_container:                     Description             Value
0                    Session id              5048
1                        Target  %dissolved solid
2                   Target type        Regression
3           Original data shape         (115, 21)
4        Transformed data shape         (115, 17)
5   Transformed train set shape          (80, 17)
6    Transformed test set shape          (35, 17)
7              Numeric features                20
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12       Low variance threshold               0.1
13     Remove multicollinearity              True
14  Multicollinearity threshold              0.95
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              8273
2023-11-04 19:32:19,040:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:32:19,041:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:32:19,107:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:32:19,109:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:32:19,109:INFO:setup() successfully completed in 1.02s...............
2023-11-04 19:32:19,109:INFO:Initializing compare_models()
2023-11-04 19:32:19,109:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb44104a100>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fb44104a100>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-11-04 19:32:19,109:INFO:Checking exceptions
2023-11-04 19:32:19,110:INFO:Preparing display monitor
2023-11-04 19:32:19,126:INFO:Initializing Linear Regression
2023-11-04 19:32:19,126:INFO:Total runtime is 2.3166338602701823e-06 minutes
2023-11-04 19:32:19,128:INFO:SubProcess create_model() called ==================================
2023-11-04 19:32:19,128:INFO:Initializing create_model()
2023-11-04 19:32:19,128:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb44104a100>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4413ea2b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:32:19,128:INFO:Checking exceptions
2023-11-04 19:32:19,128:INFO:Importing libraries
2023-11-04 19:32:19,128:INFO:Copying training dataset
2023-11-04 19:32:19,130:INFO:Defining folds
2023-11-04 19:32:19,130:INFO:Declaring metric variables
2023-11-04 19:32:19,132:INFO:Importing untrained model
2023-11-04 19:32:19,134:INFO:Linear Regression Imported successfully
2023-11-04 19:32:19,138:INFO:Starting cross validation
2023-11-04 19:32:19,138:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:32:19,192:INFO:Calculating mean and std
2023-11-04 19:32:19,192:INFO:Creating metrics dataframe
2023-11-04 19:32:19,194:INFO:Uploading results into container
2023-11-04 19:32:19,194:INFO:Uploading model into container now
2023-11-04 19:32:19,194:INFO:_master_model_container: 1
2023-11-04 19:32:19,194:INFO:_display_container: 2
2023-11-04 19:32:19,194:INFO:LinearRegression(n_jobs=-1)
2023-11-04 19:32:19,194:INFO:create_model() successfully completed......................................
2023-11-04 19:32:19,328:INFO:SubProcess create_model() end ==================================
2023-11-04 19:32:19,328:INFO:Creating metrics dataframe
2023-11-04 19:32:19,332:INFO:Initializing Lasso Regression
2023-11-04 19:32:19,332:INFO:Total runtime is 0.0034306526184082033 minutes
2023-11-04 19:32:19,334:INFO:SubProcess create_model() called ==================================
2023-11-04 19:32:19,334:INFO:Initializing create_model()
2023-11-04 19:32:19,334:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb44104a100>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4413ea2b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:32:19,334:INFO:Checking exceptions
2023-11-04 19:32:19,334:INFO:Importing libraries
2023-11-04 19:32:19,334:INFO:Copying training dataset
2023-11-04 19:32:19,336:INFO:Defining folds
2023-11-04 19:32:19,336:INFO:Declaring metric variables
2023-11-04 19:32:19,338:INFO:Importing untrained model
2023-11-04 19:32:19,339:INFO:Lasso Regression Imported successfully
2023-11-04 19:32:19,342:INFO:Starting cross validation
2023-11-04 19:32:19,343:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:32:19,402:INFO:Calculating mean and std
2023-11-04 19:32:19,402:INFO:Creating metrics dataframe
2023-11-04 19:32:19,404:INFO:Uploading results into container
2023-11-04 19:32:19,404:INFO:Uploading model into container now
2023-11-04 19:32:19,404:INFO:_master_model_container: 2
2023-11-04 19:32:19,404:INFO:_display_container: 2
2023-11-04 19:32:19,404:INFO:Lasso(random_state=5048)
2023-11-04 19:32:19,404:INFO:create_model() successfully completed......................................
2023-11-04 19:32:19,517:INFO:SubProcess create_model() end ==================================
2023-11-04 19:32:19,517:INFO:Creating metrics dataframe
2023-11-04 19:32:19,522:INFO:Initializing Ridge Regression
2023-11-04 19:32:19,522:INFO:Total runtime is 0.006594999631245931 minutes
2023-11-04 19:32:19,524:INFO:SubProcess create_model() called ==================================
2023-11-04 19:32:19,524:INFO:Initializing create_model()
2023-11-04 19:32:19,524:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb44104a100>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4413ea2b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:32:19,524:INFO:Checking exceptions
2023-11-04 19:32:19,524:INFO:Importing libraries
2023-11-04 19:32:19,524:INFO:Copying training dataset
2023-11-04 19:32:19,526:INFO:Defining folds
2023-11-04 19:32:19,526:INFO:Declaring metric variables
2023-11-04 19:32:19,527:INFO:Importing untrained model
2023-11-04 19:32:19,529:INFO:Ridge Regression Imported successfully
2023-11-04 19:32:19,532:INFO:Starting cross validation
2023-11-04 19:32:19,532:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:32:19,586:INFO:Calculating mean and std
2023-11-04 19:32:19,587:INFO:Creating metrics dataframe
2023-11-04 19:32:19,588:INFO:Uploading results into container
2023-11-04 19:32:19,589:INFO:Uploading model into container now
2023-11-04 19:32:19,589:INFO:_master_model_container: 3
2023-11-04 19:32:19,589:INFO:_display_container: 2
2023-11-04 19:32:19,589:INFO:Ridge(random_state=5048)
2023-11-04 19:32:19,589:INFO:create_model() successfully completed......................................
2023-11-04 19:32:19,701:INFO:SubProcess create_model() end ==================================
2023-11-04 19:32:19,701:INFO:Creating metrics dataframe
2023-11-04 19:32:19,706:INFO:Initializing Elastic Net
2023-11-04 19:32:19,706:INFO:Total runtime is 0.009669601917266846 minutes
2023-11-04 19:32:19,708:INFO:SubProcess create_model() called ==================================
2023-11-04 19:32:19,708:INFO:Initializing create_model()
2023-11-04 19:32:19,709:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb44104a100>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4413ea2b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:32:19,709:INFO:Checking exceptions
2023-11-04 19:32:19,709:INFO:Importing libraries
2023-11-04 19:32:19,709:INFO:Copying training dataset
2023-11-04 19:32:19,710:INFO:Defining folds
2023-11-04 19:32:19,710:INFO:Declaring metric variables
2023-11-04 19:32:19,712:INFO:Importing untrained model
2023-11-04 19:32:19,713:INFO:Elastic Net Imported successfully
2023-11-04 19:32:19,716:INFO:Starting cross validation
2023-11-04 19:32:19,717:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:32:19,774:INFO:Calculating mean and std
2023-11-04 19:32:19,774:INFO:Creating metrics dataframe
2023-11-04 19:32:19,776:INFO:Uploading results into container
2023-11-04 19:32:19,776:INFO:Uploading model into container now
2023-11-04 19:32:19,776:INFO:_master_model_container: 4
2023-11-04 19:32:19,776:INFO:_display_container: 2
2023-11-04 19:32:19,776:INFO:ElasticNet(random_state=5048)
2023-11-04 19:32:19,776:INFO:create_model() successfully completed......................................
2023-11-04 19:32:19,890:INFO:SubProcess create_model() end ==================================
2023-11-04 19:32:19,890:INFO:Creating metrics dataframe
2023-11-04 19:32:19,895:INFO:Initializing Least Angle Regression
2023-11-04 19:32:19,895:INFO:Total runtime is 0.012817800045013428 minutes
2023-11-04 19:32:19,897:INFO:SubProcess create_model() called ==================================
2023-11-04 19:32:19,897:INFO:Initializing create_model()
2023-11-04 19:32:19,897:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb44104a100>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4413ea2b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:32:19,897:INFO:Checking exceptions
2023-11-04 19:32:19,897:INFO:Importing libraries
2023-11-04 19:32:19,897:INFO:Copying training dataset
2023-11-04 19:32:19,899:INFO:Defining folds
2023-11-04 19:32:19,899:INFO:Declaring metric variables
2023-11-04 19:32:19,901:INFO:Importing untrained model
2023-11-04 19:32:19,902:INFO:Least Angle Regression Imported successfully
2023-11-04 19:32:19,905:INFO:Starting cross validation
2023-11-04 19:32:19,906:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:32:19,925:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:32:19,931:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:32:19,938:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:32:19,941:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:32:19,945:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:32:19,948:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:32:19,955:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:32:19,957:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:32:19,963:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:32:19,964:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:32:19,971:INFO:Calculating mean and std
2023-11-04 19:32:19,971:INFO:Creating metrics dataframe
2023-11-04 19:32:19,973:INFO:Uploading results into container
2023-11-04 19:32:19,973:INFO:Uploading model into container now
2023-11-04 19:32:19,973:INFO:_master_model_container: 5
2023-11-04 19:32:19,973:INFO:_display_container: 2
2023-11-04 19:32:19,973:INFO:Lars(random_state=5048)
2023-11-04 19:32:19,973:INFO:create_model() successfully completed......................................
2023-11-04 19:32:20,090:INFO:SubProcess create_model() end ==================================
2023-11-04 19:32:20,090:INFO:Creating metrics dataframe
2023-11-04 19:32:20,096:INFO:Initializing Lasso Least Angle Regression
2023-11-04 19:32:20,096:INFO:Total runtime is 0.01615963379542033 minutes
2023-11-04 19:32:20,098:INFO:SubProcess create_model() called ==================================
2023-11-04 19:32:20,098:INFO:Initializing create_model()
2023-11-04 19:32:20,098:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb44104a100>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4413ea2b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:32:20,098:INFO:Checking exceptions
2023-11-04 19:32:20,098:INFO:Importing libraries
2023-11-04 19:32:20,098:INFO:Copying training dataset
2023-11-04 19:32:20,100:INFO:Defining folds
2023-11-04 19:32:20,100:INFO:Declaring metric variables
2023-11-04 19:32:20,101:INFO:Importing untrained model
2023-11-04 19:32:20,103:INFO:Lasso Least Angle Regression Imported successfully
2023-11-04 19:32:20,106:INFO:Starting cross validation
2023-11-04 19:32:20,107:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:32:20,126:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:32:20,129:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:32:20,138:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:32:20,144:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:32:20,145:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:32:20,146:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:32:20,150:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:32:20,151:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:32:20,153:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:32:20,156:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:32:20,162:INFO:Calculating mean and std
2023-11-04 19:32:20,163:INFO:Creating metrics dataframe
2023-11-04 19:32:20,165:INFO:Uploading results into container
2023-11-04 19:32:20,165:INFO:Uploading model into container now
2023-11-04 19:32:20,165:INFO:_master_model_container: 6
2023-11-04 19:32:20,165:INFO:_display_container: 2
2023-11-04 19:32:20,165:INFO:LassoLars(random_state=5048)
2023-11-04 19:32:20,165:INFO:create_model() successfully completed......................................
2023-11-04 19:32:20,279:INFO:SubProcess create_model() end ==================================
2023-11-04 19:32:20,279:INFO:Creating metrics dataframe
2023-11-04 19:32:20,285:INFO:Initializing Orthogonal Matching Pursuit
2023-11-04 19:32:20,285:INFO:Total runtime is 0.01931458314259847 minutes
2023-11-04 19:32:20,287:INFO:SubProcess create_model() called ==================================
2023-11-04 19:32:20,287:INFO:Initializing create_model()
2023-11-04 19:32:20,287:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb44104a100>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4413ea2b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:32:20,287:INFO:Checking exceptions
2023-11-04 19:32:20,287:INFO:Importing libraries
2023-11-04 19:32:20,287:INFO:Copying training dataset
2023-11-04 19:32:20,289:INFO:Defining folds
2023-11-04 19:32:20,289:INFO:Declaring metric variables
2023-11-04 19:32:20,290:INFO:Importing untrained model
2023-11-04 19:32:20,292:INFO:Orthogonal Matching Pursuit Imported successfully
2023-11-04 19:32:20,296:INFO:Starting cross validation
2023-11-04 19:32:20,296:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:32:20,317:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:32:20,318:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:32:20,323:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:32:20,324:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:32:20,333:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:32:20,337:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:32:20,339:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:32:20,340:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:32:20,343:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:32:20,345:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:32:20,351:INFO:Calculating mean and std
2023-11-04 19:32:20,351:INFO:Creating metrics dataframe
2023-11-04 19:32:20,353:INFO:Uploading results into container
2023-11-04 19:32:20,353:INFO:Uploading model into container now
2023-11-04 19:32:20,353:INFO:_master_model_container: 7
2023-11-04 19:32:20,353:INFO:_display_container: 2
2023-11-04 19:32:20,354:INFO:OrthogonalMatchingPursuit()
2023-11-04 19:32:20,354:INFO:create_model() successfully completed......................................
2023-11-04 19:32:20,466:INFO:SubProcess create_model() end ==================================
2023-11-04 19:32:20,466:INFO:Creating metrics dataframe
2023-11-04 19:32:20,472:INFO:Initializing Bayesian Ridge
2023-11-04 19:32:20,472:INFO:Total runtime is 0.022428651650746666 minutes
2023-11-04 19:32:20,474:INFO:SubProcess create_model() called ==================================
2023-11-04 19:32:20,474:INFO:Initializing create_model()
2023-11-04 19:32:20,474:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb44104a100>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4413ea2b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:32:20,474:INFO:Checking exceptions
2023-11-04 19:32:20,474:INFO:Importing libraries
2023-11-04 19:32:20,474:INFO:Copying training dataset
2023-11-04 19:32:20,477:INFO:Defining folds
2023-11-04 19:32:20,477:INFO:Declaring metric variables
2023-11-04 19:32:20,478:INFO:Importing untrained model
2023-11-04 19:32:20,480:INFO:Bayesian Ridge Imported successfully
2023-11-04 19:32:20,484:INFO:Starting cross validation
2023-11-04 19:32:20,484:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:32:20,539:INFO:Calculating mean and std
2023-11-04 19:32:20,539:INFO:Creating metrics dataframe
2023-11-04 19:32:20,541:INFO:Uploading results into container
2023-11-04 19:32:20,541:INFO:Uploading model into container now
2023-11-04 19:32:20,542:INFO:_master_model_container: 8
2023-11-04 19:32:20,542:INFO:_display_container: 2
2023-11-04 19:32:20,542:INFO:BayesianRidge()
2023-11-04 19:32:20,542:INFO:create_model() successfully completed......................................
2023-11-04 19:32:20,654:INFO:SubProcess create_model() end ==================================
2023-11-04 19:32:20,655:INFO:Creating metrics dataframe
2023-11-04 19:32:20,660:INFO:Initializing Passive Aggressive Regressor
2023-11-04 19:32:20,660:INFO:Total runtime is 0.02556826670964559 minutes
2023-11-04 19:32:20,662:INFO:SubProcess create_model() called ==================================
2023-11-04 19:32:20,662:INFO:Initializing create_model()
2023-11-04 19:32:20,662:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb44104a100>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4413ea2b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:32:20,662:INFO:Checking exceptions
2023-11-04 19:32:20,662:INFO:Importing libraries
2023-11-04 19:32:20,662:INFO:Copying training dataset
2023-11-04 19:32:20,665:INFO:Defining folds
2023-11-04 19:32:20,665:INFO:Declaring metric variables
2023-11-04 19:32:20,666:INFO:Importing untrained model
2023-11-04 19:32:20,668:INFO:Passive Aggressive Regressor Imported successfully
2023-11-04 19:32:20,671:INFO:Starting cross validation
2023-11-04 19:32:20,672:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:32:20,734:INFO:Calculating mean and std
2023-11-04 19:32:20,734:INFO:Creating metrics dataframe
2023-11-04 19:32:20,736:INFO:Uploading results into container
2023-11-04 19:32:20,736:INFO:Uploading model into container now
2023-11-04 19:32:20,736:INFO:_master_model_container: 9
2023-11-04 19:32:20,736:INFO:_display_container: 2
2023-11-04 19:32:20,737:INFO:PassiveAggressiveRegressor(random_state=5048)
2023-11-04 19:32:20,737:INFO:create_model() successfully completed......................................
2023-11-04 19:32:20,851:INFO:SubProcess create_model() end ==================================
2023-11-04 19:32:20,851:INFO:Creating metrics dataframe
2023-11-04 19:32:20,857:INFO:Initializing Huber Regressor
2023-11-04 19:32:20,857:INFO:Total runtime is 0.02884674866994222 minutes
2023-11-04 19:32:20,859:INFO:SubProcess create_model() called ==================================
2023-11-04 19:32:20,859:INFO:Initializing create_model()
2023-11-04 19:32:20,859:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb44104a100>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4413ea2b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:32:20,859:INFO:Checking exceptions
2023-11-04 19:32:20,859:INFO:Importing libraries
2023-11-04 19:32:20,859:INFO:Copying training dataset
2023-11-04 19:32:20,862:INFO:Defining folds
2023-11-04 19:32:20,862:INFO:Declaring metric variables
2023-11-04 19:32:20,863:INFO:Importing untrained model
2023-11-04 19:32:20,865:INFO:Huber Regressor Imported successfully
2023-11-04 19:32:20,868:INFO:Starting cross validation
2023-11-04 19:32:20,869:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:32:20,902:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:32:20,908:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:32:20,909:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:32:20,917:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:32:20,926:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:32:20,927:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:32:20,936:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:32:20,938:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:32:20,938:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:32:20,940:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:32:20,946:INFO:Calculating mean and std
2023-11-04 19:32:20,946:INFO:Creating metrics dataframe
2023-11-04 19:32:20,948:INFO:Uploading results into container
2023-11-04 19:32:20,948:INFO:Uploading model into container now
2023-11-04 19:32:20,948:INFO:_master_model_container: 10
2023-11-04 19:32:20,948:INFO:_display_container: 2
2023-11-04 19:32:20,948:INFO:HuberRegressor()
2023-11-04 19:32:20,948:INFO:create_model() successfully completed......................................
2023-11-04 19:32:21,061:INFO:SubProcess create_model() end ==================================
2023-11-04 19:32:21,061:INFO:Creating metrics dataframe
2023-11-04 19:32:21,067:INFO:Initializing K Neighbors Regressor
2023-11-04 19:32:21,067:INFO:Total runtime is 0.03234010140101115 minutes
2023-11-04 19:32:21,068:INFO:SubProcess create_model() called ==================================
2023-11-04 19:32:21,068:INFO:Initializing create_model()
2023-11-04 19:32:21,069:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb44104a100>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4413ea2b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:32:21,069:INFO:Checking exceptions
2023-11-04 19:32:21,069:INFO:Importing libraries
2023-11-04 19:32:21,069:INFO:Copying training dataset
2023-11-04 19:32:21,071:INFO:Defining folds
2023-11-04 19:32:21,071:INFO:Declaring metric variables
2023-11-04 19:32:21,073:INFO:Importing untrained model
2023-11-04 19:32:21,074:INFO:K Neighbors Regressor Imported successfully
2023-11-04 19:32:21,077:INFO:Starting cross validation
2023-11-04 19:32:21,078:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:32:21,142:INFO:Calculating mean and std
2023-11-04 19:32:21,143:INFO:Creating metrics dataframe
2023-11-04 19:32:21,144:INFO:Uploading results into container
2023-11-04 19:32:21,144:INFO:Uploading model into container now
2023-11-04 19:32:21,145:INFO:_master_model_container: 11
2023-11-04 19:32:21,145:INFO:_display_container: 2
2023-11-04 19:32:21,145:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-04 19:32:21,145:INFO:create_model() successfully completed......................................
2023-11-04 19:32:21,257:INFO:SubProcess create_model() end ==================================
2023-11-04 19:32:21,258:INFO:Creating metrics dataframe
2023-11-04 19:32:21,264:INFO:Initializing Decision Tree Regressor
2023-11-04 19:32:21,264:INFO:Total runtime is 0.03563146591186524 minutes
2023-11-04 19:32:21,266:INFO:SubProcess create_model() called ==================================
2023-11-04 19:32:21,266:INFO:Initializing create_model()
2023-11-04 19:32:21,266:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb44104a100>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4413ea2b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:32:21,266:INFO:Checking exceptions
2023-11-04 19:32:21,266:INFO:Importing libraries
2023-11-04 19:32:21,266:INFO:Copying training dataset
2023-11-04 19:32:21,269:INFO:Defining folds
2023-11-04 19:32:21,269:INFO:Declaring metric variables
2023-11-04 19:32:21,270:INFO:Importing untrained model
2023-11-04 19:32:21,272:INFO:Decision Tree Regressor Imported successfully
2023-11-04 19:32:21,275:INFO:Starting cross validation
2023-11-04 19:32:21,276:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:32:21,337:INFO:Calculating mean and std
2023-11-04 19:32:21,337:INFO:Creating metrics dataframe
2023-11-04 19:32:21,339:INFO:Uploading results into container
2023-11-04 19:32:21,339:INFO:Uploading model into container now
2023-11-04 19:32:21,339:INFO:_master_model_container: 12
2023-11-04 19:32:21,339:INFO:_display_container: 2
2023-11-04 19:32:21,339:INFO:DecisionTreeRegressor(random_state=5048)
2023-11-04 19:32:21,339:INFO:create_model() successfully completed......................................
2023-11-04 19:32:21,452:INFO:SubProcess create_model() end ==================================
2023-11-04 19:32:21,452:INFO:Creating metrics dataframe
2023-11-04 19:32:21,458:INFO:Initializing Random Forest Regressor
2023-11-04 19:32:21,458:INFO:Total runtime is 0.03886263370513916 minutes
2023-11-04 19:32:21,460:INFO:SubProcess create_model() called ==================================
2023-11-04 19:32:21,460:INFO:Initializing create_model()
2023-11-04 19:32:21,460:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb44104a100>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4413ea2b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:32:21,460:INFO:Checking exceptions
2023-11-04 19:32:21,460:INFO:Importing libraries
2023-11-04 19:32:21,460:INFO:Copying training dataset
2023-11-04 19:32:21,462:INFO:Defining folds
2023-11-04 19:32:21,462:INFO:Declaring metric variables
2023-11-04 19:32:21,464:INFO:Importing untrained model
2023-11-04 19:32:21,466:INFO:Random Forest Regressor Imported successfully
2023-11-04 19:32:21,469:INFO:Starting cross validation
2023-11-04 19:32:21,470:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:32:21,727:INFO:Calculating mean and std
2023-11-04 19:32:21,727:INFO:Creating metrics dataframe
2023-11-04 19:32:21,729:INFO:Uploading results into container
2023-11-04 19:32:21,729:INFO:Uploading model into container now
2023-11-04 19:32:21,730:INFO:_master_model_container: 13
2023-11-04 19:32:21,730:INFO:_display_container: 2
2023-11-04 19:32:21,730:INFO:RandomForestRegressor(n_jobs=-1, random_state=5048)
2023-11-04 19:32:21,730:INFO:create_model() successfully completed......................................
2023-11-04 19:32:21,844:INFO:SubProcess create_model() end ==================================
2023-11-04 19:32:21,844:INFO:Creating metrics dataframe
2023-11-04 19:32:21,850:INFO:Initializing Extra Trees Regressor
2023-11-04 19:32:21,850:INFO:Total runtime is 0.04539865255355835 minutes
2023-11-04 19:32:21,852:INFO:SubProcess create_model() called ==================================
2023-11-04 19:32:21,852:INFO:Initializing create_model()
2023-11-04 19:32:21,852:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb44104a100>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4413ea2b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:32:21,852:INFO:Checking exceptions
2023-11-04 19:32:21,852:INFO:Importing libraries
2023-11-04 19:32:21,853:INFO:Copying training dataset
2023-11-04 19:32:21,854:INFO:Defining folds
2023-11-04 19:32:21,854:INFO:Declaring metric variables
2023-11-04 19:32:21,855:INFO:Importing untrained model
2023-11-04 19:32:21,857:INFO:Extra Trees Regressor Imported successfully
2023-11-04 19:32:21,860:INFO:Starting cross validation
2023-11-04 19:32:21,861:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:32:22,074:INFO:Calculating mean and std
2023-11-04 19:32:22,075:INFO:Creating metrics dataframe
2023-11-04 19:32:22,077:INFO:Uploading results into container
2023-11-04 19:32:22,077:INFO:Uploading model into container now
2023-11-04 19:32:22,078:INFO:_master_model_container: 14
2023-11-04 19:32:22,078:INFO:_display_container: 2
2023-11-04 19:32:22,078:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=5048)
2023-11-04 19:32:22,078:INFO:create_model() successfully completed......................................
2023-11-04 19:32:22,190:INFO:SubProcess create_model() end ==================================
2023-11-04 19:32:22,190:INFO:Creating metrics dataframe
2023-11-04 19:32:22,197:INFO:Initializing AdaBoost Regressor
2023-11-04 19:32:22,197:INFO:Total runtime is 0.051183752218882245 minutes
2023-11-04 19:32:22,199:INFO:SubProcess create_model() called ==================================
2023-11-04 19:32:22,199:INFO:Initializing create_model()
2023-11-04 19:32:22,199:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb44104a100>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4413ea2b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:32:22,199:INFO:Checking exceptions
2023-11-04 19:32:22,199:INFO:Importing libraries
2023-11-04 19:32:22,199:INFO:Copying training dataset
2023-11-04 19:32:22,201:INFO:Defining folds
2023-11-04 19:32:22,201:INFO:Declaring metric variables
2023-11-04 19:32:22,202:INFO:Importing untrained model
2023-11-04 19:32:22,204:INFO:AdaBoost Regressor Imported successfully
2023-11-04 19:32:22,208:INFO:Starting cross validation
2023-11-04 19:32:22,209:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:32:22,323:INFO:Calculating mean and std
2023-11-04 19:32:22,324:INFO:Creating metrics dataframe
2023-11-04 19:32:22,326:INFO:Uploading results into container
2023-11-04 19:32:22,327:INFO:Uploading model into container now
2023-11-04 19:32:22,327:INFO:_master_model_container: 15
2023-11-04 19:32:22,327:INFO:_display_container: 2
2023-11-04 19:32:22,327:INFO:AdaBoostRegressor(random_state=5048)
2023-11-04 19:32:22,327:INFO:create_model() successfully completed......................................
2023-11-04 19:32:22,441:INFO:SubProcess create_model() end ==================================
2023-11-04 19:32:22,441:INFO:Creating metrics dataframe
2023-11-04 19:32:22,448:INFO:Initializing Gradient Boosting Regressor
2023-11-04 19:32:22,448:INFO:Total runtime is 0.05536696513493856 minutes
2023-11-04 19:32:22,450:INFO:SubProcess create_model() called ==================================
2023-11-04 19:32:22,450:INFO:Initializing create_model()
2023-11-04 19:32:22,450:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb44104a100>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4413ea2b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:32:22,450:INFO:Checking exceptions
2023-11-04 19:32:22,450:INFO:Importing libraries
2023-11-04 19:32:22,450:INFO:Copying training dataset
2023-11-04 19:32:22,452:INFO:Defining folds
2023-11-04 19:32:22,452:INFO:Declaring metric variables
2023-11-04 19:32:22,453:INFO:Importing untrained model
2023-11-04 19:32:22,455:INFO:Gradient Boosting Regressor Imported successfully
2023-11-04 19:32:22,459:INFO:Starting cross validation
2023-11-04 19:32:22,459:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:32:22,541:INFO:Calculating mean and std
2023-11-04 19:32:22,542:INFO:Creating metrics dataframe
2023-11-04 19:32:22,543:INFO:Uploading results into container
2023-11-04 19:32:22,543:INFO:Uploading model into container now
2023-11-04 19:32:22,544:INFO:_master_model_container: 16
2023-11-04 19:32:22,544:INFO:_display_container: 2
2023-11-04 19:32:22,544:INFO:GradientBoostingRegressor(random_state=5048)
2023-11-04 19:32:22,544:INFO:create_model() successfully completed......................................
2023-11-04 19:32:22,657:INFO:SubProcess create_model() end ==================================
2023-11-04 19:32:22,657:INFO:Creating metrics dataframe
2023-11-04 19:32:22,664:INFO:Initializing Extreme Gradient Boosting
2023-11-04 19:32:22,664:INFO:Total runtime is 0.05895813306172689 minutes
2023-11-04 19:32:22,665:INFO:SubProcess create_model() called ==================================
2023-11-04 19:32:22,666:INFO:Initializing create_model()
2023-11-04 19:32:22,666:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb44104a100>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4413ea2b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:32:22,666:INFO:Checking exceptions
2023-11-04 19:32:22,666:INFO:Importing libraries
2023-11-04 19:32:22,666:INFO:Copying training dataset
2023-11-04 19:32:22,668:INFO:Defining folds
2023-11-04 19:32:22,668:INFO:Declaring metric variables
2023-11-04 19:32:22,670:INFO:Importing untrained model
2023-11-04 19:32:22,672:INFO:Extreme Gradient Boosting Imported successfully
2023-11-04 19:32:22,675:INFO:Starting cross validation
2023-11-04 19:32:22,675:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:32:22,767:INFO:Calculating mean and std
2023-11-04 19:32:22,768:INFO:Creating metrics dataframe
2023-11-04 19:32:22,770:INFO:Uploading results into container
2023-11-04 19:32:22,771:INFO:Uploading model into container now
2023-11-04 19:32:22,771:INFO:_master_model_container: 17
2023-11-04 19:32:22,771:INFO:_display_container: 2
2023-11-04 19:32:22,772:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=5048, ...)
2023-11-04 19:32:22,772:INFO:create_model() successfully completed......................................
2023-11-04 19:32:22,886:INFO:SubProcess create_model() end ==================================
2023-11-04 19:32:22,886:INFO:Creating metrics dataframe
2023-11-04 19:32:22,893:INFO:Initializing Light Gradient Boosting Machine
2023-11-04 19:32:22,893:INFO:Total runtime is 0.06277450323104859 minutes
2023-11-04 19:32:22,895:INFO:SubProcess create_model() called ==================================
2023-11-04 19:32:22,895:INFO:Initializing create_model()
2023-11-04 19:32:22,895:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb44104a100>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4413ea2b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:32:22,895:INFO:Checking exceptions
2023-11-04 19:32:22,895:INFO:Importing libraries
2023-11-04 19:32:22,895:INFO:Copying training dataset
2023-11-04 19:32:22,897:INFO:Defining folds
2023-11-04 19:32:22,897:INFO:Declaring metric variables
2023-11-04 19:32:22,899:INFO:Importing untrained model
2023-11-04 19:32:22,900:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-04 19:32:22,903:INFO:Starting cross validation
2023-11-04 19:32:22,904:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:32:22,969:INFO:Calculating mean and std
2023-11-04 19:32:22,970:INFO:Creating metrics dataframe
2023-11-04 19:32:22,971:INFO:Uploading results into container
2023-11-04 19:32:22,972:INFO:Uploading model into container now
2023-11-04 19:32:22,972:INFO:_master_model_container: 18
2023-11-04 19:32:22,972:INFO:_display_container: 2
2023-11-04 19:32:22,972:INFO:LGBMRegressor(random_state=5048)
2023-11-04 19:32:22,972:INFO:create_model() successfully completed......................................
2023-11-04 19:32:23,085:INFO:SubProcess create_model() end ==================================
2023-11-04 19:32:23,085:INFO:Creating metrics dataframe
2023-11-04 19:32:23,092:INFO:Initializing CatBoost Regressor
2023-11-04 19:32:23,092:INFO:Total runtime is 0.0660921851793925 minutes
2023-11-04 19:32:23,093:INFO:SubProcess create_model() called ==================================
2023-11-04 19:32:23,094:INFO:Initializing create_model()
2023-11-04 19:32:23,094:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb44104a100>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4413ea2b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:32:23,094:INFO:Checking exceptions
2023-11-04 19:32:23,094:INFO:Importing libraries
2023-11-04 19:32:23,094:INFO:Copying training dataset
2023-11-04 19:32:23,096:INFO:Defining folds
2023-11-04 19:32:23,096:INFO:Declaring metric variables
2023-11-04 19:32:23,098:INFO:Importing untrained model
2023-11-04 19:32:23,099:INFO:CatBoost Regressor Imported successfully
2023-11-04 19:32:23,102:INFO:Starting cross validation
2023-11-04 19:32:23,103:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:32:23,784:INFO:Calculating mean and std
2023-11-04 19:32:23,785:INFO:Creating metrics dataframe
2023-11-04 19:32:23,786:INFO:Uploading results into container
2023-11-04 19:32:23,787:INFO:Uploading model into container now
2023-11-04 19:32:23,787:INFO:_master_model_container: 19
2023-11-04 19:32:23,787:INFO:_display_container: 2
2023-11-04 19:32:23,787:INFO:<catboost.core.CatBoostRegressor object at 0x7fb410d31670>
2023-11-04 19:32:23,787:INFO:create_model() successfully completed......................................
2023-11-04 19:32:23,900:INFO:SubProcess create_model() end ==================================
2023-11-04 19:32:23,900:INFO:Creating metrics dataframe
2023-11-04 19:32:23,907:INFO:Initializing Dummy Regressor
2023-11-04 19:32:23,907:INFO:Total runtime is 0.07968655029932659 minutes
2023-11-04 19:32:23,909:INFO:SubProcess create_model() called ==================================
2023-11-04 19:32:23,909:INFO:Initializing create_model()
2023-11-04 19:32:23,909:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb44104a100>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4413ea2b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:32:23,909:INFO:Checking exceptions
2023-11-04 19:32:23,909:INFO:Importing libraries
2023-11-04 19:32:23,909:INFO:Copying training dataset
2023-11-04 19:32:23,912:INFO:Defining folds
2023-11-04 19:32:23,912:INFO:Declaring metric variables
2023-11-04 19:32:23,913:INFO:Importing untrained model
2023-11-04 19:32:23,915:INFO:Dummy Regressor Imported successfully
2023-11-04 19:32:23,918:INFO:Starting cross validation
2023-11-04 19:32:23,918:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:32:23,973:INFO:Calculating mean and std
2023-11-04 19:32:23,973:INFO:Creating metrics dataframe
2023-11-04 19:32:23,974:INFO:Uploading results into container
2023-11-04 19:32:23,975:INFO:Uploading model into container now
2023-11-04 19:32:23,975:INFO:_master_model_container: 20
2023-11-04 19:32:23,975:INFO:_display_container: 2
2023-11-04 19:32:23,975:INFO:DummyRegressor()
2023-11-04 19:32:23,975:INFO:create_model() successfully completed......................................
2023-11-04 19:32:24,088:INFO:SubProcess create_model() end ==================================
2023-11-04 19:32:24,088:INFO:Creating metrics dataframe
2023-11-04 19:32:24,100:INFO:Initializing create_model()
2023-11-04 19:32:24,100:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb44104a100>, estimator=RandomForestRegressor(n_jobs=-1, random_state=5048), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:32:24,100:INFO:Checking exceptions
2023-11-04 19:32:24,101:INFO:Importing libraries
2023-11-04 19:32:24,101:INFO:Copying training dataset
2023-11-04 19:32:24,103:INFO:Defining folds
2023-11-04 19:32:24,103:INFO:Declaring metric variables
2023-11-04 19:32:24,103:INFO:Importing untrained model
2023-11-04 19:32:24,103:INFO:Declaring custom model
2023-11-04 19:32:24,103:INFO:Random Forest Regressor Imported successfully
2023-11-04 19:32:24,104:INFO:Cross validation set to False
2023-11-04 19:32:24,104:INFO:Fitting Model
2023-11-04 19:32:24,178:INFO:RandomForestRegressor(n_jobs=-1, random_state=5048)
2023-11-04 19:32:24,179:INFO:create_model() successfully completed......................................
2023-11-04 19:32:24,310:INFO:_master_model_container: 20
2023-11-04 19:32:24,311:INFO:_display_container: 2
2023-11-04 19:32:24,311:INFO:RandomForestRegressor(n_jobs=-1, random_state=5048)
2023-11-04 19:32:24,311:INFO:compare_models() successfully completed......................................
2023-11-04 19:32:28,026:INFO:PyCaret RegressionExperiment
2023-11-04 19:32:28,027:INFO:Logging name: reg-default-name
2023-11-04 19:32:28,027:INFO:ML Usecase: MLUsecase.REGRESSION
2023-11-04 19:32:28,027:INFO:version 3.1.0
2023-11-04 19:32:28,027:INFO:Initializing setup()
2023-11-04 19:32:28,027:INFO:self.USI: 2386
2023-11-04 19:32:28,027:INFO:self._variable_keys: {'USI', 'log_plots_param', 'gpu_param', 'fold_generator', 'X_test', 'html_param', '_ml_usecase', '_available_plots', 'exp_id', 'target_param', 'idx', 'fold_shuffle_param', 'n_jobs_param', 'seed', 'exp_name_log', 'X', 'y_train', 'transform_target_param', 'data', 'y_test', 'fold_groups_param', 'logging_param', 'gpu_n_jobs_param', 'y', 'X_train', 'memory', 'pipeline'}
2023-11-04 19:32:28,027:INFO:Checking environment
2023-11-04 19:32:28,027:INFO:python_version: 3.9.13
2023-11-04 19:32:28,027:INFO:python_build: ('main', 'Aug 25 2022 18:29:29')
2023-11-04 19:32:28,027:INFO:machine: x86_64
2023-11-04 19:32:28,027:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-11-04 19:32:28,027:INFO:Memory: svmem(total=17179869184, available=1427288064, percent=91.7, used=1920581632, free=29155328, active=1399316480, inactive=1395695616, wired=521265152)
2023-11-04 19:32:28,027:INFO:Physical Core: 8
2023-11-04 19:32:28,028:INFO:Logical Core: 8
2023-11-04 19:32:28,028:INFO:Checking libraries
2023-11-04 19:32:28,028:INFO:System:
2023-11-04 19:32:28,028:INFO:    python: 3.9.13 (main, Aug 25 2022, 18:29:29)  [Clang 12.0.0 ]
2023-11-04 19:32:28,028:INFO:executable: /Users/michal/opt/anaconda3/bin/python
2023-11-04 19:32:28,028:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-11-04 19:32:28,028:INFO:PyCaret required dependencies:
2023-11-04 19:32:28,028:INFO:                 pip: 22.2.2
2023-11-04 19:32:28,028:INFO:          setuptools: 63.4.1
2023-11-04 19:32:28,028:INFO:             pycaret: 3.1.0
2023-11-04 19:32:28,028:INFO:             IPython: 7.31.1
2023-11-04 19:32:28,028:INFO:          ipywidgets: 7.6.5
2023-11-04 19:32:28,028:INFO:                tqdm: 4.64.1
2023-11-04 19:32:28,028:INFO:               numpy: 1.21.5
2023-11-04 19:32:28,028:INFO:              pandas: 1.4.4
2023-11-04 19:32:28,028:INFO:              jinja2: 2.11.3
2023-11-04 19:32:28,028:INFO:               scipy: 1.10.1
2023-11-04 19:32:28,028:INFO:              joblib: 1.2.0
2023-11-04 19:32:28,028:INFO:             sklearn: 1.0.2
2023-11-04 19:32:28,028:INFO:                pyod: 1.1.1
2023-11-04 19:32:28,028:INFO:            imblearn: 0.10.1
2023-11-04 19:32:28,028:INFO:   category_encoders: 2.6.3
2023-11-04 19:32:28,029:INFO:            lightgbm: 3.3.5
2023-11-04 19:32:28,029:INFO:               numba: 0.55.1
2023-11-04 19:32:28,029:INFO:            requests: 2.28.1
2023-11-04 19:32:28,029:INFO:          matplotlib: 3.5.2
2023-11-04 19:32:28,029:INFO:          scikitplot: 0.3.7
2023-11-04 19:32:28,029:INFO:         yellowbrick: 1.5
2023-11-04 19:32:28,029:INFO:              plotly: 5.9.0
2023-11-04 19:32:28,029:INFO:    plotly-resampler: Not installed
2023-11-04 19:32:28,029:INFO:             kaleido: 0.2.1
2023-11-04 19:32:28,029:INFO:           schemdraw: 0.15
2023-11-04 19:32:28,029:INFO:         statsmodels: 0.13.2
2023-11-04 19:32:28,029:INFO:              sktime: 0.21.1
2023-11-04 19:32:28,029:INFO:               tbats: 1.1.3
2023-11-04 19:32:28,029:INFO:            pmdarima: 2.0.4
2023-11-04 19:32:28,029:INFO:              psutil: 5.9.0
2023-11-04 19:32:28,029:INFO:          markupsafe: 2.0.1
2023-11-04 19:32:28,029:INFO:             pickle5: Not installed
2023-11-04 19:32:28,029:INFO:         cloudpickle: 2.0.0
2023-11-04 19:32:28,029:INFO:         deprecation: 2.1.0
2023-11-04 19:32:28,029:INFO:              xxhash: 3.4.1
2023-11-04 19:32:28,029:INFO:           wurlitzer: 3.0.2
2023-11-04 19:32:28,029:INFO:PyCaret optional dependencies:
2023-11-04 19:32:28,029:INFO:                shap: 0.41.0
2023-11-04 19:32:28,029:INFO:           interpret: Not installed
2023-11-04 19:32:28,030:INFO:                umap: 0.5.3
2023-11-04 19:32:28,030:INFO:     ydata_profiling: Not installed
2023-11-04 19:32:28,030:INFO:  explainerdashboard: Not installed
2023-11-04 19:32:28,030:INFO:             autoviz: Not installed
2023-11-04 19:32:28,030:INFO:           fairlearn: Not installed
2023-11-04 19:32:28,030:INFO:          deepchecks: Not installed
2023-11-04 19:32:28,030:INFO:             xgboost: 1.7.4
2023-11-04 19:32:28,030:INFO:            catboost: 1.2
2023-11-04 19:32:28,030:INFO:              kmodes: Not installed
2023-11-04 19:32:28,030:INFO:             mlxtend: 0.21.0
2023-11-04 19:32:28,030:INFO:       statsforecast: Not installed
2023-11-04 19:32:28,030:INFO:        tune_sklearn: Not installed
2023-11-04 19:32:28,030:INFO:                 ray: Not installed
2023-11-04 19:32:28,030:INFO:            hyperopt: Not installed
2023-11-04 19:32:28,030:INFO:              optuna: Not installed
2023-11-04 19:32:28,030:INFO:               skopt: Not installed
2023-11-04 19:32:28,030:INFO:              mlflow: Not installed
2023-11-04 19:32:28,030:INFO:              gradio: Not installed
2023-11-04 19:32:28,030:INFO:             fastapi: Not installed
2023-11-04 19:32:28,030:INFO:             uvicorn: Not installed
2023-11-04 19:32:28,030:INFO:              m2cgen: Not installed
2023-11-04 19:32:28,030:INFO:           evidently: Not installed
2023-11-04 19:32:28,031:INFO:               fugue: Not installed
2023-11-04 19:32:28,031:INFO:           streamlit: Not installed
2023-11-04 19:32:28,031:INFO:             prophet: Not installed
2023-11-04 19:32:28,031:INFO:None
2023-11-04 19:32:28,031:INFO:Set up data.
2023-11-04 19:32:28,040:INFO:Set up folding strategy.
2023-11-04 19:32:28,040:INFO:Set up train/test split.
2023-11-04 19:32:28,043:INFO:Set up index.
2023-11-04 19:32:28,044:INFO:Assigning column types.
2023-11-04 19:32:28,046:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-04 19:32:28,047:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-04 19:32:28,054:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 19:32:28,059:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:32:28,107:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:32:28,134:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:32:28,135:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:32:28,136:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:32:28,137:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-04 19:32:28,139:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 19:32:28,142:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:32:28,176:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:32:28,203:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:32:28,203:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:32:28,205:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:32:28,205:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-11-04 19:32:28,207:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 19:32:28,210:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:32:28,242:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:32:28,268:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:32:28,268:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:32:28,269:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:32:28,272:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 19:32:28,275:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:32:28,308:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:32:28,333:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:32:28,333:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:32:28,334:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:32:28,335:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-11-04 19:32:28,340:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:32:28,372:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:32:28,397:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:32:28,398:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:32:28,399:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:32:28,405:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:32:28,438:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:32:28,464:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:32:28,464:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:32:28,466:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:32:28,466:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-11-04 19:32:28,503:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:32:28,529:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:32:28,529:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:32:28,531:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:32:28,568:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:32:28,594:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:32:28,594:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:32:28,596:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:32:28,596:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-04 19:32:28,634:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:32:28,660:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:32:28,661:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:32:28,699:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:32:28,725:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:32:28,726:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:32:28,727:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-11-04 19:32:28,789:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:32:28,791:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:32:28,857:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:32:28,859:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:32:28,859:INFO:Preparing preprocessing pipeline...
2023-11-04 19:32:28,859:INFO:Set up simple imputation.
2023-11-04 19:32:28,859:INFO:Set up variance threshold.
2023-11-04 19:32:28,859:INFO:Set up removing multicollinearity.
2023-11-04 19:32:28,859:INFO:Set up column name cleaning.
2023-11-04 19:32:28,877:INFO:Finished creating preprocessing pipeline.
2023-11-04 19:32:28,880:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/h9/5_75v3qs13x63s15wwxdrd000000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['solv_dG [kcal/mol]',
                                             'Bond dissociation entalphy',
                                             'water_ads [kcal/mol]', 'Coating',
                                             'Organic Matter Conc.', 'pH',
                                             'Primary Size', 'Initial Conc.',
                                             'Temp.', 'Ionic Strenght', 'Light',
                                             'MW', 'Noxy', 'χ', 'χox',
                                             'Z_metal', 'Zv...
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.1))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-11-04 19:32:28,880:INFO:Creating final display dataframe.
2023-11-04 19:32:28,927:INFO:Setup _display_container:                     Description             Value
0                    Session id              1083
1                        Target  %dissolved solid
2                   Target type        Regression
3           Original data shape         (209, 21)
4        Transformed data shape         (209, 21)
5   Transformed train set shape         (146, 21)
6    Transformed test set shape          (63, 21)
7              Numeric features                20
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12       Low variance threshold               0.1
13     Remove multicollinearity              True
14  Multicollinearity threshold              0.95
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              2386
2023-11-04 19:32:28,996:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:32:28,997:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:32:29,063:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:32:29,064:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:32:29,065:INFO:setup() successfully completed in 1.04s...............
2023-11-04 19:32:29,065:INFO:Initializing compare_models()
2023-11-04 19:32:29,065:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb424cf57c0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fb424cf57c0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-11-04 19:32:29,065:INFO:Checking exceptions
2023-11-04 19:32:29,065:INFO:Preparing display monitor
2023-11-04 19:32:29,082:INFO:Initializing Linear Regression
2023-11-04 19:32:29,082:INFO:Total runtime is 1.998742421468099e-06 minutes
2023-11-04 19:32:29,083:INFO:SubProcess create_model() called ==================================
2023-11-04 19:32:29,083:INFO:Initializing create_model()
2023-11-04 19:32:29,083:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb424cf57c0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb410e06f70>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:32:29,084:INFO:Checking exceptions
2023-11-04 19:32:29,084:INFO:Importing libraries
2023-11-04 19:32:29,084:INFO:Copying training dataset
2023-11-04 19:32:29,085:INFO:Defining folds
2023-11-04 19:32:29,085:INFO:Declaring metric variables
2023-11-04 19:32:29,087:INFO:Importing untrained model
2023-11-04 19:32:29,089:INFO:Linear Regression Imported successfully
2023-11-04 19:32:29,092:INFO:Starting cross validation
2023-11-04 19:32:29,093:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:32:29,149:INFO:Calculating mean and std
2023-11-04 19:32:29,150:INFO:Creating metrics dataframe
2023-11-04 19:32:29,151:INFO:Uploading results into container
2023-11-04 19:32:29,152:INFO:Uploading model into container now
2023-11-04 19:32:29,152:INFO:_master_model_container: 1
2023-11-04 19:32:29,152:INFO:_display_container: 2
2023-11-04 19:32:29,152:INFO:LinearRegression(n_jobs=-1)
2023-11-04 19:32:29,152:INFO:create_model() successfully completed......................................
2023-11-04 19:32:29,270:INFO:SubProcess create_model() end ==================================
2023-11-04 19:32:29,270:INFO:Creating metrics dataframe
2023-11-04 19:32:29,275:INFO:Initializing Lasso Regression
2023-11-04 19:32:29,275:INFO:Total runtime is 0.003217832247416178 minutes
2023-11-04 19:32:29,277:INFO:SubProcess create_model() called ==================================
2023-11-04 19:32:29,277:INFO:Initializing create_model()
2023-11-04 19:32:29,277:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb424cf57c0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb410e06f70>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:32:29,277:INFO:Checking exceptions
2023-11-04 19:32:29,277:INFO:Importing libraries
2023-11-04 19:32:29,277:INFO:Copying training dataset
2023-11-04 19:32:29,278:INFO:Defining folds
2023-11-04 19:32:29,278:INFO:Declaring metric variables
2023-11-04 19:32:29,280:INFO:Importing untrained model
2023-11-04 19:32:29,281:INFO:Lasso Regression Imported successfully
2023-11-04 19:32:29,284:INFO:Starting cross validation
2023-11-04 19:32:29,285:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:32:29,344:INFO:Calculating mean and std
2023-11-04 19:32:29,344:INFO:Creating metrics dataframe
2023-11-04 19:32:29,346:INFO:Uploading results into container
2023-11-04 19:32:29,346:INFO:Uploading model into container now
2023-11-04 19:32:29,346:INFO:_master_model_container: 2
2023-11-04 19:32:29,346:INFO:_display_container: 2
2023-11-04 19:32:29,346:INFO:Lasso(random_state=1083)
2023-11-04 19:32:29,346:INFO:create_model() successfully completed......................................
2023-11-04 19:32:29,461:INFO:SubProcess create_model() end ==================================
2023-11-04 19:32:29,461:INFO:Creating metrics dataframe
2023-11-04 19:32:29,466:INFO:Initializing Ridge Regression
2023-11-04 19:32:29,466:INFO:Total runtime is 0.006408520539601644 minutes
2023-11-04 19:32:29,468:INFO:SubProcess create_model() called ==================================
2023-11-04 19:32:29,468:INFO:Initializing create_model()
2023-11-04 19:32:29,468:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb424cf57c0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb410e06f70>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:32:29,468:INFO:Checking exceptions
2023-11-04 19:32:29,468:INFO:Importing libraries
2023-11-04 19:32:29,469:INFO:Copying training dataset
2023-11-04 19:32:29,470:INFO:Defining folds
2023-11-04 19:32:29,470:INFO:Declaring metric variables
2023-11-04 19:32:29,472:INFO:Importing untrained model
2023-11-04 19:32:29,473:INFO:Ridge Regression Imported successfully
2023-11-04 19:32:29,476:INFO:Starting cross validation
2023-11-04 19:32:29,477:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:32:29,533:INFO:Calculating mean and std
2023-11-04 19:32:29,533:INFO:Creating metrics dataframe
2023-11-04 19:32:29,535:INFO:Uploading results into container
2023-11-04 19:32:29,535:INFO:Uploading model into container now
2023-11-04 19:32:29,535:INFO:_master_model_container: 3
2023-11-04 19:32:29,535:INFO:_display_container: 2
2023-11-04 19:32:29,535:INFO:Ridge(random_state=1083)
2023-11-04 19:32:29,535:INFO:create_model() successfully completed......................................
2023-11-04 19:32:29,646:INFO:SubProcess create_model() end ==================================
2023-11-04 19:32:29,646:INFO:Creating metrics dataframe
2023-11-04 19:32:29,651:INFO:Initializing Elastic Net
2023-11-04 19:32:29,651:INFO:Total runtime is 0.009495182832082113 minutes
2023-11-04 19:32:29,653:INFO:SubProcess create_model() called ==================================
2023-11-04 19:32:29,653:INFO:Initializing create_model()
2023-11-04 19:32:29,653:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb424cf57c0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb410e06f70>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:32:29,653:INFO:Checking exceptions
2023-11-04 19:32:29,653:INFO:Importing libraries
2023-11-04 19:32:29,653:INFO:Copying training dataset
2023-11-04 19:32:29,655:INFO:Defining folds
2023-11-04 19:32:29,655:INFO:Declaring metric variables
2023-11-04 19:32:29,657:INFO:Importing untrained model
2023-11-04 19:32:29,658:INFO:Elastic Net Imported successfully
2023-11-04 19:32:29,661:INFO:Starting cross validation
2023-11-04 19:32:29,662:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:32:29,715:INFO:Calculating mean and std
2023-11-04 19:32:29,716:INFO:Creating metrics dataframe
2023-11-04 19:32:29,717:INFO:Uploading results into container
2023-11-04 19:32:29,718:INFO:Uploading model into container now
2023-11-04 19:32:29,718:INFO:_master_model_container: 4
2023-11-04 19:32:29,718:INFO:_display_container: 2
2023-11-04 19:32:29,718:INFO:ElasticNet(random_state=1083)
2023-11-04 19:32:29,718:INFO:create_model() successfully completed......................................
2023-11-04 19:32:29,830:INFO:SubProcess create_model() end ==================================
2023-11-04 19:32:29,830:INFO:Creating metrics dataframe
2023-11-04 19:32:29,835:INFO:Initializing Least Angle Regression
2023-11-04 19:32:29,835:INFO:Total runtime is 0.012556199232737224 minutes
2023-11-04 19:32:29,837:INFO:SubProcess create_model() called ==================================
2023-11-04 19:32:29,837:INFO:Initializing create_model()
2023-11-04 19:32:29,837:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb424cf57c0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb410e06f70>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:32:29,837:INFO:Checking exceptions
2023-11-04 19:32:29,837:INFO:Importing libraries
2023-11-04 19:32:29,837:INFO:Copying training dataset
2023-11-04 19:32:29,839:INFO:Defining folds
2023-11-04 19:32:29,839:INFO:Declaring metric variables
2023-11-04 19:32:29,840:INFO:Importing untrained model
2023-11-04 19:32:29,842:INFO:Least Angle Regression Imported successfully
2023-11-04 19:32:29,845:INFO:Starting cross validation
2023-11-04 19:32:29,845:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:32:29,865:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:32:29,867:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:32:29,868:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:32:29,877:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:32:29,880:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:32:29,884:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:32:29,884:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:32:29,887:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:32:29,891:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:32:29,891:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:744: RuntimeWarning: overflow encountered in true_divide
  z = -coef[active] / (least_squares + tiny32)

2023-11-04 19:32:29,891:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:776: RuntimeWarning: overflow encountered in multiply
  coef[active] = prev_coef[active] + gamma_ * least_squares

2023-11-04 19:32:29,891:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:776: RuntimeWarning: overflow encountered in add
  coef[active] = prev_coef[active] + gamma_ * least_squares

2023-11-04 19:32:29,891:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:735: RuntimeWarning: overflow encountered in true_divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-11-04 19:32:29,896:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b

2023-11-04 19:32:29,900:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 761, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 103, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 264, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 191, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 96, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float32').

  warnings.warn(

2023-11-04 19:32:29,902:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:32:29,908:INFO:Calculating mean and std
2023-11-04 19:32:29,908:INFO:Creating metrics dataframe
2023-11-04 19:32:29,910:INFO:Uploading results into container
2023-11-04 19:32:29,910:INFO:Uploading model into container now
2023-11-04 19:32:29,910:INFO:_master_model_container: 5
2023-11-04 19:32:29,910:INFO:_display_container: 2
2023-11-04 19:32:29,911:INFO:Lars(random_state=1083)
2023-11-04 19:32:29,911:INFO:create_model() successfully completed......................................
2023-11-04 19:32:30,030:INFO:SubProcess create_model() end ==================================
2023-11-04 19:32:30,030:INFO:Creating metrics dataframe
2023-11-04 19:32:30,036:INFO:Initializing Lasso Least Angle Regression
2023-11-04 19:32:30,036:INFO:Total runtime is 0.0159056822458903 minutes
2023-11-04 19:32:30,038:INFO:SubProcess create_model() called ==================================
2023-11-04 19:32:30,038:INFO:Initializing create_model()
2023-11-04 19:32:30,038:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb424cf57c0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb410e06f70>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:32:30,038:INFO:Checking exceptions
2023-11-04 19:32:30,038:INFO:Importing libraries
2023-11-04 19:32:30,038:INFO:Copying training dataset
2023-11-04 19:32:30,040:INFO:Defining folds
2023-11-04 19:32:30,040:INFO:Declaring metric variables
2023-11-04 19:32:30,042:INFO:Importing untrained model
2023-11-04 19:32:30,043:INFO:Lasso Least Angle Regression Imported successfully
2023-11-04 19:32:30,046:INFO:Starting cross validation
2023-11-04 19:32:30,047:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:32:30,067:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:32:30,069:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:32:30,073:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:32:30,081:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:32:30,082:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:32:30,087:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:32:30,091:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:32:30,092:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:32:30,096:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:32:30,098:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:32:30,103:INFO:Calculating mean and std
2023-11-04 19:32:30,104:INFO:Creating metrics dataframe
2023-11-04 19:32:30,106:INFO:Uploading results into container
2023-11-04 19:32:30,107:INFO:Uploading model into container now
2023-11-04 19:32:30,107:INFO:_master_model_container: 6
2023-11-04 19:32:30,107:INFO:_display_container: 2
2023-11-04 19:32:30,107:INFO:LassoLars(random_state=1083)
2023-11-04 19:32:30,107:INFO:create_model() successfully completed......................................
2023-11-04 19:32:30,229:INFO:SubProcess create_model() end ==================================
2023-11-04 19:32:30,230:INFO:Creating metrics dataframe
2023-11-04 19:32:30,235:INFO:Initializing Orthogonal Matching Pursuit
2023-11-04 19:32:30,235:INFO:Total runtime is 0.01923056443532308 minutes
2023-11-04 19:32:30,237:INFO:SubProcess create_model() called ==================================
2023-11-04 19:32:30,237:INFO:Initializing create_model()
2023-11-04 19:32:30,237:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb424cf57c0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb410e06f70>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:32:30,237:INFO:Checking exceptions
2023-11-04 19:32:30,238:INFO:Importing libraries
2023-11-04 19:32:30,238:INFO:Copying training dataset
2023-11-04 19:32:30,239:INFO:Defining folds
2023-11-04 19:32:30,239:INFO:Declaring metric variables
2023-11-04 19:32:30,241:INFO:Importing untrained model
2023-11-04 19:32:30,242:INFO:Orthogonal Matching Pursuit Imported successfully
2023-11-04 19:32:30,246:INFO:Starting cross validation
2023-11-04 19:32:30,247:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:32:30,264:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:32:30,270:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:32:30,274:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:32:30,278:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:32:30,279:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:32:30,283:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:32:30,289:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:32:30,289:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:32:30,290:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:32:30,295:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:32:30,300:INFO:Calculating mean and std
2023-11-04 19:32:30,301:INFO:Creating metrics dataframe
2023-11-04 19:32:30,302:INFO:Uploading results into container
2023-11-04 19:32:30,302:INFO:Uploading model into container now
2023-11-04 19:32:30,303:INFO:_master_model_container: 7
2023-11-04 19:32:30,303:INFO:_display_container: 2
2023-11-04 19:32:30,303:INFO:OrthogonalMatchingPursuit()
2023-11-04 19:32:30,303:INFO:create_model() successfully completed......................................
2023-11-04 19:32:30,418:INFO:SubProcess create_model() end ==================================
2023-11-04 19:32:30,418:INFO:Creating metrics dataframe
2023-11-04 19:32:30,424:INFO:Initializing Bayesian Ridge
2023-11-04 19:32:30,424:INFO:Total runtime is 0.022367934385935463 minutes
2023-11-04 19:32:30,425:INFO:SubProcess create_model() called ==================================
2023-11-04 19:32:30,426:INFO:Initializing create_model()
2023-11-04 19:32:30,426:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb424cf57c0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb410e06f70>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:32:30,426:INFO:Checking exceptions
2023-11-04 19:32:30,426:INFO:Importing libraries
2023-11-04 19:32:30,426:INFO:Copying training dataset
2023-11-04 19:32:30,428:INFO:Defining folds
2023-11-04 19:32:30,428:INFO:Declaring metric variables
2023-11-04 19:32:30,429:INFO:Importing untrained model
2023-11-04 19:32:30,431:INFO:Bayesian Ridge Imported successfully
2023-11-04 19:32:30,434:INFO:Starting cross validation
2023-11-04 19:32:30,435:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:32:30,493:INFO:Calculating mean and std
2023-11-04 19:32:30,493:INFO:Creating metrics dataframe
2023-11-04 19:32:30,495:INFO:Uploading results into container
2023-11-04 19:32:30,495:INFO:Uploading model into container now
2023-11-04 19:32:30,495:INFO:_master_model_container: 8
2023-11-04 19:32:30,495:INFO:_display_container: 2
2023-11-04 19:32:30,495:INFO:BayesianRidge()
2023-11-04 19:32:30,495:INFO:create_model() successfully completed......................................
2023-11-04 19:32:30,617:INFO:SubProcess create_model() end ==================================
2023-11-04 19:32:30,617:INFO:Creating metrics dataframe
2023-11-04 19:32:30,623:INFO:Initializing Passive Aggressive Regressor
2023-11-04 19:32:30,624:INFO:Total runtime is 0.02569841941197713 minutes
2023-11-04 19:32:30,625:INFO:SubProcess create_model() called ==================================
2023-11-04 19:32:30,625:INFO:Initializing create_model()
2023-11-04 19:32:30,625:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb424cf57c0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb410e06f70>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:32:30,626:INFO:Checking exceptions
2023-11-04 19:32:30,626:INFO:Importing libraries
2023-11-04 19:32:30,626:INFO:Copying training dataset
2023-11-04 19:32:30,628:INFO:Defining folds
2023-11-04 19:32:30,628:INFO:Declaring metric variables
2023-11-04 19:32:30,630:INFO:Importing untrained model
2023-11-04 19:32:30,631:INFO:Passive Aggressive Regressor Imported successfully
2023-11-04 19:32:30,635:INFO:Starting cross validation
2023-11-04 19:32:30,635:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:32:30,691:INFO:Calculating mean and std
2023-11-04 19:32:30,692:INFO:Creating metrics dataframe
2023-11-04 19:32:30,693:INFO:Uploading results into container
2023-11-04 19:32:30,694:INFO:Uploading model into container now
2023-11-04 19:32:30,694:INFO:_master_model_container: 9
2023-11-04 19:32:30,694:INFO:_display_container: 2
2023-11-04 19:32:30,694:INFO:PassiveAggressiveRegressor(random_state=1083)
2023-11-04 19:32:30,694:INFO:create_model() successfully completed......................................
2023-11-04 19:32:30,811:INFO:SubProcess create_model() end ==================================
2023-11-04 19:32:30,811:INFO:Creating metrics dataframe
2023-11-04 19:32:30,817:INFO:Initializing Huber Regressor
2023-11-04 19:32:30,817:INFO:Total runtime is 0.028919215997060137 minutes
2023-11-04 19:32:30,819:INFO:SubProcess create_model() called ==================================
2023-11-04 19:32:30,819:INFO:Initializing create_model()
2023-11-04 19:32:30,819:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb424cf57c0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb410e06f70>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:32:30,819:INFO:Checking exceptions
2023-11-04 19:32:30,819:INFO:Importing libraries
2023-11-04 19:32:30,819:INFO:Copying training dataset
2023-11-04 19:32:30,821:INFO:Defining folds
2023-11-04 19:32:30,821:INFO:Declaring metric variables
2023-11-04 19:32:30,823:INFO:Importing untrained model
2023-11-04 19:32:30,824:INFO:Huber Regressor Imported successfully
2023-11-04 19:32:30,827:INFO:Starting cross validation
2023-11-04 19:32:30,828:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:32:30,858:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:32:30,861:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:32:30,874:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:32:30,886:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:32:30,886:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:32:30,886:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:32:30,898:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:32:30,902:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:32:30,910:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:32:30,913:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:32:30,918:INFO:Calculating mean and std
2023-11-04 19:32:30,918:INFO:Creating metrics dataframe
2023-11-04 19:32:30,920:INFO:Uploading results into container
2023-11-04 19:32:30,920:INFO:Uploading model into container now
2023-11-04 19:32:30,920:INFO:_master_model_container: 10
2023-11-04 19:32:30,920:INFO:_display_container: 2
2023-11-04 19:32:30,921:INFO:HuberRegressor()
2023-11-04 19:32:30,921:INFO:create_model() successfully completed......................................
2023-11-04 19:32:31,032:INFO:SubProcess create_model() end ==================================
2023-11-04 19:32:31,032:INFO:Creating metrics dataframe
2023-11-04 19:32:31,038:INFO:Initializing K Neighbors Regressor
2023-11-04 19:32:31,039:INFO:Total runtime is 0.03261439800262451 minutes
2023-11-04 19:32:31,040:INFO:SubProcess create_model() called ==================================
2023-11-04 19:32:31,040:INFO:Initializing create_model()
2023-11-04 19:32:31,041:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb424cf57c0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb410e06f70>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:32:31,041:INFO:Checking exceptions
2023-11-04 19:32:31,041:INFO:Importing libraries
2023-11-04 19:32:31,041:INFO:Copying training dataset
2023-11-04 19:32:31,043:INFO:Defining folds
2023-11-04 19:32:31,043:INFO:Declaring metric variables
2023-11-04 19:32:31,044:INFO:Importing untrained model
2023-11-04 19:32:31,046:INFO:K Neighbors Regressor Imported successfully
2023-11-04 19:32:31,049:INFO:Starting cross validation
2023-11-04 19:32:31,050:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:32:31,110:INFO:Calculating mean and std
2023-11-04 19:32:31,110:INFO:Creating metrics dataframe
2023-11-04 19:32:31,112:INFO:Uploading results into container
2023-11-04 19:32:31,112:INFO:Uploading model into container now
2023-11-04 19:32:31,113:INFO:_master_model_container: 11
2023-11-04 19:32:31,113:INFO:_display_container: 2
2023-11-04 19:32:31,113:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-04 19:32:31,113:INFO:create_model() successfully completed......................................
2023-11-04 19:32:31,228:INFO:SubProcess create_model() end ==================================
2023-11-04 19:32:31,228:INFO:Creating metrics dataframe
2023-11-04 19:32:31,234:INFO:Initializing Decision Tree Regressor
2023-11-04 19:32:31,234:INFO:Total runtime is 0.03587573369344075 minutes
2023-11-04 19:32:31,236:INFO:SubProcess create_model() called ==================================
2023-11-04 19:32:31,236:INFO:Initializing create_model()
2023-11-04 19:32:31,236:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb424cf57c0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb410e06f70>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:32:31,236:INFO:Checking exceptions
2023-11-04 19:32:31,236:INFO:Importing libraries
2023-11-04 19:32:31,236:INFO:Copying training dataset
2023-11-04 19:32:31,239:INFO:Defining folds
2023-11-04 19:32:31,239:INFO:Declaring metric variables
2023-11-04 19:32:31,240:INFO:Importing untrained model
2023-11-04 19:32:31,242:INFO:Decision Tree Regressor Imported successfully
2023-11-04 19:32:31,245:INFO:Starting cross validation
2023-11-04 19:32:31,246:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:32:31,303:INFO:Calculating mean and std
2023-11-04 19:32:31,304:INFO:Creating metrics dataframe
2023-11-04 19:32:31,305:INFO:Uploading results into container
2023-11-04 19:32:31,305:INFO:Uploading model into container now
2023-11-04 19:32:31,306:INFO:_master_model_container: 12
2023-11-04 19:32:31,306:INFO:_display_container: 2
2023-11-04 19:32:31,306:INFO:DecisionTreeRegressor(random_state=1083)
2023-11-04 19:32:31,306:INFO:create_model() successfully completed......................................
2023-11-04 19:32:31,422:INFO:SubProcess create_model() end ==================================
2023-11-04 19:32:31,422:INFO:Creating metrics dataframe
2023-11-04 19:32:31,428:INFO:Initializing Random Forest Regressor
2023-11-04 19:32:31,428:INFO:Total runtime is 0.039108848571777335 minutes
2023-11-04 19:32:31,430:INFO:SubProcess create_model() called ==================================
2023-11-04 19:32:31,430:INFO:Initializing create_model()
2023-11-04 19:32:31,430:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb424cf57c0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb410e06f70>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:32:31,430:INFO:Checking exceptions
2023-11-04 19:32:31,430:INFO:Importing libraries
2023-11-04 19:32:31,430:INFO:Copying training dataset
2023-11-04 19:32:31,433:INFO:Defining folds
2023-11-04 19:32:31,433:INFO:Declaring metric variables
2023-11-04 19:32:31,434:INFO:Importing untrained model
2023-11-04 19:32:31,436:INFO:Random Forest Regressor Imported successfully
2023-11-04 19:32:31,439:INFO:Starting cross validation
2023-11-04 19:32:31,440:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:32:31,738:INFO:Calculating mean and std
2023-11-04 19:32:31,738:INFO:Creating metrics dataframe
2023-11-04 19:32:31,741:INFO:Uploading results into container
2023-11-04 19:32:31,741:INFO:Uploading model into container now
2023-11-04 19:32:31,741:INFO:_master_model_container: 13
2023-11-04 19:32:31,741:INFO:_display_container: 2
2023-11-04 19:32:31,742:INFO:RandomForestRegressor(n_jobs=-1, random_state=1083)
2023-11-04 19:32:31,742:INFO:create_model() successfully completed......................................
2023-11-04 19:32:31,858:INFO:SubProcess create_model() end ==================================
2023-11-04 19:32:31,858:INFO:Creating metrics dataframe
2023-11-04 19:32:31,864:INFO:Initializing Extra Trees Regressor
2023-11-04 19:32:31,865:INFO:Total runtime is 0.04638118346532185 minutes
2023-11-04 19:32:31,866:INFO:SubProcess create_model() called ==================================
2023-11-04 19:32:31,866:INFO:Initializing create_model()
2023-11-04 19:32:31,866:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb424cf57c0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb410e06f70>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:32:31,867:INFO:Checking exceptions
2023-11-04 19:32:31,867:INFO:Importing libraries
2023-11-04 19:32:31,867:INFO:Copying training dataset
2023-11-04 19:32:31,868:INFO:Defining folds
2023-11-04 19:32:31,868:INFO:Declaring metric variables
2023-11-04 19:32:31,870:INFO:Importing untrained model
2023-11-04 19:32:31,872:INFO:Extra Trees Regressor Imported successfully
2023-11-04 19:32:31,875:INFO:Starting cross validation
2023-11-04 19:32:31,876:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:32:32,105:INFO:Calculating mean and std
2023-11-04 19:32:32,105:INFO:Creating metrics dataframe
2023-11-04 19:32:32,108:INFO:Uploading results into container
2023-11-04 19:32:32,108:INFO:Uploading model into container now
2023-11-04 19:32:32,108:INFO:_master_model_container: 14
2023-11-04 19:32:32,108:INFO:_display_container: 2
2023-11-04 19:32:32,109:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1083)
2023-11-04 19:32:32,109:INFO:create_model() successfully completed......................................
2023-11-04 19:32:32,225:INFO:SubProcess create_model() end ==================================
2023-11-04 19:32:32,225:INFO:Creating metrics dataframe
2023-11-04 19:32:32,233:INFO:Initializing AdaBoost Regressor
2023-11-04 19:32:32,233:INFO:Total runtime is 0.052517751852671296 minutes
2023-11-04 19:32:32,234:INFO:SubProcess create_model() called ==================================
2023-11-04 19:32:32,234:INFO:Initializing create_model()
2023-11-04 19:32:32,235:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb424cf57c0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb410e06f70>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:32:32,235:INFO:Checking exceptions
2023-11-04 19:32:32,235:INFO:Importing libraries
2023-11-04 19:32:32,235:INFO:Copying training dataset
2023-11-04 19:32:32,236:INFO:Defining folds
2023-11-04 19:32:32,236:INFO:Declaring metric variables
2023-11-04 19:32:32,238:INFO:Importing untrained model
2023-11-04 19:32:32,239:INFO:AdaBoost Regressor Imported successfully
2023-11-04 19:32:32,243:INFO:Starting cross validation
2023-11-04 19:32:32,244:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:32:32,369:INFO:Calculating mean and std
2023-11-04 19:32:32,369:INFO:Creating metrics dataframe
2023-11-04 19:32:32,371:INFO:Uploading results into container
2023-11-04 19:32:32,372:INFO:Uploading model into container now
2023-11-04 19:32:32,372:INFO:_master_model_container: 15
2023-11-04 19:32:32,372:INFO:_display_container: 2
2023-11-04 19:32:32,372:INFO:AdaBoostRegressor(random_state=1083)
2023-11-04 19:32:32,372:INFO:create_model() successfully completed......................................
2023-11-04 19:32:32,484:INFO:SubProcess create_model() end ==================================
2023-11-04 19:32:32,484:INFO:Creating metrics dataframe
2023-11-04 19:32:32,491:INFO:Initializing Gradient Boosting Regressor
2023-11-04 19:32:32,491:INFO:Total runtime is 0.05682634909947712 minutes
2023-11-04 19:32:32,493:INFO:SubProcess create_model() called ==================================
2023-11-04 19:32:32,493:INFO:Initializing create_model()
2023-11-04 19:32:32,493:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb424cf57c0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb410e06f70>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:32:32,493:INFO:Checking exceptions
2023-11-04 19:32:32,493:INFO:Importing libraries
2023-11-04 19:32:32,493:INFO:Copying training dataset
2023-11-04 19:32:32,495:INFO:Defining folds
2023-11-04 19:32:32,495:INFO:Declaring metric variables
2023-11-04 19:32:32,496:INFO:Importing untrained model
2023-11-04 19:32:32,498:INFO:Gradient Boosting Regressor Imported successfully
2023-11-04 19:32:32,502:INFO:Starting cross validation
2023-11-04 19:32:32,503:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:32:32,624:INFO:Calculating mean and std
2023-11-04 19:32:32,625:INFO:Creating metrics dataframe
2023-11-04 19:32:32,627:INFO:Uploading results into container
2023-11-04 19:32:32,627:INFO:Uploading model into container now
2023-11-04 19:32:32,628:INFO:_master_model_container: 16
2023-11-04 19:32:32,628:INFO:_display_container: 2
2023-11-04 19:32:32,628:INFO:GradientBoostingRegressor(random_state=1083)
2023-11-04 19:32:32,628:INFO:create_model() successfully completed......................................
2023-11-04 19:32:32,740:INFO:SubProcess create_model() end ==================================
2023-11-04 19:32:32,740:INFO:Creating metrics dataframe
2023-11-04 19:32:32,747:INFO:Initializing Extreme Gradient Boosting
2023-11-04 19:32:32,747:INFO:Total runtime is 0.06108728249867756 minutes
2023-11-04 19:32:32,749:INFO:SubProcess create_model() called ==================================
2023-11-04 19:32:32,749:INFO:Initializing create_model()
2023-11-04 19:32:32,749:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb424cf57c0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb410e06f70>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:32:32,749:INFO:Checking exceptions
2023-11-04 19:32:32,749:INFO:Importing libraries
2023-11-04 19:32:32,749:INFO:Copying training dataset
2023-11-04 19:32:32,750:INFO:Defining folds
2023-11-04 19:32:32,750:INFO:Declaring metric variables
2023-11-04 19:32:32,752:INFO:Importing untrained model
2023-11-04 19:32:32,754:INFO:Extreme Gradient Boosting Imported successfully
2023-11-04 19:32:32,758:INFO:Starting cross validation
2023-11-04 19:32:32,758:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:32:32,899:INFO:Calculating mean and std
2023-11-04 19:32:32,899:INFO:Creating metrics dataframe
2023-11-04 19:32:32,902:INFO:Uploading results into container
2023-11-04 19:32:32,902:INFO:Uploading model into container now
2023-11-04 19:32:32,902:INFO:_master_model_container: 17
2023-11-04 19:32:32,902:INFO:_display_container: 2
2023-11-04 19:32:32,903:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=1083, ...)
2023-11-04 19:32:32,903:INFO:create_model() successfully completed......................................
2023-11-04 19:32:33,014:INFO:SubProcess create_model() end ==================================
2023-11-04 19:32:33,014:INFO:Creating metrics dataframe
2023-11-04 19:32:33,021:INFO:Initializing Light Gradient Boosting Machine
2023-11-04 19:32:33,021:INFO:Total runtime is 0.06566368341445922 minutes
2023-11-04 19:32:33,023:INFO:SubProcess create_model() called ==================================
2023-11-04 19:32:33,023:INFO:Initializing create_model()
2023-11-04 19:32:33,023:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb424cf57c0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb410e06f70>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:32:33,024:INFO:Checking exceptions
2023-11-04 19:32:33,024:INFO:Importing libraries
2023-11-04 19:32:33,024:INFO:Copying training dataset
2023-11-04 19:32:33,025:INFO:Defining folds
2023-11-04 19:32:33,025:INFO:Declaring metric variables
2023-11-04 19:32:33,027:INFO:Importing untrained model
2023-11-04 19:32:33,028:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-04 19:32:33,032:INFO:Starting cross validation
2023-11-04 19:32:33,033:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:32:33,101:INFO:Calculating mean and std
2023-11-04 19:32:33,101:INFO:Creating metrics dataframe
2023-11-04 19:32:33,103:INFO:Uploading results into container
2023-11-04 19:32:33,103:INFO:Uploading model into container now
2023-11-04 19:32:33,103:INFO:_master_model_container: 18
2023-11-04 19:32:33,103:INFO:_display_container: 2
2023-11-04 19:32:33,104:INFO:LGBMRegressor(random_state=1083)
2023-11-04 19:32:33,104:INFO:create_model() successfully completed......................................
2023-11-04 19:32:33,215:INFO:SubProcess create_model() end ==================================
2023-11-04 19:32:33,215:INFO:Creating metrics dataframe
2023-11-04 19:32:33,222:INFO:Initializing CatBoost Regressor
2023-11-04 19:32:33,222:INFO:Total runtime is 0.06900506814320881 minutes
2023-11-04 19:32:33,224:INFO:SubProcess create_model() called ==================================
2023-11-04 19:32:33,224:INFO:Initializing create_model()
2023-11-04 19:32:33,224:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb424cf57c0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb410e06f70>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:32:33,224:INFO:Checking exceptions
2023-11-04 19:32:33,224:INFO:Importing libraries
2023-11-04 19:32:33,224:INFO:Copying training dataset
2023-11-04 19:32:33,226:INFO:Defining folds
2023-11-04 19:32:33,226:INFO:Declaring metric variables
2023-11-04 19:32:33,228:INFO:Importing untrained model
2023-11-04 19:32:33,230:INFO:CatBoost Regressor Imported successfully
2023-11-04 19:32:33,233:INFO:Starting cross validation
2023-11-04 19:32:33,233:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:32:35,523:INFO:Calculating mean and std
2023-11-04 19:32:35,524:INFO:Creating metrics dataframe
2023-11-04 19:32:35,526:INFO:Uploading results into container
2023-11-04 19:32:35,526:INFO:Uploading model into container now
2023-11-04 19:32:35,526:INFO:_master_model_container: 19
2023-11-04 19:32:35,526:INFO:_display_container: 2
2023-11-04 19:32:35,526:INFO:<catboost.core.CatBoostRegressor object at 0x7fb410f56070>
2023-11-04 19:32:35,526:INFO:create_model() successfully completed......................................
2023-11-04 19:32:35,637:INFO:SubProcess create_model() end ==================================
2023-11-04 19:32:35,637:INFO:Creating metrics dataframe
2023-11-04 19:32:35,644:INFO:Initializing Dummy Regressor
2023-11-04 19:32:35,644:INFO:Total runtime is 0.10937135219573973 minutes
2023-11-04 19:32:35,646:INFO:SubProcess create_model() called ==================================
2023-11-04 19:32:35,646:INFO:Initializing create_model()
2023-11-04 19:32:35,646:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb424cf57c0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb410e06f70>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:32:35,646:INFO:Checking exceptions
2023-11-04 19:32:35,646:INFO:Importing libraries
2023-11-04 19:32:35,646:INFO:Copying training dataset
2023-11-04 19:32:35,648:INFO:Defining folds
2023-11-04 19:32:35,648:INFO:Declaring metric variables
2023-11-04 19:32:35,650:INFO:Importing untrained model
2023-11-04 19:32:35,651:INFO:Dummy Regressor Imported successfully
2023-11-04 19:32:35,655:INFO:Starting cross validation
2023-11-04 19:32:35,655:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:32:35,707:INFO:Calculating mean and std
2023-11-04 19:32:35,708:INFO:Creating metrics dataframe
2023-11-04 19:32:35,709:INFO:Uploading results into container
2023-11-04 19:32:35,710:INFO:Uploading model into container now
2023-11-04 19:32:35,710:INFO:_master_model_container: 20
2023-11-04 19:32:35,710:INFO:_display_container: 2
2023-11-04 19:32:35,710:INFO:DummyRegressor()
2023-11-04 19:32:35,710:INFO:create_model() successfully completed......................................
2023-11-04 19:32:35,821:INFO:SubProcess create_model() end ==================================
2023-11-04 19:32:35,821:INFO:Creating metrics dataframe
2023-11-04 19:32:35,834:INFO:Initializing create_model()
2023-11-04 19:32:35,834:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb424cf57c0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=1083, ...), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:32:35,834:INFO:Checking exceptions
2023-11-04 19:32:35,835:INFO:Importing libraries
2023-11-04 19:32:35,835:INFO:Copying training dataset
2023-11-04 19:32:35,836:INFO:Defining folds
2023-11-04 19:32:35,836:INFO:Declaring metric variables
2023-11-04 19:32:35,836:INFO:Importing untrained model
2023-11-04 19:32:35,836:INFO:Declaring custom model
2023-11-04 19:32:35,837:INFO:Extreme Gradient Boosting Imported successfully
2023-11-04 19:32:35,838:INFO:Cross validation set to False
2023-11-04 19:32:35,838:INFO:Fitting Model
2023-11-04 19:32:35,946:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=1083, ...)
2023-11-04 19:32:35,946:INFO:create_model() successfully completed......................................
2023-11-04 19:32:36,082:INFO:_master_model_container: 20
2023-11-04 19:32:36,082:INFO:_display_container: 2
2023-11-04 19:32:36,082:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=1083, ...)
2023-11-04 19:32:36,082:INFO:compare_models() successfully completed......................................
2023-11-04 19:33:30,300:INFO:PyCaret RegressionExperiment
2023-11-04 19:33:30,301:INFO:Logging name: reg-default-name
2023-11-04 19:33:30,301:INFO:ML Usecase: MLUsecase.REGRESSION
2023-11-04 19:33:30,301:INFO:version 3.1.0
2023-11-04 19:33:30,301:INFO:Initializing setup()
2023-11-04 19:33:30,301:INFO:self.USI: 9da5
2023-11-04 19:33:30,301:INFO:self._variable_keys: {'USI', 'log_plots_param', 'gpu_param', 'fold_generator', 'X_test', 'html_param', '_ml_usecase', '_available_plots', 'exp_id', 'target_param', 'idx', 'fold_shuffle_param', 'n_jobs_param', 'seed', 'exp_name_log', 'X', 'y_train', 'transform_target_param', 'data', 'y_test', 'fold_groups_param', 'logging_param', 'gpu_n_jobs_param', 'y', 'X_train', 'memory', 'pipeline'}
2023-11-04 19:33:30,301:INFO:Checking environment
2023-11-04 19:33:30,301:INFO:python_version: 3.9.13
2023-11-04 19:33:30,301:INFO:python_build: ('main', 'Aug 25 2022 18:29:29')
2023-11-04 19:33:30,301:INFO:machine: x86_64
2023-11-04 19:33:30,301:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-11-04 19:33:30,301:INFO:Memory: svmem(total=17179869184, available=1433280512, percent=91.7, used=1915277312, free=26660864, active=1408442368, inactive=1404882944, wired=506834944)
2023-11-04 19:33:30,301:INFO:Physical Core: 8
2023-11-04 19:33:30,301:INFO:Logical Core: 8
2023-11-04 19:33:30,301:INFO:Checking libraries
2023-11-04 19:33:30,301:INFO:System:
2023-11-04 19:33:30,301:INFO:    python: 3.9.13 (main, Aug 25 2022, 18:29:29)  [Clang 12.0.0 ]
2023-11-04 19:33:30,301:INFO:executable: /Users/michal/opt/anaconda3/bin/python
2023-11-04 19:33:30,301:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-11-04 19:33:30,301:INFO:PyCaret required dependencies:
2023-11-04 19:33:30,301:INFO:                 pip: 22.2.2
2023-11-04 19:33:30,301:INFO:          setuptools: 63.4.1
2023-11-04 19:33:30,301:INFO:             pycaret: 3.1.0
2023-11-04 19:33:30,301:INFO:             IPython: 7.31.1
2023-11-04 19:33:30,301:INFO:          ipywidgets: 7.6.5
2023-11-04 19:33:30,301:INFO:                tqdm: 4.64.1
2023-11-04 19:33:30,301:INFO:               numpy: 1.21.5
2023-11-04 19:33:30,301:INFO:              pandas: 1.4.4
2023-11-04 19:33:30,301:INFO:              jinja2: 2.11.3
2023-11-04 19:33:30,301:INFO:               scipy: 1.10.1
2023-11-04 19:33:30,301:INFO:              joblib: 1.2.0
2023-11-04 19:33:30,301:INFO:             sklearn: 1.0.2
2023-11-04 19:33:30,301:INFO:                pyod: 1.1.1
2023-11-04 19:33:30,301:INFO:            imblearn: 0.10.1
2023-11-04 19:33:30,301:INFO:   category_encoders: 2.6.3
2023-11-04 19:33:30,301:INFO:            lightgbm: 3.3.5
2023-11-04 19:33:30,301:INFO:               numba: 0.55.1
2023-11-04 19:33:30,301:INFO:            requests: 2.28.1
2023-11-04 19:33:30,301:INFO:          matplotlib: 3.5.2
2023-11-04 19:33:30,301:INFO:          scikitplot: 0.3.7
2023-11-04 19:33:30,302:INFO:         yellowbrick: 1.5
2023-11-04 19:33:30,302:INFO:              plotly: 5.9.0
2023-11-04 19:33:30,302:INFO:    plotly-resampler: Not installed
2023-11-04 19:33:30,302:INFO:             kaleido: 0.2.1
2023-11-04 19:33:30,302:INFO:           schemdraw: 0.15
2023-11-04 19:33:30,302:INFO:         statsmodels: 0.13.2
2023-11-04 19:33:30,302:INFO:              sktime: 0.21.1
2023-11-04 19:33:30,302:INFO:               tbats: 1.1.3
2023-11-04 19:33:30,302:INFO:            pmdarima: 2.0.4
2023-11-04 19:33:30,302:INFO:              psutil: 5.9.0
2023-11-04 19:33:30,302:INFO:          markupsafe: 2.0.1
2023-11-04 19:33:30,302:INFO:             pickle5: Not installed
2023-11-04 19:33:30,302:INFO:         cloudpickle: 2.0.0
2023-11-04 19:33:30,302:INFO:         deprecation: 2.1.0
2023-11-04 19:33:30,302:INFO:              xxhash: 3.4.1
2023-11-04 19:33:30,302:INFO:           wurlitzer: 3.0.2
2023-11-04 19:33:30,302:INFO:PyCaret optional dependencies:
2023-11-04 19:33:30,302:INFO:                shap: 0.41.0
2023-11-04 19:33:30,302:INFO:           interpret: Not installed
2023-11-04 19:33:30,302:INFO:                umap: 0.5.3
2023-11-04 19:33:30,302:INFO:     ydata_profiling: Not installed
2023-11-04 19:33:30,302:INFO:  explainerdashboard: Not installed
2023-11-04 19:33:30,302:INFO:             autoviz: Not installed
2023-11-04 19:33:30,302:INFO:           fairlearn: Not installed
2023-11-04 19:33:30,302:INFO:          deepchecks: Not installed
2023-11-04 19:33:30,302:INFO:             xgboost: 1.7.4
2023-11-04 19:33:30,302:INFO:            catboost: 1.2
2023-11-04 19:33:30,302:INFO:              kmodes: Not installed
2023-11-04 19:33:30,302:INFO:             mlxtend: 0.21.0
2023-11-04 19:33:30,302:INFO:       statsforecast: Not installed
2023-11-04 19:33:30,302:INFO:        tune_sklearn: Not installed
2023-11-04 19:33:30,302:INFO:                 ray: Not installed
2023-11-04 19:33:30,302:INFO:            hyperopt: Not installed
2023-11-04 19:33:30,302:INFO:              optuna: Not installed
2023-11-04 19:33:30,302:INFO:               skopt: Not installed
2023-11-04 19:33:30,302:INFO:              mlflow: Not installed
2023-11-04 19:33:30,302:INFO:              gradio: Not installed
2023-11-04 19:33:30,302:INFO:             fastapi: Not installed
2023-11-04 19:33:30,302:INFO:             uvicorn: Not installed
2023-11-04 19:33:30,302:INFO:              m2cgen: Not installed
2023-11-04 19:33:30,302:INFO:           evidently: Not installed
2023-11-04 19:33:30,302:INFO:               fugue: Not installed
2023-11-04 19:33:30,302:INFO:           streamlit: Not installed
2023-11-04 19:33:30,302:INFO:             prophet: Not installed
2023-11-04 19:33:30,302:INFO:None
2023-11-04 19:33:30,302:INFO:Set up data.
2023-11-04 19:33:30,305:INFO:Set up folding strategy.
2023-11-04 19:33:30,306:INFO:Set up train/test split.
2023-11-04 19:33:30,307:INFO:Set up index.
2023-11-04 19:33:30,307:INFO:Assigning column types.
2023-11-04 19:33:30,309:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-04 19:33:30,309:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-04 19:33:30,311:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 19:33:30,314:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:33:30,347:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:33:30,373:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:33:30,373:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:33:30,375:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:33:30,375:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-04 19:33:30,378:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 19:33:30,380:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:33:30,413:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:33:30,439:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:33:30,439:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:33:30,440:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:33:30,441:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-11-04 19:33:30,443:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 19:33:30,446:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:33:30,479:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:33:30,505:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:33:30,505:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:33:30,507:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:33:30,510:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 19:33:30,514:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:33:30,547:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:33:30,573:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:33:30,573:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:33:30,574:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:33:30,575:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-11-04 19:33:30,580:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:33:30,612:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:33:30,638:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:33:30,638:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:33:30,640:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:33:30,645:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:33:30,678:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:33:30,704:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:33:30,704:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:33:30,705:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:33:30,706:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-11-04 19:33:30,743:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:33:30,769:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:33:30,769:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:33:30,771:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:33:30,809:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:33:30,834:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:33:30,834:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:33:30,836:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:33:30,836:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-04 19:33:30,874:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:33:30,900:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:33:30,901:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:33:30,939:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:33:30,965:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:33:30,966:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:33:30,967:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-11-04 19:33:31,030:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:33:31,032:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:33:31,096:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:33:31,097:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:33:31,098:INFO:Preparing preprocessing pipeline...
2023-11-04 19:33:31,098:INFO:Set up simple imputation.
2023-11-04 19:33:31,098:INFO:Set up variance threshold.
2023-11-04 19:33:31,098:INFO:Set up removing multicollinearity.
2023-11-04 19:33:31,098:INFO:Set up column name cleaning.
2023-11-04 19:33:31,116:INFO:Finished creating preprocessing pipeline.
2023-11-04 19:33:31,120:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/h9/5_75v3qs13x63s15wwxdrd000000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['solv_dG [kcal/mol]',
                                             'Bond dissociation entalphy',
                                             'water_ads [kcal/mol]', 'Coating',
                                             'Organic Matter Conc.', 'pH',
                                             'Primary Size', 'Initial Conc.',
                                             'Temp.', 'Ionic Strenght', 'Light',
                                             'MW', 'Noxy', 'χ', 'χox',
                                             'Z_metal', 'Zv...
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.1))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-11-04 19:33:31,120:INFO:Creating final display dataframe.
2023-11-04 19:33:31,167:INFO:Setup _display_container:                     Description             Value
0                    Session id              5094
1                        Target  %dissolved solid
2                   Target type        Regression
3           Original data shape         (115, 21)
4        Transformed data shape         (115, 17)
5   Transformed train set shape          (80, 17)
6    Transformed test set shape          (35, 17)
7              Numeric features                20
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12       Low variance threshold               0.1
13     Remove multicollinearity              True
14  Multicollinearity threshold              0.95
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              9da5
2023-11-04 19:33:31,237:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:33:31,239:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:33:31,306:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:33:31,307:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:33:31,308:INFO:setup() successfully completed in 1.01s...............
2023-11-04 19:33:31,308:INFO:Initializing compare_models()
2023-11-04 19:33:31,308:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb42471ee50>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fb42471ee50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-11-04 19:33:31,308:INFO:Checking exceptions
2023-11-04 19:33:31,309:INFO:Preparing display monitor
2023-11-04 19:33:31,325:INFO:Initializing Linear Regression
2023-11-04 19:33:31,325:INFO:Total runtime is 1.9669532775878906e-06 minutes
2023-11-04 19:33:31,327:INFO:SubProcess create_model() called ==================================
2023-11-04 19:33:31,327:INFO:Initializing create_model()
2023-11-04 19:33:31,328:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb42471ee50>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4250cd3a0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:33:31,328:INFO:Checking exceptions
2023-11-04 19:33:31,328:INFO:Importing libraries
2023-11-04 19:33:31,328:INFO:Copying training dataset
2023-11-04 19:33:31,330:INFO:Defining folds
2023-11-04 19:33:31,330:INFO:Declaring metric variables
2023-11-04 19:33:31,332:INFO:Importing untrained model
2023-11-04 19:33:31,333:INFO:Linear Regression Imported successfully
2023-11-04 19:33:31,337:INFO:Starting cross validation
2023-11-04 19:33:31,337:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:33:31,392:INFO:Calculating mean and std
2023-11-04 19:33:31,392:INFO:Creating metrics dataframe
2023-11-04 19:33:31,395:INFO:Uploading results into container
2023-11-04 19:33:31,395:INFO:Uploading model into container now
2023-11-04 19:33:31,395:INFO:_master_model_container: 1
2023-11-04 19:33:31,395:INFO:_display_container: 2
2023-11-04 19:33:31,395:INFO:LinearRegression(n_jobs=-1)
2023-11-04 19:33:31,395:INFO:create_model() successfully completed......................................
2023-11-04 19:33:31,537:INFO:SubProcess create_model() end ==================================
2023-11-04 19:33:31,538:INFO:Creating metrics dataframe
2023-11-04 19:33:31,542:INFO:Initializing Lasso Regression
2023-11-04 19:33:31,542:INFO:Total runtime is 0.003614664077758789 minutes
2023-11-04 19:33:31,544:INFO:SubProcess create_model() called ==================================
2023-11-04 19:33:31,544:INFO:Initializing create_model()
2023-11-04 19:33:31,544:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb42471ee50>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4250cd3a0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:33:31,544:INFO:Checking exceptions
2023-11-04 19:33:31,544:INFO:Importing libraries
2023-11-04 19:33:31,544:INFO:Copying training dataset
2023-11-04 19:33:31,546:INFO:Defining folds
2023-11-04 19:33:31,546:INFO:Declaring metric variables
2023-11-04 19:33:31,547:INFO:Importing untrained model
2023-11-04 19:33:31,549:INFO:Lasso Regression Imported successfully
2023-11-04 19:33:31,552:INFO:Starting cross validation
2023-11-04 19:33:31,553:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:33:31,614:INFO:Calculating mean and std
2023-11-04 19:33:31,615:INFO:Creating metrics dataframe
2023-11-04 19:33:31,616:INFO:Uploading results into container
2023-11-04 19:33:31,617:INFO:Uploading model into container now
2023-11-04 19:33:31,617:INFO:_master_model_container: 2
2023-11-04 19:33:31,617:INFO:_display_container: 2
2023-11-04 19:33:31,617:INFO:Lasso(random_state=5094)
2023-11-04 19:33:31,617:INFO:create_model() successfully completed......................................
2023-11-04 19:33:31,731:INFO:SubProcess create_model() end ==================================
2023-11-04 19:33:31,731:INFO:Creating metrics dataframe
2023-11-04 19:33:31,736:INFO:Initializing Ridge Regression
2023-11-04 19:33:31,736:INFO:Total runtime is 0.006849730014801025 minutes
2023-11-04 19:33:31,738:INFO:SubProcess create_model() called ==================================
2023-11-04 19:33:31,738:INFO:Initializing create_model()
2023-11-04 19:33:31,738:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb42471ee50>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4250cd3a0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:33:31,738:INFO:Checking exceptions
2023-11-04 19:33:31,738:INFO:Importing libraries
2023-11-04 19:33:31,738:INFO:Copying training dataset
2023-11-04 19:33:31,740:INFO:Defining folds
2023-11-04 19:33:31,740:INFO:Declaring metric variables
2023-11-04 19:33:31,741:INFO:Importing untrained model
2023-11-04 19:33:31,743:INFO:Ridge Regression Imported successfully
2023-11-04 19:33:31,746:INFO:Starting cross validation
2023-11-04 19:33:31,747:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:33:31,803:INFO:Calculating mean and std
2023-11-04 19:33:31,803:INFO:Creating metrics dataframe
2023-11-04 19:33:31,805:INFO:Uploading results into container
2023-11-04 19:33:31,805:INFO:Uploading model into container now
2023-11-04 19:33:31,805:INFO:_master_model_container: 3
2023-11-04 19:33:31,805:INFO:_display_container: 2
2023-11-04 19:33:31,806:INFO:Ridge(random_state=5094)
2023-11-04 19:33:31,806:INFO:create_model() successfully completed......................................
2023-11-04 19:33:31,923:INFO:SubProcess create_model() end ==================================
2023-11-04 19:33:31,923:INFO:Creating metrics dataframe
2023-11-04 19:33:31,928:INFO:Initializing Elastic Net
2023-11-04 19:33:31,928:INFO:Total runtime is 0.010046899318695068 minutes
2023-11-04 19:33:31,930:INFO:SubProcess create_model() called ==================================
2023-11-04 19:33:31,930:INFO:Initializing create_model()
2023-11-04 19:33:31,930:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb42471ee50>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4250cd3a0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:33:31,930:INFO:Checking exceptions
2023-11-04 19:33:31,930:INFO:Importing libraries
2023-11-04 19:33:31,930:INFO:Copying training dataset
2023-11-04 19:33:31,932:INFO:Defining folds
2023-11-04 19:33:31,932:INFO:Declaring metric variables
2023-11-04 19:33:31,933:INFO:Importing untrained model
2023-11-04 19:33:31,935:INFO:Elastic Net Imported successfully
2023-11-04 19:33:31,938:INFO:Starting cross validation
2023-11-04 19:33:31,939:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:33:32,001:INFO:Calculating mean and std
2023-11-04 19:33:32,002:INFO:Creating metrics dataframe
2023-11-04 19:33:32,003:INFO:Uploading results into container
2023-11-04 19:33:32,003:INFO:Uploading model into container now
2023-11-04 19:33:32,004:INFO:_master_model_container: 4
2023-11-04 19:33:32,004:INFO:_display_container: 2
2023-11-04 19:33:32,004:INFO:ElasticNet(random_state=5094)
2023-11-04 19:33:32,004:INFO:create_model() successfully completed......................................
2023-11-04 19:33:32,120:INFO:SubProcess create_model() end ==================================
2023-11-04 19:33:32,120:INFO:Creating metrics dataframe
2023-11-04 19:33:32,125:INFO:Initializing Least Angle Regression
2023-11-04 19:33:32,125:INFO:Total runtime is 0.013337632020314535 minutes
2023-11-04 19:33:32,127:INFO:SubProcess create_model() called ==================================
2023-11-04 19:33:32,127:INFO:Initializing create_model()
2023-11-04 19:33:32,127:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb42471ee50>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4250cd3a0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:33:32,127:INFO:Checking exceptions
2023-11-04 19:33:32,128:INFO:Importing libraries
2023-11-04 19:33:32,128:INFO:Copying training dataset
2023-11-04 19:33:32,129:INFO:Defining folds
2023-11-04 19:33:32,129:INFO:Declaring metric variables
2023-11-04 19:33:32,131:INFO:Importing untrained model
2023-11-04 19:33:32,132:INFO:Least Angle Regression Imported successfully
2023-11-04 19:33:32,135:INFO:Starting cross validation
2023-11-04 19:33:32,136:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:33:32,156:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:33:32,160:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:33:32,161:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:33:32,169:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:33:32,172:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:33:32,179:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:33:32,179:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:33:32,180:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:33:32,181:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:33:32,186:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:33:32,193:INFO:Calculating mean and std
2023-11-04 19:33:32,193:INFO:Creating metrics dataframe
2023-11-04 19:33:32,195:INFO:Uploading results into container
2023-11-04 19:33:32,195:INFO:Uploading model into container now
2023-11-04 19:33:32,195:INFO:_master_model_container: 5
2023-11-04 19:33:32,195:INFO:_display_container: 2
2023-11-04 19:33:32,195:INFO:Lars(random_state=5094)
2023-11-04 19:33:32,195:INFO:create_model() successfully completed......................................
2023-11-04 19:33:32,311:INFO:SubProcess create_model() end ==================================
2023-11-04 19:33:32,311:INFO:Creating metrics dataframe
2023-11-04 19:33:32,316:INFO:Initializing Lasso Least Angle Regression
2023-11-04 19:33:32,316:INFO:Total runtime is 0.01652439832687378 minutes
2023-11-04 19:33:32,318:INFO:SubProcess create_model() called ==================================
2023-11-04 19:33:32,318:INFO:Initializing create_model()
2023-11-04 19:33:32,319:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb42471ee50>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4250cd3a0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:33:32,319:INFO:Checking exceptions
2023-11-04 19:33:32,319:INFO:Importing libraries
2023-11-04 19:33:32,319:INFO:Copying training dataset
2023-11-04 19:33:32,321:INFO:Defining folds
2023-11-04 19:33:32,321:INFO:Declaring metric variables
2023-11-04 19:33:32,323:INFO:Importing untrained model
2023-11-04 19:33:32,325:INFO:Lasso Least Angle Regression Imported successfully
2023-11-04 19:33:32,327:INFO:Starting cross validation
2023-11-04 19:33:32,328:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:33:32,350:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:33:32,352:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:33:32,358:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:33:32,363:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:33:32,369:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:33:32,369:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:33:32,373:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:33:32,375:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:33:32,379:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:33:32,380:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:33:32,385:INFO:Calculating mean and std
2023-11-04 19:33:32,385:INFO:Creating metrics dataframe
2023-11-04 19:33:32,387:INFO:Uploading results into container
2023-11-04 19:33:32,387:INFO:Uploading model into container now
2023-11-04 19:33:32,387:INFO:_master_model_container: 6
2023-11-04 19:33:32,387:INFO:_display_container: 2
2023-11-04 19:33:32,388:INFO:LassoLars(random_state=5094)
2023-11-04 19:33:32,388:INFO:create_model() successfully completed......................................
2023-11-04 19:33:32,505:INFO:SubProcess create_model() end ==================================
2023-11-04 19:33:32,505:INFO:Creating metrics dataframe
2023-11-04 19:33:32,511:INFO:Initializing Orthogonal Matching Pursuit
2023-11-04 19:33:32,511:INFO:Total runtime is 0.019764117399851483 minutes
2023-11-04 19:33:32,513:INFO:SubProcess create_model() called ==================================
2023-11-04 19:33:32,513:INFO:Initializing create_model()
2023-11-04 19:33:32,513:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb42471ee50>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4250cd3a0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:33:32,513:INFO:Checking exceptions
2023-11-04 19:33:32,513:INFO:Importing libraries
2023-11-04 19:33:32,513:INFO:Copying training dataset
2023-11-04 19:33:32,515:INFO:Defining folds
2023-11-04 19:33:32,515:INFO:Declaring metric variables
2023-11-04 19:33:32,517:INFO:Importing untrained model
2023-11-04 19:33:32,519:INFO:Orthogonal Matching Pursuit Imported successfully
2023-11-04 19:33:32,522:INFO:Starting cross validation
2023-11-04 19:33:32,522:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:33:32,541:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:33:32,545:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:33:32,546:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:33:32,556:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:33:32,560:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:33:32,561:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:33:32,563:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:33:32,567:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:33:32,573:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:33:32,575:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:33:32,581:INFO:Calculating mean and std
2023-11-04 19:33:32,581:INFO:Creating metrics dataframe
2023-11-04 19:33:32,583:INFO:Uploading results into container
2023-11-04 19:33:32,583:INFO:Uploading model into container now
2023-11-04 19:33:32,584:INFO:_master_model_container: 7
2023-11-04 19:33:32,584:INFO:_display_container: 2
2023-11-04 19:33:32,584:INFO:OrthogonalMatchingPursuit()
2023-11-04 19:33:32,584:INFO:create_model() successfully completed......................................
2023-11-04 19:33:32,700:INFO:SubProcess create_model() end ==================================
2023-11-04 19:33:32,700:INFO:Creating metrics dataframe
2023-11-04 19:33:32,706:INFO:Initializing Bayesian Ridge
2023-11-04 19:33:32,706:INFO:Total runtime is 0.023016516367594404 minutes
2023-11-04 19:33:32,708:INFO:SubProcess create_model() called ==================================
2023-11-04 19:33:32,708:INFO:Initializing create_model()
2023-11-04 19:33:32,708:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb42471ee50>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4250cd3a0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:33:32,708:INFO:Checking exceptions
2023-11-04 19:33:32,708:INFO:Importing libraries
2023-11-04 19:33:32,708:INFO:Copying training dataset
2023-11-04 19:33:32,711:INFO:Defining folds
2023-11-04 19:33:32,711:INFO:Declaring metric variables
2023-11-04 19:33:32,712:INFO:Importing untrained model
2023-11-04 19:33:32,714:INFO:Bayesian Ridge Imported successfully
2023-11-04 19:33:32,717:INFO:Starting cross validation
2023-11-04 19:33:32,718:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:33:32,776:INFO:Calculating mean and std
2023-11-04 19:33:32,776:INFO:Creating metrics dataframe
2023-11-04 19:33:32,778:INFO:Uploading results into container
2023-11-04 19:33:32,778:INFO:Uploading model into container now
2023-11-04 19:33:32,778:INFO:_master_model_container: 8
2023-11-04 19:33:32,778:INFO:_display_container: 2
2023-11-04 19:33:32,778:INFO:BayesianRidge()
2023-11-04 19:33:32,778:INFO:create_model() successfully completed......................................
2023-11-04 19:33:32,895:INFO:SubProcess create_model() end ==================================
2023-11-04 19:33:32,895:INFO:Creating metrics dataframe
2023-11-04 19:33:32,901:INFO:Initializing Passive Aggressive Regressor
2023-11-04 19:33:32,901:INFO:Total runtime is 0.02626163164774577 minutes
2023-11-04 19:33:32,902:INFO:SubProcess create_model() called ==================================
2023-11-04 19:33:32,903:INFO:Initializing create_model()
2023-11-04 19:33:32,903:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb42471ee50>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4250cd3a0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:33:32,903:INFO:Checking exceptions
2023-11-04 19:33:32,903:INFO:Importing libraries
2023-11-04 19:33:32,903:INFO:Copying training dataset
2023-11-04 19:33:32,905:INFO:Defining folds
2023-11-04 19:33:32,905:INFO:Declaring metric variables
2023-11-04 19:33:32,907:INFO:Importing untrained model
2023-11-04 19:33:32,909:INFO:Passive Aggressive Regressor Imported successfully
2023-11-04 19:33:32,912:INFO:Starting cross validation
2023-11-04 19:33:32,912:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:33:32,966:INFO:Calculating mean and std
2023-11-04 19:33:32,966:INFO:Creating metrics dataframe
2023-11-04 19:33:32,968:INFO:Uploading results into container
2023-11-04 19:33:32,968:INFO:Uploading model into container now
2023-11-04 19:33:32,968:INFO:_master_model_container: 9
2023-11-04 19:33:32,968:INFO:_display_container: 2
2023-11-04 19:33:32,969:INFO:PassiveAggressiveRegressor(random_state=5094)
2023-11-04 19:33:32,969:INFO:create_model() successfully completed......................................
2023-11-04 19:33:33,082:INFO:SubProcess create_model() end ==================================
2023-11-04 19:33:33,082:INFO:Creating metrics dataframe
2023-11-04 19:33:33,088:INFO:Initializing Huber Regressor
2023-11-04 19:33:33,088:INFO:Total runtime is 0.029381132125854494 minutes
2023-11-04 19:33:33,090:INFO:SubProcess create_model() called ==================================
2023-11-04 19:33:33,090:INFO:Initializing create_model()
2023-11-04 19:33:33,090:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb42471ee50>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4250cd3a0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:33:33,090:INFO:Checking exceptions
2023-11-04 19:33:33,090:INFO:Importing libraries
2023-11-04 19:33:33,090:INFO:Copying training dataset
2023-11-04 19:33:33,092:INFO:Defining folds
2023-11-04 19:33:33,092:INFO:Declaring metric variables
2023-11-04 19:33:33,094:INFO:Importing untrained model
2023-11-04 19:33:33,096:INFO:Huber Regressor Imported successfully
2023-11-04 19:33:33,099:INFO:Starting cross validation
2023-11-04 19:33:33,099:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:33:33,134:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:33:33,136:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:33:33,137:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:33:33,151:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:33:33,154:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:33:33,156:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:33:33,159:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:33:33,162:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:33:33,171:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:33:33,177:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:33:33,181:INFO:Calculating mean and std
2023-11-04 19:33:33,182:INFO:Creating metrics dataframe
2023-11-04 19:33:33,183:INFO:Uploading results into container
2023-11-04 19:33:33,184:INFO:Uploading model into container now
2023-11-04 19:33:33,184:INFO:_master_model_container: 10
2023-11-04 19:33:33,184:INFO:_display_container: 2
2023-11-04 19:33:33,184:INFO:HuberRegressor()
2023-11-04 19:33:33,184:INFO:create_model() successfully completed......................................
2023-11-04 19:33:33,300:INFO:SubProcess create_model() end ==================================
2023-11-04 19:33:33,300:INFO:Creating metrics dataframe
2023-11-04 19:33:33,306:INFO:Initializing K Neighbors Regressor
2023-11-04 19:33:33,307:INFO:Total runtime is 0.03302646478017172 minutes
2023-11-04 19:33:33,308:INFO:SubProcess create_model() called ==================================
2023-11-04 19:33:33,309:INFO:Initializing create_model()
2023-11-04 19:33:33,309:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb42471ee50>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4250cd3a0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:33:33,309:INFO:Checking exceptions
2023-11-04 19:33:33,309:INFO:Importing libraries
2023-11-04 19:33:33,309:INFO:Copying training dataset
2023-11-04 19:33:33,311:INFO:Defining folds
2023-11-04 19:33:33,311:INFO:Declaring metric variables
2023-11-04 19:33:33,313:INFO:Importing untrained model
2023-11-04 19:33:33,314:INFO:K Neighbors Regressor Imported successfully
2023-11-04 19:33:33,318:INFO:Starting cross validation
2023-11-04 19:33:33,318:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:33:33,384:INFO:Calculating mean and std
2023-11-04 19:33:33,384:INFO:Creating metrics dataframe
2023-11-04 19:33:33,386:INFO:Uploading results into container
2023-11-04 19:33:33,386:INFO:Uploading model into container now
2023-11-04 19:33:33,386:INFO:_master_model_container: 11
2023-11-04 19:33:33,386:INFO:_display_container: 2
2023-11-04 19:33:33,386:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-04 19:33:33,386:INFO:create_model() successfully completed......................................
2023-11-04 19:33:33,507:INFO:SubProcess create_model() end ==================================
2023-11-04 19:33:33,507:INFO:Creating metrics dataframe
2023-11-04 19:33:33,513:INFO:Initializing Decision Tree Regressor
2023-11-04 19:33:33,513:INFO:Total runtime is 0.036474184195200605 minutes
2023-11-04 19:33:33,515:INFO:SubProcess create_model() called ==================================
2023-11-04 19:33:33,516:INFO:Initializing create_model()
2023-11-04 19:33:33,516:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb42471ee50>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4250cd3a0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:33:33,516:INFO:Checking exceptions
2023-11-04 19:33:33,516:INFO:Importing libraries
2023-11-04 19:33:33,516:INFO:Copying training dataset
2023-11-04 19:33:33,518:INFO:Defining folds
2023-11-04 19:33:33,518:INFO:Declaring metric variables
2023-11-04 19:33:33,520:INFO:Importing untrained model
2023-11-04 19:33:33,522:INFO:Decision Tree Regressor Imported successfully
2023-11-04 19:33:33,525:INFO:Starting cross validation
2023-11-04 19:33:33,526:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:33:33,581:INFO:Calculating mean and std
2023-11-04 19:33:33,581:INFO:Creating metrics dataframe
2023-11-04 19:33:33,583:INFO:Uploading results into container
2023-11-04 19:33:33,583:INFO:Uploading model into container now
2023-11-04 19:33:33,583:INFO:_master_model_container: 12
2023-11-04 19:33:33,583:INFO:_display_container: 2
2023-11-04 19:33:33,583:INFO:DecisionTreeRegressor(random_state=5094)
2023-11-04 19:33:33,583:INFO:create_model() successfully completed......................................
2023-11-04 19:33:33,701:INFO:SubProcess create_model() end ==================================
2023-11-04 19:33:33,701:INFO:Creating metrics dataframe
2023-11-04 19:33:33,708:INFO:Initializing Random Forest Regressor
2023-11-04 19:33:33,708:INFO:Total runtime is 0.039713299274444586 minutes
2023-11-04 19:33:33,710:INFO:SubProcess create_model() called ==================================
2023-11-04 19:33:33,710:INFO:Initializing create_model()
2023-11-04 19:33:33,710:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb42471ee50>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4250cd3a0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:33:33,710:INFO:Checking exceptions
2023-11-04 19:33:33,710:INFO:Importing libraries
2023-11-04 19:33:33,710:INFO:Copying training dataset
2023-11-04 19:33:33,712:INFO:Defining folds
2023-11-04 19:33:33,712:INFO:Declaring metric variables
2023-11-04 19:33:33,714:INFO:Importing untrained model
2023-11-04 19:33:33,716:INFO:Random Forest Regressor Imported successfully
2023-11-04 19:33:33,719:INFO:Starting cross validation
2023-11-04 19:33:33,719:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:33:33,978:INFO:Calculating mean and std
2023-11-04 19:33:33,979:INFO:Creating metrics dataframe
2023-11-04 19:33:33,981:INFO:Uploading results into container
2023-11-04 19:33:33,981:INFO:Uploading model into container now
2023-11-04 19:33:33,982:INFO:_master_model_container: 13
2023-11-04 19:33:33,982:INFO:_display_container: 2
2023-11-04 19:33:33,982:INFO:RandomForestRegressor(n_jobs=-1, random_state=5094)
2023-11-04 19:33:33,982:INFO:create_model() successfully completed......................................
2023-11-04 19:33:34,095:INFO:SubProcess create_model() end ==================================
2023-11-04 19:33:34,095:INFO:Creating metrics dataframe
2023-11-04 19:33:34,102:INFO:Initializing Extra Trees Regressor
2023-11-04 19:33:34,102:INFO:Total runtime is 0.046277999877929694 minutes
2023-11-04 19:33:34,103:INFO:SubProcess create_model() called ==================================
2023-11-04 19:33:34,103:INFO:Initializing create_model()
2023-11-04 19:33:34,104:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb42471ee50>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4250cd3a0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:33:34,104:INFO:Checking exceptions
2023-11-04 19:33:34,104:INFO:Importing libraries
2023-11-04 19:33:34,104:INFO:Copying training dataset
2023-11-04 19:33:34,105:INFO:Defining folds
2023-11-04 19:33:34,106:INFO:Declaring metric variables
2023-11-04 19:33:34,107:INFO:Importing untrained model
2023-11-04 19:33:34,109:INFO:Extra Trees Regressor Imported successfully
2023-11-04 19:33:34,113:INFO:Starting cross validation
2023-11-04 19:33:34,113:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:33:34,319:INFO:Calculating mean and std
2023-11-04 19:33:34,320:INFO:Creating metrics dataframe
2023-11-04 19:33:34,322:INFO:Uploading results into container
2023-11-04 19:33:34,322:INFO:Uploading model into container now
2023-11-04 19:33:34,322:INFO:_master_model_container: 14
2023-11-04 19:33:34,323:INFO:_display_container: 2
2023-11-04 19:33:34,323:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=5094)
2023-11-04 19:33:34,323:INFO:create_model() successfully completed......................................
2023-11-04 19:33:34,439:INFO:SubProcess create_model() end ==================================
2023-11-04 19:33:34,439:INFO:Creating metrics dataframe
2023-11-04 19:33:34,446:INFO:Initializing AdaBoost Regressor
2023-11-04 19:33:34,446:INFO:Total runtime is 0.052021813392639164 minutes
2023-11-04 19:33:34,448:INFO:SubProcess create_model() called ==================================
2023-11-04 19:33:34,448:INFO:Initializing create_model()
2023-11-04 19:33:34,448:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb42471ee50>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4250cd3a0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:33:34,448:INFO:Checking exceptions
2023-11-04 19:33:34,448:INFO:Importing libraries
2023-11-04 19:33:34,448:INFO:Copying training dataset
2023-11-04 19:33:34,450:INFO:Defining folds
2023-11-04 19:33:34,450:INFO:Declaring metric variables
2023-11-04 19:33:34,452:INFO:Importing untrained model
2023-11-04 19:33:34,453:INFO:AdaBoost Regressor Imported successfully
2023-11-04 19:33:34,457:INFO:Starting cross validation
2023-11-04 19:33:34,458:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:33:34,561:INFO:Calculating mean and std
2023-11-04 19:33:34,561:INFO:Creating metrics dataframe
2023-11-04 19:33:34,564:INFO:Uploading results into container
2023-11-04 19:33:34,564:INFO:Uploading model into container now
2023-11-04 19:33:34,565:INFO:_master_model_container: 15
2023-11-04 19:33:34,565:INFO:_display_container: 2
2023-11-04 19:33:34,565:INFO:AdaBoostRegressor(random_state=5094)
2023-11-04 19:33:34,565:INFO:create_model() successfully completed......................................
2023-11-04 19:33:34,678:INFO:SubProcess create_model() end ==================================
2023-11-04 19:33:34,678:INFO:Creating metrics dataframe
2023-11-04 19:33:34,684:INFO:Initializing Gradient Boosting Regressor
2023-11-04 19:33:34,684:INFO:Total runtime is 0.05599065224329631 minutes
2023-11-04 19:33:34,686:INFO:SubProcess create_model() called ==================================
2023-11-04 19:33:34,686:INFO:Initializing create_model()
2023-11-04 19:33:34,686:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb42471ee50>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4250cd3a0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:33:34,686:INFO:Checking exceptions
2023-11-04 19:33:34,686:INFO:Importing libraries
2023-11-04 19:33:34,687:INFO:Copying training dataset
2023-11-04 19:33:34,688:INFO:Defining folds
2023-11-04 19:33:34,688:INFO:Declaring metric variables
2023-11-04 19:33:34,690:INFO:Importing untrained model
2023-11-04 19:33:34,691:INFO:Gradient Boosting Regressor Imported successfully
2023-11-04 19:33:34,695:INFO:Starting cross validation
2023-11-04 19:33:34,695:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:33:34,787:INFO:Calculating mean and std
2023-11-04 19:33:34,787:INFO:Creating metrics dataframe
2023-11-04 19:33:34,789:INFO:Uploading results into container
2023-11-04 19:33:34,789:INFO:Uploading model into container now
2023-11-04 19:33:34,790:INFO:_master_model_container: 16
2023-11-04 19:33:34,790:INFO:_display_container: 2
2023-11-04 19:33:34,790:INFO:GradientBoostingRegressor(random_state=5094)
2023-11-04 19:33:34,790:INFO:create_model() successfully completed......................................
2023-11-04 19:33:34,924:INFO:SubProcess create_model() end ==================================
2023-11-04 19:33:34,924:INFO:Creating metrics dataframe
2023-11-04 19:33:34,934:INFO:Initializing Extreme Gradient Boosting
2023-11-04 19:33:34,934:INFO:Total runtime is 0.06014713048934937 minutes
2023-11-04 19:33:34,936:INFO:SubProcess create_model() called ==================================
2023-11-04 19:33:34,936:INFO:Initializing create_model()
2023-11-04 19:33:34,936:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb42471ee50>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4250cd3a0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:33:34,936:INFO:Checking exceptions
2023-11-04 19:33:34,936:INFO:Importing libraries
2023-11-04 19:33:34,936:INFO:Copying training dataset
2023-11-04 19:33:34,939:INFO:Defining folds
2023-11-04 19:33:34,939:INFO:Declaring metric variables
2023-11-04 19:33:34,940:INFO:Importing untrained model
2023-11-04 19:33:34,942:INFO:Extreme Gradient Boosting Imported successfully
2023-11-04 19:33:34,945:INFO:Starting cross validation
2023-11-04 19:33:34,946:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:33:35,081:INFO:Calculating mean and std
2023-11-04 19:33:35,083:INFO:Creating metrics dataframe
2023-11-04 19:33:35,085:INFO:Uploading results into container
2023-11-04 19:33:35,085:INFO:Uploading model into container now
2023-11-04 19:33:35,085:INFO:_master_model_container: 17
2023-11-04 19:33:35,085:INFO:_display_container: 2
2023-11-04 19:33:35,086:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=5094, ...)
2023-11-04 19:33:35,086:INFO:create_model() successfully completed......................................
2023-11-04 19:33:35,248:INFO:SubProcess create_model() end ==================================
2023-11-04 19:33:35,248:INFO:Creating metrics dataframe
2023-11-04 19:33:35,257:INFO:Initializing Light Gradient Boosting Machine
2023-11-04 19:33:35,257:INFO:Total runtime is 0.06552772919336955 minutes
2023-11-04 19:33:35,259:INFO:SubProcess create_model() called ==================================
2023-11-04 19:33:35,259:INFO:Initializing create_model()
2023-11-04 19:33:35,259:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb42471ee50>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4250cd3a0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:33:35,259:INFO:Checking exceptions
2023-11-04 19:33:35,259:INFO:Importing libraries
2023-11-04 19:33:35,259:INFO:Copying training dataset
2023-11-04 19:33:35,261:INFO:Defining folds
2023-11-04 19:33:35,262:INFO:Declaring metric variables
2023-11-04 19:33:35,263:INFO:Importing untrained model
2023-11-04 19:33:35,265:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-04 19:33:35,269:INFO:Starting cross validation
2023-11-04 19:33:35,270:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:33:35,364:INFO:Calculating mean and std
2023-11-04 19:33:35,365:INFO:Creating metrics dataframe
2023-11-04 19:33:35,368:INFO:Uploading results into container
2023-11-04 19:33:35,368:INFO:Uploading model into container now
2023-11-04 19:33:35,368:INFO:_master_model_container: 18
2023-11-04 19:33:35,368:INFO:_display_container: 2
2023-11-04 19:33:35,369:INFO:LGBMRegressor(random_state=5094)
2023-11-04 19:33:35,369:INFO:create_model() successfully completed......................................
2023-11-04 19:33:35,502:INFO:SubProcess create_model() end ==================================
2023-11-04 19:33:35,502:INFO:Creating metrics dataframe
2023-11-04 19:33:35,510:INFO:Initializing CatBoost Regressor
2023-11-04 19:33:35,510:INFO:Total runtime is 0.06974398295084636 minutes
2023-11-04 19:33:35,511:INFO:SubProcess create_model() called ==================================
2023-11-04 19:33:35,512:INFO:Initializing create_model()
2023-11-04 19:33:35,512:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb42471ee50>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4250cd3a0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:33:35,512:INFO:Checking exceptions
2023-11-04 19:33:35,512:INFO:Importing libraries
2023-11-04 19:33:35,512:INFO:Copying training dataset
2023-11-04 19:33:35,514:INFO:Defining folds
2023-11-04 19:33:35,514:INFO:Declaring metric variables
2023-11-04 19:33:35,516:INFO:Importing untrained model
2023-11-04 19:33:35,518:INFO:CatBoost Regressor Imported successfully
2023-11-04 19:33:35,521:INFO:Starting cross validation
2023-11-04 19:33:35,522:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:33:36,297:INFO:Calculating mean and std
2023-11-04 19:33:36,298:INFO:Creating metrics dataframe
2023-11-04 19:33:36,300:INFO:Uploading results into container
2023-11-04 19:33:36,301:INFO:Uploading model into container now
2023-11-04 19:33:36,301:INFO:_master_model_container: 19
2023-11-04 19:33:36,301:INFO:_display_container: 2
2023-11-04 19:33:36,301:INFO:<catboost.core.CatBoostRegressor object at 0x7fb435acc190>
2023-11-04 19:33:36,301:INFO:create_model() successfully completed......................................
2023-11-04 19:33:36,440:INFO:SubProcess create_model() end ==================================
2023-11-04 19:33:36,440:INFO:Creating metrics dataframe
2023-11-04 19:33:36,448:INFO:Initializing Dummy Regressor
2023-11-04 19:33:36,448:INFO:Total runtime is 0.08538450002670288 minutes
2023-11-04 19:33:36,450:INFO:SubProcess create_model() called ==================================
2023-11-04 19:33:36,450:INFO:Initializing create_model()
2023-11-04 19:33:36,450:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb42471ee50>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4250cd3a0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:33:36,450:INFO:Checking exceptions
2023-11-04 19:33:36,450:INFO:Importing libraries
2023-11-04 19:33:36,450:INFO:Copying training dataset
2023-11-04 19:33:36,453:INFO:Defining folds
2023-11-04 19:33:36,453:INFO:Declaring metric variables
2023-11-04 19:33:36,455:INFO:Importing untrained model
2023-11-04 19:33:36,456:INFO:Dummy Regressor Imported successfully
2023-11-04 19:33:36,459:INFO:Starting cross validation
2023-11-04 19:33:36,460:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:33:36,519:INFO:Calculating mean and std
2023-11-04 19:33:36,519:INFO:Creating metrics dataframe
2023-11-04 19:33:36,521:INFO:Uploading results into container
2023-11-04 19:33:36,521:INFO:Uploading model into container now
2023-11-04 19:33:36,522:INFO:_master_model_container: 20
2023-11-04 19:33:36,522:INFO:_display_container: 2
2023-11-04 19:33:36,522:INFO:DummyRegressor()
2023-11-04 19:33:36,522:INFO:create_model() successfully completed......................................
2023-11-04 19:33:36,655:INFO:SubProcess create_model() end ==================================
2023-11-04 19:33:36,655:INFO:Creating metrics dataframe
2023-11-04 19:33:36,670:INFO:Initializing create_model()
2023-11-04 19:33:36,670:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb42471ee50>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=5094, ...), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:33:36,670:INFO:Checking exceptions
2023-11-04 19:33:36,671:INFO:Importing libraries
2023-11-04 19:33:36,671:INFO:Copying training dataset
2023-11-04 19:33:36,673:INFO:Defining folds
2023-11-04 19:33:36,673:INFO:Declaring metric variables
2023-11-04 19:33:36,673:INFO:Importing untrained model
2023-11-04 19:33:36,673:INFO:Declaring custom model
2023-11-04 19:33:36,674:INFO:Extreme Gradient Boosting Imported successfully
2023-11-04 19:33:36,675:INFO:Cross validation set to False
2023-11-04 19:33:36,675:INFO:Fitting Model
2023-11-04 19:33:36,866:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=5094, ...)
2023-11-04 19:33:36,866:INFO:create_model() successfully completed......................................
2023-11-04 19:33:37,025:INFO:_master_model_container: 20
2023-11-04 19:33:37,025:INFO:_display_container: 2
2023-11-04 19:33:37,026:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=5094, ...)
2023-11-04 19:33:37,026:INFO:compare_models() successfully completed......................................
2023-11-04 19:33:40,468:INFO:PyCaret RegressionExperiment
2023-11-04 19:33:40,468:INFO:Logging name: reg-default-name
2023-11-04 19:33:40,469:INFO:ML Usecase: MLUsecase.REGRESSION
2023-11-04 19:33:40,469:INFO:version 3.1.0
2023-11-04 19:33:40,469:INFO:Initializing setup()
2023-11-04 19:33:40,469:INFO:self.USI: 8d46
2023-11-04 19:33:40,469:INFO:self._variable_keys: {'USI', 'log_plots_param', 'gpu_param', 'fold_generator', 'X_test', 'html_param', '_ml_usecase', '_available_plots', 'exp_id', 'target_param', 'idx', 'fold_shuffle_param', 'n_jobs_param', 'seed', 'exp_name_log', 'X', 'y_train', 'transform_target_param', 'data', 'y_test', 'fold_groups_param', 'logging_param', 'gpu_n_jobs_param', 'y', 'X_train', 'memory', 'pipeline'}
2023-11-04 19:33:40,469:INFO:Checking environment
2023-11-04 19:33:40,469:INFO:python_version: 3.9.13
2023-11-04 19:33:40,469:INFO:python_build: ('main', 'Aug 25 2022 18:29:29')
2023-11-04 19:33:40,469:INFO:machine: x86_64
2023-11-04 19:33:40,470:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-11-04 19:33:40,470:INFO:Memory: svmem(total=17179869184, available=1246167040, percent=92.7, used=1750364160, free=14716928, active=1234358272, inactive=1177755648, wired=516005888)
2023-11-04 19:33:40,470:INFO:Physical Core: 8
2023-11-04 19:33:40,470:INFO:Logical Core: 8
2023-11-04 19:33:40,470:INFO:Checking libraries
2023-11-04 19:33:40,470:INFO:System:
2023-11-04 19:33:40,470:INFO:    python: 3.9.13 (main, Aug 25 2022, 18:29:29)  [Clang 12.0.0 ]
2023-11-04 19:33:40,470:INFO:executable: /Users/michal/opt/anaconda3/bin/python
2023-11-04 19:33:40,470:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-11-04 19:33:40,471:INFO:PyCaret required dependencies:
2023-11-04 19:33:40,471:INFO:                 pip: 22.2.2
2023-11-04 19:33:40,471:INFO:          setuptools: 63.4.1
2023-11-04 19:33:40,471:INFO:             pycaret: 3.1.0
2023-11-04 19:33:40,471:INFO:             IPython: 7.31.1
2023-11-04 19:33:40,471:INFO:          ipywidgets: 7.6.5
2023-11-04 19:33:40,471:INFO:                tqdm: 4.64.1
2023-11-04 19:33:40,471:INFO:               numpy: 1.21.5
2023-11-04 19:33:40,471:INFO:              pandas: 1.4.4
2023-11-04 19:33:40,471:INFO:              jinja2: 2.11.3
2023-11-04 19:33:40,471:INFO:               scipy: 1.10.1
2023-11-04 19:33:40,471:INFO:              joblib: 1.2.0
2023-11-04 19:33:40,471:INFO:             sklearn: 1.0.2
2023-11-04 19:33:40,471:INFO:                pyod: 1.1.1
2023-11-04 19:33:40,471:INFO:            imblearn: 0.10.1
2023-11-04 19:33:40,471:INFO:   category_encoders: 2.6.3
2023-11-04 19:33:40,472:INFO:            lightgbm: 3.3.5
2023-11-04 19:33:40,472:INFO:               numba: 0.55.1
2023-11-04 19:33:40,472:INFO:            requests: 2.28.1
2023-11-04 19:33:40,472:INFO:          matplotlib: 3.5.2
2023-11-04 19:33:40,472:INFO:          scikitplot: 0.3.7
2023-11-04 19:33:40,472:INFO:         yellowbrick: 1.5
2023-11-04 19:33:40,472:INFO:              plotly: 5.9.0
2023-11-04 19:33:40,472:INFO:    plotly-resampler: Not installed
2023-11-04 19:33:40,472:INFO:             kaleido: 0.2.1
2023-11-04 19:33:40,472:INFO:           schemdraw: 0.15
2023-11-04 19:33:40,472:INFO:         statsmodels: 0.13.2
2023-11-04 19:33:40,472:INFO:              sktime: 0.21.1
2023-11-04 19:33:40,472:INFO:               tbats: 1.1.3
2023-11-04 19:33:40,472:INFO:            pmdarima: 2.0.4
2023-11-04 19:33:40,472:INFO:              psutil: 5.9.0
2023-11-04 19:33:40,472:INFO:          markupsafe: 2.0.1
2023-11-04 19:33:40,472:INFO:             pickle5: Not installed
2023-11-04 19:33:40,472:INFO:         cloudpickle: 2.0.0
2023-11-04 19:33:40,472:INFO:         deprecation: 2.1.0
2023-11-04 19:33:40,472:INFO:              xxhash: 3.4.1
2023-11-04 19:33:40,472:INFO:           wurlitzer: 3.0.2
2023-11-04 19:33:40,472:INFO:PyCaret optional dependencies:
2023-11-04 19:33:40,473:INFO:                shap: 0.41.0
2023-11-04 19:33:40,473:INFO:           interpret: Not installed
2023-11-04 19:33:40,473:INFO:                umap: 0.5.3
2023-11-04 19:33:40,473:INFO:     ydata_profiling: Not installed
2023-11-04 19:33:40,473:INFO:  explainerdashboard: Not installed
2023-11-04 19:33:40,473:INFO:             autoviz: Not installed
2023-11-04 19:33:40,473:INFO:           fairlearn: Not installed
2023-11-04 19:33:40,473:INFO:          deepchecks: Not installed
2023-11-04 19:33:40,473:INFO:             xgboost: 1.7.4
2023-11-04 19:33:40,473:INFO:            catboost: 1.2
2023-11-04 19:33:40,473:INFO:              kmodes: Not installed
2023-11-04 19:33:40,473:INFO:             mlxtend: 0.21.0
2023-11-04 19:33:40,473:INFO:       statsforecast: Not installed
2023-11-04 19:33:40,473:INFO:        tune_sklearn: Not installed
2023-11-04 19:33:40,473:INFO:                 ray: Not installed
2023-11-04 19:33:40,473:INFO:            hyperopt: Not installed
2023-11-04 19:33:40,473:INFO:              optuna: Not installed
2023-11-04 19:33:40,473:INFO:               skopt: Not installed
2023-11-04 19:33:40,473:INFO:              mlflow: Not installed
2023-11-04 19:33:40,473:INFO:              gradio: Not installed
2023-11-04 19:33:40,473:INFO:             fastapi: Not installed
2023-11-04 19:33:40,474:INFO:             uvicorn: Not installed
2023-11-04 19:33:40,474:INFO:              m2cgen: Not installed
2023-11-04 19:33:40,474:INFO:           evidently: Not installed
2023-11-04 19:33:40,474:INFO:               fugue: Not installed
2023-11-04 19:33:40,474:INFO:           streamlit: Not installed
2023-11-04 19:33:40,474:INFO:             prophet: Not installed
2023-11-04 19:33:40,474:INFO:None
2023-11-04 19:33:40,474:INFO:Set up data.
2023-11-04 19:33:40,487:INFO:Set up folding strategy.
2023-11-04 19:33:40,487:INFO:Set up train/test split.
2023-11-04 19:33:40,491:INFO:Set up index.
2023-11-04 19:33:40,492:INFO:Assigning column types.
2023-11-04 19:33:40,495:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-04 19:33:40,495:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-04 19:33:40,500:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 19:33:40,506:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:33:40,554:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:33:40,580:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:33:40,580:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:33:40,582:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:33:40,583:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-04 19:33:40,585:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 19:33:40,588:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:33:40,621:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:33:40,647:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:33:40,647:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:33:40,649:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:33:40,649:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-11-04 19:33:40,652:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 19:33:40,655:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:33:40,688:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:33:40,714:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:33:40,714:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:33:40,716:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:33:40,718:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 19:33:40,721:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:33:40,754:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:33:40,781:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:33:40,781:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:33:40,783:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:33:40,783:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-11-04 19:33:40,788:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:33:40,821:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:33:40,848:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:33:40,848:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:33:40,849:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:33:40,855:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:33:40,888:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:33:40,914:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:33:40,914:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:33:40,915:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:33:40,915:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-11-04 19:33:40,954:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:33:40,980:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:33:40,980:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:33:40,981:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:33:41,020:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:33:41,047:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:33:41,047:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:33:41,049:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:33:41,049:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-04 19:33:41,089:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:33:41,117:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:33:41,118:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:33:41,158:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:33:41,186:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:33:41,187:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:33:41,187:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-11-04 19:33:41,251:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:33:41,252:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:33:41,321:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:33:41,322:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:33:41,323:INFO:Preparing preprocessing pipeline...
2023-11-04 19:33:41,323:INFO:Set up simple imputation.
2023-11-04 19:33:41,323:INFO:Set up variance threshold.
2023-11-04 19:33:41,323:INFO:Set up removing multicollinearity.
2023-11-04 19:33:41,323:INFO:Set up column name cleaning.
2023-11-04 19:33:41,343:INFO:Finished creating preprocessing pipeline.
2023-11-04 19:33:41,346:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/h9/5_75v3qs13x63s15wwxdrd000000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['solv_dG [kcal/mol]',
                                             'Bond dissociation entalphy',
                                             'water_ads [kcal/mol]', 'Coating',
                                             'Organic Matter Conc.', 'pH',
                                             'Primary Size', 'Initial Conc.',
                                             'Temp.', 'Ionic Strenght', 'Light',
                                             'MW', 'Noxy', 'χ', 'χox',
                                             'Z_metal', 'Zv...
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.1))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-11-04 19:33:41,346:INFO:Creating final display dataframe.
2023-11-04 19:33:41,393:INFO:Setup _display_container:                     Description             Value
0                    Session id              6792
1                        Target  %dissolved solid
2                   Target type        Regression
3           Original data shape        (1226, 21)
4        Transformed data shape        (1226, 21)
5   Transformed train set shape         (858, 21)
6    Transformed test set shape         (368, 21)
7              Numeric features                20
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12       Low variance threshold               0.1
13     Remove multicollinearity              True
14  Multicollinearity threshold              0.95
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              8d46
2023-11-04 19:33:41,467:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:33:41,469:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:33:41,537:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:33:41,538:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:33:41,539:INFO:setup() successfully completed in 1.07s...............
2023-11-04 19:33:41,539:INFO:Initializing compare_models()
2023-11-04 19:33:41,539:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4370d8b80>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fb4370d8b80>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-11-04 19:33:41,539:INFO:Checking exceptions
2023-11-04 19:33:41,539:INFO:Preparing display monitor
2023-11-04 19:33:41,556:INFO:Initializing Linear Regression
2023-11-04 19:33:41,556:INFO:Total runtime is 1.899401346842448e-06 minutes
2023-11-04 19:33:41,558:INFO:SubProcess create_model() called ==================================
2023-11-04 19:33:41,558:INFO:Initializing create_model()
2023-11-04 19:33:41,558:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4370d8b80>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4245978b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:33:41,558:INFO:Checking exceptions
2023-11-04 19:33:41,558:INFO:Importing libraries
2023-11-04 19:33:41,558:INFO:Copying training dataset
2023-11-04 19:33:41,561:INFO:Defining folds
2023-11-04 19:33:41,561:INFO:Declaring metric variables
2023-11-04 19:33:41,562:INFO:Importing untrained model
2023-11-04 19:33:41,564:INFO:Linear Regression Imported successfully
2023-11-04 19:33:41,567:INFO:Starting cross validation
2023-11-04 19:33:41,568:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:33:41,638:INFO:Calculating mean and std
2023-11-04 19:33:41,638:INFO:Creating metrics dataframe
2023-11-04 19:33:41,640:INFO:Uploading results into container
2023-11-04 19:33:41,640:INFO:Uploading model into container now
2023-11-04 19:33:41,641:INFO:_master_model_container: 1
2023-11-04 19:33:41,641:INFO:_display_container: 2
2023-11-04 19:33:41,641:INFO:LinearRegression(n_jobs=-1)
2023-11-04 19:33:41,641:INFO:create_model() successfully completed......................................
2023-11-04 19:33:41,757:INFO:SubProcess create_model() end ==================================
2023-11-04 19:33:41,757:INFO:Creating metrics dataframe
2023-11-04 19:33:41,761:INFO:Initializing Lasso Regression
2023-11-04 19:33:41,761:INFO:Total runtime is 0.003415632247924805 minutes
2023-11-04 19:33:41,763:INFO:SubProcess create_model() called ==================================
2023-11-04 19:33:41,763:INFO:Initializing create_model()
2023-11-04 19:33:41,763:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4370d8b80>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4245978b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:33:41,763:INFO:Checking exceptions
2023-11-04 19:33:41,763:INFO:Importing libraries
2023-11-04 19:33:41,763:INFO:Copying training dataset
2023-11-04 19:33:41,765:INFO:Defining folds
2023-11-04 19:33:41,765:INFO:Declaring metric variables
2023-11-04 19:33:41,766:INFO:Importing untrained model
2023-11-04 19:33:41,768:INFO:Lasso Regression Imported successfully
2023-11-04 19:33:41,771:INFO:Starting cross validation
2023-11-04 19:33:41,772:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:33:41,831:INFO:Calculating mean and std
2023-11-04 19:33:41,832:INFO:Creating metrics dataframe
2023-11-04 19:33:41,833:INFO:Uploading results into container
2023-11-04 19:33:41,834:INFO:Uploading model into container now
2023-11-04 19:33:41,834:INFO:_master_model_container: 2
2023-11-04 19:33:41,834:INFO:_display_container: 2
2023-11-04 19:33:41,834:INFO:Lasso(random_state=6792)
2023-11-04 19:33:41,834:INFO:create_model() successfully completed......................................
2023-11-04 19:33:41,945:INFO:SubProcess create_model() end ==================================
2023-11-04 19:33:41,945:INFO:Creating metrics dataframe
2023-11-04 19:33:41,950:INFO:Initializing Ridge Regression
2023-11-04 19:33:41,950:INFO:Total runtime is 0.006560583909352621 minutes
2023-11-04 19:33:41,952:INFO:SubProcess create_model() called ==================================
2023-11-04 19:33:41,952:INFO:Initializing create_model()
2023-11-04 19:33:41,952:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4370d8b80>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4245978b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:33:41,952:INFO:Checking exceptions
2023-11-04 19:33:41,952:INFO:Importing libraries
2023-11-04 19:33:41,952:INFO:Copying training dataset
2023-11-04 19:33:41,954:INFO:Defining folds
2023-11-04 19:33:41,954:INFO:Declaring metric variables
2023-11-04 19:33:41,955:INFO:Importing untrained model
2023-11-04 19:33:41,957:INFO:Ridge Regression Imported successfully
2023-11-04 19:33:41,960:INFO:Starting cross validation
2023-11-04 19:33:41,960:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:33:42,024:INFO:Calculating mean and std
2023-11-04 19:33:42,024:INFO:Creating metrics dataframe
2023-11-04 19:33:42,026:INFO:Uploading results into container
2023-11-04 19:33:42,026:INFO:Uploading model into container now
2023-11-04 19:33:42,026:INFO:_master_model_container: 3
2023-11-04 19:33:42,026:INFO:_display_container: 2
2023-11-04 19:33:42,026:INFO:Ridge(random_state=6792)
2023-11-04 19:33:42,026:INFO:create_model() successfully completed......................................
2023-11-04 19:33:42,142:INFO:SubProcess create_model() end ==================================
2023-11-04 19:33:42,142:INFO:Creating metrics dataframe
2023-11-04 19:33:42,147:INFO:Initializing Elastic Net
2023-11-04 19:33:42,147:INFO:Total runtime is 0.009848848978678385 minutes
2023-11-04 19:33:42,149:INFO:SubProcess create_model() called ==================================
2023-11-04 19:33:42,149:INFO:Initializing create_model()
2023-11-04 19:33:42,149:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4370d8b80>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4245978b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:33:42,149:INFO:Checking exceptions
2023-11-04 19:33:42,149:INFO:Importing libraries
2023-11-04 19:33:42,150:INFO:Copying training dataset
2023-11-04 19:33:42,151:INFO:Defining folds
2023-11-04 19:33:42,151:INFO:Declaring metric variables
2023-11-04 19:33:42,152:INFO:Importing untrained model
2023-11-04 19:33:42,154:INFO:Elastic Net Imported successfully
2023-11-04 19:33:42,157:INFO:Starting cross validation
2023-11-04 19:33:42,158:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:33:42,219:INFO:Calculating mean and std
2023-11-04 19:33:42,219:INFO:Creating metrics dataframe
2023-11-04 19:33:42,221:INFO:Uploading results into container
2023-11-04 19:33:42,221:INFO:Uploading model into container now
2023-11-04 19:33:42,221:INFO:_master_model_container: 4
2023-11-04 19:33:42,221:INFO:_display_container: 2
2023-11-04 19:33:42,221:INFO:ElasticNet(random_state=6792)
2023-11-04 19:33:42,221:INFO:create_model() successfully completed......................................
2023-11-04 19:33:42,338:INFO:SubProcess create_model() end ==================================
2023-11-04 19:33:42,338:INFO:Creating metrics dataframe
2023-11-04 19:33:42,343:INFO:Initializing Least Angle Regression
2023-11-04 19:33:42,344:INFO:Total runtime is 0.013123448689778645 minutes
2023-11-04 19:33:42,345:INFO:SubProcess create_model() called ==================================
2023-11-04 19:33:42,346:INFO:Initializing create_model()
2023-11-04 19:33:42,346:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4370d8b80>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4245978b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:33:42,346:INFO:Checking exceptions
2023-11-04 19:33:42,346:INFO:Importing libraries
2023-11-04 19:33:42,346:INFO:Copying training dataset
2023-11-04 19:33:42,347:INFO:Defining folds
2023-11-04 19:33:42,347:INFO:Declaring metric variables
2023-11-04 19:33:42,349:INFO:Importing untrained model
2023-11-04 19:33:42,351:INFO:Least Angle Regression Imported successfully
2023-11-04 19:33:42,354:INFO:Starting cross validation
2023-11-04 19:33:42,354:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:33:42,374:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:33:42,388:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:33:42,392:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:33:42,394:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:33:42,395:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:33:42,399:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:33:42,408:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:33:42,412:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:33:42,416:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:33:42,418:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:33:42,425:INFO:Calculating mean and std
2023-11-04 19:33:42,425:INFO:Creating metrics dataframe
2023-11-04 19:33:42,426:INFO:Uploading results into container
2023-11-04 19:33:42,427:INFO:Uploading model into container now
2023-11-04 19:33:42,427:INFO:_master_model_container: 5
2023-11-04 19:33:42,427:INFO:_display_container: 2
2023-11-04 19:33:42,427:INFO:Lars(random_state=6792)
2023-11-04 19:33:42,427:INFO:create_model() successfully completed......................................
2023-11-04 19:33:42,548:INFO:SubProcess create_model() end ==================================
2023-11-04 19:33:42,548:INFO:Creating metrics dataframe
2023-11-04 19:33:42,554:INFO:Initializing Lasso Least Angle Regression
2023-11-04 19:33:42,554:INFO:Total runtime is 0.016624780495961507 minutes
2023-11-04 19:33:42,555:INFO:SubProcess create_model() called ==================================
2023-11-04 19:33:42,556:INFO:Initializing create_model()
2023-11-04 19:33:42,556:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4370d8b80>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4245978b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:33:42,556:INFO:Checking exceptions
2023-11-04 19:33:42,556:INFO:Importing libraries
2023-11-04 19:33:42,556:INFO:Copying training dataset
2023-11-04 19:33:42,558:INFO:Defining folds
2023-11-04 19:33:42,558:INFO:Declaring metric variables
2023-11-04 19:33:42,560:INFO:Importing untrained model
2023-11-04 19:33:42,562:INFO:Lasso Least Angle Regression Imported successfully
2023-11-04 19:33:42,565:INFO:Starting cross validation
2023-11-04 19:33:42,566:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:33:42,587:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:33:42,590:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:33:42,597:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:33:42,600:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:33:42,604:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:33:42,612:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:33:42,614:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:33:42,619:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:33:42,625:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:33:42,625:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:33:42,630:INFO:Calculating mean and std
2023-11-04 19:33:42,631:INFO:Creating metrics dataframe
2023-11-04 19:33:42,632:INFO:Uploading results into container
2023-11-04 19:33:42,633:INFO:Uploading model into container now
2023-11-04 19:33:42,633:INFO:_master_model_container: 6
2023-11-04 19:33:42,633:INFO:_display_container: 2
2023-11-04 19:33:42,633:INFO:LassoLars(random_state=6792)
2023-11-04 19:33:42,633:INFO:create_model() successfully completed......................................
2023-11-04 19:33:42,753:INFO:SubProcess create_model() end ==================================
2023-11-04 19:33:42,753:INFO:Creating metrics dataframe
2023-11-04 19:33:42,758:INFO:Initializing Orthogonal Matching Pursuit
2023-11-04 19:33:42,758:INFO:Total runtime is 0.020037047068277993 minutes
2023-11-04 19:33:42,760:INFO:SubProcess create_model() called ==================================
2023-11-04 19:33:42,760:INFO:Initializing create_model()
2023-11-04 19:33:42,760:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4370d8b80>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4245978b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:33:42,760:INFO:Checking exceptions
2023-11-04 19:33:42,760:INFO:Importing libraries
2023-11-04 19:33:42,761:INFO:Copying training dataset
2023-11-04 19:33:42,763:INFO:Defining folds
2023-11-04 19:33:42,763:INFO:Declaring metric variables
2023-11-04 19:33:42,765:INFO:Importing untrained model
2023-11-04 19:33:42,767:INFO:Orthogonal Matching Pursuit Imported successfully
2023-11-04 19:33:42,770:INFO:Starting cross validation
2023-11-04 19:33:42,770:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:33:42,790:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:33:42,797:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:33:42,799:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:33:42,805:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:33:42,805:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:33:42,813:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:33:42,815:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:33:42,821:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:33:42,826:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:33:42,831:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:33:42,836:INFO:Calculating mean and std
2023-11-04 19:33:42,837:INFO:Creating metrics dataframe
2023-11-04 19:33:42,838:INFO:Uploading results into container
2023-11-04 19:33:42,839:INFO:Uploading model into container now
2023-11-04 19:33:42,839:INFO:_master_model_container: 7
2023-11-04 19:33:42,839:INFO:_display_container: 2
2023-11-04 19:33:42,839:INFO:OrthogonalMatchingPursuit()
2023-11-04 19:33:42,839:INFO:create_model() successfully completed......................................
2023-11-04 19:33:42,956:INFO:SubProcess create_model() end ==================================
2023-11-04 19:33:42,956:INFO:Creating metrics dataframe
2023-11-04 19:33:42,961:INFO:Initializing Bayesian Ridge
2023-11-04 19:33:42,961:INFO:Total runtime is 0.023421450455983477 minutes
2023-11-04 19:33:42,963:INFO:SubProcess create_model() called ==================================
2023-11-04 19:33:42,963:INFO:Initializing create_model()
2023-11-04 19:33:42,964:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4370d8b80>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4245978b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:33:42,964:INFO:Checking exceptions
2023-11-04 19:33:42,964:INFO:Importing libraries
2023-11-04 19:33:42,964:INFO:Copying training dataset
2023-11-04 19:33:42,966:INFO:Defining folds
2023-11-04 19:33:42,966:INFO:Declaring metric variables
2023-11-04 19:33:42,968:INFO:Importing untrained model
2023-11-04 19:33:42,970:INFO:Bayesian Ridge Imported successfully
2023-11-04 19:33:42,973:INFO:Starting cross validation
2023-11-04 19:33:42,973:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:33:43,046:INFO:Calculating mean and std
2023-11-04 19:33:43,046:INFO:Creating metrics dataframe
2023-11-04 19:33:43,048:INFO:Uploading results into container
2023-11-04 19:33:43,048:INFO:Uploading model into container now
2023-11-04 19:33:43,049:INFO:_master_model_container: 8
2023-11-04 19:33:43,049:INFO:_display_container: 2
2023-11-04 19:33:43,049:INFO:BayesianRidge()
2023-11-04 19:33:43,049:INFO:create_model() successfully completed......................................
2023-11-04 19:33:43,165:INFO:SubProcess create_model() end ==================================
2023-11-04 19:33:43,165:INFO:Creating metrics dataframe
2023-11-04 19:33:43,171:INFO:Initializing Passive Aggressive Regressor
2023-11-04 19:33:43,171:INFO:Total runtime is 0.026907765865325926 minutes
2023-11-04 19:33:43,172:INFO:SubProcess create_model() called ==================================
2023-11-04 19:33:43,173:INFO:Initializing create_model()
2023-11-04 19:33:43,173:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4370d8b80>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4245978b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:33:43,173:INFO:Checking exceptions
2023-11-04 19:33:43,173:INFO:Importing libraries
2023-11-04 19:33:43,173:INFO:Copying training dataset
2023-11-04 19:33:43,175:INFO:Defining folds
2023-11-04 19:33:43,175:INFO:Declaring metric variables
2023-11-04 19:33:43,177:INFO:Importing untrained model
2023-11-04 19:33:43,179:INFO:Passive Aggressive Regressor Imported successfully
2023-11-04 19:33:43,182:INFO:Starting cross validation
2023-11-04 19:33:43,182:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:33:43,246:INFO:Calculating mean and std
2023-11-04 19:33:43,246:INFO:Creating metrics dataframe
2023-11-04 19:33:43,248:INFO:Uploading results into container
2023-11-04 19:33:43,248:INFO:Uploading model into container now
2023-11-04 19:33:43,248:INFO:_master_model_container: 9
2023-11-04 19:33:43,248:INFO:_display_container: 2
2023-11-04 19:33:43,249:INFO:PassiveAggressiveRegressor(random_state=6792)
2023-11-04 19:33:43,249:INFO:create_model() successfully completed......................................
2023-11-04 19:33:43,363:INFO:SubProcess create_model() end ==================================
2023-11-04 19:33:43,363:INFO:Creating metrics dataframe
2023-11-04 19:33:43,369:INFO:Initializing Huber Regressor
2023-11-04 19:33:43,370:INFO:Total runtime is 0.030223564306894934 minutes
2023-11-04 19:33:43,371:INFO:SubProcess create_model() called ==================================
2023-11-04 19:33:43,372:INFO:Initializing create_model()
2023-11-04 19:33:43,372:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4370d8b80>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4245978b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:33:43,372:INFO:Checking exceptions
2023-11-04 19:33:43,372:INFO:Importing libraries
2023-11-04 19:33:43,372:INFO:Copying training dataset
2023-11-04 19:33:43,374:INFO:Defining folds
2023-11-04 19:33:43,374:INFO:Declaring metric variables
2023-11-04 19:33:43,376:INFO:Importing untrained model
2023-11-04 19:33:43,378:INFO:Huber Regressor Imported successfully
2023-11-04 19:33:43,381:INFO:Starting cross validation
2023-11-04 19:33:43,382:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:33:43,417:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:33:43,424:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:33:43,426:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:33:43,428:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:33:43,447:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:33:43,448:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:33:43,458:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:33:43,458:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:33:43,459:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:33:43,470:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:33:43,475:INFO:Calculating mean and std
2023-11-04 19:33:43,476:INFO:Creating metrics dataframe
2023-11-04 19:33:43,478:INFO:Uploading results into container
2023-11-04 19:33:43,478:INFO:Uploading model into container now
2023-11-04 19:33:43,479:INFO:_master_model_container: 10
2023-11-04 19:33:43,479:INFO:_display_container: 2
2023-11-04 19:33:43,479:INFO:HuberRegressor()
2023-11-04 19:33:43,479:INFO:create_model() successfully completed......................................
2023-11-04 19:33:43,596:INFO:SubProcess create_model() end ==================================
2023-11-04 19:33:43,596:INFO:Creating metrics dataframe
2023-11-04 19:33:43,603:INFO:Initializing K Neighbors Regressor
2023-11-04 19:33:43,603:INFO:Total runtime is 0.03410706917444865 minutes
2023-11-04 19:33:43,604:INFO:SubProcess create_model() called ==================================
2023-11-04 19:33:43,605:INFO:Initializing create_model()
2023-11-04 19:33:43,605:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4370d8b80>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4245978b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:33:43,605:INFO:Checking exceptions
2023-11-04 19:33:43,605:INFO:Importing libraries
2023-11-04 19:33:43,605:INFO:Copying training dataset
2023-11-04 19:33:43,607:INFO:Defining folds
2023-11-04 19:33:43,607:INFO:Declaring metric variables
2023-11-04 19:33:43,609:INFO:Importing untrained model
2023-11-04 19:33:43,611:INFO:K Neighbors Regressor Imported successfully
2023-11-04 19:33:43,614:INFO:Starting cross validation
2023-11-04 19:33:43,615:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:33:43,684:INFO:Calculating mean and std
2023-11-04 19:33:43,685:INFO:Creating metrics dataframe
2023-11-04 19:33:43,686:INFO:Uploading results into container
2023-11-04 19:33:43,687:INFO:Uploading model into container now
2023-11-04 19:33:43,687:INFO:_master_model_container: 11
2023-11-04 19:33:43,687:INFO:_display_container: 2
2023-11-04 19:33:43,687:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-04 19:33:43,687:INFO:create_model() successfully completed......................................
2023-11-04 19:33:43,803:INFO:SubProcess create_model() end ==================================
2023-11-04 19:33:43,803:INFO:Creating metrics dataframe
2023-11-04 19:33:43,810:INFO:Initializing Decision Tree Regressor
2023-11-04 19:33:43,810:INFO:Total runtime is 0.03755831321080526 minutes
2023-11-04 19:33:43,811:INFO:SubProcess create_model() called ==================================
2023-11-04 19:33:43,812:INFO:Initializing create_model()
2023-11-04 19:33:43,812:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4370d8b80>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4245978b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:33:43,812:INFO:Checking exceptions
2023-11-04 19:33:43,812:INFO:Importing libraries
2023-11-04 19:33:43,812:INFO:Copying training dataset
2023-11-04 19:33:43,814:INFO:Defining folds
2023-11-04 19:33:43,814:INFO:Declaring metric variables
2023-11-04 19:33:43,816:INFO:Importing untrained model
2023-11-04 19:33:43,818:INFO:Decision Tree Regressor Imported successfully
2023-11-04 19:33:43,821:INFO:Starting cross validation
2023-11-04 19:33:43,821:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:33:43,909:INFO:Calculating mean and std
2023-11-04 19:33:43,909:INFO:Creating metrics dataframe
2023-11-04 19:33:43,911:INFO:Uploading results into container
2023-11-04 19:33:43,911:INFO:Uploading model into container now
2023-11-04 19:33:43,912:INFO:_master_model_container: 12
2023-11-04 19:33:43,912:INFO:_display_container: 2
2023-11-04 19:33:43,912:INFO:DecisionTreeRegressor(random_state=6792)
2023-11-04 19:33:43,912:INFO:create_model() successfully completed......................................
2023-11-04 19:33:44,027:INFO:SubProcess create_model() end ==================================
2023-11-04 19:33:44,027:INFO:Creating metrics dataframe
2023-11-04 19:33:44,034:INFO:Initializing Random Forest Regressor
2023-11-04 19:33:44,034:INFO:Total runtime is 0.041296132405598956 minutes
2023-11-04 19:33:44,036:INFO:SubProcess create_model() called ==================================
2023-11-04 19:33:44,036:INFO:Initializing create_model()
2023-11-04 19:33:44,036:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4370d8b80>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4245978b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:33:44,036:INFO:Checking exceptions
2023-11-04 19:33:44,036:INFO:Importing libraries
2023-11-04 19:33:44,036:INFO:Copying training dataset
2023-11-04 19:33:44,039:INFO:Defining folds
2023-11-04 19:33:44,039:INFO:Declaring metric variables
2023-11-04 19:33:44,040:INFO:Importing untrained model
2023-11-04 19:33:44,042:INFO:Random Forest Regressor Imported successfully
2023-11-04 19:33:44,045:INFO:Starting cross validation
2023-11-04 19:33:44,046:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:33:45,183:INFO:Calculating mean and std
2023-11-04 19:33:45,184:INFO:Creating metrics dataframe
2023-11-04 19:33:45,186:INFO:Uploading results into container
2023-11-04 19:33:45,186:INFO:Uploading model into container now
2023-11-04 19:33:45,186:INFO:_master_model_container: 13
2023-11-04 19:33:45,186:INFO:_display_container: 2
2023-11-04 19:33:45,187:INFO:RandomForestRegressor(n_jobs=-1, random_state=6792)
2023-11-04 19:33:45,187:INFO:create_model() successfully completed......................................
2023-11-04 19:33:45,301:INFO:SubProcess create_model() end ==================================
2023-11-04 19:33:45,301:INFO:Creating metrics dataframe
2023-11-04 19:33:45,308:INFO:Initializing Extra Trees Regressor
2023-11-04 19:33:45,308:INFO:Total runtime is 0.06252421538035074 minutes
2023-11-04 19:33:45,309:INFO:SubProcess create_model() called ==================================
2023-11-04 19:33:45,310:INFO:Initializing create_model()
2023-11-04 19:33:45,310:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4370d8b80>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4245978b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:33:45,310:INFO:Checking exceptions
2023-11-04 19:33:45,310:INFO:Importing libraries
2023-11-04 19:33:45,310:INFO:Copying training dataset
2023-11-04 19:33:45,312:INFO:Defining folds
2023-11-04 19:33:45,312:INFO:Declaring metric variables
2023-11-04 19:33:45,314:INFO:Importing untrained model
2023-11-04 19:33:45,316:INFO:Extra Trees Regressor Imported successfully
2023-11-04 19:33:45,319:INFO:Starting cross validation
2023-11-04 19:33:45,319:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:33:45,841:INFO:Calculating mean and std
2023-11-04 19:33:45,842:INFO:Creating metrics dataframe
2023-11-04 19:33:45,844:INFO:Uploading results into container
2023-11-04 19:33:45,844:INFO:Uploading model into container now
2023-11-04 19:33:45,845:INFO:_master_model_container: 14
2023-11-04 19:33:45,845:INFO:_display_container: 2
2023-11-04 19:33:45,845:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=6792)
2023-11-04 19:33:45,845:INFO:create_model() successfully completed......................................
2023-11-04 19:33:45,960:INFO:SubProcess create_model() end ==================================
2023-11-04 19:33:45,960:INFO:Creating metrics dataframe
2023-11-04 19:33:45,967:INFO:Initializing AdaBoost Regressor
2023-11-04 19:33:45,967:INFO:Total runtime is 0.07351086537043253 minutes
2023-11-04 19:33:45,969:INFO:SubProcess create_model() called ==================================
2023-11-04 19:33:45,969:INFO:Initializing create_model()
2023-11-04 19:33:45,969:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4370d8b80>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4245978b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:33:45,969:INFO:Checking exceptions
2023-11-04 19:33:45,969:INFO:Importing libraries
2023-11-04 19:33:45,969:INFO:Copying training dataset
2023-11-04 19:33:45,971:INFO:Defining folds
2023-11-04 19:33:45,971:INFO:Declaring metric variables
2023-11-04 19:33:45,973:INFO:Importing untrained model
2023-11-04 19:33:45,975:INFO:AdaBoost Regressor Imported successfully
2023-11-04 19:33:45,978:INFO:Starting cross validation
2023-11-04 19:33:45,978:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:33:46,258:INFO:Calculating mean and std
2023-11-04 19:33:46,259:INFO:Creating metrics dataframe
2023-11-04 19:33:46,261:INFO:Uploading results into container
2023-11-04 19:33:46,261:INFO:Uploading model into container now
2023-11-04 19:33:46,262:INFO:_master_model_container: 15
2023-11-04 19:33:46,262:INFO:_display_container: 2
2023-11-04 19:33:46,262:INFO:AdaBoostRegressor(random_state=6792)
2023-11-04 19:33:46,262:INFO:create_model() successfully completed......................................
2023-11-04 19:33:46,379:INFO:SubProcess create_model() end ==================================
2023-11-04 19:33:46,380:INFO:Creating metrics dataframe
2023-11-04 19:33:46,387:INFO:Initializing Gradient Boosting Regressor
2023-11-04 19:33:46,387:INFO:Total runtime is 0.08050994873046874 minutes
2023-11-04 19:33:46,389:INFO:SubProcess create_model() called ==================================
2023-11-04 19:33:46,389:INFO:Initializing create_model()
2023-11-04 19:33:46,389:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4370d8b80>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4245978b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:33:46,389:INFO:Checking exceptions
2023-11-04 19:33:46,389:INFO:Importing libraries
2023-11-04 19:33:46,389:INFO:Copying training dataset
2023-11-04 19:33:46,391:INFO:Defining folds
2023-11-04 19:33:46,392:INFO:Declaring metric variables
2023-11-04 19:33:46,393:INFO:Importing untrained model
2023-11-04 19:33:46,395:INFO:Gradient Boosting Regressor Imported successfully
2023-11-04 19:33:46,398:INFO:Starting cross validation
2023-11-04 19:33:46,399:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:33:47,064:INFO:Calculating mean and std
2023-11-04 19:33:47,065:INFO:Creating metrics dataframe
2023-11-04 19:33:47,067:INFO:Uploading results into container
2023-11-04 19:33:47,068:INFO:Uploading model into container now
2023-11-04 19:33:47,068:INFO:_master_model_container: 16
2023-11-04 19:33:47,068:INFO:_display_container: 2
2023-11-04 19:33:47,068:INFO:GradientBoostingRegressor(random_state=6792)
2023-11-04 19:33:47,068:INFO:create_model() successfully completed......................................
2023-11-04 19:33:47,190:INFO:SubProcess create_model() end ==================================
2023-11-04 19:33:47,190:INFO:Creating metrics dataframe
2023-11-04 19:33:47,197:INFO:Initializing Extreme Gradient Boosting
2023-11-04 19:33:47,197:INFO:Total runtime is 0.094019083182017 minutes
2023-11-04 19:33:47,199:INFO:SubProcess create_model() called ==================================
2023-11-04 19:33:47,199:INFO:Initializing create_model()
2023-11-04 19:33:47,199:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4370d8b80>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4245978b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:33:47,200:INFO:Checking exceptions
2023-11-04 19:33:47,200:INFO:Importing libraries
2023-11-04 19:33:47,200:INFO:Copying training dataset
2023-11-04 19:33:47,202:INFO:Defining folds
2023-11-04 19:33:47,202:INFO:Declaring metric variables
2023-11-04 19:33:47,204:INFO:Importing untrained model
2023-11-04 19:33:47,206:INFO:Extreme Gradient Boosting Imported successfully
2023-11-04 19:33:47,209:INFO:Starting cross validation
2023-11-04 19:33:47,209:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:33:47,734:INFO:Calculating mean and std
2023-11-04 19:33:47,735:INFO:Creating metrics dataframe
2023-11-04 19:33:47,737:INFO:Uploading results into container
2023-11-04 19:33:47,738:INFO:Uploading model into container now
2023-11-04 19:33:47,738:INFO:_master_model_container: 17
2023-11-04 19:33:47,738:INFO:_display_container: 2
2023-11-04 19:33:47,739:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=6792, ...)
2023-11-04 19:33:47,739:INFO:create_model() successfully completed......................................
2023-11-04 19:33:47,858:INFO:SubProcess create_model() end ==================================
2023-11-04 19:33:47,858:INFO:Creating metrics dataframe
2023-11-04 19:33:47,865:INFO:Initializing Light Gradient Boosting Machine
2023-11-04 19:33:47,865:INFO:Total runtime is 0.10514883597691853 minutes
2023-11-04 19:33:47,867:INFO:SubProcess create_model() called ==================================
2023-11-04 19:33:47,867:INFO:Initializing create_model()
2023-11-04 19:33:47,867:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4370d8b80>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4245978b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:33:47,867:INFO:Checking exceptions
2023-11-04 19:33:47,867:INFO:Importing libraries
2023-11-04 19:33:47,867:INFO:Copying training dataset
2023-11-04 19:33:47,870:INFO:Defining folds
2023-11-04 19:33:47,870:INFO:Declaring metric variables
2023-11-04 19:33:47,871:INFO:Importing untrained model
2023-11-04 19:33:47,873:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-04 19:33:47,876:INFO:Starting cross validation
2023-11-04 19:33:47,877:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:33:48,129:INFO:Calculating mean and std
2023-11-04 19:33:48,130:INFO:Creating metrics dataframe
2023-11-04 19:33:48,132:INFO:Uploading results into container
2023-11-04 19:33:48,133:INFO:Uploading model into container now
2023-11-04 19:33:48,133:INFO:_master_model_container: 18
2023-11-04 19:33:48,133:INFO:_display_container: 2
2023-11-04 19:33:48,133:INFO:LGBMRegressor(random_state=6792)
2023-11-04 19:33:48,133:INFO:create_model() successfully completed......................................
2023-11-04 19:33:48,249:INFO:SubProcess create_model() end ==================================
2023-11-04 19:33:48,250:INFO:Creating metrics dataframe
2023-11-04 19:33:48,257:INFO:Initializing CatBoost Regressor
2023-11-04 19:33:48,257:INFO:Total runtime is 0.111676816145579 minutes
2023-11-04 19:33:48,259:INFO:SubProcess create_model() called ==================================
2023-11-04 19:33:48,259:INFO:Initializing create_model()
2023-11-04 19:33:48,259:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4370d8b80>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4245978b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:33:48,259:INFO:Checking exceptions
2023-11-04 19:33:48,259:INFO:Importing libraries
2023-11-04 19:33:48,259:INFO:Copying training dataset
2023-11-04 19:33:48,261:INFO:Defining folds
2023-11-04 19:33:48,262:INFO:Declaring metric variables
2023-11-04 19:33:48,263:INFO:Importing untrained model
2023-11-04 19:33:48,265:INFO:CatBoost Regressor Imported successfully
2023-11-04 19:33:48,268:INFO:Starting cross validation
2023-11-04 19:33:48,269:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:33:56,188:INFO:Calculating mean and std
2023-11-04 19:33:56,190:INFO:Creating metrics dataframe
2023-11-04 19:33:56,192:INFO:Uploading results into container
2023-11-04 19:33:56,192:INFO:Uploading model into container now
2023-11-04 19:33:56,192:INFO:_master_model_container: 19
2023-11-04 19:33:56,192:INFO:_display_container: 2
2023-11-04 19:33:56,193:INFO:<catboost.core.CatBoostRegressor object at 0x7fb410de0eb0>
2023-11-04 19:33:56,193:INFO:create_model() successfully completed......................................
2023-11-04 19:33:56,321:INFO:SubProcess create_model() end ==================================
2023-11-04 19:33:56,321:INFO:Creating metrics dataframe
2023-11-04 19:33:56,329:INFO:Initializing Dummy Regressor
2023-11-04 19:33:56,329:INFO:Total runtime is 0.24621271689732868 minutes
2023-11-04 19:33:56,331:INFO:SubProcess create_model() called ==================================
2023-11-04 19:33:56,331:INFO:Initializing create_model()
2023-11-04 19:33:56,331:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4370d8b80>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb4245978b0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:33:56,331:INFO:Checking exceptions
2023-11-04 19:33:56,331:INFO:Importing libraries
2023-11-04 19:33:56,331:INFO:Copying training dataset
2023-11-04 19:33:56,333:INFO:Defining folds
2023-11-04 19:33:56,334:INFO:Declaring metric variables
2023-11-04 19:33:56,335:INFO:Importing untrained model
2023-11-04 19:33:56,337:INFO:Dummy Regressor Imported successfully
2023-11-04 19:33:56,340:INFO:Starting cross validation
2023-11-04 19:33:56,341:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:33:56,404:INFO:Calculating mean and std
2023-11-04 19:33:56,404:INFO:Creating metrics dataframe
2023-11-04 19:33:56,406:INFO:Uploading results into container
2023-11-04 19:33:56,406:INFO:Uploading model into container now
2023-11-04 19:33:56,406:INFO:_master_model_container: 20
2023-11-04 19:33:56,406:INFO:_display_container: 2
2023-11-04 19:33:56,406:INFO:DummyRegressor()
2023-11-04 19:33:56,406:INFO:create_model() successfully completed......................................
2023-11-04 19:33:56,523:INFO:SubProcess create_model() end ==================================
2023-11-04 19:33:56,523:INFO:Creating metrics dataframe
2023-11-04 19:33:56,536:INFO:Initializing create_model()
2023-11-04 19:33:56,536:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4370d8b80>, estimator=<catboost.core.CatBoostRegressor object at 0x7fb410de0eb0>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:33:56,536:INFO:Checking exceptions
2023-11-04 19:33:56,537:INFO:Importing libraries
2023-11-04 19:33:56,537:INFO:Copying training dataset
2023-11-04 19:33:56,539:INFO:Defining folds
2023-11-04 19:33:56,539:INFO:Declaring metric variables
2023-11-04 19:33:56,539:INFO:Importing untrained model
2023-11-04 19:33:56,539:INFO:Declaring custom model
2023-11-04 19:33:56,539:INFO:CatBoost Regressor Imported successfully
2023-11-04 19:33:56,540:INFO:Cross validation set to False
2023-11-04 19:33:56,540:INFO:Fitting Model
2023-11-04 19:33:57,733:INFO:<catboost.core.CatBoostRegressor object at 0x7fb410e65880>
2023-11-04 19:33:57,733:INFO:create_model() successfully completed......................................
2023-11-04 19:33:57,861:INFO:_master_model_container: 20
2023-11-04 19:33:57,861:INFO:_display_container: 2
2023-11-04 19:33:57,861:INFO:<catboost.core.CatBoostRegressor object at 0x7fb410e65880>
2023-11-04 19:33:57,861:INFO:compare_models() successfully completed......................................
2023-11-04 19:36:29,571:INFO:PyCaret RegressionExperiment
2023-11-04 19:36:29,572:INFO:Logging name: reg-default-name
2023-11-04 19:36:29,572:INFO:ML Usecase: MLUsecase.REGRESSION
2023-11-04 19:36:29,572:INFO:version 3.1.0
2023-11-04 19:36:29,572:INFO:Initializing setup()
2023-11-04 19:36:29,572:INFO:self.USI: c8c9
2023-11-04 19:36:29,572:INFO:self._variable_keys: {'USI', 'log_plots_param', 'gpu_param', 'fold_generator', 'X_test', 'html_param', '_ml_usecase', '_available_plots', 'exp_id', 'target_param', 'idx', 'fold_shuffle_param', 'n_jobs_param', 'seed', 'exp_name_log', 'X', 'y_train', 'transform_target_param', 'data', 'y_test', 'fold_groups_param', 'logging_param', 'gpu_n_jobs_param', 'y', 'X_train', 'memory', 'pipeline'}
2023-11-04 19:36:29,572:INFO:Checking environment
2023-11-04 19:36:29,572:INFO:python_version: 3.9.13
2023-11-04 19:36:29,572:INFO:python_build: ('main', 'Aug 25 2022 18:29:29')
2023-11-04 19:36:29,572:INFO:machine: x86_64
2023-11-04 19:36:29,572:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-11-04 19:36:29,572:INFO:Memory: svmem(total=17179869184, available=1056063488, percent=93.9, used=1518886912, free=25772032, active=1038270464, inactive=1028710400, wired=480616448)
2023-11-04 19:36:29,572:INFO:Physical Core: 8
2023-11-04 19:36:29,572:INFO:Logical Core: 8
2023-11-04 19:36:29,572:INFO:Checking libraries
2023-11-04 19:36:29,572:INFO:System:
2023-11-04 19:36:29,572:INFO:    python: 3.9.13 (main, Aug 25 2022, 18:29:29)  [Clang 12.0.0 ]
2023-11-04 19:36:29,572:INFO:executable: /Users/michal/opt/anaconda3/bin/python
2023-11-04 19:36:29,572:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-11-04 19:36:29,572:INFO:PyCaret required dependencies:
2023-11-04 19:36:29,572:INFO:                 pip: 22.2.2
2023-11-04 19:36:29,572:INFO:          setuptools: 63.4.1
2023-11-04 19:36:29,572:INFO:             pycaret: 3.1.0
2023-11-04 19:36:29,572:INFO:             IPython: 7.31.1
2023-11-04 19:36:29,572:INFO:          ipywidgets: 7.6.5
2023-11-04 19:36:29,572:INFO:                tqdm: 4.64.1
2023-11-04 19:36:29,572:INFO:               numpy: 1.21.5
2023-11-04 19:36:29,572:INFO:              pandas: 1.4.4
2023-11-04 19:36:29,573:INFO:              jinja2: 2.11.3
2023-11-04 19:36:29,573:INFO:               scipy: 1.10.1
2023-11-04 19:36:29,573:INFO:              joblib: 1.2.0
2023-11-04 19:36:29,573:INFO:             sklearn: 1.0.2
2023-11-04 19:36:29,573:INFO:                pyod: 1.1.1
2023-11-04 19:36:29,573:INFO:            imblearn: 0.10.1
2023-11-04 19:36:29,573:INFO:   category_encoders: 2.6.3
2023-11-04 19:36:29,573:INFO:            lightgbm: 3.3.5
2023-11-04 19:36:29,573:INFO:               numba: 0.55.1
2023-11-04 19:36:29,573:INFO:            requests: 2.28.1
2023-11-04 19:36:29,573:INFO:          matplotlib: 3.5.2
2023-11-04 19:36:29,573:INFO:          scikitplot: 0.3.7
2023-11-04 19:36:29,573:INFO:         yellowbrick: 1.5
2023-11-04 19:36:29,573:INFO:              plotly: 5.9.0
2023-11-04 19:36:29,573:INFO:    plotly-resampler: Not installed
2023-11-04 19:36:29,573:INFO:             kaleido: 0.2.1
2023-11-04 19:36:29,573:INFO:           schemdraw: 0.15
2023-11-04 19:36:29,573:INFO:         statsmodels: 0.13.2
2023-11-04 19:36:29,573:INFO:              sktime: 0.21.1
2023-11-04 19:36:29,573:INFO:               tbats: 1.1.3
2023-11-04 19:36:29,573:INFO:            pmdarima: 2.0.4
2023-11-04 19:36:29,573:INFO:              psutil: 5.9.0
2023-11-04 19:36:29,573:INFO:          markupsafe: 2.0.1
2023-11-04 19:36:29,573:INFO:             pickle5: Not installed
2023-11-04 19:36:29,573:INFO:         cloudpickle: 2.0.0
2023-11-04 19:36:29,573:INFO:         deprecation: 2.1.0
2023-11-04 19:36:29,573:INFO:              xxhash: 3.4.1
2023-11-04 19:36:29,573:INFO:           wurlitzer: 3.0.2
2023-11-04 19:36:29,573:INFO:PyCaret optional dependencies:
2023-11-04 19:36:29,573:INFO:                shap: 0.41.0
2023-11-04 19:36:29,573:INFO:           interpret: Not installed
2023-11-04 19:36:29,573:INFO:                umap: 0.5.3
2023-11-04 19:36:29,573:INFO:     ydata_profiling: Not installed
2023-11-04 19:36:29,573:INFO:  explainerdashboard: Not installed
2023-11-04 19:36:29,573:INFO:             autoviz: Not installed
2023-11-04 19:36:29,573:INFO:           fairlearn: Not installed
2023-11-04 19:36:29,573:INFO:          deepchecks: Not installed
2023-11-04 19:36:29,573:INFO:             xgboost: 1.7.4
2023-11-04 19:36:29,573:INFO:            catboost: 1.2
2023-11-04 19:36:29,573:INFO:              kmodes: Not installed
2023-11-04 19:36:29,573:INFO:             mlxtend: 0.21.0
2023-11-04 19:36:29,573:INFO:       statsforecast: Not installed
2023-11-04 19:36:29,573:INFO:        tune_sklearn: Not installed
2023-11-04 19:36:29,573:INFO:                 ray: Not installed
2023-11-04 19:36:29,573:INFO:            hyperopt: Not installed
2023-11-04 19:36:29,573:INFO:              optuna: Not installed
2023-11-04 19:36:29,573:INFO:               skopt: Not installed
2023-11-04 19:36:29,573:INFO:              mlflow: Not installed
2023-11-04 19:36:29,573:INFO:              gradio: Not installed
2023-11-04 19:36:29,573:INFO:             fastapi: Not installed
2023-11-04 19:36:29,573:INFO:             uvicorn: Not installed
2023-11-04 19:36:29,573:INFO:              m2cgen: Not installed
2023-11-04 19:36:29,573:INFO:           evidently: Not installed
2023-11-04 19:36:29,573:INFO:               fugue: Not installed
2023-11-04 19:36:29,573:INFO:           streamlit: Not installed
2023-11-04 19:36:29,573:INFO:             prophet: Not installed
2023-11-04 19:36:29,573:INFO:None
2023-11-04 19:36:29,573:INFO:Set up data.
2023-11-04 19:36:29,577:INFO:Set up folding strategy.
2023-11-04 19:36:29,577:INFO:Set up train/test split.
2023-11-04 19:36:29,579:INFO:Set up index.
2023-11-04 19:36:29,579:INFO:Assigning column types.
2023-11-04 19:36:29,580:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-04 19:36:29,580:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-04 19:36:29,583:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 19:36:29,586:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:36:29,621:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:36:29,648:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:36:29,648:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:36:29,650:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:36:29,651:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-04 19:36:29,654:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 19:36:29,656:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:36:29,690:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:36:29,717:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:36:29,717:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:36:29,718:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:36:29,719:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-11-04 19:36:29,721:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 19:36:29,724:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:36:29,758:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:36:29,785:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:36:29,785:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:36:29,787:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:36:29,790:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 19:36:29,792:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:36:29,826:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:36:29,854:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:36:29,854:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:36:29,855:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:36:29,856:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-11-04 19:36:29,861:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:36:29,895:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:36:29,921:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:36:29,921:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:36:29,923:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:36:29,928:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:36:29,962:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:36:29,989:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:36:29,989:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:36:29,991:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:36:29,991:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-11-04 19:36:30,029:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:36:30,056:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:36:30,057:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:36:30,058:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:36:30,097:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:36:30,124:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:36:30,124:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:36:30,126:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:36:30,126:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-04 19:36:30,165:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:36:30,192:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:36:30,194:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:36:30,232:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:36:30,259:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:36:30,260:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:36:30,261:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-11-04 19:36:30,326:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:36:30,328:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:36:30,393:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:36:30,395:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:36:30,395:INFO:Preparing preprocessing pipeline...
2023-11-04 19:36:30,395:INFO:Set up simple imputation.
2023-11-04 19:36:30,395:INFO:Set up variance threshold.
2023-11-04 19:36:30,395:INFO:Set up removing multicollinearity.
2023-11-04 19:36:30,396:INFO:Set up column name cleaning.
2023-11-04 19:36:30,416:INFO:Finished creating preprocessing pipeline.
2023-11-04 19:36:30,420:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/h9/5_75v3qs13x63s15wwxdrd000000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['solv_dG [kcal/mol]',
                                             'Bond dissociation entalphy',
                                             'water_ads [kcal/mol]', 'Coating',
                                             'Organic Matter Conc.', 'pH',
                                             'Primary Size', 'Initial Conc.',
                                             'Temp.', 'Ionic Strenght', 'Light',
                                             'MW', 'Noxy', 'χ', 'χox',
                                             'Z_metal', 'Zv...
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.1))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-11-04 19:36:30,420:INFO:Creating final display dataframe.
2023-11-04 19:36:30,468:INFO:Setup _display_container:                     Description             Value
0                    Session id              8917
1                        Target  %dissolved solid
2                   Target type        Regression
3           Original data shape         (115, 21)
4        Transformed data shape         (115, 17)
5   Transformed train set shape          (80, 17)
6    Transformed test set shape          (35, 17)
7              Numeric features                20
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12       Low variance threshold               0.1
13     Remove multicollinearity              True
14  Multicollinearity threshold              0.95
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              c8c9
2023-11-04 19:36:30,543:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:36:30,545:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:36:30,611:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:36:30,612:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:36:30,613:INFO:setup() successfully completed in 1.04s...............
2023-11-04 19:36:30,613:INFO:Initializing compare_models()
2023-11-04 19:36:30,613:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb410bc8490>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fb410bc8490>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-11-04 19:36:30,613:INFO:Checking exceptions
2023-11-04 19:36:30,614:INFO:Preparing display monitor
2023-11-04 19:36:30,631:INFO:Initializing Linear Regression
2023-11-04 19:36:30,631:INFO:Total runtime is 3.03188959757487e-06 minutes
2023-11-04 19:36:30,632:INFO:SubProcess create_model() called ==================================
2023-11-04 19:36:30,633:INFO:Initializing create_model()
2023-11-04 19:36:30,633:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb410bc8490>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb425095b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:36:30,633:INFO:Checking exceptions
2023-11-04 19:36:30,633:INFO:Importing libraries
2023-11-04 19:36:30,633:INFO:Copying training dataset
2023-11-04 19:36:30,635:INFO:Defining folds
2023-11-04 19:36:30,635:INFO:Declaring metric variables
2023-11-04 19:36:30,637:INFO:Importing untrained model
2023-11-04 19:36:30,638:INFO:Linear Regression Imported successfully
2023-11-04 19:36:30,642:INFO:Starting cross validation
2023-11-04 19:36:30,642:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:36:30,763:INFO:Calculating mean and std
2023-11-04 19:36:30,763:INFO:Creating metrics dataframe
2023-11-04 19:36:30,765:INFO:Uploading results into container
2023-11-04 19:36:30,765:INFO:Uploading model into container now
2023-11-04 19:36:30,765:INFO:_master_model_container: 1
2023-11-04 19:36:30,765:INFO:_display_container: 2
2023-11-04 19:36:30,765:INFO:LinearRegression(n_jobs=-1)
2023-11-04 19:36:30,765:INFO:create_model() successfully completed......................................
2023-11-04 19:36:30,938:INFO:SubProcess create_model() end ==================================
2023-11-04 19:36:30,939:INFO:Creating metrics dataframe
2023-11-04 19:36:30,943:INFO:Initializing Lasso Regression
2023-11-04 19:36:30,943:INFO:Total runtime is 0.005204033851623535 minutes
2023-11-04 19:36:30,945:INFO:SubProcess create_model() called ==================================
2023-11-04 19:36:30,945:INFO:Initializing create_model()
2023-11-04 19:36:30,945:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb410bc8490>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb425095b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:36:30,945:INFO:Checking exceptions
2023-11-04 19:36:30,945:INFO:Importing libraries
2023-11-04 19:36:30,945:INFO:Copying training dataset
2023-11-04 19:36:30,947:INFO:Defining folds
2023-11-04 19:36:30,947:INFO:Declaring metric variables
2023-11-04 19:36:30,948:INFO:Importing untrained model
2023-11-04 19:36:30,950:INFO:Lasso Regression Imported successfully
2023-11-04 19:36:30,953:INFO:Starting cross validation
2023-11-04 19:36:30,954:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:36:31,022:INFO:Calculating mean and std
2023-11-04 19:36:31,022:INFO:Creating metrics dataframe
2023-11-04 19:36:31,023:INFO:Uploading results into container
2023-11-04 19:36:31,024:INFO:Uploading model into container now
2023-11-04 19:36:31,024:INFO:_master_model_container: 2
2023-11-04 19:36:31,024:INFO:_display_container: 2
2023-11-04 19:36:31,024:INFO:Lasso(random_state=8917)
2023-11-04 19:36:31,024:INFO:create_model() successfully completed......................................
2023-11-04 19:36:31,139:INFO:SubProcess create_model() end ==================================
2023-11-04 19:36:31,139:INFO:Creating metrics dataframe
2023-11-04 19:36:31,144:INFO:Initializing Ridge Regression
2023-11-04 19:36:31,144:INFO:Total runtime is 0.008550500869750977 minutes
2023-11-04 19:36:31,146:INFO:SubProcess create_model() called ==================================
2023-11-04 19:36:31,146:INFO:Initializing create_model()
2023-11-04 19:36:31,146:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb410bc8490>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb425095b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:36:31,146:INFO:Checking exceptions
2023-11-04 19:36:31,146:INFO:Importing libraries
2023-11-04 19:36:31,146:INFO:Copying training dataset
2023-11-04 19:36:31,148:INFO:Defining folds
2023-11-04 19:36:31,148:INFO:Declaring metric variables
2023-11-04 19:36:31,149:INFO:Importing untrained model
2023-11-04 19:36:31,151:INFO:Ridge Regression Imported successfully
2023-11-04 19:36:31,154:INFO:Starting cross validation
2023-11-04 19:36:31,155:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:36:31,212:INFO:Calculating mean and std
2023-11-04 19:36:31,213:INFO:Creating metrics dataframe
2023-11-04 19:36:31,214:INFO:Uploading results into container
2023-11-04 19:36:31,214:INFO:Uploading model into container now
2023-11-04 19:36:31,215:INFO:_master_model_container: 3
2023-11-04 19:36:31,215:INFO:_display_container: 2
2023-11-04 19:36:31,215:INFO:Ridge(random_state=8917)
2023-11-04 19:36:31,215:INFO:create_model() successfully completed......................................
2023-11-04 19:36:31,331:INFO:SubProcess create_model() end ==================================
2023-11-04 19:36:31,332:INFO:Creating metrics dataframe
2023-11-04 19:36:31,337:INFO:Initializing Elastic Net
2023-11-04 19:36:31,337:INFO:Total runtime is 0.011767915884653727 minutes
2023-11-04 19:36:31,339:INFO:SubProcess create_model() called ==================================
2023-11-04 19:36:31,339:INFO:Initializing create_model()
2023-11-04 19:36:31,339:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb410bc8490>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb425095b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:36:31,339:INFO:Checking exceptions
2023-11-04 19:36:31,339:INFO:Importing libraries
2023-11-04 19:36:31,339:INFO:Copying training dataset
2023-11-04 19:36:31,341:INFO:Defining folds
2023-11-04 19:36:31,341:INFO:Declaring metric variables
2023-11-04 19:36:31,342:INFO:Importing untrained model
2023-11-04 19:36:31,344:INFO:Elastic Net Imported successfully
2023-11-04 19:36:31,347:INFO:Starting cross validation
2023-11-04 19:36:31,348:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:36:31,407:INFO:Calculating mean and std
2023-11-04 19:36:31,407:INFO:Creating metrics dataframe
2023-11-04 19:36:31,409:INFO:Uploading results into container
2023-11-04 19:36:31,409:INFO:Uploading model into container now
2023-11-04 19:36:31,410:INFO:_master_model_container: 4
2023-11-04 19:36:31,410:INFO:_display_container: 2
2023-11-04 19:36:31,410:INFO:ElasticNet(random_state=8917)
2023-11-04 19:36:31,410:INFO:create_model() successfully completed......................................
2023-11-04 19:36:31,525:INFO:SubProcess create_model() end ==================================
2023-11-04 19:36:31,525:INFO:Creating metrics dataframe
2023-11-04 19:36:31,530:INFO:Initializing Least Angle Regression
2023-11-04 19:36:31,531:INFO:Total runtime is 0.014995984236399333 minutes
2023-11-04 19:36:31,532:INFO:SubProcess create_model() called ==================================
2023-11-04 19:36:31,532:INFO:Initializing create_model()
2023-11-04 19:36:31,532:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb410bc8490>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb425095b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:36:31,532:INFO:Checking exceptions
2023-11-04 19:36:31,533:INFO:Importing libraries
2023-11-04 19:36:31,533:INFO:Copying training dataset
2023-11-04 19:36:31,534:INFO:Defining folds
2023-11-04 19:36:31,534:INFO:Declaring metric variables
2023-11-04 19:36:31,536:INFO:Importing untrained model
2023-11-04 19:36:31,537:INFO:Least Angle Regression Imported successfully
2023-11-04 19:36:31,540:INFO:Starting cross validation
2023-11-04 19:36:31,541:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:36:31,561:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:36:31,565:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:36:31,568:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:36:31,579:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:36:31,583:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:36:31,584:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:36:31,586:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:36:31,588:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:36:31,594:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:36:31,598:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:36:31,604:INFO:Calculating mean and std
2023-11-04 19:36:31,604:INFO:Creating metrics dataframe
2023-11-04 19:36:31,606:INFO:Uploading results into container
2023-11-04 19:36:31,606:INFO:Uploading model into container now
2023-11-04 19:36:31,607:INFO:_master_model_container: 5
2023-11-04 19:36:31,607:INFO:_display_container: 2
2023-11-04 19:36:31,607:INFO:Lars(random_state=8917)
2023-11-04 19:36:31,607:INFO:create_model() successfully completed......................................
2023-11-04 19:36:31,721:INFO:SubProcess create_model() end ==================================
2023-11-04 19:36:31,722:INFO:Creating metrics dataframe
2023-11-04 19:36:31,727:INFO:Initializing Lasso Least Angle Regression
2023-11-04 19:36:31,727:INFO:Total runtime is 0.018267981211344403 minutes
2023-11-04 19:36:31,729:INFO:SubProcess create_model() called ==================================
2023-11-04 19:36:31,729:INFO:Initializing create_model()
2023-11-04 19:36:31,729:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb410bc8490>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb425095b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:36:31,729:INFO:Checking exceptions
2023-11-04 19:36:31,729:INFO:Importing libraries
2023-11-04 19:36:31,729:INFO:Copying training dataset
2023-11-04 19:36:31,731:INFO:Defining folds
2023-11-04 19:36:31,731:INFO:Declaring metric variables
2023-11-04 19:36:31,733:INFO:Importing untrained model
2023-11-04 19:36:31,735:INFO:Lasso Least Angle Regression Imported successfully
2023-11-04 19:36:31,738:INFO:Starting cross validation
2023-11-04 19:36:31,738:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:36:31,759:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:36:31,765:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:36:31,765:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:36:31,775:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:36:31,778:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:36:31,783:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:36:31,783:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:36:31,785:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:36:31,788:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:36:31,793:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:36:31,798:INFO:Calculating mean and std
2023-11-04 19:36:31,798:INFO:Creating metrics dataframe
2023-11-04 19:36:31,800:INFO:Uploading results into container
2023-11-04 19:36:31,800:INFO:Uploading model into container now
2023-11-04 19:36:31,800:INFO:_master_model_container: 6
2023-11-04 19:36:31,800:INFO:_display_container: 2
2023-11-04 19:36:31,800:INFO:LassoLars(random_state=8917)
2023-11-04 19:36:31,800:INFO:create_model() successfully completed......................................
2023-11-04 19:36:31,919:INFO:SubProcess create_model() end ==================================
2023-11-04 19:36:31,919:INFO:Creating metrics dataframe
2023-11-04 19:36:31,924:INFO:Initializing Orthogonal Matching Pursuit
2023-11-04 19:36:31,924:INFO:Total runtime is 0.021556496620178223 minutes
2023-11-04 19:36:31,926:INFO:SubProcess create_model() called ==================================
2023-11-04 19:36:31,926:INFO:Initializing create_model()
2023-11-04 19:36:31,926:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb410bc8490>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb425095b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:36:31,926:INFO:Checking exceptions
2023-11-04 19:36:31,926:INFO:Importing libraries
2023-11-04 19:36:31,926:INFO:Copying training dataset
2023-11-04 19:36:31,929:INFO:Defining folds
2023-11-04 19:36:31,929:INFO:Declaring metric variables
2023-11-04 19:36:31,931:INFO:Importing untrained model
2023-11-04 19:36:31,932:INFO:Orthogonal Matching Pursuit Imported successfully
2023-11-04 19:36:31,935:INFO:Starting cross validation
2023-11-04 19:36:31,936:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:36:31,956:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:36:31,959:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:36:31,967:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:36:31,974:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:36:31,974:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:36:31,974:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:36:31,978:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:36:31,978:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:36:31,988:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:36:31,989:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:36:31,994:INFO:Calculating mean and std
2023-11-04 19:36:31,995:INFO:Creating metrics dataframe
2023-11-04 19:36:31,996:INFO:Uploading results into container
2023-11-04 19:36:31,997:INFO:Uploading model into container now
2023-11-04 19:36:31,997:INFO:_master_model_container: 7
2023-11-04 19:36:31,997:INFO:_display_container: 2
2023-11-04 19:36:31,997:INFO:OrthogonalMatchingPursuit()
2023-11-04 19:36:31,997:INFO:create_model() successfully completed......................................
2023-11-04 19:36:32,116:INFO:SubProcess create_model() end ==================================
2023-11-04 19:36:32,116:INFO:Creating metrics dataframe
2023-11-04 19:36:32,122:INFO:Initializing Bayesian Ridge
2023-11-04 19:36:32,122:INFO:Total runtime is 0.024854131539662677 minutes
2023-11-04 19:36:32,124:INFO:SubProcess create_model() called ==================================
2023-11-04 19:36:32,124:INFO:Initializing create_model()
2023-11-04 19:36:32,124:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb410bc8490>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb425095b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:36:32,124:INFO:Checking exceptions
2023-11-04 19:36:32,124:INFO:Importing libraries
2023-11-04 19:36:32,124:INFO:Copying training dataset
2023-11-04 19:36:32,126:INFO:Defining folds
2023-11-04 19:36:32,127:INFO:Declaring metric variables
2023-11-04 19:36:32,128:INFO:Importing untrained model
2023-11-04 19:36:32,130:INFO:Bayesian Ridge Imported successfully
2023-11-04 19:36:32,133:INFO:Starting cross validation
2023-11-04 19:36:32,134:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:36:32,190:INFO:Calculating mean and std
2023-11-04 19:36:32,190:INFO:Creating metrics dataframe
2023-11-04 19:36:32,192:INFO:Uploading results into container
2023-11-04 19:36:32,192:INFO:Uploading model into container now
2023-11-04 19:36:32,192:INFO:_master_model_container: 8
2023-11-04 19:36:32,192:INFO:_display_container: 2
2023-11-04 19:36:32,192:INFO:BayesianRidge()
2023-11-04 19:36:32,192:INFO:create_model() successfully completed......................................
2023-11-04 19:36:32,307:INFO:SubProcess create_model() end ==================================
2023-11-04 19:36:32,307:INFO:Creating metrics dataframe
2023-11-04 19:36:32,313:INFO:Initializing Passive Aggressive Regressor
2023-11-04 19:36:32,313:INFO:Total runtime is 0.028040432929992674 minutes
2023-11-04 19:36:32,315:INFO:SubProcess create_model() called ==================================
2023-11-04 19:36:32,315:INFO:Initializing create_model()
2023-11-04 19:36:32,315:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb410bc8490>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb425095b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:36:32,315:INFO:Checking exceptions
2023-11-04 19:36:32,315:INFO:Importing libraries
2023-11-04 19:36:32,316:INFO:Copying training dataset
2023-11-04 19:36:32,318:INFO:Defining folds
2023-11-04 19:36:32,318:INFO:Declaring metric variables
2023-11-04 19:36:32,319:INFO:Importing untrained model
2023-11-04 19:36:32,321:INFO:Passive Aggressive Regressor Imported successfully
2023-11-04 19:36:32,324:INFO:Starting cross validation
2023-11-04 19:36:32,325:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:36:32,383:INFO:Calculating mean and std
2023-11-04 19:36:32,383:INFO:Creating metrics dataframe
2023-11-04 19:36:32,385:INFO:Uploading results into container
2023-11-04 19:36:32,385:INFO:Uploading model into container now
2023-11-04 19:36:32,385:INFO:_master_model_container: 9
2023-11-04 19:36:32,385:INFO:_display_container: 2
2023-11-04 19:36:32,386:INFO:PassiveAggressiveRegressor(random_state=8917)
2023-11-04 19:36:32,386:INFO:create_model() successfully completed......................................
2023-11-04 19:36:32,500:INFO:SubProcess create_model() end ==================================
2023-11-04 19:36:32,500:INFO:Creating metrics dataframe
2023-11-04 19:36:32,506:INFO:Initializing Huber Regressor
2023-11-04 19:36:32,506:INFO:Total runtime is 0.031249515215555825 minutes
2023-11-04 19:36:32,507:INFO:SubProcess create_model() called ==================================
2023-11-04 19:36:32,508:INFO:Initializing create_model()
2023-11-04 19:36:32,508:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb410bc8490>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb425095b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:36:32,508:INFO:Checking exceptions
2023-11-04 19:36:32,508:INFO:Importing libraries
2023-11-04 19:36:32,508:INFO:Copying training dataset
2023-11-04 19:36:32,510:INFO:Defining folds
2023-11-04 19:36:32,510:INFO:Declaring metric variables
2023-11-04 19:36:32,512:INFO:Importing untrained model
2023-11-04 19:36:32,514:INFO:Huber Regressor Imported successfully
2023-11-04 19:36:32,517:INFO:Starting cross validation
2023-11-04 19:36:32,518:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:36:32,548:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:36:32,550:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:36:32,558:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:36:32,564:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:36:32,577:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:36:32,580:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:36:32,582:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:36:32,583:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:36:32,589:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:36:32,592:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:36:32,597:INFO:Calculating mean and std
2023-11-04 19:36:32,597:INFO:Creating metrics dataframe
2023-11-04 19:36:32,599:INFO:Uploading results into container
2023-11-04 19:36:32,599:INFO:Uploading model into container now
2023-11-04 19:36:32,599:INFO:_master_model_container: 10
2023-11-04 19:36:32,599:INFO:_display_container: 2
2023-11-04 19:36:32,600:INFO:HuberRegressor()
2023-11-04 19:36:32,600:INFO:create_model() successfully completed......................................
2023-11-04 19:36:32,715:INFO:SubProcess create_model() end ==================================
2023-11-04 19:36:32,716:INFO:Creating metrics dataframe
2023-11-04 19:36:32,722:INFO:Initializing K Neighbors Regressor
2023-11-04 19:36:32,722:INFO:Total runtime is 0.03484923442204793 minutes
2023-11-04 19:36:32,723:INFO:SubProcess create_model() called ==================================
2023-11-04 19:36:32,724:INFO:Initializing create_model()
2023-11-04 19:36:32,724:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb410bc8490>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb425095b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:36:32,724:INFO:Checking exceptions
2023-11-04 19:36:32,724:INFO:Importing libraries
2023-11-04 19:36:32,724:INFO:Copying training dataset
2023-11-04 19:36:32,726:INFO:Defining folds
2023-11-04 19:36:32,726:INFO:Declaring metric variables
2023-11-04 19:36:32,728:INFO:Importing untrained model
2023-11-04 19:36:32,730:INFO:K Neighbors Regressor Imported successfully
2023-11-04 19:36:32,732:INFO:Starting cross validation
2023-11-04 19:36:32,733:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:36:32,806:INFO:Calculating mean and std
2023-11-04 19:36:32,807:INFO:Creating metrics dataframe
2023-11-04 19:36:32,808:INFO:Uploading results into container
2023-11-04 19:36:32,809:INFO:Uploading model into container now
2023-11-04 19:36:32,809:INFO:_master_model_container: 11
2023-11-04 19:36:32,809:INFO:_display_container: 2
2023-11-04 19:36:32,809:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-04 19:36:32,809:INFO:create_model() successfully completed......................................
2023-11-04 19:36:32,927:INFO:SubProcess create_model() end ==================================
2023-11-04 19:36:32,927:INFO:Creating metrics dataframe
2023-11-04 19:36:32,933:INFO:Initializing Decision Tree Regressor
2023-11-04 19:36:32,933:INFO:Total runtime is 0.03837538162867228 minutes
2023-11-04 19:36:32,935:INFO:SubProcess create_model() called ==================================
2023-11-04 19:36:32,935:INFO:Initializing create_model()
2023-11-04 19:36:32,935:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb410bc8490>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb425095b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:36:32,936:INFO:Checking exceptions
2023-11-04 19:36:32,936:INFO:Importing libraries
2023-11-04 19:36:32,936:INFO:Copying training dataset
2023-11-04 19:36:32,938:INFO:Defining folds
2023-11-04 19:36:32,938:INFO:Declaring metric variables
2023-11-04 19:36:32,940:INFO:Importing untrained model
2023-11-04 19:36:32,941:INFO:Decision Tree Regressor Imported successfully
2023-11-04 19:36:32,944:INFO:Starting cross validation
2023-11-04 19:36:32,945:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:36:33,003:INFO:Calculating mean and std
2023-11-04 19:36:33,003:INFO:Creating metrics dataframe
2023-11-04 19:36:33,005:INFO:Uploading results into container
2023-11-04 19:36:33,005:INFO:Uploading model into container now
2023-11-04 19:36:33,005:INFO:_master_model_container: 12
2023-11-04 19:36:33,005:INFO:_display_container: 2
2023-11-04 19:36:33,005:INFO:DecisionTreeRegressor(random_state=8917)
2023-11-04 19:36:33,005:INFO:create_model() successfully completed......................................
2023-11-04 19:36:33,124:INFO:SubProcess create_model() end ==================================
2023-11-04 19:36:33,124:INFO:Creating metrics dataframe
2023-11-04 19:36:33,130:INFO:Initializing Random Forest Regressor
2023-11-04 19:36:33,130:INFO:Total runtime is 0.04165508349736532 minutes
2023-11-04 19:36:33,132:INFO:SubProcess create_model() called ==================================
2023-11-04 19:36:33,132:INFO:Initializing create_model()
2023-11-04 19:36:33,132:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb410bc8490>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb425095b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:36:33,132:INFO:Checking exceptions
2023-11-04 19:36:33,132:INFO:Importing libraries
2023-11-04 19:36:33,132:INFO:Copying training dataset
2023-11-04 19:36:33,134:INFO:Defining folds
2023-11-04 19:36:33,135:INFO:Declaring metric variables
2023-11-04 19:36:33,136:INFO:Importing untrained model
2023-11-04 19:36:33,138:INFO:Random Forest Regressor Imported successfully
2023-11-04 19:36:33,141:INFO:Starting cross validation
2023-11-04 19:36:33,141:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:36:33,413:INFO:Calculating mean and std
2023-11-04 19:36:33,414:INFO:Creating metrics dataframe
2023-11-04 19:36:33,416:INFO:Uploading results into container
2023-11-04 19:36:33,416:INFO:Uploading model into container now
2023-11-04 19:36:33,416:INFO:_master_model_container: 13
2023-11-04 19:36:33,417:INFO:_display_container: 2
2023-11-04 19:36:33,417:INFO:RandomForestRegressor(n_jobs=-1, random_state=8917)
2023-11-04 19:36:33,417:INFO:create_model() successfully completed......................................
2023-11-04 19:36:33,532:INFO:SubProcess create_model() end ==================================
2023-11-04 19:36:33,532:INFO:Creating metrics dataframe
2023-11-04 19:36:33,539:INFO:Initializing Extra Trees Regressor
2023-11-04 19:36:33,539:INFO:Total runtime is 0.04847139914830526 minutes
2023-11-04 19:36:33,541:INFO:SubProcess create_model() called ==================================
2023-11-04 19:36:33,541:INFO:Initializing create_model()
2023-11-04 19:36:33,541:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb410bc8490>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb425095b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:36:33,541:INFO:Checking exceptions
2023-11-04 19:36:33,541:INFO:Importing libraries
2023-11-04 19:36:33,541:INFO:Copying training dataset
2023-11-04 19:36:33,543:INFO:Defining folds
2023-11-04 19:36:33,544:INFO:Declaring metric variables
2023-11-04 19:36:33,545:INFO:Importing untrained model
2023-11-04 19:36:33,547:INFO:Extra Trees Regressor Imported successfully
2023-11-04 19:36:33,550:INFO:Starting cross validation
2023-11-04 19:36:33,551:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:36:33,758:INFO:Calculating mean and std
2023-11-04 19:36:33,759:INFO:Creating metrics dataframe
2023-11-04 19:36:33,761:INFO:Uploading results into container
2023-11-04 19:36:33,761:INFO:Uploading model into container now
2023-11-04 19:36:33,762:INFO:_master_model_container: 14
2023-11-04 19:36:33,762:INFO:_display_container: 2
2023-11-04 19:36:33,762:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=8917)
2023-11-04 19:36:33,762:INFO:create_model() successfully completed......................................
2023-11-04 19:36:33,878:INFO:SubProcess create_model() end ==================================
2023-11-04 19:36:33,878:INFO:Creating metrics dataframe
2023-11-04 19:36:33,884:INFO:Initializing AdaBoost Regressor
2023-11-04 19:36:33,884:INFO:Total runtime is 0.054228881994883224 minutes
2023-11-04 19:36:33,886:INFO:SubProcess create_model() called ==================================
2023-11-04 19:36:33,886:INFO:Initializing create_model()
2023-11-04 19:36:33,886:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb410bc8490>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb425095b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:36:33,887:INFO:Checking exceptions
2023-11-04 19:36:33,887:INFO:Importing libraries
2023-11-04 19:36:33,887:INFO:Copying training dataset
2023-11-04 19:36:33,889:INFO:Defining folds
2023-11-04 19:36:33,889:INFO:Declaring metric variables
2023-11-04 19:36:33,891:INFO:Importing untrained model
2023-11-04 19:36:33,892:INFO:AdaBoost Regressor Imported successfully
2023-11-04 19:36:33,895:INFO:Starting cross validation
2023-11-04 19:36:33,896:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:36:34,011:INFO:Calculating mean and std
2023-11-04 19:36:34,012:INFO:Creating metrics dataframe
2023-11-04 19:36:34,014:INFO:Uploading results into container
2023-11-04 19:36:34,014:INFO:Uploading model into container now
2023-11-04 19:36:34,014:INFO:_master_model_container: 15
2023-11-04 19:36:34,015:INFO:_display_container: 2
2023-11-04 19:36:34,015:INFO:AdaBoostRegressor(random_state=8917)
2023-11-04 19:36:34,015:INFO:create_model() successfully completed......................................
2023-11-04 19:36:34,130:INFO:SubProcess create_model() end ==================================
2023-11-04 19:36:34,130:INFO:Creating metrics dataframe
2023-11-04 19:36:34,137:INFO:Initializing Gradient Boosting Regressor
2023-11-04 19:36:34,137:INFO:Total runtime is 0.05843128363291423 minutes
2023-11-04 19:36:34,138:INFO:SubProcess create_model() called ==================================
2023-11-04 19:36:34,139:INFO:Initializing create_model()
2023-11-04 19:36:34,139:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb410bc8490>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb425095b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:36:34,139:INFO:Checking exceptions
2023-11-04 19:36:34,139:INFO:Importing libraries
2023-11-04 19:36:34,139:INFO:Copying training dataset
2023-11-04 19:36:34,141:INFO:Defining folds
2023-11-04 19:36:34,141:INFO:Declaring metric variables
2023-11-04 19:36:34,143:INFO:Importing untrained model
2023-11-04 19:36:34,144:INFO:Gradient Boosting Regressor Imported successfully
2023-11-04 19:36:34,147:INFO:Starting cross validation
2023-11-04 19:36:34,148:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:36:34,230:INFO:Calculating mean and std
2023-11-04 19:36:34,230:INFO:Creating metrics dataframe
2023-11-04 19:36:34,231:INFO:Uploading results into container
2023-11-04 19:36:34,232:INFO:Uploading model into container now
2023-11-04 19:36:34,232:INFO:_master_model_container: 16
2023-11-04 19:36:34,232:INFO:_display_container: 2
2023-11-04 19:36:34,232:INFO:GradientBoostingRegressor(random_state=8917)
2023-11-04 19:36:34,232:INFO:create_model() successfully completed......................................
2023-11-04 19:36:34,346:INFO:SubProcess create_model() end ==================================
2023-11-04 19:36:34,346:INFO:Creating metrics dataframe
2023-11-04 19:36:34,353:INFO:Initializing Extreme Gradient Boosting
2023-11-04 19:36:34,353:INFO:Total runtime is 0.06204373439153036 minutes
2023-11-04 19:36:34,355:INFO:SubProcess create_model() called ==================================
2023-11-04 19:36:34,355:INFO:Initializing create_model()
2023-11-04 19:36:34,355:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb410bc8490>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb425095b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:36:34,355:INFO:Checking exceptions
2023-11-04 19:36:34,355:INFO:Importing libraries
2023-11-04 19:36:34,355:INFO:Copying training dataset
2023-11-04 19:36:34,358:INFO:Defining folds
2023-11-04 19:36:34,358:INFO:Declaring metric variables
2023-11-04 19:36:34,359:INFO:Importing untrained model
2023-11-04 19:36:34,361:INFO:Extreme Gradient Boosting Imported successfully
2023-11-04 19:36:34,364:INFO:Starting cross validation
2023-11-04 19:36:34,365:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:36:34,483:INFO:Calculating mean and std
2023-11-04 19:36:34,484:INFO:Creating metrics dataframe
2023-11-04 19:36:34,486:INFO:Uploading results into container
2023-11-04 19:36:34,486:INFO:Uploading model into container now
2023-11-04 19:36:34,486:INFO:_master_model_container: 17
2023-11-04 19:36:34,486:INFO:_display_container: 2
2023-11-04 19:36:34,487:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=8917, ...)
2023-11-04 19:36:34,487:INFO:create_model() successfully completed......................................
2023-11-04 19:36:34,603:INFO:SubProcess create_model() end ==================================
2023-11-04 19:36:34,603:INFO:Creating metrics dataframe
2023-11-04 19:36:34,610:INFO:Initializing Light Gradient Boosting Machine
2023-11-04 19:36:34,610:INFO:Total runtime is 0.06631486415863037 minutes
2023-11-04 19:36:34,611:INFO:SubProcess create_model() called ==================================
2023-11-04 19:36:34,612:INFO:Initializing create_model()
2023-11-04 19:36:34,612:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb410bc8490>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb425095b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:36:34,612:INFO:Checking exceptions
2023-11-04 19:36:34,612:INFO:Importing libraries
2023-11-04 19:36:34,612:INFO:Copying training dataset
2023-11-04 19:36:34,614:INFO:Defining folds
2023-11-04 19:36:34,614:INFO:Declaring metric variables
2023-11-04 19:36:34,616:INFO:Importing untrained model
2023-11-04 19:36:34,618:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-04 19:36:34,621:INFO:Starting cross validation
2023-11-04 19:36:34,622:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:36:34,690:INFO:Calculating mean and std
2023-11-04 19:36:34,690:INFO:Creating metrics dataframe
2023-11-04 19:36:34,692:INFO:Uploading results into container
2023-11-04 19:36:34,692:INFO:Uploading model into container now
2023-11-04 19:36:34,692:INFO:_master_model_container: 18
2023-11-04 19:36:34,692:INFO:_display_container: 2
2023-11-04 19:36:34,692:INFO:LGBMRegressor(random_state=8917)
2023-11-04 19:36:34,692:INFO:create_model() successfully completed......................................
2023-11-04 19:36:34,807:INFO:SubProcess create_model() end ==================================
2023-11-04 19:36:34,808:INFO:Creating metrics dataframe
2023-11-04 19:36:34,815:INFO:Initializing CatBoost Regressor
2023-11-04 19:36:34,815:INFO:Total runtime is 0.06973448197046916 minutes
2023-11-04 19:36:34,817:INFO:SubProcess create_model() called ==================================
2023-11-04 19:36:34,817:INFO:Initializing create_model()
2023-11-04 19:36:34,817:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb410bc8490>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb425095b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:36:34,817:INFO:Checking exceptions
2023-11-04 19:36:34,817:INFO:Importing libraries
2023-11-04 19:36:34,817:INFO:Copying training dataset
2023-11-04 19:36:34,819:INFO:Defining folds
2023-11-04 19:36:34,819:INFO:Declaring metric variables
2023-11-04 19:36:34,821:INFO:Importing untrained model
2023-11-04 19:36:34,823:INFO:CatBoost Regressor Imported successfully
2023-11-04 19:36:34,826:INFO:Starting cross validation
2023-11-04 19:36:34,826:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:36:35,584:INFO:Calculating mean and std
2023-11-04 19:36:35,585:INFO:Creating metrics dataframe
2023-11-04 19:36:35,587:INFO:Uploading results into container
2023-11-04 19:36:35,587:INFO:Uploading model into container now
2023-11-04 19:36:35,587:INFO:_master_model_container: 19
2023-11-04 19:36:35,588:INFO:_display_container: 2
2023-11-04 19:36:35,588:INFO:<catboost.core.CatBoostRegressor object at 0x7fb424635d00>
2023-11-04 19:36:35,588:INFO:create_model() successfully completed......................................
2023-11-04 19:36:35,702:INFO:SubProcess create_model() end ==================================
2023-11-04 19:36:35,702:INFO:Creating metrics dataframe
2023-11-04 19:36:35,710:INFO:Initializing Dummy Regressor
2023-11-04 19:36:35,710:INFO:Total runtime is 0.0846567988395691 minutes
2023-11-04 19:36:35,712:INFO:SubProcess create_model() called ==================================
2023-11-04 19:36:35,712:INFO:Initializing create_model()
2023-11-04 19:36:35,712:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb410bc8490>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb425095b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:36:35,712:INFO:Checking exceptions
2023-11-04 19:36:35,712:INFO:Importing libraries
2023-11-04 19:36:35,712:INFO:Copying training dataset
2023-11-04 19:36:35,715:INFO:Defining folds
2023-11-04 19:36:35,715:INFO:Declaring metric variables
2023-11-04 19:36:35,716:INFO:Importing untrained model
2023-11-04 19:36:35,718:INFO:Dummy Regressor Imported successfully
2023-11-04 19:36:35,721:INFO:Starting cross validation
2023-11-04 19:36:35,722:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:36:35,775:INFO:Calculating mean and std
2023-11-04 19:36:35,776:INFO:Creating metrics dataframe
2023-11-04 19:36:35,777:INFO:Uploading results into container
2023-11-04 19:36:35,778:INFO:Uploading model into container now
2023-11-04 19:36:35,778:INFO:_master_model_container: 20
2023-11-04 19:36:35,778:INFO:_display_container: 2
2023-11-04 19:36:35,778:INFO:DummyRegressor()
2023-11-04 19:36:35,778:INFO:create_model() successfully completed......................................
2023-11-04 19:36:35,895:INFO:SubProcess create_model() end ==================================
2023-11-04 19:36:35,895:INFO:Creating metrics dataframe
2023-11-04 19:36:35,908:INFO:Initializing create_model()
2023-11-04 19:36:35,908:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb410bc8490>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=8917, ...), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:36:35,908:INFO:Checking exceptions
2023-11-04 19:36:35,909:INFO:Importing libraries
2023-11-04 19:36:35,909:INFO:Copying training dataset
2023-11-04 19:36:35,911:INFO:Defining folds
2023-11-04 19:36:35,911:INFO:Declaring metric variables
2023-11-04 19:36:35,911:INFO:Importing untrained model
2023-11-04 19:36:35,911:INFO:Declaring custom model
2023-11-04 19:36:35,912:INFO:Extreme Gradient Boosting Imported successfully
2023-11-04 19:36:35,913:INFO:Cross validation set to False
2023-11-04 19:36:35,913:INFO:Fitting Model
2023-11-04 19:36:36,029:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=8917, ...)
2023-11-04 19:36:36,029:INFO:create_model() successfully completed......................................
2023-11-04 19:36:36,166:INFO:_master_model_container: 20
2023-11-04 19:36:36,166:INFO:_display_container: 2
2023-11-04 19:36:36,167:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=8917, ...)
2023-11-04 19:36:36,167:INFO:compare_models() successfully completed......................................
2023-11-04 19:36:41,178:INFO:PyCaret RegressionExperiment
2023-11-04 19:36:41,182:INFO:Logging name: reg-default-name
2023-11-04 19:36:41,183:INFO:ML Usecase: MLUsecase.REGRESSION
2023-11-04 19:36:41,183:INFO:version 3.1.0
2023-11-04 19:36:41,183:INFO:Initializing setup()
2023-11-04 19:36:41,184:INFO:self.USI: 27aa
2023-11-04 19:36:41,184:INFO:self._variable_keys: {'USI', 'log_plots_param', 'gpu_param', 'fold_generator', 'X_test', 'html_param', '_ml_usecase', '_available_plots', 'exp_id', 'target_param', 'idx', 'fold_shuffle_param', 'n_jobs_param', 'seed', 'exp_name_log', 'X', 'y_train', 'transform_target_param', 'data', 'y_test', 'fold_groups_param', 'logging_param', 'gpu_n_jobs_param', 'y', 'X_train', 'memory', 'pipeline'}
2023-11-04 19:36:41,184:INFO:Checking environment
2023-11-04 19:36:41,184:INFO:python_version: 3.9.13
2023-11-04 19:36:41,184:INFO:python_build: ('main', 'Aug 25 2022 18:29:29')
2023-11-04 19:36:41,184:INFO:machine: x86_64
2023-11-04 19:36:41,184:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-11-04 19:36:41,184:INFO:Memory: svmem(total=17179869184, available=1055195136, percent=93.9, used=1544396800, free=15724544, active=1043292160, inactive=1035673600, wired=501104640)
2023-11-04 19:36:41,184:INFO:Physical Core: 8
2023-11-04 19:36:41,184:INFO:Logical Core: 8
2023-11-04 19:36:41,184:INFO:Checking libraries
2023-11-04 19:36:41,184:INFO:System:
2023-11-04 19:36:41,185:INFO:    python: 3.9.13 (main, Aug 25 2022, 18:29:29)  [Clang 12.0.0 ]
2023-11-04 19:36:41,185:INFO:executable: /Users/michal/opt/anaconda3/bin/python
2023-11-04 19:36:41,185:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-11-04 19:36:41,185:INFO:PyCaret required dependencies:
2023-11-04 19:36:41,185:INFO:                 pip: 22.2.2
2023-11-04 19:36:41,185:INFO:          setuptools: 63.4.1
2023-11-04 19:36:41,185:INFO:             pycaret: 3.1.0
2023-11-04 19:36:41,185:INFO:             IPython: 7.31.1
2023-11-04 19:36:41,185:INFO:          ipywidgets: 7.6.5
2023-11-04 19:36:41,185:INFO:                tqdm: 4.64.1
2023-11-04 19:36:41,185:INFO:               numpy: 1.21.5
2023-11-04 19:36:41,185:INFO:              pandas: 1.4.4
2023-11-04 19:36:41,185:INFO:              jinja2: 2.11.3
2023-11-04 19:36:41,185:INFO:               scipy: 1.10.1
2023-11-04 19:36:41,186:INFO:              joblib: 1.2.0
2023-11-04 19:36:41,186:INFO:             sklearn: 1.0.2
2023-11-04 19:36:41,186:INFO:                pyod: 1.1.1
2023-11-04 19:36:41,186:INFO:            imblearn: 0.10.1
2023-11-04 19:36:41,186:INFO:   category_encoders: 2.6.3
2023-11-04 19:36:41,186:INFO:            lightgbm: 3.3.5
2023-11-04 19:36:41,186:INFO:               numba: 0.55.1
2023-11-04 19:36:41,186:INFO:            requests: 2.28.1
2023-11-04 19:36:41,186:INFO:          matplotlib: 3.5.2
2023-11-04 19:36:41,186:INFO:          scikitplot: 0.3.7
2023-11-04 19:36:41,186:INFO:         yellowbrick: 1.5
2023-11-04 19:36:41,186:INFO:              plotly: 5.9.0
2023-11-04 19:36:41,186:INFO:    plotly-resampler: Not installed
2023-11-04 19:36:41,186:INFO:             kaleido: 0.2.1
2023-11-04 19:36:41,186:INFO:           schemdraw: 0.15
2023-11-04 19:36:41,186:INFO:         statsmodels: 0.13.2
2023-11-04 19:36:41,186:INFO:              sktime: 0.21.1
2023-11-04 19:36:41,186:INFO:               tbats: 1.1.3
2023-11-04 19:36:41,186:INFO:            pmdarima: 2.0.4
2023-11-04 19:36:41,187:INFO:              psutil: 5.9.0
2023-11-04 19:36:41,187:INFO:          markupsafe: 2.0.1
2023-11-04 19:36:41,187:INFO:             pickle5: Not installed
2023-11-04 19:36:41,187:INFO:         cloudpickle: 2.0.0
2023-11-04 19:36:41,187:INFO:         deprecation: 2.1.0
2023-11-04 19:36:41,187:INFO:              xxhash: 3.4.1
2023-11-04 19:36:41,187:INFO:           wurlitzer: 3.0.2
2023-11-04 19:36:41,187:INFO:PyCaret optional dependencies:
2023-11-04 19:36:41,187:INFO:                shap: 0.41.0
2023-11-04 19:36:41,187:INFO:           interpret: Not installed
2023-11-04 19:36:41,187:INFO:                umap: 0.5.3
2023-11-04 19:36:41,187:INFO:     ydata_profiling: Not installed
2023-11-04 19:36:41,187:INFO:  explainerdashboard: Not installed
2023-11-04 19:36:41,187:INFO:             autoviz: Not installed
2023-11-04 19:36:41,187:INFO:           fairlearn: Not installed
2023-11-04 19:36:41,187:INFO:          deepchecks: Not installed
2023-11-04 19:36:41,187:INFO:             xgboost: 1.7.4
2023-11-04 19:36:41,187:INFO:            catboost: 1.2
2023-11-04 19:36:41,188:INFO:              kmodes: Not installed
2023-11-04 19:36:41,188:INFO:             mlxtend: 0.21.0
2023-11-04 19:36:41,188:INFO:       statsforecast: Not installed
2023-11-04 19:36:41,188:INFO:        tune_sklearn: Not installed
2023-11-04 19:36:41,188:INFO:                 ray: Not installed
2023-11-04 19:36:41,188:INFO:            hyperopt: Not installed
2023-11-04 19:36:41,188:INFO:              optuna: Not installed
2023-11-04 19:36:41,188:INFO:               skopt: Not installed
2023-11-04 19:36:41,188:INFO:              mlflow: Not installed
2023-11-04 19:36:41,188:INFO:              gradio: Not installed
2023-11-04 19:36:41,188:INFO:             fastapi: Not installed
2023-11-04 19:36:41,188:INFO:             uvicorn: Not installed
2023-11-04 19:36:41,188:INFO:              m2cgen: Not installed
2023-11-04 19:36:41,188:INFO:           evidently: Not installed
2023-11-04 19:36:41,188:INFO:               fugue: Not installed
2023-11-04 19:36:41,188:INFO:           streamlit: Not installed
2023-11-04 19:36:41,189:INFO:             prophet: Not installed
2023-11-04 19:36:41,189:INFO:None
2023-11-04 19:36:41,189:INFO:Set up data.
2023-11-04 19:36:41,198:INFO:Set up folding strategy.
2023-11-04 19:36:41,198:INFO:Set up train/test split.
2023-11-04 19:36:41,200:INFO:Set up index.
2023-11-04 19:36:41,201:INFO:Assigning column types.
2023-11-04 19:36:41,204:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-04 19:36:41,204:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-04 19:36:41,210:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 19:36:41,216:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:36:41,262:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:36:41,289:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:36:41,289:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:36:41,291:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:36:41,291:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-04 19:36:41,294:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 19:36:41,297:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:36:41,330:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:36:41,357:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:36:41,357:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:36:41,358:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:36:41,359:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-11-04 19:36:41,361:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 19:36:41,364:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:36:41,398:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:36:41,423:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:36:41,424:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:36:41,425:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:36:41,428:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 19:36:41,431:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:36:41,464:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:36:41,491:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:36:41,491:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:36:41,492:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:36:41,493:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-11-04 19:36:41,498:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:36:41,531:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:36:41,558:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:36:41,558:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:36:41,559:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:36:41,565:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 19:36:41,598:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:36:41,624:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:36:41,625:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:36:41,626:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:36:41,626:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-11-04 19:36:41,664:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:36:41,690:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:36:41,691:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:36:41,692:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:36:41,731:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:36:41,758:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 19:36:41,758:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:36:41,759:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:36:41,760:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-04 19:36:41,797:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:36:41,824:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:36:41,826:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:36:41,864:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 19:36:41,891:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:36:41,892:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:36:41,893:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-11-04 19:36:41,960:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:36:41,962:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:36:42,035:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:36:42,037:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:36:42,037:INFO:Preparing preprocessing pipeline...
2023-11-04 19:36:42,037:INFO:Set up simple imputation.
2023-11-04 19:36:42,037:INFO:Set up variance threshold.
2023-11-04 19:36:42,037:INFO:Set up removing multicollinearity.
2023-11-04 19:36:42,038:INFO:Set up column name cleaning.
2023-11-04 19:36:42,057:INFO:Finished creating preprocessing pipeline.
2023-11-04 19:36:42,061:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/h9/5_75v3qs13x63s15wwxdrd000000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['solv_dG [kcal/mol]',
                                             'Bond dissociation entalphy',
                                             'water_ads [kcal/mol]', 'Coating',
                                             'Organic Matter Conc.', 'pH',
                                             'Primary Size', 'Initial Conc.',
                                             'Temp.', 'Ionic Strenght', 'Light',
                                             'MW', 'Noxy', 'χ', 'χox',
                                             'Z_metal', 'Zv...
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.1))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-11-04 19:36:42,061:INFO:Creating final display dataframe.
2023-11-04 19:36:42,111:INFO:Setup _display_container:                     Description             Value
0                    Session id               918
1                        Target  %dissolved solid
2                   Target type        Regression
3           Original data shape         (526, 21)
4        Transformed data shape         (526, 21)
5   Transformed train set shape         (368, 21)
6    Transformed test set shape         (158, 21)
7              Numeric features                20
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12       Low variance threshold               0.1
13     Remove multicollinearity              True
14  Multicollinearity threshold              0.95
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              27aa
2023-11-04 19:36:42,184:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:36:42,185:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:36:42,255:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 19:36:42,257:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 19:36:42,257:INFO:setup() successfully completed in 1.08s...............
2023-11-04 19:36:42,258:INFO:Initializing compare_models()
2023-11-04 19:36:42,258:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412b7700>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fb4412b7700>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-11-04 19:36:42,258:INFO:Checking exceptions
2023-11-04 19:36:42,258:INFO:Preparing display monitor
2023-11-04 19:36:42,275:INFO:Initializing Linear Regression
2023-11-04 19:36:42,276:INFO:Total runtime is 1.815954844156901e-06 minutes
2023-11-04 19:36:42,277:INFO:SubProcess create_model() called ==================================
2023-11-04 19:36:42,277:INFO:Initializing create_model()
2023-11-04 19:36:42,277:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412b7700>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb44124d8e0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:36:42,278:INFO:Checking exceptions
2023-11-04 19:36:42,278:INFO:Importing libraries
2023-11-04 19:36:42,278:INFO:Copying training dataset
2023-11-04 19:36:42,279:INFO:Defining folds
2023-11-04 19:36:42,279:INFO:Declaring metric variables
2023-11-04 19:36:42,281:INFO:Importing untrained model
2023-11-04 19:36:42,282:INFO:Linear Regression Imported successfully
2023-11-04 19:36:42,286:INFO:Starting cross validation
2023-11-04 19:36:42,287:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:36:42,347:INFO:Calculating mean and std
2023-11-04 19:36:42,347:INFO:Creating metrics dataframe
2023-11-04 19:36:42,349:INFO:Uploading results into container
2023-11-04 19:36:42,349:INFO:Uploading model into container now
2023-11-04 19:36:42,349:INFO:_master_model_container: 1
2023-11-04 19:36:42,349:INFO:_display_container: 2
2023-11-04 19:36:42,349:INFO:LinearRegression(n_jobs=-1)
2023-11-04 19:36:42,349:INFO:create_model() successfully completed......................................
2023-11-04 19:36:42,470:INFO:SubProcess create_model() end ==================================
2023-11-04 19:36:42,470:INFO:Creating metrics dataframe
2023-11-04 19:36:42,475:INFO:Initializing Lasso Regression
2023-11-04 19:36:42,475:INFO:Total runtime is 0.003323634465535482 minutes
2023-11-04 19:36:42,477:INFO:SubProcess create_model() called ==================================
2023-11-04 19:36:42,477:INFO:Initializing create_model()
2023-11-04 19:36:42,477:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412b7700>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb44124d8e0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:36:42,477:INFO:Checking exceptions
2023-11-04 19:36:42,477:INFO:Importing libraries
2023-11-04 19:36:42,477:INFO:Copying training dataset
2023-11-04 19:36:42,479:INFO:Defining folds
2023-11-04 19:36:42,479:INFO:Declaring metric variables
2023-11-04 19:36:42,481:INFO:Importing untrained model
2023-11-04 19:36:42,482:INFO:Lasso Regression Imported successfully
2023-11-04 19:36:42,485:INFO:Starting cross validation
2023-11-04 19:36:42,486:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:36:42,541:INFO:Calculating mean and std
2023-11-04 19:36:42,541:INFO:Creating metrics dataframe
2023-11-04 19:36:42,543:INFO:Uploading results into container
2023-11-04 19:36:42,543:INFO:Uploading model into container now
2023-11-04 19:36:42,543:INFO:_master_model_container: 2
2023-11-04 19:36:42,543:INFO:_display_container: 2
2023-11-04 19:36:42,543:INFO:Lasso(random_state=918)
2023-11-04 19:36:42,543:INFO:create_model() successfully completed......................................
2023-11-04 19:36:42,661:INFO:SubProcess create_model() end ==================================
2023-11-04 19:36:42,661:INFO:Creating metrics dataframe
2023-11-04 19:36:42,666:INFO:Initializing Ridge Regression
2023-11-04 19:36:42,666:INFO:Total runtime is 0.006517549355824789 minutes
2023-11-04 19:36:42,668:INFO:SubProcess create_model() called ==================================
2023-11-04 19:36:42,669:INFO:Initializing create_model()
2023-11-04 19:36:42,669:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412b7700>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb44124d8e0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:36:42,669:INFO:Checking exceptions
2023-11-04 19:36:42,669:INFO:Importing libraries
2023-11-04 19:36:42,669:INFO:Copying training dataset
2023-11-04 19:36:42,670:INFO:Defining folds
2023-11-04 19:36:42,670:INFO:Declaring metric variables
2023-11-04 19:36:42,672:INFO:Importing untrained model
2023-11-04 19:36:42,674:INFO:Ridge Regression Imported successfully
2023-11-04 19:36:42,677:INFO:Starting cross validation
2023-11-04 19:36:42,677:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:36:42,734:INFO:Calculating mean and std
2023-11-04 19:36:42,734:INFO:Creating metrics dataframe
2023-11-04 19:36:42,736:INFO:Uploading results into container
2023-11-04 19:36:42,736:INFO:Uploading model into container now
2023-11-04 19:36:42,736:INFO:_master_model_container: 3
2023-11-04 19:36:42,736:INFO:_display_container: 2
2023-11-04 19:36:42,736:INFO:Ridge(random_state=918)
2023-11-04 19:36:42,736:INFO:create_model() successfully completed......................................
2023-11-04 19:36:42,853:INFO:SubProcess create_model() end ==================================
2023-11-04 19:36:42,853:INFO:Creating metrics dataframe
2023-11-04 19:36:42,858:INFO:Initializing Elastic Net
2023-11-04 19:36:42,858:INFO:Total runtime is 0.009713999430338542 minutes
2023-11-04 19:36:42,860:INFO:SubProcess create_model() called ==================================
2023-11-04 19:36:42,860:INFO:Initializing create_model()
2023-11-04 19:36:42,860:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412b7700>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb44124d8e0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:36:42,860:INFO:Checking exceptions
2023-11-04 19:36:42,861:INFO:Importing libraries
2023-11-04 19:36:42,861:INFO:Copying training dataset
2023-11-04 19:36:42,862:INFO:Defining folds
2023-11-04 19:36:42,862:INFO:Declaring metric variables
2023-11-04 19:36:42,864:INFO:Importing untrained model
2023-11-04 19:36:42,865:INFO:Elastic Net Imported successfully
2023-11-04 19:36:42,869:INFO:Starting cross validation
2023-11-04 19:36:42,869:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:36:42,927:INFO:Calculating mean and std
2023-11-04 19:36:42,927:INFO:Creating metrics dataframe
2023-11-04 19:36:42,929:INFO:Uploading results into container
2023-11-04 19:36:42,929:INFO:Uploading model into container now
2023-11-04 19:36:42,929:INFO:_master_model_container: 4
2023-11-04 19:36:42,930:INFO:_display_container: 2
2023-11-04 19:36:42,930:INFO:ElasticNet(random_state=918)
2023-11-04 19:36:42,930:INFO:create_model() successfully completed......................................
2023-11-04 19:36:43,049:INFO:SubProcess create_model() end ==================================
2023-11-04 19:36:43,049:INFO:Creating metrics dataframe
2023-11-04 19:36:43,054:INFO:Initializing Least Angle Regression
2023-11-04 19:36:43,055:INFO:Total runtime is 0.012984951337178549 minutes
2023-11-04 19:36:43,056:INFO:SubProcess create_model() called ==================================
2023-11-04 19:36:43,056:INFO:Initializing create_model()
2023-11-04 19:36:43,057:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412b7700>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb44124d8e0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:36:43,057:INFO:Checking exceptions
2023-11-04 19:36:43,057:INFO:Importing libraries
2023-11-04 19:36:43,057:INFO:Copying training dataset
2023-11-04 19:36:43,058:INFO:Defining folds
2023-11-04 19:36:43,058:INFO:Declaring metric variables
2023-11-04 19:36:43,060:INFO:Importing untrained model
2023-11-04 19:36:43,062:INFO:Least Angle Regression Imported successfully
2023-11-04 19:36:43,065:INFO:Starting cross validation
2023-11-04 19:36:43,065:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:36:43,084:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:36:43,086:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:36:43,094:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:36:43,100:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:36:43,107:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:36:43,109:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:36:43,111:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:36:43,115:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:36:43,118:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:36:43,125:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:36:43,132:INFO:Calculating mean and std
2023-11-04 19:36:43,132:INFO:Creating metrics dataframe
2023-11-04 19:36:43,134:INFO:Uploading results into container
2023-11-04 19:36:43,134:INFO:Uploading model into container now
2023-11-04 19:36:43,134:INFO:_master_model_container: 5
2023-11-04 19:36:43,134:INFO:_display_container: 2
2023-11-04 19:36:43,135:INFO:Lars(random_state=918)
2023-11-04 19:36:43,135:INFO:create_model() successfully completed......................................
2023-11-04 19:36:43,256:INFO:SubProcess create_model() end ==================================
2023-11-04 19:36:43,256:INFO:Creating metrics dataframe
2023-11-04 19:36:43,262:INFO:Initializing Lasso Least Angle Regression
2023-11-04 19:36:43,262:INFO:Total runtime is 0.016438802083333336 minutes
2023-11-04 19:36:43,264:INFO:SubProcess create_model() called ==================================
2023-11-04 19:36:43,264:INFO:Initializing create_model()
2023-11-04 19:36:43,264:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412b7700>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb44124d8e0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:36:43,264:INFO:Checking exceptions
2023-11-04 19:36:43,264:INFO:Importing libraries
2023-11-04 19:36:43,264:INFO:Copying training dataset
2023-11-04 19:36:43,266:INFO:Defining folds
2023-11-04 19:36:43,266:INFO:Declaring metric variables
2023-11-04 19:36:43,268:INFO:Importing untrained model
2023-11-04 19:36:43,270:INFO:Lasso Least Angle Regression Imported successfully
2023-11-04 19:36:43,273:INFO:Starting cross validation
2023-11-04 19:36:43,274:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:36:43,292:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:36:43,300:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:36:43,301:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:36:43,306:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:36:43,310:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:36:43,316:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:36:43,318:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:36:43,319:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:36:43,320:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:36:43,328:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 19:36:43,333:INFO:Calculating mean and std
2023-11-04 19:36:43,334:INFO:Creating metrics dataframe
2023-11-04 19:36:43,335:INFO:Uploading results into container
2023-11-04 19:36:43,336:INFO:Uploading model into container now
2023-11-04 19:36:43,336:INFO:_master_model_container: 6
2023-11-04 19:36:43,336:INFO:_display_container: 2
2023-11-04 19:36:43,336:INFO:LassoLars(random_state=918)
2023-11-04 19:36:43,336:INFO:create_model() successfully completed......................................
2023-11-04 19:36:43,454:INFO:SubProcess create_model() end ==================================
2023-11-04 19:36:43,454:INFO:Creating metrics dataframe
2023-11-04 19:36:43,460:INFO:Initializing Orthogonal Matching Pursuit
2023-11-04 19:36:43,460:INFO:Total runtime is 0.019741348425547284 minutes
2023-11-04 19:36:43,462:INFO:SubProcess create_model() called ==================================
2023-11-04 19:36:43,462:INFO:Initializing create_model()
2023-11-04 19:36:43,462:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412b7700>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb44124d8e0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:36:43,462:INFO:Checking exceptions
2023-11-04 19:36:43,462:INFO:Importing libraries
2023-11-04 19:36:43,462:INFO:Copying training dataset
2023-11-04 19:36:43,464:INFO:Defining folds
2023-11-04 19:36:43,464:INFO:Declaring metric variables
2023-11-04 19:36:43,466:INFO:Importing untrained model
2023-11-04 19:36:43,468:INFO:Orthogonal Matching Pursuit Imported successfully
2023-11-04 19:36:43,471:INFO:Starting cross validation
2023-11-04 19:36:43,472:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:36:43,493:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:36:43,493:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:36:43,495:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:36:43,504:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:36:43,507:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:36:43,512:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:36:43,514:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:36:43,518:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:36:43,518:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:36:43,521:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 19:36:43,527:INFO:Calculating mean and std
2023-11-04 19:36:43,527:INFO:Creating metrics dataframe
2023-11-04 19:36:43,529:INFO:Uploading results into container
2023-11-04 19:36:43,529:INFO:Uploading model into container now
2023-11-04 19:36:43,529:INFO:_master_model_container: 7
2023-11-04 19:36:43,529:INFO:_display_container: 2
2023-11-04 19:36:43,530:INFO:OrthogonalMatchingPursuit()
2023-11-04 19:36:43,530:INFO:create_model() successfully completed......................................
2023-11-04 19:36:43,652:INFO:SubProcess create_model() end ==================================
2023-11-04 19:36:43,652:INFO:Creating metrics dataframe
2023-11-04 19:36:43,658:INFO:Initializing Bayesian Ridge
2023-11-04 19:36:43,658:INFO:Total runtime is 0.023043100039164228 minutes
2023-11-04 19:36:43,660:INFO:SubProcess create_model() called ==================================
2023-11-04 19:36:43,660:INFO:Initializing create_model()
2023-11-04 19:36:43,660:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412b7700>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb44124d8e0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:36:43,660:INFO:Checking exceptions
2023-11-04 19:36:43,660:INFO:Importing libraries
2023-11-04 19:36:43,660:INFO:Copying training dataset
2023-11-04 19:36:43,663:INFO:Defining folds
2023-11-04 19:36:43,663:INFO:Declaring metric variables
2023-11-04 19:36:43,664:INFO:Importing untrained model
2023-11-04 19:36:43,666:INFO:Bayesian Ridge Imported successfully
2023-11-04 19:36:43,669:INFO:Starting cross validation
2023-11-04 19:36:43,670:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:36:43,731:INFO:Calculating mean and std
2023-11-04 19:36:43,731:INFO:Creating metrics dataframe
2023-11-04 19:36:43,733:INFO:Uploading results into container
2023-11-04 19:36:43,733:INFO:Uploading model into container now
2023-11-04 19:36:43,733:INFO:_master_model_container: 8
2023-11-04 19:36:43,733:INFO:_display_container: 2
2023-11-04 19:36:43,733:INFO:BayesianRidge()
2023-11-04 19:36:43,733:INFO:create_model() successfully completed......................................
2023-11-04 19:36:43,851:INFO:SubProcess create_model() end ==================================
2023-11-04 19:36:43,851:INFO:Creating metrics dataframe
2023-11-04 19:36:43,857:INFO:Initializing Passive Aggressive Regressor
2023-11-04 19:36:43,857:INFO:Total runtime is 0.026355584462483726 minutes
2023-11-04 19:36:43,858:INFO:SubProcess create_model() called ==================================
2023-11-04 19:36:43,859:INFO:Initializing create_model()
2023-11-04 19:36:43,859:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412b7700>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb44124d8e0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:36:43,859:INFO:Checking exceptions
2023-11-04 19:36:43,859:INFO:Importing libraries
2023-11-04 19:36:43,859:INFO:Copying training dataset
2023-11-04 19:36:43,861:INFO:Defining folds
2023-11-04 19:36:43,861:INFO:Declaring metric variables
2023-11-04 19:36:43,863:INFO:Importing untrained model
2023-11-04 19:36:43,864:INFO:Passive Aggressive Regressor Imported successfully
2023-11-04 19:36:43,867:INFO:Starting cross validation
2023-11-04 19:36:43,868:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:36:43,929:INFO:Calculating mean and std
2023-11-04 19:36:43,929:INFO:Creating metrics dataframe
2023-11-04 19:36:43,930:INFO:Uploading results into container
2023-11-04 19:36:43,931:INFO:Uploading model into container now
2023-11-04 19:36:43,931:INFO:_master_model_container: 9
2023-11-04 19:36:43,931:INFO:_display_container: 2
2023-11-04 19:36:43,931:INFO:PassiveAggressiveRegressor(random_state=918)
2023-11-04 19:36:43,931:INFO:create_model() successfully completed......................................
2023-11-04 19:36:44,045:INFO:SubProcess create_model() end ==================================
2023-11-04 19:36:44,045:INFO:Creating metrics dataframe
2023-11-04 19:36:44,051:INFO:Initializing Huber Regressor
2023-11-04 19:36:44,051:INFO:Total runtime is 0.02958668470382691 minutes
2023-11-04 19:36:44,052:INFO:SubProcess create_model() called ==================================
2023-11-04 19:36:44,053:INFO:Initializing create_model()
2023-11-04 19:36:44,053:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412b7700>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb44124d8e0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:36:44,053:INFO:Checking exceptions
2023-11-04 19:36:44,053:INFO:Importing libraries
2023-11-04 19:36:44,053:INFO:Copying training dataset
2023-11-04 19:36:44,055:INFO:Defining folds
2023-11-04 19:36:44,055:INFO:Declaring metric variables
2023-11-04 19:36:44,057:INFO:Importing untrained model
2023-11-04 19:36:44,058:INFO:Huber Regressor Imported successfully
2023-11-04 19:36:44,061:INFO:Starting cross validation
2023-11-04 19:36:44,062:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:36:44,096:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:36:44,098:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:36:44,104:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:36:44,113:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:36:44,117:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:36:44,125:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:36:44,131:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:36:44,131:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:36:44,132:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:36:44,136:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-04 19:36:44,141:INFO:Calculating mean and std
2023-11-04 19:36:44,141:INFO:Creating metrics dataframe
2023-11-04 19:36:44,143:INFO:Uploading results into container
2023-11-04 19:36:44,143:INFO:Uploading model into container now
2023-11-04 19:36:44,144:INFO:_master_model_container: 10
2023-11-04 19:36:44,144:INFO:_display_container: 2
2023-11-04 19:36:44,144:INFO:HuberRegressor()
2023-11-04 19:36:44,144:INFO:create_model() successfully completed......................................
2023-11-04 19:36:44,256:INFO:SubProcess create_model() end ==================================
2023-11-04 19:36:44,256:INFO:Creating metrics dataframe
2023-11-04 19:36:44,262:INFO:Initializing K Neighbors Regressor
2023-11-04 19:36:44,263:INFO:Total runtime is 0.03311873277028402 minutes
2023-11-04 19:36:44,264:INFO:SubProcess create_model() called ==================================
2023-11-04 19:36:44,265:INFO:Initializing create_model()
2023-11-04 19:36:44,265:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412b7700>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb44124d8e0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:36:44,265:INFO:Checking exceptions
2023-11-04 19:36:44,265:INFO:Importing libraries
2023-11-04 19:36:44,265:INFO:Copying training dataset
2023-11-04 19:36:44,267:INFO:Defining folds
2023-11-04 19:36:44,267:INFO:Declaring metric variables
2023-11-04 19:36:44,268:INFO:Importing untrained model
2023-11-04 19:36:44,270:INFO:K Neighbors Regressor Imported successfully
2023-11-04 19:36:44,273:INFO:Starting cross validation
2023-11-04 19:36:44,274:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:36:44,341:INFO:Calculating mean and std
2023-11-04 19:36:44,341:INFO:Creating metrics dataframe
2023-11-04 19:36:44,343:INFO:Uploading results into container
2023-11-04 19:36:44,343:INFO:Uploading model into container now
2023-11-04 19:36:44,343:INFO:_master_model_container: 11
2023-11-04 19:36:44,343:INFO:_display_container: 2
2023-11-04 19:36:44,343:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-04 19:36:44,343:INFO:create_model() successfully completed......................................
2023-11-04 19:36:44,457:INFO:SubProcess create_model() end ==================================
2023-11-04 19:36:44,457:INFO:Creating metrics dataframe
2023-11-04 19:36:44,463:INFO:Initializing Decision Tree Regressor
2023-11-04 19:36:44,463:INFO:Total runtime is 0.036463499069213874 minutes
2023-11-04 19:36:44,465:INFO:SubProcess create_model() called ==================================
2023-11-04 19:36:44,465:INFO:Initializing create_model()
2023-11-04 19:36:44,465:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412b7700>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb44124d8e0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:36:44,465:INFO:Checking exceptions
2023-11-04 19:36:44,465:INFO:Importing libraries
2023-11-04 19:36:44,465:INFO:Copying training dataset
2023-11-04 19:36:44,467:INFO:Defining folds
2023-11-04 19:36:44,467:INFO:Declaring metric variables
2023-11-04 19:36:44,469:INFO:Importing untrained model
2023-11-04 19:36:44,471:INFO:Decision Tree Regressor Imported successfully
2023-11-04 19:36:44,474:INFO:Starting cross validation
2023-11-04 19:36:44,474:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:36:44,538:INFO:Calculating mean and std
2023-11-04 19:36:44,538:INFO:Creating metrics dataframe
2023-11-04 19:36:44,540:INFO:Uploading results into container
2023-11-04 19:36:44,540:INFO:Uploading model into container now
2023-11-04 19:36:44,540:INFO:_master_model_container: 12
2023-11-04 19:36:44,540:INFO:_display_container: 2
2023-11-04 19:36:44,541:INFO:DecisionTreeRegressor(random_state=918)
2023-11-04 19:36:44,541:INFO:create_model() successfully completed......................................
2023-11-04 19:36:44,653:INFO:SubProcess create_model() end ==================================
2023-11-04 19:36:44,653:INFO:Creating metrics dataframe
2023-11-04 19:36:44,660:INFO:Initializing Random Forest Regressor
2023-11-04 19:36:44,660:INFO:Total runtime is 0.03973684708277385 minutes
2023-11-04 19:36:44,661:INFO:SubProcess create_model() called ==================================
2023-11-04 19:36:44,662:INFO:Initializing create_model()
2023-11-04 19:36:44,662:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412b7700>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb44124d8e0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:36:44,662:INFO:Checking exceptions
2023-11-04 19:36:44,662:INFO:Importing libraries
2023-11-04 19:36:44,662:INFO:Copying training dataset
2023-11-04 19:36:44,664:INFO:Defining folds
2023-11-04 19:36:44,664:INFO:Declaring metric variables
2023-11-04 19:36:44,665:INFO:Importing untrained model
2023-11-04 19:36:44,667:INFO:Random Forest Regressor Imported successfully
2023-11-04 19:36:44,670:INFO:Starting cross validation
2023-11-04 19:36:44,671:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:36:45,219:INFO:Calculating mean and std
2023-11-04 19:36:45,219:INFO:Creating metrics dataframe
2023-11-04 19:36:45,221:INFO:Uploading results into container
2023-11-04 19:36:45,222:INFO:Uploading model into container now
2023-11-04 19:36:45,222:INFO:_master_model_container: 13
2023-11-04 19:36:45,222:INFO:_display_container: 2
2023-11-04 19:36:45,222:INFO:RandomForestRegressor(n_jobs=-1, random_state=918)
2023-11-04 19:36:45,222:INFO:create_model() successfully completed......................................
2023-11-04 19:36:45,342:INFO:SubProcess create_model() end ==================================
2023-11-04 19:36:45,342:INFO:Creating metrics dataframe
2023-11-04 19:36:45,349:INFO:Initializing Extra Trees Regressor
2023-11-04 19:36:45,349:INFO:Total runtime is 0.05122145414352418 minutes
2023-11-04 19:36:45,350:INFO:SubProcess create_model() called ==================================
2023-11-04 19:36:45,351:INFO:Initializing create_model()
2023-11-04 19:36:45,351:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412b7700>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb44124d8e0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:36:45,351:INFO:Checking exceptions
2023-11-04 19:36:45,351:INFO:Importing libraries
2023-11-04 19:36:45,351:INFO:Copying training dataset
2023-11-04 19:36:45,352:INFO:Defining folds
2023-11-04 19:36:45,352:INFO:Declaring metric variables
2023-11-04 19:36:45,354:INFO:Importing untrained model
2023-11-04 19:36:45,356:INFO:Extra Trees Regressor Imported successfully
2023-11-04 19:36:45,359:INFO:Starting cross validation
2023-11-04 19:36:45,360:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:36:45,714:INFO:Calculating mean and std
2023-11-04 19:36:45,715:INFO:Creating metrics dataframe
2023-11-04 19:36:45,717:INFO:Uploading results into container
2023-11-04 19:36:45,717:INFO:Uploading model into container now
2023-11-04 19:36:45,718:INFO:_master_model_container: 14
2023-11-04 19:36:45,718:INFO:_display_container: 2
2023-11-04 19:36:45,718:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=918)
2023-11-04 19:36:45,718:INFO:create_model() successfully completed......................................
2023-11-04 19:36:45,838:INFO:SubProcess create_model() end ==================================
2023-11-04 19:36:45,838:INFO:Creating metrics dataframe
2023-11-04 19:36:45,846:INFO:Initializing AdaBoost Regressor
2023-11-04 19:36:45,846:INFO:Total runtime is 0.05950918197631837 minutes
2023-11-04 19:36:45,848:INFO:SubProcess create_model() called ==================================
2023-11-04 19:36:45,848:INFO:Initializing create_model()
2023-11-04 19:36:45,848:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412b7700>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb44124d8e0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:36:45,848:INFO:Checking exceptions
2023-11-04 19:36:45,848:INFO:Importing libraries
2023-11-04 19:36:45,848:INFO:Copying training dataset
2023-11-04 19:36:45,850:INFO:Defining folds
2023-11-04 19:36:45,850:INFO:Declaring metric variables
2023-11-04 19:36:45,851:INFO:Importing untrained model
2023-11-04 19:36:45,853:INFO:AdaBoost Regressor Imported successfully
2023-11-04 19:36:45,858:INFO:Starting cross validation
2023-11-04 19:36:45,858:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:36:46,029:INFO:Calculating mean and std
2023-11-04 19:36:46,029:INFO:Creating metrics dataframe
2023-11-04 19:36:46,032:INFO:Uploading results into container
2023-11-04 19:36:46,032:INFO:Uploading model into container now
2023-11-04 19:36:46,032:INFO:_master_model_container: 15
2023-11-04 19:36:46,032:INFO:_display_container: 2
2023-11-04 19:36:46,033:INFO:AdaBoostRegressor(random_state=918)
2023-11-04 19:36:46,033:INFO:create_model() successfully completed......................................
2023-11-04 19:36:46,151:INFO:SubProcess create_model() end ==================================
2023-11-04 19:36:46,151:INFO:Creating metrics dataframe
2023-11-04 19:36:46,158:INFO:Initializing Gradient Boosting Regressor
2023-11-04 19:36:46,158:INFO:Total runtime is 0.06470938523610434 minutes
2023-11-04 19:36:46,160:INFO:SubProcess create_model() called ==================================
2023-11-04 19:36:46,160:INFO:Initializing create_model()
2023-11-04 19:36:46,160:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412b7700>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb44124d8e0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:36:46,160:INFO:Checking exceptions
2023-11-04 19:36:46,160:INFO:Importing libraries
2023-11-04 19:36:46,160:INFO:Copying training dataset
2023-11-04 19:36:46,162:INFO:Defining folds
2023-11-04 19:36:46,162:INFO:Declaring metric variables
2023-11-04 19:36:46,163:INFO:Importing untrained model
2023-11-04 19:36:46,165:INFO:Gradient Boosting Regressor Imported successfully
2023-11-04 19:36:46,169:INFO:Starting cross validation
2023-11-04 19:36:46,169:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:36:46,447:INFO:Calculating mean and std
2023-11-04 19:36:46,447:INFO:Creating metrics dataframe
2023-11-04 19:36:46,450:INFO:Uploading results into container
2023-11-04 19:36:46,450:INFO:Uploading model into container now
2023-11-04 19:36:46,450:INFO:_master_model_container: 16
2023-11-04 19:36:46,450:INFO:_display_container: 2
2023-11-04 19:36:46,451:INFO:GradientBoostingRegressor(random_state=918)
2023-11-04 19:36:46,451:INFO:create_model() successfully completed......................................
2023-11-04 19:36:46,569:INFO:SubProcess create_model() end ==================================
2023-11-04 19:36:46,570:INFO:Creating metrics dataframe
2023-11-04 19:36:46,577:INFO:Initializing Extreme Gradient Boosting
2023-11-04 19:36:46,577:INFO:Total runtime is 0.0716914971669515 minutes
2023-11-04 19:36:46,579:INFO:SubProcess create_model() called ==================================
2023-11-04 19:36:46,579:INFO:Initializing create_model()
2023-11-04 19:36:46,579:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412b7700>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb44124d8e0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:36:46,579:INFO:Checking exceptions
2023-11-04 19:36:46,579:INFO:Importing libraries
2023-11-04 19:36:46,579:INFO:Copying training dataset
2023-11-04 19:36:46,580:INFO:Defining folds
2023-11-04 19:36:46,581:INFO:Declaring metric variables
2023-11-04 19:36:46,582:INFO:Importing untrained model
2023-11-04 19:36:46,584:INFO:Extreme Gradient Boosting Imported successfully
2023-11-04 19:36:46,588:INFO:Starting cross validation
2023-11-04 19:36:46,588:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:36:46,846:INFO:Calculating mean and std
2023-11-04 19:36:46,846:INFO:Creating metrics dataframe
2023-11-04 19:36:46,849:INFO:Uploading results into container
2023-11-04 19:36:46,849:INFO:Uploading model into container now
2023-11-04 19:36:46,849:INFO:_master_model_container: 17
2023-11-04 19:36:46,850:INFO:_display_container: 2
2023-11-04 19:36:46,850:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=918, ...)
2023-11-04 19:36:46,850:INFO:create_model() successfully completed......................................
2023-11-04 19:36:46,972:INFO:SubProcess create_model() end ==================================
2023-11-04 19:36:46,972:INFO:Creating metrics dataframe
2023-11-04 19:36:46,980:INFO:Initializing Light Gradient Boosting Machine
2023-11-04 19:36:46,980:INFO:Total runtime is 0.07840334971745809 minutes
2023-11-04 19:36:46,981:INFO:SubProcess create_model() called ==================================
2023-11-04 19:36:46,982:INFO:Initializing create_model()
2023-11-04 19:36:46,982:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412b7700>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb44124d8e0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:36:46,982:INFO:Checking exceptions
2023-11-04 19:36:46,982:INFO:Importing libraries
2023-11-04 19:36:46,982:INFO:Copying training dataset
2023-11-04 19:36:46,983:INFO:Defining folds
2023-11-04 19:36:46,983:INFO:Declaring metric variables
2023-11-04 19:36:46,985:INFO:Importing untrained model
2023-11-04 19:36:46,987:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-04 19:36:46,990:INFO:Starting cross validation
2023-11-04 19:36:46,991:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:36:47,106:INFO:Calculating mean and std
2023-11-04 19:36:47,106:INFO:Creating metrics dataframe
2023-11-04 19:36:47,108:INFO:Uploading results into container
2023-11-04 19:36:47,109:INFO:Uploading model into container now
2023-11-04 19:36:47,109:INFO:_master_model_container: 18
2023-11-04 19:36:47,109:INFO:_display_container: 2
2023-11-04 19:36:47,109:INFO:LGBMRegressor(random_state=918)
2023-11-04 19:36:47,109:INFO:create_model() successfully completed......................................
2023-11-04 19:36:47,227:INFO:SubProcess create_model() end ==================================
2023-11-04 19:36:47,227:INFO:Creating metrics dataframe
2023-11-04 19:36:47,235:INFO:Initializing CatBoost Regressor
2023-11-04 19:36:47,235:INFO:Total runtime is 0.08265556891759236 minutes
2023-11-04 19:36:47,237:INFO:SubProcess create_model() called ==================================
2023-11-04 19:36:47,237:INFO:Initializing create_model()
2023-11-04 19:36:47,237:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412b7700>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb44124d8e0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:36:47,237:INFO:Checking exceptions
2023-11-04 19:36:47,237:INFO:Importing libraries
2023-11-04 19:36:47,237:INFO:Copying training dataset
2023-11-04 19:36:47,238:INFO:Defining folds
2023-11-04 19:36:47,238:INFO:Declaring metric variables
2023-11-04 19:36:47,240:INFO:Importing untrained model
2023-11-04 19:36:47,242:INFO:CatBoost Regressor Imported successfully
2023-11-04 19:36:47,246:INFO:Starting cross validation
2023-11-04 19:36:47,247:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:36:54,734:INFO:Calculating mean and std
2023-11-04 19:36:54,734:INFO:Creating metrics dataframe
2023-11-04 19:36:54,737:INFO:Uploading results into container
2023-11-04 19:36:54,737:INFO:Uploading model into container now
2023-11-04 19:36:54,737:INFO:_master_model_container: 19
2023-11-04 19:36:54,737:INFO:_display_container: 2
2023-11-04 19:36:54,738:INFO:<catboost.core.CatBoostRegressor object at 0x7fb4410577f0>
2023-11-04 19:36:54,738:INFO:create_model() successfully completed......................................
2023-11-04 19:36:54,855:INFO:SubProcess create_model() end ==================================
2023-11-04 19:36:54,856:INFO:Creating metrics dataframe
2023-11-04 19:36:54,863:INFO:Initializing Dummy Regressor
2023-11-04 19:36:54,863:INFO:Total runtime is 0.20979231595993042 minutes
2023-11-04 19:36:54,865:INFO:SubProcess create_model() called ==================================
2023-11-04 19:36:54,865:INFO:Initializing create_model()
2023-11-04 19:36:54,865:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412b7700>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb44124d8e0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:36:54,865:INFO:Checking exceptions
2023-11-04 19:36:54,865:INFO:Importing libraries
2023-11-04 19:36:54,865:INFO:Copying training dataset
2023-11-04 19:36:54,867:INFO:Defining folds
2023-11-04 19:36:54,867:INFO:Declaring metric variables
2023-11-04 19:36:54,869:INFO:Importing untrained model
2023-11-04 19:36:54,871:INFO:Dummy Regressor Imported successfully
2023-11-04 19:36:54,874:INFO:Starting cross validation
2023-11-04 19:36:54,875:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 19:36:54,929:INFO:Calculating mean and std
2023-11-04 19:36:54,929:INFO:Creating metrics dataframe
2023-11-04 19:36:54,931:INFO:Uploading results into container
2023-11-04 19:36:54,931:INFO:Uploading model into container now
2023-11-04 19:36:54,931:INFO:_master_model_container: 20
2023-11-04 19:36:54,931:INFO:_display_container: 2
2023-11-04 19:36:54,931:INFO:DummyRegressor()
2023-11-04 19:36:54,931:INFO:create_model() successfully completed......................................
2023-11-04 19:36:55,050:INFO:SubProcess create_model() end ==================================
2023-11-04 19:36:55,050:INFO:Creating metrics dataframe
2023-11-04 19:36:55,062:INFO:Initializing create_model()
2023-11-04 19:36:55,062:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb4412b7700>, estimator=RandomForestRegressor(n_jobs=-1, random_state=918), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-04 19:36:55,062:INFO:Checking exceptions
2023-11-04 19:36:55,063:INFO:Importing libraries
2023-11-04 19:36:55,063:INFO:Copying training dataset
2023-11-04 19:36:55,065:INFO:Defining folds
2023-11-04 19:36:55,065:INFO:Declaring metric variables
2023-11-04 19:36:55,065:INFO:Importing untrained model
2023-11-04 19:36:55,065:INFO:Declaring custom model
2023-11-04 19:36:55,065:INFO:Random Forest Regressor Imported successfully
2023-11-04 19:36:55,066:INFO:Cross validation set to False
2023-11-04 19:36:55,066:INFO:Fitting Model
2023-11-04 19:36:55,173:INFO:RandomForestRegressor(n_jobs=-1, random_state=918)
2023-11-04 19:36:55,173:INFO:create_model() successfully completed......................................
2023-11-04 19:36:55,306:INFO:_master_model_container: 20
2023-11-04 19:36:55,306:INFO:_display_container: 2
2023-11-04 19:36:55,306:INFO:RandomForestRegressor(n_jobs=-1, random_state=918)
2023-11-04 19:36:55,307:INFO:compare_models() successfully completed......................................
2023-11-04 23:32:33,133:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-04 23:32:33,133:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-04 23:32:33,134:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-04 23:32:33,134:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-04 23:32:37,662:INFO:PyCaret RegressionExperiment
2023-11-04 23:32:37,662:INFO:Logging name: reg-default-name
2023-11-04 23:32:37,662:INFO:ML Usecase: MLUsecase.REGRESSION
2023-11-04 23:32:37,662:INFO:version 3.1.0
2023-11-04 23:32:37,662:INFO:Initializing setup()
2023-11-04 23:32:37,662:INFO:self.USI: 4daf
2023-11-04 23:32:37,662:INFO:self._variable_keys: {'X_test', 'logging_param', 'y_test', 'y_train', 'X_train', 'transform_target_param', 'target_param', 'pipeline', '_available_plots', 'log_plots_param', 'seed', 'exp_id', 'X', 'memory', 'fold_generator', 'fold_groups_param', 'html_param', 'idx', 'gpu_n_jobs_param', 'fold_shuffle_param', 'exp_name_log', 'USI', 'data', 'n_jobs_param', '_ml_usecase', 'gpu_param', 'y'}
2023-11-04 23:32:37,662:INFO:Checking environment
2023-11-04 23:32:37,662:INFO:python_version: 3.9.13
2023-11-04 23:32:37,662:INFO:python_build: ('main', 'Aug 25 2022 18:29:29')
2023-11-04 23:32:37,662:INFO:machine: x86_64
2023-11-04 23:32:37,662:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-11-04 23:32:37,662:INFO:Memory: svmem(total=17179869184, available=1413210112, percent=91.8, used=1885401088, free=20131840, active=1398599680, inactive=1376616448, wired=486801408)
2023-11-04 23:32:37,662:INFO:Physical Core: 8
2023-11-04 23:32:37,662:INFO:Logical Core: 8
2023-11-04 23:32:37,662:INFO:Checking libraries
2023-11-04 23:32:37,662:INFO:System:
2023-11-04 23:32:37,662:INFO:    python: 3.9.13 (main, Aug 25 2022, 18:29:29)  [Clang 12.0.0 ]
2023-11-04 23:32:37,662:INFO:executable: /Users/michal/opt/anaconda3/bin/python
2023-11-04 23:32:37,663:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-11-04 23:32:37,663:INFO:PyCaret required dependencies:
2023-11-04 23:32:37,664:INFO:                 pip: 22.2.2
2023-11-04 23:32:37,664:INFO:          setuptools: 63.4.1
2023-11-04 23:32:37,664:INFO:             pycaret: 3.1.0
2023-11-04 23:32:37,664:INFO:             IPython: 7.31.1
2023-11-04 23:32:37,664:INFO:          ipywidgets: 7.6.5
2023-11-04 23:32:37,664:INFO:                tqdm: 4.64.1
2023-11-04 23:32:37,664:INFO:               numpy: 1.21.5
2023-11-04 23:32:37,664:INFO:              pandas: 1.4.4
2023-11-04 23:32:37,664:INFO:              jinja2: 2.11.3
2023-11-04 23:32:37,664:INFO:               scipy: 1.10.1
2023-11-04 23:32:37,664:INFO:              joblib: 1.2.0
2023-11-04 23:32:37,664:INFO:             sklearn: 1.0.2
2023-11-04 23:32:37,664:INFO:                pyod: 1.1.1
2023-11-04 23:32:37,664:INFO:            imblearn: 0.10.1
2023-11-04 23:32:37,664:INFO:   category_encoders: 2.6.3
2023-11-04 23:32:37,664:INFO:            lightgbm: 3.3.5
2023-11-04 23:32:37,664:INFO:               numba: 0.55.1
2023-11-04 23:32:37,664:INFO:            requests: 2.28.1
2023-11-04 23:32:37,664:INFO:          matplotlib: 3.5.2
2023-11-04 23:32:37,664:INFO:          scikitplot: 0.3.7
2023-11-04 23:32:37,664:INFO:         yellowbrick: 1.5
2023-11-04 23:32:37,664:INFO:              plotly: 5.9.0
2023-11-04 23:32:37,664:INFO:    plotly-resampler: Not installed
2023-11-04 23:32:37,664:INFO:             kaleido: 0.2.1
2023-11-04 23:32:37,664:INFO:           schemdraw: 0.15
2023-11-04 23:32:37,664:INFO:         statsmodels: 0.13.2
2023-11-04 23:32:37,664:INFO:              sktime: 0.21.1
2023-11-04 23:32:37,664:INFO:               tbats: 1.1.3
2023-11-04 23:32:37,664:INFO:            pmdarima: 2.0.4
2023-11-04 23:32:37,664:INFO:              psutil: 5.9.0
2023-11-04 23:32:37,664:INFO:          markupsafe: 2.0.1
2023-11-04 23:32:37,664:INFO:             pickle5: Not installed
2023-11-04 23:32:37,664:INFO:         cloudpickle: 2.0.0
2023-11-04 23:32:37,664:INFO:         deprecation: 2.1.0
2023-11-04 23:32:37,664:INFO:              xxhash: 3.4.1
2023-11-04 23:32:37,664:INFO:           wurlitzer: 3.0.2
2023-11-04 23:32:37,664:INFO:PyCaret optional dependencies:
2023-11-04 23:32:37,673:INFO:                shap: 0.41.0
2023-11-04 23:32:37,673:INFO:           interpret: Not installed
2023-11-04 23:32:37,673:INFO:                umap: 0.5.3
2023-11-04 23:32:37,673:INFO:     ydata_profiling: Not installed
2023-11-04 23:32:37,673:INFO:  explainerdashboard: Not installed
2023-11-04 23:32:37,673:INFO:             autoviz: Not installed
2023-11-04 23:32:37,673:INFO:           fairlearn: Not installed
2023-11-04 23:32:37,673:INFO:          deepchecks: Not installed
2023-11-04 23:32:37,673:INFO:             xgboost: 1.7.4
2023-11-04 23:32:37,673:INFO:            catboost: 1.2
2023-11-04 23:32:37,673:INFO:              kmodes: Not installed
2023-11-04 23:32:37,673:INFO:             mlxtend: 0.21.0
2023-11-04 23:32:37,673:INFO:       statsforecast: Not installed
2023-11-04 23:32:37,673:INFO:        tune_sklearn: Not installed
2023-11-04 23:32:37,673:INFO:                 ray: Not installed
2023-11-04 23:32:37,674:INFO:            hyperopt: Not installed
2023-11-04 23:32:37,674:INFO:              optuna: Not installed
2023-11-04 23:32:37,674:INFO:               skopt: Not installed
2023-11-04 23:32:37,674:INFO:              mlflow: Not installed
2023-11-04 23:32:37,674:INFO:              gradio: Not installed
2023-11-04 23:32:37,674:INFO:             fastapi: Not installed
2023-11-04 23:32:37,674:INFO:             uvicorn: Not installed
2023-11-04 23:32:37,674:INFO:              m2cgen: Not installed
2023-11-04 23:32:37,674:INFO:           evidently: Not installed
2023-11-04 23:32:37,674:INFO:               fugue: Not installed
2023-11-04 23:32:37,674:INFO:           streamlit: Not installed
2023-11-04 23:32:37,674:INFO:             prophet: Not installed
2023-11-04 23:32:37,674:INFO:None
2023-11-04 23:32:37,674:INFO:Set up data.
2023-11-04 23:33:12,538:INFO:PyCaret RegressionExperiment
2023-11-04 23:33:12,539:INFO:Logging name: reg-default-name
2023-11-04 23:33:12,539:INFO:ML Usecase: MLUsecase.REGRESSION
2023-11-04 23:33:12,539:INFO:version 3.1.0
2023-11-04 23:33:12,539:INFO:Initializing setup()
2023-11-04 23:33:12,539:INFO:self.USI: 6985
2023-11-04 23:33:12,539:INFO:self._variable_keys: {'X_test', 'logging_param', 'y_test', 'y_train', 'X_train', 'transform_target_param', 'target_param', 'pipeline', '_available_plots', 'log_plots_param', 'seed', 'exp_id', 'X', 'memory', 'fold_generator', 'fold_groups_param', 'html_param', 'idx', 'gpu_n_jobs_param', 'fold_shuffle_param', 'exp_name_log', 'USI', 'data', 'n_jobs_param', '_ml_usecase', 'gpu_param', 'y'}
2023-11-04 23:33:12,539:INFO:Checking environment
2023-11-04 23:33:12,539:INFO:python_version: 3.9.13
2023-11-04 23:33:12,539:INFO:python_build: ('main', 'Aug 25 2022 18:29:29')
2023-11-04 23:33:12,539:INFO:machine: x86_64
2023-11-04 23:33:12,539:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-11-04 23:33:12,539:INFO:Memory: svmem(total=17179869184, available=1362563072, percent=92.1, used=1846218752, free=15605760, active=1350148096, inactive=1345191936, wired=496070656)
2023-11-04 23:33:12,539:INFO:Physical Core: 8
2023-11-04 23:33:12,539:INFO:Logical Core: 8
2023-11-04 23:33:12,539:INFO:Checking libraries
2023-11-04 23:33:12,539:INFO:System:
2023-11-04 23:33:12,539:INFO:    python: 3.9.13 (main, Aug 25 2022, 18:29:29)  [Clang 12.0.0 ]
2023-11-04 23:33:12,539:INFO:executable: /Users/michal/opt/anaconda3/bin/python
2023-11-04 23:33:12,539:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-11-04 23:33:12,539:INFO:PyCaret required dependencies:
2023-11-04 23:33:12,539:INFO:                 pip: 22.2.2
2023-11-04 23:33:12,539:INFO:          setuptools: 63.4.1
2023-11-04 23:33:12,539:INFO:             pycaret: 3.1.0
2023-11-04 23:33:12,539:INFO:             IPython: 7.31.1
2023-11-04 23:33:12,539:INFO:          ipywidgets: 7.6.5
2023-11-04 23:33:12,539:INFO:                tqdm: 4.64.1
2023-11-04 23:33:12,539:INFO:               numpy: 1.21.5
2023-11-04 23:33:12,539:INFO:              pandas: 1.4.4
2023-11-04 23:33:12,539:INFO:              jinja2: 2.11.3
2023-11-04 23:33:12,539:INFO:               scipy: 1.10.1
2023-11-04 23:33:12,539:INFO:              joblib: 1.2.0
2023-11-04 23:33:12,539:INFO:             sklearn: 1.0.2
2023-11-04 23:33:12,539:INFO:                pyod: 1.1.1
2023-11-04 23:33:12,539:INFO:            imblearn: 0.10.1
2023-11-04 23:33:12,539:INFO:   category_encoders: 2.6.3
2023-11-04 23:33:12,539:INFO:            lightgbm: 3.3.5
2023-11-04 23:33:12,539:INFO:               numba: 0.55.1
2023-11-04 23:33:12,539:INFO:            requests: 2.28.1
2023-11-04 23:33:12,539:INFO:          matplotlib: 3.5.2
2023-11-04 23:33:12,539:INFO:          scikitplot: 0.3.7
2023-11-04 23:33:12,539:INFO:         yellowbrick: 1.5
2023-11-04 23:33:12,539:INFO:              plotly: 5.9.0
2023-11-04 23:33:12,539:INFO:    plotly-resampler: Not installed
2023-11-04 23:33:12,540:INFO:             kaleido: 0.2.1
2023-11-04 23:33:12,540:INFO:           schemdraw: 0.15
2023-11-04 23:33:12,540:INFO:         statsmodels: 0.13.2
2023-11-04 23:33:12,540:INFO:              sktime: 0.21.1
2023-11-04 23:33:12,540:INFO:               tbats: 1.1.3
2023-11-04 23:33:12,540:INFO:            pmdarima: 2.0.4
2023-11-04 23:33:12,540:INFO:              psutil: 5.9.0
2023-11-04 23:33:12,540:INFO:          markupsafe: 2.0.1
2023-11-04 23:33:12,540:INFO:             pickle5: Not installed
2023-11-04 23:33:12,540:INFO:         cloudpickle: 2.0.0
2023-11-04 23:33:12,540:INFO:         deprecation: 2.1.0
2023-11-04 23:33:12,540:INFO:              xxhash: 3.4.1
2023-11-04 23:33:12,540:INFO:           wurlitzer: 3.0.2
2023-11-04 23:33:12,540:INFO:PyCaret optional dependencies:
2023-11-04 23:33:12,540:INFO:                shap: 0.41.0
2023-11-04 23:33:12,540:INFO:           interpret: Not installed
2023-11-04 23:33:12,540:INFO:                umap: 0.5.3
2023-11-04 23:33:12,540:INFO:     ydata_profiling: Not installed
2023-11-04 23:33:12,540:INFO:  explainerdashboard: Not installed
2023-11-04 23:33:12,540:INFO:             autoviz: Not installed
2023-11-04 23:33:12,540:INFO:           fairlearn: Not installed
2023-11-04 23:33:12,540:INFO:          deepchecks: Not installed
2023-11-04 23:33:12,540:INFO:             xgboost: 1.7.4
2023-11-04 23:33:12,540:INFO:            catboost: 1.2
2023-11-04 23:33:12,540:INFO:              kmodes: Not installed
2023-11-04 23:33:12,540:INFO:             mlxtend: 0.21.0
2023-11-04 23:33:12,540:INFO:       statsforecast: Not installed
2023-11-04 23:33:12,540:INFO:        tune_sklearn: Not installed
2023-11-04 23:33:12,540:INFO:                 ray: Not installed
2023-11-04 23:33:12,540:INFO:            hyperopt: Not installed
2023-11-04 23:33:12,540:INFO:              optuna: Not installed
2023-11-04 23:33:12,540:INFO:               skopt: Not installed
2023-11-04 23:33:12,540:INFO:              mlflow: Not installed
2023-11-04 23:33:12,540:INFO:              gradio: Not installed
2023-11-04 23:33:12,540:INFO:             fastapi: Not installed
2023-11-04 23:33:12,540:INFO:             uvicorn: Not installed
2023-11-04 23:33:12,540:INFO:              m2cgen: Not installed
2023-11-04 23:33:12,540:INFO:           evidently: Not installed
2023-11-04 23:33:12,540:INFO:               fugue: Not installed
2023-11-04 23:33:12,540:INFO:           streamlit: Not installed
2023-11-04 23:33:12,540:INFO:             prophet: Not installed
2023-11-04 23:33:12,540:INFO:None
2023-11-04 23:33:12,540:INFO:Set up data.
2023-11-04 23:33:12,542:INFO:Set up folding strategy.
2023-11-04 23:33:12,542:INFO:Set up train/test split.
2023-11-04 23:33:12,544:INFO:Set up index.
2023-11-04 23:33:12,544:INFO:Assigning column types.
2023-11-04 23:33:12,545:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-04 23:33:12,545:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-04 23:33:12,548:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 23:33:12,550:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 23:33:12,582:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:33:12,608:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:33:12,608:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:33:12,704:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:33:12,717:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-04 23:33:12,719:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 23:33:12,722:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 23:33:12,755:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:33:12,780:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:33:12,781:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:33:12,782:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:33:12,782:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-11-04 23:33:12,785:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 23:33:12,788:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 23:33:12,820:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:33:12,845:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:33:12,845:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:33:12,847:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:33:12,850:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 23:33:12,852:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 23:33:12,884:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:33:12,909:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:33:12,910:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:33:12,911:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:33:12,911:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-11-04 23:33:12,916:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 23:33:12,948:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:33:12,973:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:33:12,973:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:33:12,974:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:33:12,980:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 23:33:13,012:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:33:13,038:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:33:13,038:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:33:13,039:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:33:13,040:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-11-04 23:33:13,077:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:33:13,102:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:33:13,103:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:33:13,104:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:33:13,142:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:33:13,167:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:33:13,168:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:33:13,169:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:33:13,169:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-04 23:33:13,206:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:33:13,232:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:33:13,233:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:33:13,270:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:33:13,296:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:33:13,297:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:33:13,297:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-11-04 23:33:13,359:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:33:13,361:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:33:13,424:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:33:13,425:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:33:13,426:INFO:Preparing preprocessing pipeline...
2023-11-04 23:33:13,426:INFO:Set up simple imputation.
2023-11-04 23:33:13,426:INFO:Set up variance threshold.
2023-11-04 23:33:13,426:INFO:Set up removing multicollinearity.
2023-11-04 23:33:13,427:INFO:Set up column name cleaning.
2023-11-04 23:33:13,443:INFO:Finished creating preprocessing pipeline.
2023-11-04 23:33:13,447:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/h9/5_75v3qs13x63s15wwxdrd000000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['sepal length (cm)',
                                             'petal length (cm)',
                                             'petal width (cm)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.1))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-11-04 23:33:13,447:INFO:Creating final display dataframe.
2023-11-04 23:33:13,490:INFO:Setup _display_container:                     Description             Value
0                    Session id              1707
1                        Target  sepal width (cm)
2                   Target type        Regression
3           Original data shape          (150, 4)
4        Transformed data shape          (150, 3)
5   Transformed train set shape          (105, 3)
6    Transformed test set shape           (45, 3)
7              Numeric features                 3
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12       Low variance threshold               0.1
13     Remove multicollinearity              True
14  Multicollinearity threshold              0.95
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              6985
2023-11-04 23:33:13,562:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:33:13,563:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:33:13,630:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:33:13,631:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:33:13,632:INFO:setup() successfully completed in 1.09s...............
2023-11-04 23:33:13,632:INFO:Initializing compare_models()
2023-11-04 23:33:13,632:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb6109f26a0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fb6109f26a0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-11-04 23:33:13,632:INFO:Checking exceptions
2023-11-04 23:33:13,633:INFO:Preparing display monitor
2023-11-04 23:33:13,651:INFO:Initializing Linear Regression
2023-11-04 23:33:13,651:INFO:Total runtime is 2.2649765014648438e-06 minutes
2023-11-04 23:33:13,653:INFO:SubProcess create_model() called ==================================
2023-11-04 23:33:13,653:INFO:Initializing create_model()
2023-11-04 23:33:13,653:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb6109f26a0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614d71b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:13,654:INFO:Checking exceptions
2023-11-04 23:33:13,654:INFO:Importing libraries
2023-11-04 23:33:13,654:INFO:Copying training dataset
2023-11-04 23:33:13,655:INFO:Defining folds
2023-11-04 23:33:13,656:INFO:Declaring metric variables
2023-11-04 23:33:13,657:INFO:Importing untrained model
2023-11-04 23:33:13,659:INFO:Linear Regression Imported successfully
2023-11-04 23:33:13,663:INFO:Starting cross validation
2023-11-04 23:33:13,668:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:33:16,397:INFO:Calculating mean and std
2023-11-04 23:33:16,399:INFO:Creating metrics dataframe
2023-11-04 23:33:16,403:INFO:Uploading results into container
2023-11-04 23:33:16,403:INFO:Uploading model into container now
2023-11-04 23:33:16,403:INFO:_master_model_container: 1
2023-11-04 23:33:16,404:INFO:_display_container: 2
2023-11-04 23:33:16,404:INFO:LinearRegression(n_jobs=-1)
2023-11-04 23:33:16,404:INFO:create_model() successfully completed......................................
2023-11-04 23:33:16,597:INFO:SubProcess create_model() end ==================================
2023-11-04 23:33:16,597:INFO:Creating metrics dataframe
2023-11-04 23:33:16,602:INFO:Initializing Lasso Regression
2023-11-04 23:33:16,602:INFO:Total runtime is 0.049179697036743165 minutes
2023-11-04 23:33:16,604:INFO:SubProcess create_model() called ==================================
2023-11-04 23:33:16,604:INFO:Initializing create_model()
2023-11-04 23:33:16,604:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb6109f26a0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614d71b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:16,604:INFO:Checking exceptions
2023-11-04 23:33:16,604:INFO:Importing libraries
2023-11-04 23:33:16,604:INFO:Copying training dataset
2023-11-04 23:33:16,606:INFO:Defining folds
2023-11-04 23:33:16,606:INFO:Declaring metric variables
2023-11-04 23:33:16,608:INFO:Importing untrained model
2023-11-04 23:33:16,610:INFO:Lasso Regression Imported successfully
2023-11-04 23:33:16,613:INFO:Starting cross validation
2023-11-04 23:33:16,614:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:33:16,664:INFO:Calculating mean and std
2023-11-04 23:33:16,664:INFO:Creating metrics dataframe
2023-11-04 23:33:16,666:INFO:Uploading results into container
2023-11-04 23:33:16,666:INFO:Uploading model into container now
2023-11-04 23:33:16,666:INFO:_master_model_container: 2
2023-11-04 23:33:16,666:INFO:_display_container: 2
2023-11-04 23:33:16,666:INFO:Lasso(random_state=1707)
2023-11-04 23:33:16,667:INFO:create_model() successfully completed......................................
2023-11-04 23:33:16,802:INFO:SubProcess create_model() end ==================================
2023-11-04 23:33:16,802:INFO:Creating metrics dataframe
2023-11-04 23:33:16,807:INFO:Initializing Ridge Regression
2023-11-04 23:33:16,807:INFO:Total runtime is 0.052596763769785566 minutes
2023-11-04 23:33:16,809:INFO:SubProcess create_model() called ==================================
2023-11-04 23:33:16,809:INFO:Initializing create_model()
2023-11-04 23:33:16,809:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb6109f26a0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614d71b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:16,809:INFO:Checking exceptions
2023-11-04 23:33:16,809:INFO:Importing libraries
2023-11-04 23:33:16,809:INFO:Copying training dataset
2023-11-04 23:33:16,811:INFO:Defining folds
2023-11-04 23:33:16,811:INFO:Declaring metric variables
2023-11-04 23:33:16,813:INFO:Importing untrained model
2023-11-04 23:33:16,815:INFO:Ridge Regression Imported successfully
2023-11-04 23:33:16,818:INFO:Starting cross validation
2023-11-04 23:33:16,819:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:33:16,878:INFO:Calculating mean and std
2023-11-04 23:33:16,878:INFO:Creating metrics dataframe
2023-11-04 23:33:16,880:INFO:Uploading results into container
2023-11-04 23:33:16,881:INFO:Uploading model into container now
2023-11-04 23:33:16,881:INFO:_master_model_container: 3
2023-11-04 23:33:16,881:INFO:_display_container: 2
2023-11-04 23:33:16,881:INFO:Ridge(random_state=1707)
2023-11-04 23:33:16,881:INFO:create_model() successfully completed......................................
2023-11-04 23:33:17,017:INFO:SubProcess create_model() end ==================================
2023-11-04 23:33:17,017:INFO:Creating metrics dataframe
2023-11-04 23:33:17,022:INFO:Initializing Elastic Net
2023-11-04 23:33:17,022:INFO:Total runtime is 0.05618565082550049 minutes
2023-11-04 23:33:17,024:INFO:SubProcess create_model() called ==================================
2023-11-04 23:33:17,024:INFO:Initializing create_model()
2023-11-04 23:33:17,024:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb6109f26a0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614d71b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:17,024:INFO:Checking exceptions
2023-11-04 23:33:17,024:INFO:Importing libraries
2023-11-04 23:33:17,025:INFO:Copying training dataset
2023-11-04 23:33:17,027:INFO:Defining folds
2023-11-04 23:33:17,027:INFO:Declaring metric variables
2023-11-04 23:33:17,028:INFO:Importing untrained model
2023-11-04 23:33:17,030:INFO:Elastic Net Imported successfully
2023-11-04 23:33:17,033:INFO:Starting cross validation
2023-11-04 23:33:17,034:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:33:17,082:INFO:Calculating mean and std
2023-11-04 23:33:17,082:INFO:Creating metrics dataframe
2023-11-04 23:33:17,084:INFO:Uploading results into container
2023-11-04 23:33:17,084:INFO:Uploading model into container now
2023-11-04 23:33:17,084:INFO:_master_model_container: 4
2023-11-04 23:33:17,084:INFO:_display_container: 2
2023-11-04 23:33:17,084:INFO:ElasticNet(random_state=1707)
2023-11-04 23:33:17,084:INFO:create_model() successfully completed......................................
2023-11-04 23:33:17,219:INFO:SubProcess create_model() end ==================================
2023-11-04 23:33:17,219:INFO:Creating metrics dataframe
2023-11-04 23:33:17,225:INFO:Initializing Least Angle Regression
2023-11-04 23:33:17,225:INFO:Total runtime is 0.05955841541290283 minutes
2023-11-04 23:33:17,227:INFO:SubProcess create_model() called ==================================
2023-11-04 23:33:17,227:INFO:Initializing create_model()
2023-11-04 23:33:17,227:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb6109f26a0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614d71b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:17,227:INFO:Checking exceptions
2023-11-04 23:33:17,227:INFO:Importing libraries
2023-11-04 23:33:17,227:INFO:Copying training dataset
2023-11-04 23:33:17,229:INFO:Defining folds
2023-11-04 23:33:17,229:INFO:Declaring metric variables
2023-11-04 23:33:17,231:INFO:Importing untrained model
2023-11-04 23:33:17,233:INFO:Least Angle Regression Imported successfully
2023-11-04 23:33:17,236:INFO:Starting cross validation
2023-11-04 23:33:17,236:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:33:17,255:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:33:17,266:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:33:17,268:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:33:17,269:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:33:17,273:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:33:17,280:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:33:17,282:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:33:17,283:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:33:17,284:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:33:17,285:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:33:17,291:INFO:Calculating mean and std
2023-11-04 23:33:17,291:INFO:Creating metrics dataframe
2023-11-04 23:33:17,293:INFO:Uploading results into container
2023-11-04 23:33:17,293:INFO:Uploading model into container now
2023-11-04 23:33:17,293:INFO:_master_model_container: 5
2023-11-04 23:33:17,293:INFO:_display_container: 2
2023-11-04 23:33:17,293:INFO:Lars(random_state=1707)
2023-11-04 23:33:17,293:INFO:create_model() successfully completed......................................
2023-11-04 23:33:17,434:INFO:SubProcess create_model() end ==================================
2023-11-04 23:33:17,435:INFO:Creating metrics dataframe
2023-11-04 23:33:17,440:INFO:Initializing Lasso Least Angle Regression
2023-11-04 23:33:17,440:INFO:Total runtime is 0.06314791440963745 minutes
2023-11-04 23:33:17,442:INFO:SubProcess create_model() called ==================================
2023-11-04 23:33:17,442:INFO:Initializing create_model()
2023-11-04 23:33:17,442:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb6109f26a0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614d71b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:17,442:INFO:Checking exceptions
2023-11-04 23:33:17,442:INFO:Importing libraries
2023-11-04 23:33:17,442:INFO:Copying training dataset
2023-11-04 23:33:17,444:INFO:Defining folds
2023-11-04 23:33:17,444:INFO:Declaring metric variables
2023-11-04 23:33:17,446:INFO:Importing untrained model
2023-11-04 23:33:17,448:INFO:Lasso Least Angle Regression Imported successfully
2023-11-04 23:33:17,451:INFO:Starting cross validation
2023-11-04 23:33:17,452:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:33:17,470:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:33:17,480:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:33:17,482:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:33:17,487:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:33:17,491:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:33:17,491:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:33:17,496:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:33:17,496:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:33:17,502:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:33:17,502:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:33:17,507:INFO:Calculating mean and std
2023-11-04 23:33:17,507:INFO:Creating metrics dataframe
2023-11-04 23:33:17,509:INFO:Uploading results into container
2023-11-04 23:33:17,509:INFO:Uploading model into container now
2023-11-04 23:33:17,509:INFO:_master_model_container: 6
2023-11-04 23:33:17,509:INFO:_display_container: 2
2023-11-04 23:33:17,509:INFO:LassoLars(random_state=1707)
2023-11-04 23:33:17,509:INFO:create_model() successfully completed......................................
2023-11-04 23:33:17,647:INFO:SubProcess create_model() end ==================================
2023-11-04 23:33:17,648:INFO:Creating metrics dataframe
2023-11-04 23:33:17,653:INFO:Initializing Orthogonal Matching Pursuit
2023-11-04 23:33:17,653:INFO:Total runtime is 0.06670276721318563 minutes
2023-11-04 23:33:17,655:INFO:SubProcess create_model() called ==================================
2023-11-04 23:33:17,655:INFO:Initializing create_model()
2023-11-04 23:33:17,656:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb6109f26a0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614d71b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:17,656:INFO:Checking exceptions
2023-11-04 23:33:17,656:INFO:Importing libraries
2023-11-04 23:33:17,656:INFO:Copying training dataset
2023-11-04 23:33:17,658:INFO:Defining folds
2023-11-04 23:33:17,658:INFO:Declaring metric variables
2023-11-04 23:33:17,659:INFO:Importing untrained model
2023-11-04 23:33:17,661:INFO:Orthogonal Matching Pursuit Imported successfully
2023-11-04 23:33:17,665:INFO:Starting cross validation
2023-11-04 23:33:17,665:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:33:17,683:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:33:17,690:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:33:17,695:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:33:17,695:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:33:17,700:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:33:17,704:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:33:17,705:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:33:17,708:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:33:17,712:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:33:17,715:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:33:17,721:INFO:Calculating mean and std
2023-11-04 23:33:17,721:INFO:Creating metrics dataframe
2023-11-04 23:33:17,723:INFO:Uploading results into container
2023-11-04 23:33:17,723:INFO:Uploading model into container now
2023-11-04 23:33:17,723:INFO:_master_model_container: 7
2023-11-04 23:33:17,723:INFO:_display_container: 2
2023-11-04 23:33:17,723:INFO:OrthogonalMatchingPursuit()
2023-11-04 23:33:17,723:INFO:create_model() successfully completed......................................
2023-11-04 23:33:17,860:INFO:SubProcess create_model() end ==================================
2023-11-04 23:33:17,860:INFO:Creating metrics dataframe
2023-11-04 23:33:17,866:INFO:Initializing Bayesian Ridge
2023-11-04 23:33:17,866:INFO:Total runtime is 0.07024718125661214 minutes
2023-11-04 23:33:17,868:INFO:SubProcess create_model() called ==================================
2023-11-04 23:33:17,868:INFO:Initializing create_model()
2023-11-04 23:33:17,868:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb6109f26a0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614d71b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:17,868:INFO:Checking exceptions
2023-11-04 23:33:17,868:INFO:Importing libraries
2023-11-04 23:33:17,868:INFO:Copying training dataset
2023-11-04 23:33:17,871:INFO:Defining folds
2023-11-04 23:33:17,871:INFO:Declaring metric variables
2023-11-04 23:33:17,872:INFO:Importing untrained model
2023-11-04 23:33:17,874:INFO:Bayesian Ridge Imported successfully
2023-11-04 23:33:17,877:INFO:Starting cross validation
2023-11-04 23:33:17,878:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:33:17,931:INFO:Calculating mean and std
2023-11-04 23:33:17,931:INFO:Creating metrics dataframe
2023-11-04 23:33:17,933:INFO:Uploading results into container
2023-11-04 23:33:17,933:INFO:Uploading model into container now
2023-11-04 23:33:17,934:INFO:_master_model_container: 8
2023-11-04 23:33:17,934:INFO:_display_container: 2
2023-11-04 23:33:17,934:INFO:BayesianRidge()
2023-11-04 23:33:17,934:INFO:create_model() successfully completed......................................
2023-11-04 23:33:18,074:INFO:SubProcess create_model() end ==================================
2023-11-04 23:33:18,074:INFO:Creating metrics dataframe
2023-11-04 23:33:18,080:INFO:Initializing Passive Aggressive Regressor
2023-11-04 23:33:18,080:INFO:Total runtime is 0.07382139762242634 minutes
2023-11-04 23:33:18,082:INFO:SubProcess create_model() called ==================================
2023-11-04 23:33:18,083:INFO:Initializing create_model()
2023-11-04 23:33:18,083:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb6109f26a0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614d71b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:18,083:INFO:Checking exceptions
2023-11-04 23:33:18,083:INFO:Importing libraries
2023-11-04 23:33:18,083:INFO:Copying training dataset
2023-11-04 23:33:18,085:INFO:Defining folds
2023-11-04 23:33:18,085:INFO:Declaring metric variables
2023-11-04 23:33:18,086:INFO:Importing untrained model
2023-11-04 23:33:18,088:INFO:Passive Aggressive Regressor Imported successfully
2023-11-04 23:33:18,091:INFO:Starting cross validation
2023-11-04 23:33:18,092:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:33:18,145:INFO:Calculating mean and std
2023-11-04 23:33:18,145:INFO:Creating metrics dataframe
2023-11-04 23:33:18,147:INFO:Uploading results into container
2023-11-04 23:33:18,147:INFO:Uploading model into container now
2023-11-04 23:33:18,147:INFO:_master_model_container: 9
2023-11-04 23:33:18,147:INFO:_display_container: 2
2023-11-04 23:33:18,148:INFO:PassiveAggressiveRegressor(random_state=1707)
2023-11-04 23:33:18,148:INFO:create_model() successfully completed......................................
2023-11-04 23:33:18,283:INFO:SubProcess create_model() end ==================================
2023-11-04 23:33:18,283:INFO:Creating metrics dataframe
2023-11-04 23:33:18,289:INFO:Initializing Huber Regressor
2023-11-04 23:33:18,289:INFO:Total runtime is 0.0772929310798645 minutes
2023-11-04 23:33:18,291:INFO:SubProcess create_model() called ==================================
2023-11-04 23:33:18,291:INFO:Initializing create_model()
2023-11-04 23:33:18,291:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb6109f26a0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614d71b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:18,291:INFO:Checking exceptions
2023-11-04 23:33:18,291:INFO:Importing libraries
2023-11-04 23:33:18,291:INFO:Copying training dataset
2023-11-04 23:33:18,293:INFO:Defining folds
2023-11-04 23:33:18,293:INFO:Declaring metric variables
2023-11-04 23:33:18,295:INFO:Importing untrained model
2023-11-04 23:33:18,296:INFO:Huber Regressor Imported successfully
2023-11-04 23:33:18,299:INFO:Starting cross validation
2023-11-04 23:33:18,300:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:33:18,360:INFO:Calculating mean and std
2023-11-04 23:33:18,360:INFO:Creating metrics dataframe
2023-11-04 23:33:18,362:INFO:Uploading results into container
2023-11-04 23:33:18,363:INFO:Uploading model into container now
2023-11-04 23:33:18,363:INFO:_master_model_container: 10
2023-11-04 23:33:18,363:INFO:_display_container: 2
2023-11-04 23:33:18,363:INFO:HuberRegressor()
2023-11-04 23:33:18,363:INFO:create_model() successfully completed......................................
2023-11-04 23:33:18,505:INFO:SubProcess create_model() end ==================================
2023-11-04 23:33:18,506:INFO:Creating metrics dataframe
2023-11-04 23:33:18,512:INFO:Initializing K Neighbors Regressor
2023-11-04 23:33:18,512:INFO:Total runtime is 0.0810101310412089 minutes
2023-11-04 23:33:18,514:INFO:SubProcess create_model() called ==================================
2023-11-04 23:33:18,514:INFO:Initializing create_model()
2023-11-04 23:33:18,514:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb6109f26a0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614d71b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:18,514:INFO:Checking exceptions
2023-11-04 23:33:18,514:INFO:Importing libraries
2023-11-04 23:33:18,514:INFO:Copying training dataset
2023-11-04 23:33:18,516:INFO:Defining folds
2023-11-04 23:33:18,516:INFO:Declaring metric variables
2023-11-04 23:33:18,518:INFO:Importing untrained model
2023-11-04 23:33:18,519:INFO:K Neighbors Regressor Imported successfully
2023-11-04 23:33:18,523:INFO:Starting cross validation
2023-11-04 23:33:18,523:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:33:18,583:INFO:Calculating mean and std
2023-11-04 23:33:18,583:INFO:Creating metrics dataframe
2023-11-04 23:33:18,585:INFO:Uploading results into container
2023-11-04 23:33:18,585:INFO:Uploading model into container now
2023-11-04 23:33:18,585:INFO:_master_model_container: 11
2023-11-04 23:33:18,585:INFO:_display_container: 2
2023-11-04 23:33:18,585:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-04 23:33:18,585:INFO:create_model() successfully completed......................................
2023-11-04 23:33:18,725:INFO:SubProcess create_model() end ==================================
2023-11-04 23:33:18,726:INFO:Creating metrics dataframe
2023-11-04 23:33:18,732:INFO:Initializing Decision Tree Regressor
2023-11-04 23:33:18,732:INFO:Total runtime is 0.08467903137207031 minutes
2023-11-04 23:33:18,734:INFO:SubProcess create_model() called ==================================
2023-11-04 23:33:18,734:INFO:Initializing create_model()
2023-11-04 23:33:18,734:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb6109f26a0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614d71b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:18,734:INFO:Checking exceptions
2023-11-04 23:33:18,734:INFO:Importing libraries
2023-11-04 23:33:18,734:INFO:Copying training dataset
2023-11-04 23:33:18,736:INFO:Defining folds
2023-11-04 23:33:18,736:INFO:Declaring metric variables
2023-11-04 23:33:18,738:INFO:Importing untrained model
2023-11-04 23:33:18,740:INFO:Decision Tree Regressor Imported successfully
2023-11-04 23:33:18,743:INFO:Starting cross validation
2023-11-04 23:33:18,743:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:33:18,792:INFO:Calculating mean and std
2023-11-04 23:33:18,793:INFO:Creating metrics dataframe
2023-11-04 23:33:18,794:INFO:Uploading results into container
2023-11-04 23:33:18,794:INFO:Uploading model into container now
2023-11-04 23:33:18,795:INFO:_master_model_container: 12
2023-11-04 23:33:18,795:INFO:_display_container: 2
2023-11-04 23:33:18,795:INFO:DecisionTreeRegressor(random_state=1707)
2023-11-04 23:33:18,795:INFO:create_model() successfully completed......................................
2023-11-04 23:33:18,930:INFO:SubProcess create_model() end ==================================
2023-11-04 23:33:18,930:INFO:Creating metrics dataframe
2023-11-04 23:33:18,936:INFO:Initializing Random Forest Regressor
2023-11-04 23:33:18,936:INFO:Total runtime is 0.08808344602584839 minutes
2023-11-04 23:33:18,938:INFO:SubProcess create_model() called ==================================
2023-11-04 23:33:18,938:INFO:Initializing create_model()
2023-11-04 23:33:18,938:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb6109f26a0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614d71b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:18,938:INFO:Checking exceptions
2023-11-04 23:33:18,938:INFO:Importing libraries
2023-11-04 23:33:18,938:INFO:Copying training dataset
2023-11-04 23:33:18,940:INFO:Defining folds
2023-11-04 23:33:18,941:INFO:Declaring metric variables
2023-11-04 23:33:18,942:INFO:Importing untrained model
2023-11-04 23:33:18,945:INFO:Random Forest Regressor Imported successfully
2023-11-04 23:33:18,948:INFO:Starting cross validation
2023-11-04 23:33:18,949:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:33:19,200:INFO:Calculating mean and std
2023-11-04 23:33:19,201:INFO:Creating metrics dataframe
2023-11-04 23:33:19,203:INFO:Uploading results into container
2023-11-04 23:33:19,203:INFO:Uploading model into container now
2023-11-04 23:33:19,204:INFO:_master_model_container: 13
2023-11-04 23:33:19,204:INFO:_display_container: 2
2023-11-04 23:33:19,204:INFO:RandomForestRegressor(n_jobs=-1, random_state=1707)
2023-11-04 23:33:19,204:INFO:create_model() successfully completed......................................
2023-11-04 23:33:19,344:INFO:SubProcess create_model() end ==================================
2023-11-04 23:33:19,344:INFO:Creating metrics dataframe
2023-11-04 23:33:19,351:INFO:Initializing Extra Trees Regressor
2023-11-04 23:33:19,351:INFO:Total runtime is 0.09500509897867838 minutes
2023-11-04 23:33:19,353:INFO:SubProcess create_model() called ==================================
2023-11-04 23:33:19,353:INFO:Initializing create_model()
2023-11-04 23:33:19,353:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb6109f26a0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614d71b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:19,353:INFO:Checking exceptions
2023-11-04 23:33:19,354:INFO:Importing libraries
2023-11-04 23:33:19,354:INFO:Copying training dataset
2023-11-04 23:33:19,356:INFO:Defining folds
2023-11-04 23:33:19,356:INFO:Declaring metric variables
2023-11-04 23:33:19,357:INFO:Importing untrained model
2023-11-04 23:33:19,359:INFO:Extra Trees Regressor Imported successfully
2023-11-04 23:33:19,362:INFO:Starting cross validation
2023-11-04 23:33:19,363:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:33:19,572:INFO:Calculating mean and std
2023-11-04 23:33:19,573:INFO:Creating metrics dataframe
2023-11-04 23:33:19,574:INFO:Uploading results into container
2023-11-04 23:33:19,575:INFO:Uploading model into container now
2023-11-04 23:33:19,575:INFO:_master_model_container: 14
2023-11-04 23:33:19,575:INFO:_display_container: 2
2023-11-04 23:33:19,575:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1707)
2023-11-04 23:33:19,575:INFO:create_model() successfully completed......................................
2023-11-04 23:33:19,712:INFO:SubProcess create_model() end ==================================
2023-11-04 23:33:19,712:INFO:Creating metrics dataframe
2023-11-04 23:33:19,720:INFO:Initializing AdaBoost Regressor
2023-11-04 23:33:19,720:INFO:Total runtime is 0.10114191770553589 minutes
2023-11-04 23:33:19,721:INFO:SubProcess create_model() called ==================================
2023-11-04 23:33:19,722:INFO:Initializing create_model()
2023-11-04 23:33:19,722:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb6109f26a0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614d71b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:19,722:INFO:Checking exceptions
2023-11-04 23:33:19,722:INFO:Importing libraries
2023-11-04 23:33:19,722:INFO:Copying training dataset
2023-11-04 23:33:19,724:INFO:Defining folds
2023-11-04 23:33:19,724:INFO:Declaring metric variables
2023-11-04 23:33:19,726:INFO:Importing untrained model
2023-11-04 23:33:19,727:INFO:AdaBoost Regressor Imported successfully
2023-11-04 23:33:19,731:INFO:Starting cross validation
2023-11-04 23:33:19,731:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:33:19,807:INFO:Calculating mean and std
2023-11-04 23:33:19,808:INFO:Creating metrics dataframe
2023-11-04 23:33:19,809:INFO:Uploading results into container
2023-11-04 23:33:19,810:INFO:Uploading model into container now
2023-11-04 23:33:19,810:INFO:_master_model_container: 15
2023-11-04 23:33:19,810:INFO:_display_container: 2
2023-11-04 23:33:19,810:INFO:AdaBoostRegressor(random_state=1707)
2023-11-04 23:33:19,810:INFO:create_model() successfully completed......................................
2023-11-04 23:33:19,954:INFO:SubProcess create_model() end ==================================
2023-11-04 23:33:19,954:INFO:Creating metrics dataframe
2023-11-04 23:33:19,961:INFO:Initializing Gradient Boosting Regressor
2023-11-04 23:33:19,961:INFO:Total runtime is 0.10516043106714884 minutes
2023-11-04 23:33:19,963:INFO:SubProcess create_model() called ==================================
2023-11-04 23:33:19,963:INFO:Initializing create_model()
2023-11-04 23:33:19,963:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb6109f26a0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614d71b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:19,963:INFO:Checking exceptions
2023-11-04 23:33:19,963:INFO:Importing libraries
2023-11-04 23:33:19,963:INFO:Copying training dataset
2023-11-04 23:33:19,965:INFO:Defining folds
2023-11-04 23:33:19,965:INFO:Declaring metric variables
2023-11-04 23:33:19,967:INFO:Importing untrained model
2023-11-04 23:33:19,969:INFO:Gradient Boosting Regressor Imported successfully
2023-11-04 23:33:19,972:INFO:Starting cross validation
2023-11-04 23:33:19,972:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:33:20,044:INFO:Calculating mean and std
2023-11-04 23:33:20,044:INFO:Creating metrics dataframe
2023-11-04 23:33:20,046:INFO:Uploading results into container
2023-11-04 23:33:20,046:INFO:Uploading model into container now
2023-11-04 23:33:20,046:INFO:_master_model_container: 16
2023-11-04 23:33:20,046:INFO:_display_container: 2
2023-11-04 23:33:20,047:INFO:GradientBoostingRegressor(random_state=1707)
2023-11-04 23:33:20,047:INFO:create_model() successfully completed......................................
2023-11-04 23:33:20,187:INFO:SubProcess create_model() end ==================================
2023-11-04 23:33:20,187:INFO:Creating metrics dataframe
2023-11-04 23:33:20,194:INFO:Initializing Extreme Gradient Boosting
2023-11-04 23:33:20,194:INFO:Total runtime is 0.10904494921366373 minutes
2023-11-04 23:33:20,196:INFO:SubProcess create_model() called ==================================
2023-11-04 23:33:20,196:INFO:Initializing create_model()
2023-11-04 23:33:20,196:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb6109f26a0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614d71b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:20,196:INFO:Checking exceptions
2023-11-04 23:33:20,196:INFO:Importing libraries
2023-11-04 23:33:20,196:INFO:Copying training dataset
2023-11-04 23:33:20,198:INFO:Defining folds
2023-11-04 23:33:20,198:INFO:Declaring metric variables
2023-11-04 23:33:20,200:INFO:Importing untrained model
2023-11-04 23:33:20,202:INFO:Extreme Gradient Boosting Imported successfully
2023-11-04 23:33:20,205:INFO:Starting cross validation
2023-11-04 23:33:20,206:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:33:20,308:INFO:Calculating mean and std
2023-11-04 23:33:20,309:INFO:Creating metrics dataframe
2023-11-04 23:33:20,312:INFO:Uploading results into container
2023-11-04 23:33:20,312:INFO:Uploading model into container now
2023-11-04 23:33:20,312:INFO:_master_model_container: 17
2023-11-04 23:33:20,312:INFO:_display_container: 2
2023-11-04 23:33:20,313:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=1707, ...)
2023-11-04 23:33:20,313:INFO:create_model() successfully completed......................................
2023-11-04 23:33:20,454:INFO:SubProcess create_model() end ==================================
2023-11-04 23:33:20,455:INFO:Creating metrics dataframe
2023-11-04 23:33:20,462:INFO:Initializing Light Gradient Boosting Machine
2023-11-04 23:33:20,462:INFO:Total runtime is 0.11351087888081868 minutes
2023-11-04 23:33:20,464:INFO:SubProcess create_model() called ==================================
2023-11-04 23:33:20,464:INFO:Initializing create_model()
2023-11-04 23:33:20,464:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb6109f26a0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614d71b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:20,464:INFO:Checking exceptions
2023-11-04 23:33:20,464:INFO:Importing libraries
2023-11-04 23:33:20,464:INFO:Copying training dataset
2023-11-04 23:33:20,466:INFO:Defining folds
2023-11-04 23:33:20,466:INFO:Declaring metric variables
2023-11-04 23:33:20,468:INFO:Importing untrained model
2023-11-04 23:33:20,470:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-04 23:33:20,473:INFO:Starting cross validation
2023-11-04 23:33:20,473:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:33:21,049:INFO:Calculating mean and std
2023-11-04 23:33:21,050:INFO:Creating metrics dataframe
2023-11-04 23:33:21,052:INFO:Uploading results into container
2023-11-04 23:33:21,052:INFO:Uploading model into container now
2023-11-04 23:33:21,053:INFO:_master_model_container: 18
2023-11-04 23:33:21,053:INFO:_display_container: 2
2023-11-04 23:33:21,053:INFO:LGBMRegressor(random_state=1707)
2023-11-04 23:33:21,053:INFO:create_model() successfully completed......................................
2023-11-04 23:33:21,188:INFO:SubProcess create_model() end ==================================
2023-11-04 23:33:21,188:INFO:Creating metrics dataframe
2023-11-04 23:33:21,195:INFO:Initializing CatBoost Regressor
2023-11-04 23:33:21,195:INFO:Total runtime is 0.12573511600494383 minutes
2023-11-04 23:33:21,197:INFO:SubProcess create_model() called ==================================
2023-11-04 23:33:21,197:INFO:Initializing create_model()
2023-11-04 23:33:21,197:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb6109f26a0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614d71b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:21,197:INFO:Checking exceptions
2023-11-04 23:33:21,197:INFO:Importing libraries
2023-11-04 23:33:21,198:INFO:Copying training dataset
2023-11-04 23:33:21,200:INFO:Defining folds
2023-11-04 23:33:21,200:INFO:Declaring metric variables
2023-11-04 23:33:21,201:INFO:Importing untrained model
2023-11-04 23:33:21,203:INFO:CatBoost Regressor Imported successfully
2023-11-04 23:33:21,206:INFO:Starting cross validation
2023-11-04 23:33:21,207:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:33:21,967:INFO:Calculating mean and std
2023-11-04 23:33:21,968:INFO:Creating metrics dataframe
2023-11-04 23:33:21,970:INFO:Uploading results into container
2023-11-04 23:33:21,970:INFO:Uploading model into container now
2023-11-04 23:33:21,971:INFO:_master_model_container: 19
2023-11-04 23:33:21,971:INFO:_display_container: 2
2023-11-04 23:33:21,971:INFO:<catboost.core.CatBoostRegressor object at 0x7fb5e6daf5e0>
2023-11-04 23:33:21,971:INFO:create_model() successfully completed......................................
2023-11-04 23:33:22,110:INFO:SubProcess create_model() end ==================================
2023-11-04 23:33:22,110:INFO:Creating metrics dataframe
2023-11-04 23:33:22,117:INFO:Initializing Dummy Regressor
2023-11-04 23:33:22,117:INFO:Total runtime is 0.1410970131556193 minutes
2023-11-04 23:33:22,119:INFO:SubProcess create_model() called ==================================
2023-11-04 23:33:22,119:INFO:Initializing create_model()
2023-11-04 23:33:22,119:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb6109f26a0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614d71b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:22,119:INFO:Checking exceptions
2023-11-04 23:33:22,119:INFO:Importing libraries
2023-11-04 23:33:22,119:INFO:Copying training dataset
2023-11-04 23:33:22,121:INFO:Defining folds
2023-11-04 23:33:22,122:INFO:Declaring metric variables
2023-11-04 23:33:22,123:INFO:Importing untrained model
2023-11-04 23:33:22,125:INFO:Dummy Regressor Imported successfully
2023-11-04 23:33:22,128:INFO:Starting cross validation
2023-11-04 23:33:22,129:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:33:22,183:INFO:Calculating mean and std
2023-11-04 23:33:22,183:INFO:Creating metrics dataframe
2023-11-04 23:33:22,185:INFO:Uploading results into container
2023-11-04 23:33:22,185:INFO:Uploading model into container now
2023-11-04 23:33:22,185:INFO:_master_model_container: 20
2023-11-04 23:33:22,185:INFO:_display_container: 2
2023-11-04 23:33:22,185:INFO:DummyRegressor()
2023-11-04 23:33:22,185:INFO:create_model() successfully completed......................................
2023-11-04 23:33:22,327:INFO:SubProcess create_model() end ==================================
2023-11-04 23:33:22,327:INFO:Creating metrics dataframe
2023-11-04 23:33:22,339:INFO:Initializing create_model()
2023-11-04 23:33:22,339:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb6109f26a0>, estimator=KNeighborsRegressor(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:22,339:INFO:Checking exceptions
2023-11-04 23:33:22,340:INFO:Importing libraries
2023-11-04 23:33:22,341:INFO:Copying training dataset
2023-11-04 23:33:22,342:INFO:Defining folds
2023-11-04 23:33:22,342:INFO:Declaring metric variables
2023-11-04 23:33:22,342:INFO:Importing untrained model
2023-11-04 23:33:22,343:INFO:Declaring custom model
2023-11-04 23:33:22,343:INFO:K Neighbors Regressor Imported successfully
2023-11-04 23:33:22,343:INFO:Cross validation set to False
2023-11-04 23:33:22,344:INFO:Fitting Model
2023-11-04 23:33:22,351:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-04 23:33:22,351:INFO:create_model() successfully completed......................................
2023-11-04 23:33:22,507:INFO:_master_model_container: 20
2023-11-04 23:33:22,507:INFO:_display_container: 2
2023-11-04 23:33:22,507:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-04 23:33:22,507:INFO:compare_models() successfully completed......................................
2023-11-04 23:33:40,100:INFO:PyCaret RegressionExperiment
2023-11-04 23:33:40,101:INFO:Logging name: reg-default-name
2023-11-04 23:33:40,101:INFO:ML Usecase: MLUsecase.REGRESSION
2023-11-04 23:33:40,101:INFO:version 3.1.0
2023-11-04 23:33:40,101:INFO:Initializing setup()
2023-11-04 23:33:40,101:INFO:self.USI: 4948
2023-11-04 23:33:40,101:INFO:self._variable_keys: {'X_test', 'logging_param', 'y_test', 'y_train', 'X_train', 'transform_target_param', 'target_param', 'pipeline', '_available_plots', 'log_plots_param', 'seed', 'exp_id', 'X', 'memory', 'fold_generator', 'fold_groups_param', 'html_param', 'idx', 'gpu_n_jobs_param', 'fold_shuffle_param', 'exp_name_log', 'USI', 'data', 'n_jobs_param', '_ml_usecase', 'gpu_param', 'y'}
2023-11-04 23:33:40,101:INFO:Checking environment
2023-11-04 23:33:40,101:INFO:python_version: 3.9.13
2023-11-04 23:33:40,101:INFO:python_build: ('main', 'Aug 25 2022 18:29:29')
2023-11-04 23:33:40,101:INFO:machine: x86_64
2023-11-04 23:33:40,101:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-11-04 23:33:40,101:INFO:Memory: svmem(total=17179869184, available=1368395776, percent=92.0, used=1852116992, free=15835136, active=1381810176, inactive=1350168576, wired=470306816)
2023-11-04 23:33:40,101:INFO:Physical Core: 8
2023-11-04 23:33:40,101:INFO:Logical Core: 8
2023-11-04 23:33:40,101:INFO:Checking libraries
2023-11-04 23:33:40,101:INFO:System:
2023-11-04 23:33:40,101:INFO:    python: 3.9.13 (main, Aug 25 2022, 18:29:29)  [Clang 12.0.0 ]
2023-11-04 23:33:40,101:INFO:executable: /Users/michal/opt/anaconda3/bin/python
2023-11-04 23:33:40,101:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-11-04 23:33:40,101:INFO:PyCaret required dependencies:
2023-11-04 23:33:40,101:INFO:                 pip: 22.2.2
2023-11-04 23:33:40,101:INFO:          setuptools: 63.4.1
2023-11-04 23:33:40,101:INFO:             pycaret: 3.1.0
2023-11-04 23:33:40,101:INFO:             IPython: 7.31.1
2023-11-04 23:33:40,101:INFO:          ipywidgets: 7.6.5
2023-11-04 23:33:40,101:INFO:                tqdm: 4.64.1
2023-11-04 23:33:40,101:INFO:               numpy: 1.21.5
2023-11-04 23:33:40,101:INFO:              pandas: 1.4.4
2023-11-04 23:33:40,101:INFO:              jinja2: 2.11.3
2023-11-04 23:33:40,101:INFO:               scipy: 1.10.1
2023-11-04 23:33:40,101:INFO:              joblib: 1.2.0
2023-11-04 23:33:40,101:INFO:             sklearn: 1.0.2
2023-11-04 23:33:40,101:INFO:                pyod: 1.1.1
2023-11-04 23:33:40,101:INFO:            imblearn: 0.10.1
2023-11-04 23:33:40,101:INFO:   category_encoders: 2.6.3
2023-11-04 23:33:40,101:INFO:            lightgbm: 3.3.5
2023-11-04 23:33:40,101:INFO:               numba: 0.55.1
2023-11-04 23:33:40,101:INFO:            requests: 2.28.1
2023-11-04 23:33:40,101:INFO:          matplotlib: 3.5.2
2023-11-04 23:33:40,101:INFO:          scikitplot: 0.3.7
2023-11-04 23:33:40,101:INFO:         yellowbrick: 1.5
2023-11-04 23:33:40,101:INFO:              plotly: 5.9.0
2023-11-04 23:33:40,101:INFO:    plotly-resampler: Not installed
2023-11-04 23:33:40,101:INFO:             kaleido: 0.2.1
2023-11-04 23:33:40,101:INFO:           schemdraw: 0.15
2023-11-04 23:33:40,101:INFO:         statsmodels: 0.13.2
2023-11-04 23:33:40,101:INFO:              sktime: 0.21.1
2023-11-04 23:33:40,101:INFO:               tbats: 1.1.3
2023-11-04 23:33:40,101:INFO:            pmdarima: 2.0.4
2023-11-04 23:33:40,101:INFO:              psutil: 5.9.0
2023-11-04 23:33:40,101:INFO:          markupsafe: 2.0.1
2023-11-04 23:33:40,101:INFO:             pickle5: Not installed
2023-11-04 23:33:40,102:INFO:         cloudpickle: 2.0.0
2023-11-04 23:33:40,102:INFO:         deprecation: 2.1.0
2023-11-04 23:33:40,102:INFO:              xxhash: 3.4.1
2023-11-04 23:33:40,102:INFO:           wurlitzer: 3.0.2
2023-11-04 23:33:40,102:INFO:PyCaret optional dependencies:
2023-11-04 23:33:40,102:INFO:                shap: 0.41.0
2023-11-04 23:33:40,102:INFO:           interpret: Not installed
2023-11-04 23:33:40,102:INFO:                umap: 0.5.3
2023-11-04 23:33:40,102:INFO:     ydata_profiling: Not installed
2023-11-04 23:33:40,102:INFO:  explainerdashboard: Not installed
2023-11-04 23:33:40,102:INFO:             autoviz: Not installed
2023-11-04 23:33:40,102:INFO:           fairlearn: Not installed
2023-11-04 23:33:40,102:INFO:          deepchecks: Not installed
2023-11-04 23:33:40,102:INFO:             xgboost: 1.7.4
2023-11-04 23:33:40,102:INFO:            catboost: 1.2
2023-11-04 23:33:40,102:INFO:              kmodes: Not installed
2023-11-04 23:33:40,102:INFO:             mlxtend: 0.21.0
2023-11-04 23:33:40,102:INFO:       statsforecast: Not installed
2023-11-04 23:33:40,102:INFO:        tune_sklearn: Not installed
2023-11-04 23:33:40,102:INFO:                 ray: Not installed
2023-11-04 23:33:40,102:INFO:            hyperopt: Not installed
2023-11-04 23:33:40,102:INFO:              optuna: Not installed
2023-11-04 23:33:40,102:INFO:               skopt: Not installed
2023-11-04 23:33:40,102:INFO:              mlflow: Not installed
2023-11-04 23:33:40,102:INFO:              gradio: Not installed
2023-11-04 23:33:40,102:INFO:             fastapi: Not installed
2023-11-04 23:33:40,102:INFO:             uvicorn: Not installed
2023-11-04 23:33:40,102:INFO:              m2cgen: Not installed
2023-11-04 23:33:40,102:INFO:           evidently: Not installed
2023-11-04 23:33:40,102:INFO:               fugue: Not installed
2023-11-04 23:33:40,102:INFO:           streamlit: Not installed
2023-11-04 23:33:40,102:INFO:             prophet: Not installed
2023-11-04 23:33:40,102:INFO:None
2023-11-04 23:33:40,102:INFO:Set up data.
2023-11-04 23:33:40,104:INFO:Set up folding strategy.
2023-11-04 23:33:40,104:INFO:Set up train/test split.
2023-11-04 23:33:40,105:INFO:Set up index.
2023-11-04 23:33:40,105:INFO:Assigning column types.
2023-11-04 23:33:40,106:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-04 23:33:40,106:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-04 23:33:40,109:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 23:33:40,113:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 23:33:40,148:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:33:40,176:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:33:40,177:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:33:40,178:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:33:40,179:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-04 23:33:40,182:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 23:33:40,185:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 23:33:40,220:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:33:40,248:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:33:40,248:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:33:40,250:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:33:40,250:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-11-04 23:33:40,253:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 23:33:40,256:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 23:33:40,291:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:33:40,320:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:33:40,320:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:33:40,322:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:33:40,325:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 23:33:40,328:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 23:33:40,363:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:33:40,390:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:33:40,391:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:33:40,392:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:33:40,393:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-11-04 23:33:40,398:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 23:33:40,434:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:33:40,462:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:33:40,463:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:33:40,464:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:33:40,470:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 23:33:40,506:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:33:40,534:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:33:40,534:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:33:40,536:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:33:40,536:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-11-04 23:33:40,577:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:33:40,605:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:33:40,605:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:33:40,607:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:33:40,649:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:33:40,676:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:33:40,679:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:33:40,681:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:33:40,681:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-04 23:33:40,721:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:33:40,749:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:33:40,750:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:33:40,791:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:33:40,819:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:33:40,820:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:33:40,821:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-11-04 23:33:40,888:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:33:40,889:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:33:40,956:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:33:40,958:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:33:40,959:INFO:Preparing preprocessing pipeline...
2023-11-04 23:33:40,959:INFO:Set up simple imputation.
2023-11-04 23:33:40,959:INFO:Set up variance threshold.
2023-11-04 23:33:40,959:INFO:Set up removing multicollinearity.
2023-11-04 23:33:40,959:INFO:Set up column name cleaning.
2023-11-04 23:33:40,976:INFO:Finished creating preprocessing pipeline.
2023-11-04 23:33:40,980:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/h9/5_75v3qs13x63s15wwxdrd000000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['sepal length (cm)',
                                             'petal length (cm)',
                                             'petal width (cm)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.1))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-11-04 23:33:40,980:INFO:Creating final display dataframe.
2023-11-04 23:33:41,023:INFO:Setup _display_container:                     Description             Value
0                    Session id              1902
1                        Target  sepal width (cm)
2                   Target type        Regression
3           Original data shape          (150, 4)
4        Transformed data shape          (150, 3)
5   Transformed train set shape          (105, 3)
6    Transformed test set shape           (45, 3)
7              Numeric features                 3
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12       Low variance threshold               0.1
13     Remove multicollinearity              True
14  Multicollinearity threshold              0.95
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              4948
2023-11-04 23:33:41,099:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:33:41,100:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:33:41,169:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:33:41,171:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:33:41,171:INFO:setup() successfully completed in 1.07s...............
2023-11-04 23:33:41,171:INFO:Initializing compare_models()
2023-11-04 23:33:41,172:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e68a9fa0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fb5e68a9fa0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-11-04 23:33:41,172:INFO:Checking exceptions
2023-11-04 23:33:41,172:INFO:Preparing display monitor
2023-11-04 23:33:41,190:INFO:Initializing Linear Regression
2023-11-04 23:33:41,190:INFO:Total runtime is 2.2490819295247396e-06 minutes
2023-11-04 23:33:41,192:INFO:SubProcess create_model() called ==================================
2023-11-04 23:33:41,192:INFO:Initializing create_model()
2023-11-04 23:33:41,192:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e68a9fa0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614b05ac0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:41,192:INFO:Checking exceptions
2023-11-04 23:33:41,192:INFO:Importing libraries
2023-11-04 23:33:41,192:INFO:Copying training dataset
2023-11-04 23:33:41,194:INFO:Defining folds
2023-11-04 23:33:41,194:INFO:Declaring metric variables
2023-11-04 23:33:41,196:INFO:Importing untrained model
2023-11-04 23:33:41,197:INFO:Linear Regression Imported successfully
2023-11-04 23:33:41,201:INFO:Starting cross validation
2023-11-04 23:33:41,201:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:33:41,250:INFO:Calculating mean and std
2023-11-04 23:33:41,250:INFO:Creating metrics dataframe
2023-11-04 23:33:41,252:INFO:Uploading results into container
2023-11-04 23:33:41,252:INFO:Uploading model into container now
2023-11-04 23:33:41,252:INFO:_master_model_container: 1
2023-11-04 23:33:41,252:INFO:_display_container: 2
2023-11-04 23:33:41,252:INFO:LinearRegression(n_jobs=-1)
2023-11-04 23:33:41,252:INFO:create_model() successfully completed......................................
2023-11-04 23:33:41,411:INFO:SubProcess create_model() end ==================================
2023-11-04 23:33:41,411:INFO:Creating metrics dataframe
2023-11-04 23:33:41,415:INFO:Initializing Lasso Regression
2023-11-04 23:33:41,415:INFO:Total runtime is 0.0037550171216328937 minutes
2023-11-04 23:33:41,417:INFO:SubProcess create_model() called ==================================
2023-11-04 23:33:41,417:INFO:Initializing create_model()
2023-11-04 23:33:41,417:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e68a9fa0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614b05ac0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:41,417:INFO:Checking exceptions
2023-11-04 23:33:41,417:INFO:Importing libraries
2023-11-04 23:33:41,418:INFO:Copying training dataset
2023-11-04 23:33:41,419:INFO:Defining folds
2023-11-04 23:33:41,419:INFO:Declaring metric variables
2023-11-04 23:33:41,420:INFO:Importing untrained model
2023-11-04 23:33:41,422:INFO:Lasso Regression Imported successfully
2023-11-04 23:33:41,425:INFO:Starting cross validation
2023-11-04 23:33:41,426:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:33:41,475:INFO:Calculating mean and std
2023-11-04 23:33:41,475:INFO:Creating metrics dataframe
2023-11-04 23:33:41,477:INFO:Uploading results into container
2023-11-04 23:33:41,477:INFO:Uploading model into container now
2023-11-04 23:33:41,478:INFO:_master_model_container: 2
2023-11-04 23:33:41,478:INFO:_display_container: 2
2023-11-04 23:33:41,478:INFO:Lasso(random_state=1902)
2023-11-04 23:33:41,478:INFO:create_model() successfully completed......................................
2023-11-04 23:33:41,614:INFO:SubProcess create_model() end ==================================
2023-11-04 23:33:41,615:INFO:Creating metrics dataframe
2023-11-04 23:33:41,619:INFO:Initializing Ridge Regression
2023-11-04 23:33:41,620:INFO:Total runtime is 0.007164283593495687 minutes
2023-11-04 23:33:41,621:INFO:SubProcess create_model() called ==================================
2023-11-04 23:33:41,622:INFO:Initializing create_model()
2023-11-04 23:33:41,622:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e68a9fa0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614b05ac0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:41,622:INFO:Checking exceptions
2023-11-04 23:33:41,622:INFO:Importing libraries
2023-11-04 23:33:41,622:INFO:Copying training dataset
2023-11-04 23:33:41,623:INFO:Defining folds
2023-11-04 23:33:41,623:INFO:Declaring metric variables
2023-11-04 23:33:41,625:INFO:Importing untrained model
2023-11-04 23:33:41,627:INFO:Ridge Regression Imported successfully
2023-11-04 23:33:41,630:INFO:Starting cross validation
2023-11-04 23:33:41,630:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:33:41,680:INFO:Calculating mean and std
2023-11-04 23:33:41,680:INFO:Creating metrics dataframe
2023-11-04 23:33:41,682:INFO:Uploading results into container
2023-11-04 23:33:41,682:INFO:Uploading model into container now
2023-11-04 23:33:41,683:INFO:_master_model_container: 3
2023-11-04 23:33:41,683:INFO:_display_container: 2
2023-11-04 23:33:41,683:INFO:Ridge(random_state=1902)
2023-11-04 23:33:41,683:INFO:create_model() successfully completed......................................
2023-11-04 23:33:41,820:INFO:SubProcess create_model() end ==================================
2023-11-04 23:33:41,820:INFO:Creating metrics dataframe
2023-11-04 23:33:41,825:INFO:Initializing Elastic Net
2023-11-04 23:33:41,825:INFO:Total runtime is 0.010595365365346273 minutes
2023-11-04 23:33:41,827:INFO:SubProcess create_model() called ==================================
2023-11-04 23:33:41,827:INFO:Initializing create_model()
2023-11-04 23:33:41,827:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e68a9fa0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614b05ac0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:41,828:INFO:Checking exceptions
2023-11-04 23:33:41,828:INFO:Importing libraries
2023-11-04 23:33:41,828:INFO:Copying training dataset
2023-11-04 23:33:41,829:INFO:Defining folds
2023-11-04 23:33:41,829:INFO:Declaring metric variables
2023-11-04 23:33:41,831:INFO:Importing untrained model
2023-11-04 23:33:41,832:INFO:Elastic Net Imported successfully
2023-11-04 23:33:41,836:INFO:Starting cross validation
2023-11-04 23:33:41,837:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:33:41,892:INFO:Calculating mean and std
2023-11-04 23:33:41,892:INFO:Creating metrics dataframe
2023-11-04 23:33:41,894:INFO:Uploading results into container
2023-11-04 23:33:41,894:INFO:Uploading model into container now
2023-11-04 23:33:41,894:INFO:_master_model_container: 4
2023-11-04 23:33:41,894:INFO:_display_container: 2
2023-11-04 23:33:41,894:INFO:ElasticNet(random_state=1902)
2023-11-04 23:33:41,894:INFO:create_model() successfully completed......................................
2023-11-04 23:33:42,030:INFO:SubProcess create_model() end ==================================
2023-11-04 23:33:42,030:INFO:Creating metrics dataframe
2023-11-04 23:33:42,035:INFO:Initializing Least Angle Regression
2023-11-04 23:33:42,035:INFO:Total runtime is 0.014093236128489176 minutes
2023-11-04 23:33:42,037:INFO:SubProcess create_model() called ==================================
2023-11-04 23:33:42,037:INFO:Initializing create_model()
2023-11-04 23:33:42,037:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e68a9fa0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614b05ac0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:42,037:INFO:Checking exceptions
2023-11-04 23:33:42,038:INFO:Importing libraries
2023-11-04 23:33:42,038:INFO:Copying training dataset
2023-11-04 23:33:42,039:INFO:Defining folds
2023-11-04 23:33:42,039:INFO:Declaring metric variables
2023-11-04 23:33:42,041:INFO:Importing untrained model
2023-11-04 23:33:42,042:INFO:Least Angle Regression Imported successfully
2023-11-04 23:33:42,045:INFO:Starting cross validation
2023-11-04 23:33:42,046:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:33:42,064:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:33:42,066:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:33:42,073:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:33:42,077:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:33:42,080:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:33:42,081:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:33:42,083:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:33:42,086:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:33:42,087:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:33:42,089:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:33:42,094:INFO:Calculating mean and std
2023-11-04 23:33:42,095:INFO:Creating metrics dataframe
2023-11-04 23:33:42,096:INFO:Uploading results into container
2023-11-04 23:33:42,097:INFO:Uploading model into container now
2023-11-04 23:33:42,097:INFO:_master_model_container: 5
2023-11-04 23:33:42,097:INFO:_display_container: 2
2023-11-04 23:33:42,097:INFO:Lars(random_state=1902)
2023-11-04 23:33:42,097:INFO:create_model() successfully completed......................................
2023-11-04 23:33:42,233:INFO:SubProcess create_model() end ==================================
2023-11-04 23:33:42,234:INFO:Creating metrics dataframe
2023-11-04 23:33:42,239:INFO:Initializing Lasso Least Angle Regression
2023-11-04 23:33:42,239:INFO:Total runtime is 0.017488785584767658 minutes
2023-11-04 23:33:42,241:INFO:SubProcess create_model() called ==================================
2023-11-04 23:33:42,241:INFO:Initializing create_model()
2023-11-04 23:33:42,241:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e68a9fa0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614b05ac0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:42,241:INFO:Checking exceptions
2023-11-04 23:33:42,241:INFO:Importing libraries
2023-11-04 23:33:42,241:INFO:Copying training dataset
2023-11-04 23:33:42,243:INFO:Defining folds
2023-11-04 23:33:42,244:INFO:Declaring metric variables
2023-11-04 23:33:42,245:INFO:Importing untrained model
2023-11-04 23:33:42,247:INFO:Lasso Least Angle Regression Imported successfully
2023-11-04 23:33:42,250:INFO:Starting cross validation
2023-11-04 23:33:42,251:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:33:42,267:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:33:42,273:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:33:42,282:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:33:42,282:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:33:42,286:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:33:42,287:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:33:42,294:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:33:42,295:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:33:42,296:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:33:42,297:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:33:42,302:INFO:Calculating mean and std
2023-11-04 23:33:42,302:INFO:Creating metrics dataframe
2023-11-04 23:33:42,304:INFO:Uploading results into container
2023-11-04 23:33:42,304:INFO:Uploading model into container now
2023-11-04 23:33:42,304:INFO:_master_model_container: 6
2023-11-04 23:33:42,304:INFO:_display_container: 2
2023-11-04 23:33:42,304:INFO:LassoLars(random_state=1902)
2023-11-04 23:33:42,304:INFO:create_model() successfully completed......................................
2023-11-04 23:33:42,441:INFO:SubProcess create_model() end ==================================
2023-11-04 23:33:42,441:INFO:Creating metrics dataframe
2023-11-04 23:33:42,446:INFO:Initializing Orthogonal Matching Pursuit
2023-11-04 23:33:42,446:INFO:Total runtime is 0.020940232276916503 minutes
2023-11-04 23:33:42,448:INFO:SubProcess create_model() called ==================================
2023-11-04 23:33:42,448:INFO:Initializing create_model()
2023-11-04 23:33:42,448:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e68a9fa0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614b05ac0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:42,448:INFO:Checking exceptions
2023-11-04 23:33:42,448:INFO:Importing libraries
2023-11-04 23:33:42,449:INFO:Copying training dataset
2023-11-04 23:33:42,451:INFO:Defining folds
2023-11-04 23:33:42,451:INFO:Declaring metric variables
2023-11-04 23:33:42,452:INFO:Importing untrained model
2023-11-04 23:33:42,454:INFO:Orthogonal Matching Pursuit Imported successfully
2023-11-04 23:33:42,457:INFO:Starting cross validation
2023-11-04 23:33:42,458:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:33:42,474:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:33:42,478:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:33:42,485:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:33:42,486:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:33:42,490:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:33:42,490:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:33:42,496:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:33:42,497:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:33:42,503:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:33:42,503:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:33:42,508:INFO:Calculating mean and std
2023-11-04 23:33:42,508:INFO:Creating metrics dataframe
2023-11-04 23:33:42,510:INFO:Uploading results into container
2023-11-04 23:33:42,510:INFO:Uploading model into container now
2023-11-04 23:33:42,511:INFO:_master_model_container: 7
2023-11-04 23:33:42,511:INFO:_display_container: 2
2023-11-04 23:33:42,511:INFO:OrthogonalMatchingPursuit()
2023-11-04 23:33:42,511:INFO:create_model() successfully completed......................................
2023-11-04 23:33:42,646:INFO:SubProcess create_model() end ==================================
2023-11-04 23:33:42,646:INFO:Creating metrics dataframe
2023-11-04 23:33:42,652:INFO:Initializing Bayesian Ridge
2023-11-04 23:33:42,652:INFO:Total runtime is 0.02436998685201009 minutes
2023-11-04 23:33:42,654:INFO:SubProcess create_model() called ==================================
2023-11-04 23:33:42,654:INFO:Initializing create_model()
2023-11-04 23:33:42,654:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e68a9fa0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614b05ac0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:42,654:INFO:Checking exceptions
2023-11-04 23:33:42,654:INFO:Importing libraries
2023-11-04 23:33:42,654:INFO:Copying training dataset
2023-11-04 23:33:42,656:INFO:Defining folds
2023-11-04 23:33:42,656:INFO:Declaring metric variables
2023-11-04 23:33:42,658:INFO:Importing untrained model
2023-11-04 23:33:42,660:INFO:Bayesian Ridge Imported successfully
2023-11-04 23:33:42,663:INFO:Starting cross validation
2023-11-04 23:33:42,664:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:33:42,717:INFO:Calculating mean and std
2023-11-04 23:33:42,718:INFO:Creating metrics dataframe
2023-11-04 23:33:42,719:INFO:Uploading results into container
2023-11-04 23:33:42,720:INFO:Uploading model into container now
2023-11-04 23:33:42,720:INFO:_master_model_container: 8
2023-11-04 23:33:42,720:INFO:_display_container: 2
2023-11-04 23:33:42,720:INFO:BayesianRidge()
2023-11-04 23:33:42,720:INFO:create_model() successfully completed......................................
2023-11-04 23:33:42,860:INFO:SubProcess create_model() end ==================================
2023-11-04 23:33:42,861:INFO:Creating metrics dataframe
2023-11-04 23:33:42,866:INFO:Initializing Passive Aggressive Regressor
2023-11-04 23:33:42,866:INFO:Total runtime is 0.027943948904673256 minutes
2023-11-04 23:33:42,868:INFO:SubProcess create_model() called ==================================
2023-11-04 23:33:42,868:INFO:Initializing create_model()
2023-11-04 23:33:42,869:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e68a9fa0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614b05ac0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:42,869:INFO:Checking exceptions
2023-11-04 23:33:42,869:INFO:Importing libraries
2023-11-04 23:33:42,869:INFO:Copying training dataset
2023-11-04 23:33:42,871:INFO:Defining folds
2023-11-04 23:33:42,871:INFO:Declaring metric variables
2023-11-04 23:33:42,873:INFO:Importing untrained model
2023-11-04 23:33:42,874:INFO:Passive Aggressive Regressor Imported successfully
2023-11-04 23:33:42,878:INFO:Starting cross validation
2023-11-04 23:33:42,878:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:33:42,928:INFO:Calculating mean and std
2023-11-04 23:33:42,929:INFO:Creating metrics dataframe
2023-11-04 23:33:42,930:INFO:Uploading results into container
2023-11-04 23:33:42,930:INFO:Uploading model into container now
2023-11-04 23:33:42,931:INFO:_master_model_container: 9
2023-11-04 23:33:42,931:INFO:_display_container: 2
2023-11-04 23:33:42,931:INFO:PassiveAggressiveRegressor(random_state=1902)
2023-11-04 23:33:42,931:INFO:create_model() successfully completed......................................
2023-11-04 23:33:43,071:INFO:SubProcess create_model() end ==================================
2023-11-04 23:33:43,071:INFO:Creating metrics dataframe
2023-11-04 23:33:43,077:INFO:Initializing Huber Regressor
2023-11-04 23:33:43,077:INFO:Total runtime is 0.03145140012105306 minutes
2023-11-04 23:33:43,079:INFO:SubProcess create_model() called ==================================
2023-11-04 23:33:43,079:INFO:Initializing create_model()
2023-11-04 23:33:43,079:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e68a9fa0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614b05ac0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:43,079:INFO:Checking exceptions
2023-11-04 23:33:43,079:INFO:Importing libraries
2023-11-04 23:33:43,079:INFO:Copying training dataset
2023-11-04 23:33:43,081:INFO:Defining folds
2023-11-04 23:33:43,081:INFO:Declaring metric variables
2023-11-04 23:33:43,083:INFO:Importing untrained model
2023-11-04 23:33:43,085:INFO:Huber Regressor Imported successfully
2023-11-04 23:33:43,088:INFO:Starting cross validation
2023-11-04 23:33:43,088:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:33:43,144:INFO:Calculating mean and std
2023-11-04 23:33:43,144:INFO:Creating metrics dataframe
2023-11-04 23:33:43,146:INFO:Uploading results into container
2023-11-04 23:33:43,146:INFO:Uploading model into container now
2023-11-04 23:33:43,147:INFO:_master_model_container: 10
2023-11-04 23:33:43,147:INFO:_display_container: 2
2023-11-04 23:33:43,147:INFO:HuberRegressor()
2023-11-04 23:33:43,147:INFO:create_model() successfully completed......................................
2023-11-04 23:33:43,291:INFO:SubProcess create_model() end ==================================
2023-11-04 23:33:43,291:INFO:Creating metrics dataframe
2023-11-04 23:33:43,297:INFO:Initializing K Neighbors Regressor
2023-11-04 23:33:43,297:INFO:Total runtime is 0.03512311379114787 minutes
2023-11-04 23:33:43,299:INFO:SubProcess create_model() called ==================================
2023-11-04 23:33:43,299:INFO:Initializing create_model()
2023-11-04 23:33:43,299:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e68a9fa0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614b05ac0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:43,299:INFO:Checking exceptions
2023-11-04 23:33:43,300:INFO:Importing libraries
2023-11-04 23:33:43,300:INFO:Copying training dataset
2023-11-04 23:33:43,302:INFO:Defining folds
2023-11-04 23:33:43,302:INFO:Declaring metric variables
2023-11-04 23:33:43,303:INFO:Importing untrained model
2023-11-04 23:33:43,305:INFO:K Neighbors Regressor Imported successfully
2023-11-04 23:33:43,308:INFO:Starting cross validation
2023-11-04 23:33:43,309:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:33:43,370:INFO:Calculating mean and std
2023-11-04 23:33:43,371:INFO:Creating metrics dataframe
2023-11-04 23:33:43,372:INFO:Uploading results into container
2023-11-04 23:33:43,372:INFO:Uploading model into container now
2023-11-04 23:33:43,373:INFO:_master_model_container: 11
2023-11-04 23:33:43,373:INFO:_display_container: 2
2023-11-04 23:33:43,373:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-04 23:33:43,373:INFO:create_model() successfully completed......................................
2023-11-04 23:33:43,509:INFO:SubProcess create_model() end ==================================
2023-11-04 23:33:43,509:INFO:Creating metrics dataframe
2023-11-04 23:33:43,515:INFO:Initializing Decision Tree Regressor
2023-11-04 23:33:43,515:INFO:Total runtime is 0.038756565252939856 minutes
2023-11-04 23:33:43,517:INFO:SubProcess create_model() called ==================================
2023-11-04 23:33:43,517:INFO:Initializing create_model()
2023-11-04 23:33:43,517:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e68a9fa0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614b05ac0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:43,517:INFO:Checking exceptions
2023-11-04 23:33:43,517:INFO:Importing libraries
2023-11-04 23:33:43,518:INFO:Copying training dataset
2023-11-04 23:33:43,520:INFO:Defining folds
2023-11-04 23:33:43,520:INFO:Declaring metric variables
2023-11-04 23:33:43,521:INFO:Importing untrained model
2023-11-04 23:33:43,523:INFO:Decision Tree Regressor Imported successfully
2023-11-04 23:33:43,526:INFO:Starting cross validation
2023-11-04 23:33:43,527:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:33:43,580:INFO:Calculating mean and std
2023-11-04 23:33:43,580:INFO:Creating metrics dataframe
2023-11-04 23:33:43,582:INFO:Uploading results into container
2023-11-04 23:33:43,582:INFO:Uploading model into container now
2023-11-04 23:33:43,582:INFO:_master_model_container: 12
2023-11-04 23:33:43,582:INFO:_display_container: 2
2023-11-04 23:33:43,582:INFO:DecisionTreeRegressor(random_state=1902)
2023-11-04 23:33:43,582:INFO:create_model() successfully completed......................................
2023-11-04 23:33:43,718:INFO:SubProcess create_model() end ==================================
2023-11-04 23:33:43,718:INFO:Creating metrics dataframe
2023-11-04 23:33:43,725:INFO:Initializing Random Forest Regressor
2023-11-04 23:33:43,725:INFO:Total runtime is 0.042249504725138345 minutes
2023-11-04 23:33:43,727:INFO:SubProcess create_model() called ==================================
2023-11-04 23:33:43,727:INFO:Initializing create_model()
2023-11-04 23:33:43,727:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e68a9fa0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614b05ac0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:43,727:INFO:Checking exceptions
2023-11-04 23:33:43,727:INFO:Importing libraries
2023-11-04 23:33:43,727:INFO:Copying training dataset
2023-11-04 23:33:43,729:INFO:Defining folds
2023-11-04 23:33:43,729:INFO:Declaring metric variables
2023-11-04 23:33:43,731:INFO:Importing untrained model
2023-11-04 23:33:43,733:INFO:Random Forest Regressor Imported successfully
2023-11-04 23:33:43,737:INFO:Starting cross validation
2023-11-04 23:33:43,737:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:33:43,978:INFO:Calculating mean and std
2023-11-04 23:33:43,979:INFO:Creating metrics dataframe
2023-11-04 23:33:43,981:INFO:Uploading results into container
2023-11-04 23:33:43,981:INFO:Uploading model into container now
2023-11-04 23:33:43,981:INFO:_master_model_container: 13
2023-11-04 23:33:43,982:INFO:_display_container: 2
2023-11-04 23:33:43,982:INFO:RandomForestRegressor(n_jobs=-1, random_state=1902)
2023-11-04 23:33:43,982:INFO:create_model() successfully completed......................................
2023-11-04 23:33:44,123:INFO:SubProcess create_model() end ==================================
2023-11-04 23:33:44,123:INFO:Creating metrics dataframe
2023-11-04 23:33:44,129:INFO:Initializing Extra Trees Regressor
2023-11-04 23:33:44,129:INFO:Total runtime is 0.04899600346883138 minutes
2023-11-04 23:33:44,131:INFO:SubProcess create_model() called ==================================
2023-11-04 23:33:44,131:INFO:Initializing create_model()
2023-11-04 23:33:44,132:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e68a9fa0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614b05ac0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:44,132:INFO:Checking exceptions
2023-11-04 23:33:44,132:INFO:Importing libraries
2023-11-04 23:33:44,132:INFO:Copying training dataset
2023-11-04 23:33:44,134:INFO:Defining folds
2023-11-04 23:33:44,134:INFO:Declaring metric variables
2023-11-04 23:33:44,136:INFO:Importing untrained model
2023-11-04 23:33:44,137:INFO:Extra Trees Regressor Imported successfully
2023-11-04 23:33:44,140:INFO:Starting cross validation
2023-11-04 23:33:44,141:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:33:44,337:INFO:Calculating mean and std
2023-11-04 23:33:44,338:INFO:Creating metrics dataframe
2023-11-04 23:33:44,340:INFO:Uploading results into container
2023-11-04 23:33:44,340:INFO:Uploading model into container now
2023-11-04 23:33:44,341:INFO:_master_model_container: 14
2023-11-04 23:33:44,341:INFO:_display_container: 2
2023-11-04 23:33:44,341:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1902)
2023-11-04 23:33:44,341:INFO:create_model() successfully completed......................................
2023-11-04 23:33:44,476:INFO:SubProcess create_model() end ==================================
2023-11-04 23:33:44,477:INFO:Creating metrics dataframe
2023-11-04 23:33:44,483:INFO:Initializing AdaBoost Regressor
2023-11-04 23:33:44,483:INFO:Total runtime is 0.054889249801635745 minutes
2023-11-04 23:33:44,485:INFO:SubProcess create_model() called ==================================
2023-11-04 23:33:44,485:INFO:Initializing create_model()
2023-11-04 23:33:44,485:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e68a9fa0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614b05ac0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:44,485:INFO:Checking exceptions
2023-11-04 23:33:44,485:INFO:Importing libraries
2023-11-04 23:33:44,486:INFO:Copying training dataset
2023-11-04 23:33:44,487:INFO:Defining folds
2023-11-04 23:33:44,488:INFO:Declaring metric variables
2023-11-04 23:33:44,489:INFO:Importing untrained model
2023-11-04 23:33:44,491:INFO:AdaBoost Regressor Imported successfully
2023-11-04 23:33:44,494:INFO:Starting cross validation
2023-11-04 23:33:44,495:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:33:44,581:INFO:Calculating mean and std
2023-11-04 23:33:44,582:INFO:Creating metrics dataframe
2023-11-04 23:33:44,583:INFO:Uploading results into container
2023-11-04 23:33:44,584:INFO:Uploading model into container now
2023-11-04 23:33:44,584:INFO:_master_model_container: 15
2023-11-04 23:33:44,584:INFO:_display_container: 2
2023-11-04 23:33:44,584:INFO:AdaBoostRegressor(random_state=1902)
2023-11-04 23:33:44,584:INFO:create_model() successfully completed......................................
2023-11-04 23:33:44,722:INFO:SubProcess create_model() end ==================================
2023-11-04 23:33:44,722:INFO:Creating metrics dataframe
2023-11-04 23:33:44,728:INFO:Initializing Gradient Boosting Regressor
2023-11-04 23:33:44,729:INFO:Total runtime is 0.05898096561431885 minutes
2023-11-04 23:33:44,730:INFO:SubProcess create_model() called ==================================
2023-11-04 23:33:44,731:INFO:Initializing create_model()
2023-11-04 23:33:44,731:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e68a9fa0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614b05ac0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:44,731:INFO:Checking exceptions
2023-11-04 23:33:44,731:INFO:Importing libraries
2023-11-04 23:33:44,731:INFO:Copying training dataset
2023-11-04 23:33:44,733:INFO:Defining folds
2023-11-04 23:33:44,733:INFO:Declaring metric variables
2023-11-04 23:33:44,735:INFO:Importing untrained model
2023-11-04 23:33:44,737:INFO:Gradient Boosting Regressor Imported successfully
2023-11-04 23:33:44,740:INFO:Starting cross validation
2023-11-04 23:33:44,740:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:33:44,813:INFO:Calculating mean and std
2023-11-04 23:33:44,813:INFO:Creating metrics dataframe
2023-11-04 23:33:44,815:INFO:Uploading results into container
2023-11-04 23:33:44,815:INFO:Uploading model into container now
2023-11-04 23:33:44,815:INFO:_master_model_container: 16
2023-11-04 23:33:44,815:INFO:_display_container: 2
2023-11-04 23:33:44,816:INFO:GradientBoostingRegressor(random_state=1902)
2023-11-04 23:33:44,816:INFO:create_model() successfully completed......................................
2023-11-04 23:33:44,957:INFO:SubProcess create_model() end ==================================
2023-11-04 23:33:44,957:INFO:Creating metrics dataframe
2023-11-04 23:33:44,964:INFO:Initializing Extreme Gradient Boosting
2023-11-04 23:33:44,964:INFO:Total runtime is 0.06290335257848104 minutes
2023-11-04 23:33:44,966:INFO:SubProcess create_model() called ==================================
2023-11-04 23:33:44,966:INFO:Initializing create_model()
2023-11-04 23:33:44,966:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e68a9fa0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614b05ac0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:44,966:INFO:Checking exceptions
2023-11-04 23:33:44,966:INFO:Importing libraries
2023-11-04 23:33:44,966:INFO:Copying training dataset
2023-11-04 23:33:44,968:INFO:Defining folds
2023-11-04 23:33:44,969:INFO:Declaring metric variables
2023-11-04 23:33:44,970:INFO:Importing untrained model
2023-11-04 23:33:44,972:INFO:Extreme Gradient Boosting Imported successfully
2023-11-04 23:33:44,975:INFO:Starting cross validation
2023-11-04 23:33:44,976:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:33:45,051:INFO:Calculating mean and std
2023-11-04 23:33:45,052:INFO:Creating metrics dataframe
2023-11-04 23:33:45,053:INFO:Uploading results into container
2023-11-04 23:33:45,054:INFO:Uploading model into container now
2023-11-04 23:33:45,054:INFO:_master_model_container: 17
2023-11-04 23:33:45,054:INFO:_display_container: 2
2023-11-04 23:33:45,054:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=1902, ...)
2023-11-04 23:33:45,054:INFO:create_model() successfully completed......................................
2023-11-04 23:33:45,192:INFO:SubProcess create_model() end ==================================
2023-11-04 23:33:45,193:INFO:Creating metrics dataframe
2023-11-04 23:33:45,200:INFO:Initializing Light Gradient Boosting Machine
2023-11-04 23:33:45,200:INFO:Total runtime is 0.06683340072631835 minutes
2023-11-04 23:33:45,202:INFO:SubProcess create_model() called ==================================
2023-11-04 23:33:45,202:INFO:Initializing create_model()
2023-11-04 23:33:45,202:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e68a9fa0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614b05ac0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:45,202:INFO:Checking exceptions
2023-11-04 23:33:45,202:INFO:Importing libraries
2023-11-04 23:33:45,202:INFO:Copying training dataset
2023-11-04 23:33:45,204:INFO:Defining folds
2023-11-04 23:33:45,204:INFO:Declaring metric variables
2023-11-04 23:33:45,206:INFO:Importing untrained model
2023-11-04 23:33:45,208:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-04 23:33:45,211:INFO:Starting cross validation
2023-11-04 23:33:45,211:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:33:45,273:INFO:Calculating mean and std
2023-11-04 23:33:45,273:INFO:Creating metrics dataframe
2023-11-04 23:33:45,275:INFO:Uploading results into container
2023-11-04 23:33:45,275:INFO:Uploading model into container now
2023-11-04 23:33:45,275:INFO:_master_model_container: 18
2023-11-04 23:33:45,275:INFO:_display_container: 2
2023-11-04 23:33:45,275:INFO:LGBMRegressor(random_state=1902)
2023-11-04 23:33:45,275:INFO:create_model() successfully completed......................................
2023-11-04 23:33:45,412:INFO:SubProcess create_model() end ==================================
2023-11-04 23:33:45,412:INFO:Creating metrics dataframe
2023-11-04 23:33:45,419:INFO:Initializing CatBoost Regressor
2023-11-04 23:33:45,419:INFO:Total runtime is 0.07048759857813516 minutes
2023-11-04 23:33:45,421:INFO:SubProcess create_model() called ==================================
2023-11-04 23:33:45,421:INFO:Initializing create_model()
2023-11-04 23:33:45,421:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e68a9fa0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614b05ac0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:45,421:INFO:Checking exceptions
2023-11-04 23:33:45,421:INFO:Importing libraries
2023-11-04 23:33:45,421:INFO:Copying training dataset
2023-11-04 23:33:45,423:INFO:Defining folds
2023-11-04 23:33:45,423:INFO:Declaring metric variables
2023-11-04 23:33:45,425:INFO:Importing untrained model
2023-11-04 23:33:45,427:INFO:CatBoost Regressor Imported successfully
2023-11-04 23:33:45,430:INFO:Starting cross validation
2023-11-04 23:33:45,431:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:33:45,773:INFO:Calculating mean and std
2023-11-04 23:33:45,774:INFO:Creating metrics dataframe
2023-11-04 23:33:45,776:INFO:Uploading results into container
2023-11-04 23:33:45,776:INFO:Uploading model into container now
2023-11-04 23:33:45,776:INFO:_master_model_container: 19
2023-11-04 23:33:45,776:INFO:_display_container: 2
2023-11-04 23:33:45,776:INFO:<catboost.core.CatBoostRegressor object at 0x7fb5f0e10fa0>
2023-11-04 23:33:45,777:INFO:create_model() successfully completed......................................
2023-11-04 23:33:45,914:INFO:SubProcess create_model() end ==================================
2023-11-04 23:33:45,914:INFO:Creating metrics dataframe
2023-11-04 23:33:45,922:INFO:Initializing Dummy Regressor
2023-11-04 23:33:45,922:INFO:Total runtime is 0.0788661519686381 minutes
2023-11-04 23:33:45,923:INFO:SubProcess create_model() called ==================================
2023-11-04 23:33:45,924:INFO:Initializing create_model()
2023-11-04 23:33:45,924:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e68a9fa0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614b05ac0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:45,924:INFO:Checking exceptions
2023-11-04 23:33:45,924:INFO:Importing libraries
2023-11-04 23:33:45,924:INFO:Copying training dataset
2023-11-04 23:33:45,926:INFO:Defining folds
2023-11-04 23:33:45,926:INFO:Declaring metric variables
2023-11-04 23:33:45,928:INFO:Importing untrained model
2023-11-04 23:33:45,930:INFO:Dummy Regressor Imported successfully
2023-11-04 23:33:45,933:INFO:Starting cross validation
2023-11-04 23:33:45,933:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:33:45,981:INFO:Calculating mean and std
2023-11-04 23:33:45,981:INFO:Creating metrics dataframe
2023-11-04 23:33:45,983:INFO:Uploading results into container
2023-11-04 23:33:45,983:INFO:Uploading model into container now
2023-11-04 23:33:45,984:INFO:_master_model_container: 20
2023-11-04 23:33:45,984:INFO:_display_container: 2
2023-11-04 23:33:45,984:INFO:DummyRegressor()
2023-11-04 23:33:45,984:INFO:create_model() successfully completed......................................
2023-11-04 23:33:46,127:INFO:SubProcess create_model() end ==================================
2023-11-04 23:33:46,127:INFO:Creating metrics dataframe
2023-11-04 23:33:46,139:INFO:Initializing create_model()
2023-11-04 23:33:46,139:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e68a9fa0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=1902), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:46,139:INFO:Checking exceptions
2023-11-04 23:33:46,140:INFO:Importing libraries
2023-11-04 23:33:46,141:INFO:Copying training dataset
2023-11-04 23:33:46,142:INFO:Defining folds
2023-11-04 23:33:46,142:INFO:Declaring metric variables
2023-11-04 23:33:46,142:INFO:Importing untrained model
2023-11-04 23:33:46,142:INFO:Declaring custom model
2023-11-04 23:33:46,143:INFO:Random Forest Regressor Imported successfully
2023-11-04 23:33:46,143:INFO:Cross validation set to False
2023-11-04 23:33:46,143:INFO:Fitting Model
2023-11-04 23:33:46,218:INFO:RandomForestRegressor(n_jobs=-1, random_state=1902)
2023-11-04 23:33:46,218:INFO:create_model() successfully completed......................................
2023-11-04 23:33:46,373:INFO:_master_model_container: 20
2023-11-04 23:33:46,373:INFO:_display_container: 2
2023-11-04 23:33:46,373:INFO:RandomForestRegressor(n_jobs=-1, random_state=1902)
2023-11-04 23:33:46,373:INFO:compare_models() successfully completed......................................
2023-11-04 23:33:58,550:INFO:PyCaret RegressionExperiment
2023-11-04 23:33:58,551:INFO:Logging name: reg-default-name
2023-11-04 23:33:58,551:INFO:ML Usecase: MLUsecase.REGRESSION
2023-11-04 23:33:58,551:INFO:version 3.1.0
2023-11-04 23:33:58,551:INFO:Initializing setup()
2023-11-04 23:33:58,551:INFO:self.USI: f0ce
2023-11-04 23:33:58,551:INFO:self._variable_keys: {'X_test', 'logging_param', 'y_test', 'y_train', 'X_train', 'transform_target_param', 'target_param', 'pipeline', '_available_plots', 'log_plots_param', 'seed', 'exp_id', 'X', 'memory', 'fold_generator', 'fold_groups_param', 'html_param', 'idx', 'gpu_n_jobs_param', 'fold_shuffle_param', 'exp_name_log', 'USI', 'data', 'n_jobs_param', '_ml_usecase', 'gpu_param', 'y'}
2023-11-04 23:33:58,551:INFO:Checking environment
2023-11-04 23:33:58,552:INFO:python_version: 3.9.13
2023-11-04 23:33:58,552:INFO:python_build: ('main', 'Aug 25 2022 18:29:29')
2023-11-04 23:33:58,552:INFO:machine: x86_64
2023-11-04 23:33:58,552:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-11-04 23:33:58,552:INFO:Memory: svmem(total=17179869184, available=1381679104, percent=92.0, used=1851342848, free=19628032, active=1381838848, inactive=1358557184, wired=469504000)
2023-11-04 23:33:58,552:INFO:Physical Core: 8
2023-11-04 23:33:58,552:INFO:Logical Core: 8
2023-11-04 23:33:58,552:INFO:Checking libraries
2023-11-04 23:33:58,552:INFO:System:
2023-11-04 23:33:58,552:INFO:    python: 3.9.13 (main, Aug 25 2022, 18:29:29)  [Clang 12.0.0 ]
2023-11-04 23:33:58,553:INFO:executable: /Users/michal/opt/anaconda3/bin/python
2023-11-04 23:33:58,553:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-11-04 23:33:58,553:INFO:PyCaret required dependencies:
2023-11-04 23:33:58,553:INFO:                 pip: 22.2.2
2023-11-04 23:33:58,553:INFO:          setuptools: 63.4.1
2023-11-04 23:33:58,553:INFO:             pycaret: 3.1.0
2023-11-04 23:33:58,553:INFO:             IPython: 7.31.1
2023-11-04 23:33:58,553:INFO:          ipywidgets: 7.6.5
2023-11-04 23:33:58,553:INFO:                tqdm: 4.64.1
2023-11-04 23:33:58,553:INFO:               numpy: 1.21.5
2023-11-04 23:33:58,553:INFO:              pandas: 1.4.4
2023-11-04 23:33:58,553:INFO:              jinja2: 2.11.3
2023-11-04 23:33:58,553:INFO:               scipy: 1.10.1
2023-11-04 23:33:58,553:INFO:              joblib: 1.2.0
2023-11-04 23:33:58,553:INFO:             sklearn: 1.0.2
2023-11-04 23:33:58,553:INFO:                pyod: 1.1.1
2023-11-04 23:33:58,553:INFO:            imblearn: 0.10.1
2023-11-04 23:33:58,553:INFO:   category_encoders: 2.6.3
2023-11-04 23:33:58,554:INFO:            lightgbm: 3.3.5
2023-11-04 23:33:58,554:INFO:               numba: 0.55.1
2023-11-04 23:33:58,554:INFO:            requests: 2.28.1
2023-11-04 23:33:58,554:INFO:          matplotlib: 3.5.2
2023-11-04 23:33:58,554:INFO:          scikitplot: 0.3.7
2023-11-04 23:33:58,554:INFO:         yellowbrick: 1.5
2023-11-04 23:33:58,554:INFO:              plotly: 5.9.0
2023-11-04 23:33:58,554:INFO:    plotly-resampler: Not installed
2023-11-04 23:33:58,554:INFO:             kaleido: 0.2.1
2023-11-04 23:33:58,554:INFO:           schemdraw: 0.15
2023-11-04 23:33:58,554:INFO:         statsmodels: 0.13.2
2023-11-04 23:33:58,554:INFO:              sktime: 0.21.1
2023-11-04 23:33:58,554:INFO:               tbats: 1.1.3
2023-11-04 23:33:58,554:INFO:            pmdarima: 2.0.4
2023-11-04 23:33:58,554:INFO:              psutil: 5.9.0
2023-11-04 23:33:58,554:INFO:          markupsafe: 2.0.1
2023-11-04 23:33:58,554:INFO:             pickle5: Not installed
2023-11-04 23:33:58,554:INFO:         cloudpickle: 2.0.0
2023-11-04 23:33:58,554:INFO:         deprecation: 2.1.0
2023-11-04 23:33:58,554:INFO:              xxhash: 3.4.1
2023-11-04 23:33:58,554:INFO:           wurlitzer: 3.0.2
2023-11-04 23:33:58,555:INFO:PyCaret optional dependencies:
2023-11-04 23:33:58,555:INFO:                shap: 0.41.0
2023-11-04 23:33:58,555:INFO:           interpret: Not installed
2023-11-04 23:33:58,555:INFO:                umap: 0.5.3
2023-11-04 23:33:58,555:INFO:     ydata_profiling: Not installed
2023-11-04 23:33:58,555:INFO:  explainerdashboard: Not installed
2023-11-04 23:33:58,555:INFO:             autoviz: Not installed
2023-11-04 23:33:58,555:INFO:           fairlearn: Not installed
2023-11-04 23:33:58,555:INFO:          deepchecks: Not installed
2023-11-04 23:33:58,555:INFO:             xgboost: 1.7.4
2023-11-04 23:33:58,555:INFO:            catboost: 1.2
2023-11-04 23:33:58,555:INFO:              kmodes: Not installed
2023-11-04 23:33:58,555:INFO:             mlxtend: 0.21.0
2023-11-04 23:33:58,555:INFO:       statsforecast: Not installed
2023-11-04 23:33:58,555:INFO:        tune_sklearn: Not installed
2023-11-04 23:33:58,555:INFO:                 ray: Not installed
2023-11-04 23:33:58,555:INFO:            hyperopt: Not installed
2023-11-04 23:33:58,556:INFO:              optuna: Not installed
2023-11-04 23:33:58,556:INFO:               skopt: Not installed
2023-11-04 23:33:58,556:INFO:              mlflow: Not installed
2023-11-04 23:33:58,556:INFO:              gradio: Not installed
2023-11-04 23:33:58,556:INFO:             fastapi: Not installed
2023-11-04 23:33:58,556:INFO:             uvicorn: Not installed
2023-11-04 23:33:58,556:INFO:              m2cgen: Not installed
2023-11-04 23:33:58,556:INFO:           evidently: Not installed
2023-11-04 23:33:58,556:INFO:               fugue: Not installed
2023-11-04 23:33:58,556:INFO:           streamlit: Not installed
2023-11-04 23:33:58,556:INFO:             prophet: Not installed
2023-11-04 23:33:58,556:INFO:None
2023-11-04 23:33:58,556:INFO:Set up data.
2023-11-04 23:33:58,562:INFO:Set up folding strategy.
2023-11-04 23:33:58,562:INFO:Set up train/test split.
2023-11-04 23:33:58,565:INFO:Set up index.
2023-11-04 23:33:58,565:INFO:Assigning column types.
2023-11-04 23:33:58,567:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-04 23:33:58,567:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-04 23:33:58,570:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 23:33:58,572:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 23:33:58,607:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:33:58,633:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:33:58,634:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:33:58,635:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:33:58,636:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-04 23:33:58,639:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 23:33:58,641:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 23:33:58,675:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:33:58,702:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:33:58,702:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:33:58,703:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:33:58,704:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-11-04 23:33:58,706:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 23:33:58,709:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 23:33:58,743:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:33:58,769:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:33:58,770:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:33:58,771:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:33:58,774:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 23:33:58,777:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 23:33:58,812:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:33:58,838:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:33:58,839:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:33:58,840:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:33:58,840:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-11-04 23:33:58,846:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 23:33:58,880:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:33:58,906:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:33:58,906:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:33:58,908:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:33:58,913:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 23:33:58,947:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:33:58,972:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:33:58,973:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:33:58,974:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:33:58,974:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-11-04 23:33:59,012:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:33:59,039:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:33:59,039:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:33:59,040:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:33:59,079:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:33:59,104:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:33:59,105:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:33:59,106:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:33:59,106:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-04 23:33:59,144:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:33:59,170:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:33:59,171:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:33:59,209:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:33:59,235:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:33:59,237:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:33:59,237:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-11-04 23:33:59,301:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:33:59,302:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:33:59,369:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:33:59,371:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:33:59,371:INFO:Preparing preprocessing pipeline...
2023-11-04 23:33:59,371:INFO:Set up simple imputation.
2023-11-04 23:33:59,371:INFO:Set up variance threshold.
2023-11-04 23:33:59,371:INFO:Set up removing multicollinearity.
2023-11-04 23:33:59,372:INFO:Set up column name cleaning.
2023-11-04 23:33:59,387:INFO:Finished creating preprocessing pipeline.
2023-11-04 23:33:59,391:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/h9/5_75v3qs13x63s15wwxdrd000000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['sepal length (cm)',
                                             'petal length (cm)',
                                             'petal width (cm)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.1))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-11-04 23:33:59,391:INFO:Creating final display dataframe.
2023-11-04 23:33:59,433:INFO:Setup _display_container:                     Description             Value
0                    Session id              8452
1                        Target  sepal width (cm)
2                   Target type        Regression
3           Original data shape          (322, 4)
4        Transformed data shape          (322, 3)
5   Transformed train set shape          (225, 3)
6    Transformed test set shape           (97, 3)
7              Numeric features                 3
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12       Low variance threshold               0.1
13     Remove multicollinearity              True
14  Multicollinearity threshold              0.95
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              f0ce
2023-11-04 23:33:59,501:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:33:59,502:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:33:59,568:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:33:59,570:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:33:59,570:INFO:setup() successfully completed in 1.02s...............
2023-11-04 23:33:59,570:INFO:Initializing compare_models()
2023-11-04 23:33:59,570:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb61435c250>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fb61435c250>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-11-04 23:33:59,570:INFO:Checking exceptions
2023-11-04 23:33:59,571:INFO:Preparing display monitor
2023-11-04 23:33:59,587:INFO:Initializing Linear Regression
2023-11-04 23:33:59,587:INFO:Total runtime is 1.923243204752604e-06 minutes
2023-11-04 23:33:59,589:INFO:SubProcess create_model() called ==================================
2023-11-04 23:33:59,590:INFO:Initializing create_model()
2023-11-04 23:33:59,590:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb61435c250>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb5e5e09ee0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:59,590:INFO:Checking exceptions
2023-11-04 23:33:59,590:INFO:Importing libraries
2023-11-04 23:33:59,590:INFO:Copying training dataset
2023-11-04 23:33:59,592:INFO:Defining folds
2023-11-04 23:33:59,592:INFO:Declaring metric variables
2023-11-04 23:33:59,594:INFO:Importing untrained model
2023-11-04 23:33:59,595:INFO:Linear Regression Imported successfully
2023-11-04 23:33:59,599:INFO:Starting cross validation
2023-11-04 23:33:59,599:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:33:59,656:INFO:Calculating mean and std
2023-11-04 23:33:59,657:INFO:Creating metrics dataframe
2023-11-04 23:33:59,658:INFO:Uploading results into container
2023-11-04 23:33:59,659:INFO:Uploading model into container now
2023-11-04 23:33:59,659:INFO:_master_model_container: 1
2023-11-04 23:33:59,659:INFO:_display_container: 2
2023-11-04 23:33:59,659:INFO:LinearRegression(n_jobs=-1)
2023-11-04 23:33:59,659:INFO:create_model() successfully completed......................................
2023-11-04 23:33:59,801:INFO:SubProcess create_model() end ==================================
2023-11-04 23:33:59,801:INFO:Creating metrics dataframe
2023-11-04 23:33:59,805:INFO:Initializing Lasso Regression
2023-11-04 23:33:59,805:INFO:Total runtime is 0.003627920150756836 minutes
2023-11-04 23:33:59,807:INFO:SubProcess create_model() called ==================================
2023-11-04 23:33:59,807:INFO:Initializing create_model()
2023-11-04 23:33:59,807:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb61435c250>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb5e5e09ee0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:33:59,807:INFO:Checking exceptions
2023-11-04 23:33:59,807:INFO:Importing libraries
2023-11-04 23:33:59,807:INFO:Copying training dataset
2023-11-04 23:33:59,809:INFO:Defining folds
2023-11-04 23:33:59,809:INFO:Declaring metric variables
2023-11-04 23:33:59,810:INFO:Importing untrained model
2023-11-04 23:33:59,812:INFO:Lasso Regression Imported successfully
2023-11-04 23:33:59,815:INFO:Starting cross validation
2023-11-04 23:33:59,816:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:33:59,866:INFO:Calculating mean and std
2023-11-04 23:33:59,866:INFO:Creating metrics dataframe
2023-11-04 23:33:59,868:INFO:Uploading results into container
2023-11-04 23:33:59,868:INFO:Uploading model into container now
2023-11-04 23:33:59,868:INFO:_master_model_container: 2
2023-11-04 23:33:59,868:INFO:_display_container: 2
2023-11-04 23:33:59,868:INFO:Lasso(random_state=8452)
2023-11-04 23:33:59,868:INFO:create_model() successfully completed......................................
2023-11-04 23:34:00,003:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:00,003:INFO:Creating metrics dataframe
2023-11-04 23:34:00,008:INFO:Initializing Ridge Regression
2023-11-04 23:34:00,008:INFO:Total runtime is 0.007015633583068848 minutes
2023-11-04 23:34:00,010:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:00,010:INFO:Initializing create_model()
2023-11-04 23:34:00,010:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb61435c250>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb5e5e09ee0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:00,010:INFO:Checking exceptions
2023-11-04 23:34:00,010:INFO:Importing libraries
2023-11-04 23:34:00,010:INFO:Copying training dataset
2023-11-04 23:34:00,012:INFO:Defining folds
2023-11-04 23:34:00,012:INFO:Declaring metric variables
2023-11-04 23:34:00,014:INFO:Importing untrained model
2023-11-04 23:34:00,015:INFO:Ridge Regression Imported successfully
2023-11-04 23:34:00,018:INFO:Starting cross validation
2023-11-04 23:34:00,019:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:00,069:INFO:Calculating mean and std
2023-11-04 23:34:00,069:INFO:Creating metrics dataframe
2023-11-04 23:34:00,071:INFO:Uploading results into container
2023-11-04 23:34:00,071:INFO:Uploading model into container now
2023-11-04 23:34:00,071:INFO:_master_model_container: 3
2023-11-04 23:34:00,071:INFO:_display_container: 2
2023-11-04 23:34:00,071:INFO:Ridge(random_state=8452)
2023-11-04 23:34:00,071:INFO:create_model() successfully completed......................................
2023-11-04 23:34:00,207:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:00,207:INFO:Creating metrics dataframe
2023-11-04 23:34:00,212:INFO:Initializing Elastic Net
2023-11-04 23:34:00,212:INFO:Total runtime is 0.010413618882497151 minutes
2023-11-04 23:34:00,214:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:00,214:INFO:Initializing create_model()
2023-11-04 23:34:00,214:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb61435c250>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb5e5e09ee0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:00,214:INFO:Checking exceptions
2023-11-04 23:34:00,214:INFO:Importing libraries
2023-11-04 23:34:00,215:INFO:Copying training dataset
2023-11-04 23:34:00,216:INFO:Defining folds
2023-11-04 23:34:00,216:INFO:Declaring metric variables
2023-11-04 23:34:00,217:INFO:Importing untrained model
2023-11-04 23:34:00,219:INFO:Elastic Net Imported successfully
2023-11-04 23:34:00,222:INFO:Starting cross validation
2023-11-04 23:34:00,223:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:00,276:INFO:Calculating mean and std
2023-11-04 23:34:00,276:INFO:Creating metrics dataframe
2023-11-04 23:34:00,278:INFO:Uploading results into container
2023-11-04 23:34:00,278:INFO:Uploading model into container now
2023-11-04 23:34:00,278:INFO:_master_model_container: 4
2023-11-04 23:34:00,278:INFO:_display_container: 2
2023-11-04 23:34:00,278:INFO:ElasticNet(random_state=8452)
2023-11-04 23:34:00,278:INFO:create_model() successfully completed......................................
2023-11-04 23:34:00,419:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:00,419:INFO:Creating metrics dataframe
2023-11-04 23:34:00,424:INFO:Initializing Least Angle Regression
2023-11-04 23:34:00,424:INFO:Total runtime is 0.013944470882415771 minutes
2023-11-04 23:34:00,426:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:00,426:INFO:Initializing create_model()
2023-11-04 23:34:00,426:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb61435c250>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb5e5e09ee0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:00,426:INFO:Checking exceptions
2023-11-04 23:34:00,426:INFO:Importing libraries
2023-11-04 23:34:00,426:INFO:Copying training dataset
2023-11-04 23:34:00,428:INFO:Defining folds
2023-11-04 23:34:00,428:INFO:Declaring metric variables
2023-11-04 23:34:00,429:INFO:Importing untrained model
2023-11-04 23:34:00,431:INFO:Least Angle Regression Imported successfully
2023-11-04 23:34:00,434:INFO:Starting cross validation
2023-11-04 23:34:00,435:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:00,452:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:00,462:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:00,463:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:00,469:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:00,471:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:00,474:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:00,478:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:00,480:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:00,481:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:00,484:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:00,490:INFO:Calculating mean and std
2023-11-04 23:34:00,490:INFO:Creating metrics dataframe
2023-11-04 23:34:00,492:INFO:Uploading results into container
2023-11-04 23:34:00,492:INFO:Uploading model into container now
2023-11-04 23:34:00,492:INFO:_master_model_container: 5
2023-11-04 23:34:00,492:INFO:_display_container: 2
2023-11-04 23:34:00,492:INFO:Lars(random_state=8452)
2023-11-04 23:34:00,492:INFO:create_model() successfully completed......................................
2023-11-04 23:34:00,633:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:00,633:INFO:Creating metrics dataframe
2023-11-04 23:34:00,638:INFO:Initializing Lasso Least Angle Regression
2023-11-04 23:34:00,638:INFO:Total runtime is 0.017517534891764323 minutes
2023-11-04 23:34:00,640:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:00,640:INFO:Initializing create_model()
2023-11-04 23:34:00,641:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb61435c250>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb5e5e09ee0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:00,641:INFO:Checking exceptions
2023-11-04 23:34:00,641:INFO:Importing libraries
2023-11-04 23:34:00,641:INFO:Copying training dataset
2023-11-04 23:34:00,643:INFO:Defining folds
2023-11-04 23:34:00,643:INFO:Declaring metric variables
2023-11-04 23:34:00,645:INFO:Importing untrained model
2023-11-04 23:34:00,647:INFO:Lasso Least Angle Regression Imported successfully
2023-11-04 23:34:00,650:INFO:Starting cross validation
2023-11-04 23:34:00,650:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:00,668:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:34:00,670:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:34:00,674:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:34:00,683:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:34:00,684:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:34:00,686:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:34:00,687:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:34:00,688:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:34:00,690:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:34:00,698:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:34:00,702:INFO:Calculating mean and std
2023-11-04 23:34:00,703:INFO:Creating metrics dataframe
2023-11-04 23:34:00,704:INFO:Uploading results into container
2023-11-04 23:34:00,705:INFO:Uploading model into container now
2023-11-04 23:34:00,705:INFO:_master_model_container: 6
2023-11-04 23:34:00,705:INFO:_display_container: 2
2023-11-04 23:34:00,705:INFO:LassoLars(random_state=8452)
2023-11-04 23:34:00,705:INFO:create_model() successfully completed......................................
2023-11-04 23:34:00,844:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:00,844:INFO:Creating metrics dataframe
2023-11-04 23:34:00,849:INFO:Initializing Orthogonal Matching Pursuit
2023-11-04 23:34:00,849:INFO:Total runtime is 0.02103646993637085 minutes
2023-11-04 23:34:00,851:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:00,851:INFO:Initializing create_model()
2023-11-04 23:34:00,851:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb61435c250>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb5e5e09ee0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:00,851:INFO:Checking exceptions
2023-11-04 23:34:00,852:INFO:Importing libraries
2023-11-04 23:34:00,852:INFO:Copying training dataset
2023-11-04 23:34:00,854:INFO:Defining folds
2023-11-04 23:34:00,854:INFO:Declaring metric variables
2023-11-04 23:34:00,856:INFO:Importing untrained model
2023-11-04 23:34:00,857:INFO:Orthogonal Matching Pursuit Imported successfully
2023-11-04 23:34:00,860:INFO:Starting cross validation
2023-11-04 23:34:00,861:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:00,880:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:00,883:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:00,885:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:00,889:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:00,900:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:00,901:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:00,902:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:00,903:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:00,905:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:00,906:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:00,912:INFO:Calculating mean and std
2023-11-04 23:34:00,912:INFO:Creating metrics dataframe
2023-11-04 23:34:00,914:INFO:Uploading results into container
2023-11-04 23:34:00,914:INFO:Uploading model into container now
2023-11-04 23:34:00,914:INFO:_master_model_container: 7
2023-11-04 23:34:00,914:INFO:_display_container: 2
2023-11-04 23:34:00,914:INFO:OrthogonalMatchingPursuit()
2023-11-04 23:34:00,914:INFO:create_model() successfully completed......................................
2023-11-04 23:34:01,055:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:01,055:INFO:Creating metrics dataframe
2023-11-04 23:34:01,061:INFO:Initializing Bayesian Ridge
2023-11-04 23:34:01,061:INFO:Total runtime is 0.024556589126586915 minutes
2023-11-04 23:34:01,062:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:01,063:INFO:Initializing create_model()
2023-11-04 23:34:01,063:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb61435c250>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb5e5e09ee0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:01,063:INFO:Checking exceptions
2023-11-04 23:34:01,063:INFO:Importing libraries
2023-11-04 23:34:01,063:INFO:Copying training dataset
2023-11-04 23:34:01,065:INFO:Defining folds
2023-11-04 23:34:01,065:INFO:Declaring metric variables
2023-11-04 23:34:01,067:INFO:Importing untrained model
2023-11-04 23:34:01,069:INFO:Bayesian Ridge Imported successfully
2023-11-04 23:34:01,072:INFO:Starting cross validation
2023-11-04 23:34:01,072:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:01,127:INFO:Calculating mean and std
2023-11-04 23:34:01,128:INFO:Creating metrics dataframe
2023-11-04 23:34:01,129:INFO:Uploading results into container
2023-11-04 23:34:01,130:INFO:Uploading model into container now
2023-11-04 23:34:01,130:INFO:_master_model_container: 8
2023-11-04 23:34:01,130:INFO:_display_container: 2
2023-11-04 23:34:01,130:INFO:BayesianRidge()
2023-11-04 23:34:01,130:INFO:create_model() successfully completed......................................
2023-11-04 23:34:01,264:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:01,264:INFO:Creating metrics dataframe
2023-11-04 23:34:01,270:INFO:Initializing Passive Aggressive Regressor
2023-11-04 23:34:01,270:INFO:Total runtime is 0.02804551919301351 minutes
2023-11-04 23:34:01,272:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:01,272:INFO:Initializing create_model()
2023-11-04 23:34:01,272:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb61435c250>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb5e5e09ee0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:01,272:INFO:Checking exceptions
2023-11-04 23:34:01,272:INFO:Importing libraries
2023-11-04 23:34:01,272:INFO:Copying training dataset
2023-11-04 23:34:01,274:INFO:Defining folds
2023-11-04 23:34:01,274:INFO:Declaring metric variables
2023-11-04 23:34:01,276:INFO:Importing untrained model
2023-11-04 23:34:01,278:INFO:Passive Aggressive Regressor Imported successfully
2023-11-04 23:34:01,281:INFO:Starting cross validation
2023-11-04 23:34:01,281:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:01,339:INFO:Calculating mean and std
2023-11-04 23:34:01,339:INFO:Creating metrics dataframe
2023-11-04 23:34:01,341:INFO:Uploading results into container
2023-11-04 23:34:01,341:INFO:Uploading model into container now
2023-11-04 23:34:01,342:INFO:_master_model_container: 9
2023-11-04 23:34:01,342:INFO:_display_container: 2
2023-11-04 23:34:01,342:INFO:PassiveAggressiveRegressor(random_state=8452)
2023-11-04 23:34:01,342:INFO:create_model() successfully completed......................................
2023-11-04 23:34:01,476:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:01,476:INFO:Creating metrics dataframe
2023-11-04 23:34:01,482:INFO:Initializing Huber Regressor
2023-11-04 23:34:01,482:INFO:Total runtime is 0.031574904918670654 minutes
2023-11-04 23:34:01,484:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:01,484:INFO:Initializing create_model()
2023-11-04 23:34:01,484:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb61435c250>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb5e5e09ee0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:01,484:INFO:Checking exceptions
2023-11-04 23:34:01,484:INFO:Importing libraries
2023-11-04 23:34:01,484:INFO:Copying training dataset
2023-11-04 23:34:01,486:INFO:Defining folds
2023-11-04 23:34:01,486:INFO:Declaring metric variables
2023-11-04 23:34:01,488:INFO:Importing untrained model
2023-11-04 23:34:01,489:INFO:Huber Regressor Imported successfully
2023-11-04 23:34:01,493:INFO:Starting cross validation
2023-11-04 23:34:01,493:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:01,553:INFO:Calculating mean and std
2023-11-04 23:34:01,553:INFO:Creating metrics dataframe
2023-11-04 23:34:01,555:INFO:Uploading results into container
2023-11-04 23:34:01,555:INFO:Uploading model into container now
2023-11-04 23:34:01,556:INFO:_master_model_container: 10
2023-11-04 23:34:01,556:INFO:_display_container: 2
2023-11-04 23:34:01,556:INFO:HuberRegressor()
2023-11-04 23:34:01,556:INFO:create_model() successfully completed......................................
2023-11-04 23:34:01,690:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:01,690:INFO:Creating metrics dataframe
2023-11-04 23:34:01,696:INFO:Initializing K Neighbors Regressor
2023-11-04 23:34:01,696:INFO:Total runtime is 0.03514616886774699 minutes
2023-11-04 23:34:01,698:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:01,698:INFO:Initializing create_model()
2023-11-04 23:34:01,698:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb61435c250>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb5e5e09ee0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:01,698:INFO:Checking exceptions
2023-11-04 23:34:01,698:INFO:Importing libraries
2023-11-04 23:34:01,698:INFO:Copying training dataset
2023-11-04 23:34:01,700:INFO:Defining folds
2023-11-04 23:34:01,700:INFO:Declaring metric variables
2023-11-04 23:34:01,702:INFO:Importing untrained model
2023-11-04 23:34:01,704:INFO:K Neighbors Regressor Imported successfully
2023-11-04 23:34:01,707:INFO:Starting cross validation
2023-11-04 23:34:01,707:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:01,768:INFO:Calculating mean and std
2023-11-04 23:34:01,768:INFO:Creating metrics dataframe
2023-11-04 23:34:01,770:INFO:Uploading results into container
2023-11-04 23:34:01,770:INFO:Uploading model into container now
2023-11-04 23:34:01,770:INFO:_master_model_container: 11
2023-11-04 23:34:01,770:INFO:_display_container: 2
2023-11-04 23:34:01,771:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-04 23:34:01,771:INFO:create_model() successfully completed......................................
2023-11-04 23:34:01,905:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:01,905:INFO:Creating metrics dataframe
2023-11-04 23:34:01,911:INFO:Initializing Decision Tree Regressor
2023-11-04 23:34:01,911:INFO:Total runtime is 0.03872652053833008 minutes
2023-11-04 23:34:01,913:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:01,913:INFO:Initializing create_model()
2023-11-04 23:34:01,913:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb61435c250>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb5e5e09ee0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:01,913:INFO:Checking exceptions
2023-11-04 23:34:01,913:INFO:Importing libraries
2023-11-04 23:34:01,913:INFO:Copying training dataset
2023-11-04 23:34:01,915:INFO:Defining folds
2023-11-04 23:34:01,915:INFO:Declaring metric variables
2023-11-04 23:34:01,917:INFO:Importing untrained model
2023-11-04 23:34:01,919:INFO:Decision Tree Regressor Imported successfully
2023-11-04 23:34:01,922:INFO:Starting cross validation
2023-11-04 23:34:01,922:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:01,977:INFO:Calculating mean and std
2023-11-04 23:34:01,978:INFO:Creating metrics dataframe
2023-11-04 23:34:01,979:INFO:Uploading results into container
2023-11-04 23:34:01,979:INFO:Uploading model into container now
2023-11-04 23:34:01,980:INFO:_master_model_container: 12
2023-11-04 23:34:01,980:INFO:_display_container: 2
2023-11-04 23:34:01,980:INFO:DecisionTreeRegressor(random_state=8452)
2023-11-04 23:34:01,980:INFO:create_model() successfully completed......................................
2023-11-04 23:34:02,114:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:02,114:INFO:Creating metrics dataframe
2023-11-04 23:34:02,121:INFO:Initializing Random Forest Regressor
2023-11-04 23:34:02,121:INFO:Total runtime is 0.042223370075225836 minutes
2023-11-04 23:34:02,122:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:02,123:INFO:Initializing create_model()
2023-11-04 23:34:02,123:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb61435c250>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb5e5e09ee0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:02,123:INFO:Checking exceptions
2023-11-04 23:34:02,123:INFO:Importing libraries
2023-11-04 23:34:02,123:INFO:Copying training dataset
2023-11-04 23:34:02,125:INFO:Defining folds
2023-11-04 23:34:02,125:INFO:Declaring metric variables
2023-11-04 23:34:02,127:INFO:Importing untrained model
2023-11-04 23:34:02,128:INFO:Random Forest Regressor Imported successfully
2023-11-04 23:34:02,131:INFO:Starting cross validation
2023-11-04 23:34:02,132:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:02,399:INFO:Calculating mean and std
2023-11-04 23:34:02,400:INFO:Creating metrics dataframe
2023-11-04 23:34:02,401:INFO:Uploading results into container
2023-11-04 23:34:02,402:INFO:Uploading model into container now
2023-11-04 23:34:02,402:INFO:_master_model_container: 13
2023-11-04 23:34:02,402:INFO:_display_container: 2
2023-11-04 23:34:02,402:INFO:RandomForestRegressor(n_jobs=-1, random_state=8452)
2023-11-04 23:34:02,402:INFO:create_model() successfully completed......................................
2023-11-04 23:34:02,537:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:02,537:INFO:Creating metrics dataframe
2023-11-04 23:34:02,543:INFO:Initializing Extra Trees Regressor
2023-11-04 23:34:02,544:INFO:Total runtime is 0.0492710828781128 minutes
2023-11-04 23:34:02,545:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:02,546:INFO:Initializing create_model()
2023-11-04 23:34:02,546:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb61435c250>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb5e5e09ee0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:02,546:INFO:Checking exceptions
2023-11-04 23:34:02,546:INFO:Importing libraries
2023-11-04 23:34:02,546:INFO:Copying training dataset
2023-11-04 23:34:02,548:INFO:Defining folds
2023-11-04 23:34:02,548:INFO:Declaring metric variables
2023-11-04 23:34:02,550:INFO:Importing untrained model
2023-11-04 23:34:02,551:INFO:Extra Trees Regressor Imported successfully
2023-11-04 23:34:02,554:INFO:Starting cross validation
2023-11-04 23:34:02,555:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:02,766:INFO:Calculating mean and std
2023-11-04 23:34:02,767:INFO:Creating metrics dataframe
2023-11-04 23:34:02,769:INFO:Uploading results into container
2023-11-04 23:34:02,769:INFO:Uploading model into container now
2023-11-04 23:34:02,769:INFO:_master_model_container: 14
2023-11-04 23:34:02,769:INFO:_display_container: 2
2023-11-04 23:34:02,770:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=8452)
2023-11-04 23:34:02,770:INFO:create_model() successfully completed......................................
2023-11-04 23:34:02,905:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:02,905:INFO:Creating metrics dataframe
2023-11-04 23:34:02,912:INFO:Initializing AdaBoost Regressor
2023-11-04 23:34:02,912:INFO:Total runtime is 0.055405318737030036 minutes
2023-11-04 23:34:02,913:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:02,914:INFO:Initializing create_model()
2023-11-04 23:34:02,914:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb61435c250>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb5e5e09ee0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:02,914:INFO:Checking exceptions
2023-11-04 23:34:02,914:INFO:Importing libraries
2023-11-04 23:34:02,914:INFO:Copying training dataset
2023-11-04 23:34:02,916:INFO:Defining folds
2023-11-04 23:34:02,916:INFO:Declaring metric variables
2023-11-04 23:34:02,918:INFO:Importing untrained model
2023-11-04 23:34:02,919:INFO:AdaBoost Regressor Imported successfully
2023-11-04 23:34:02,923:INFO:Starting cross validation
2023-11-04 23:34:02,923:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:03,006:INFO:Calculating mean and std
2023-11-04 23:34:03,007:INFO:Creating metrics dataframe
2023-11-04 23:34:03,008:INFO:Uploading results into container
2023-11-04 23:34:03,009:INFO:Uploading model into container now
2023-11-04 23:34:03,009:INFO:_master_model_container: 15
2023-11-04 23:34:03,009:INFO:_display_container: 2
2023-11-04 23:34:03,009:INFO:AdaBoostRegressor(random_state=8452)
2023-11-04 23:34:03,009:INFO:create_model() successfully completed......................................
2023-11-04 23:34:03,143:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:03,143:INFO:Creating metrics dataframe
2023-11-04 23:34:03,150:INFO:Initializing Gradient Boosting Regressor
2023-11-04 23:34:03,150:INFO:Total runtime is 0.059373605251312266 minutes
2023-11-04 23:34:03,151:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:03,152:INFO:Initializing create_model()
2023-11-04 23:34:03,152:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb61435c250>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb5e5e09ee0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:03,152:INFO:Checking exceptions
2023-11-04 23:34:03,152:INFO:Importing libraries
2023-11-04 23:34:03,152:INFO:Copying training dataset
2023-11-04 23:34:03,154:INFO:Defining folds
2023-11-04 23:34:03,154:INFO:Declaring metric variables
2023-11-04 23:34:03,156:INFO:Importing untrained model
2023-11-04 23:34:03,157:INFO:Gradient Boosting Regressor Imported successfully
2023-11-04 23:34:03,160:INFO:Starting cross validation
2023-11-04 23:34:03,161:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:03,236:INFO:Calculating mean and std
2023-11-04 23:34:03,236:INFO:Creating metrics dataframe
2023-11-04 23:34:03,238:INFO:Uploading results into container
2023-11-04 23:34:03,238:INFO:Uploading model into container now
2023-11-04 23:34:03,238:INFO:_master_model_container: 16
2023-11-04 23:34:03,238:INFO:_display_container: 2
2023-11-04 23:34:03,239:INFO:GradientBoostingRegressor(random_state=8452)
2023-11-04 23:34:03,239:INFO:create_model() successfully completed......................................
2023-11-04 23:34:03,373:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:03,373:INFO:Creating metrics dataframe
2023-11-04 23:34:03,380:INFO:Initializing Extreme Gradient Boosting
2023-11-04 23:34:03,380:INFO:Total runtime is 0.06321535110473633 minutes
2023-11-04 23:34:03,382:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:03,382:INFO:Initializing create_model()
2023-11-04 23:34:03,382:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb61435c250>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb5e5e09ee0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:03,382:INFO:Checking exceptions
2023-11-04 23:34:03,383:INFO:Importing libraries
2023-11-04 23:34:03,383:INFO:Copying training dataset
2023-11-04 23:34:03,384:INFO:Defining folds
2023-11-04 23:34:03,385:INFO:Declaring metric variables
2023-11-04 23:34:03,386:INFO:Importing untrained model
2023-11-04 23:34:03,388:INFO:Extreme Gradient Boosting Imported successfully
2023-11-04 23:34:03,391:INFO:Starting cross validation
2023-11-04 23:34:03,392:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:03,478:INFO:Calculating mean and std
2023-11-04 23:34:03,479:INFO:Creating metrics dataframe
2023-11-04 23:34:03,480:INFO:Uploading results into container
2023-11-04 23:34:03,481:INFO:Uploading model into container now
2023-11-04 23:34:03,481:INFO:_master_model_container: 17
2023-11-04 23:34:03,481:INFO:_display_container: 2
2023-11-04 23:34:03,481:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=8452, ...)
2023-11-04 23:34:03,481:INFO:create_model() successfully completed......................................
2023-11-04 23:34:03,615:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:03,616:INFO:Creating metrics dataframe
2023-11-04 23:34:03,623:INFO:Initializing Light Gradient Boosting Machine
2023-11-04 23:34:03,623:INFO:Total runtime is 0.06725606918334961 minutes
2023-11-04 23:34:03,624:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:03,625:INFO:Initializing create_model()
2023-11-04 23:34:03,625:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb61435c250>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb5e5e09ee0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:03,625:INFO:Checking exceptions
2023-11-04 23:34:03,625:INFO:Importing libraries
2023-11-04 23:34:03,625:INFO:Copying training dataset
2023-11-04 23:34:03,627:INFO:Defining folds
2023-11-04 23:34:03,627:INFO:Declaring metric variables
2023-11-04 23:34:03,629:INFO:Importing untrained model
2023-11-04 23:34:03,631:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-04 23:34:03,634:INFO:Starting cross validation
2023-11-04 23:34:03,634:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:03,695:INFO:Calculating mean and std
2023-11-04 23:34:03,695:INFO:Creating metrics dataframe
2023-11-04 23:34:03,697:INFO:Uploading results into container
2023-11-04 23:34:03,697:INFO:Uploading model into container now
2023-11-04 23:34:03,697:INFO:_master_model_container: 18
2023-11-04 23:34:03,697:INFO:_display_container: 2
2023-11-04 23:34:03,698:INFO:LGBMRegressor(random_state=8452)
2023-11-04 23:34:03,698:INFO:create_model() successfully completed......................................
2023-11-04 23:34:03,833:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:03,834:INFO:Creating metrics dataframe
2023-11-04 23:34:03,841:INFO:Initializing CatBoost Regressor
2023-11-04 23:34:03,841:INFO:Total runtime is 0.07089055379231772 minutes
2023-11-04 23:34:03,842:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:03,843:INFO:Initializing create_model()
2023-11-04 23:34:03,843:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb61435c250>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb5e5e09ee0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:03,843:INFO:Checking exceptions
2023-11-04 23:34:03,843:INFO:Importing libraries
2023-11-04 23:34:03,843:INFO:Copying training dataset
2023-11-04 23:34:03,845:INFO:Defining folds
2023-11-04 23:34:03,845:INFO:Declaring metric variables
2023-11-04 23:34:03,847:INFO:Importing untrained model
2023-11-04 23:34:03,848:INFO:CatBoost Regressor Imported successfully
2023-11-04 23:34:03,851:INFO:Starting cross validation
2023-11-04 23:34:03,852:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:04,590:INFO:Calculating mean and std
2023-11-04 23:34:04,591:INFO:Creating metrics dataframe
2023-11-04 23:34:04,593:INFO:Uploading results into container
2023-11-04 23:34:04,593:INFO:Uploading model into container now
2023-11-04 23:34:04,594:INFO:_master_model_container: 19
2023-11-04 23:34:04,594:INFO:_display_container: 2
2023-11-04 23:34:04,594:INFO:<catboost.core.CatBoostRegressor object at 0x7fb5f0a60880>
2023-11-04 23:34:04,594:INFO:create_model() successfully completed......................................
2023-11-04 23:34:04,736:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:04,736:INFO:Creating metrics dataframe
2023-11-04 23:34:04,744:INFO:Initializing Dummy Regressor
2023-11-04 23:34:04,744:INFO:Total runtime is 0.08594011863072715 minutes
2023-11-04 23:34:04,746:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:04,746:INFO:Initializing create_model()
2023-11-04 23:34:04,746:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb61435c250>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb5e5e09ee0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:04,746:INFO:Checking exceptions
2023-11-04 23:34:04,746:INFO:Importing libraries
2023-11-04 23:34:04,746:INFO:Copying training dataset
2023-11-04 23:34:04,748:INFO:Defining folds
2023-11-04 23:34:04,748:INFO:Declaring metric variables
2023-11-04 23:34:04,750:INFO:Importing untrained model
2023-11-04 23:34:04,752:INFO:Dummy Regressor Imported successfully
2023-11-04 23:34:04,755:INFO:Starting cross validation
2023-11-04 23:34:04,756:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:04,801:INFO:Calculating mean and std
2023-11-04 23:34:04,801:INFO:Creating metrics dataframe
2023-11-04 23:34:04,803:INFO:Uploading results into container
2023-11-04 23:34:04,803:INFO:Uploading model into container now
2023-11-04 23:34:04,803:INFO:_master_model_container: 20
2023-11-04 23:34:04,803:INFO:_display_container: 2
2023-11-04 23:34:04,803:INFO:DummyRegressor()
2023-11-04 23:34:04,803:INFO:create_model() successfully completed......................................
2023-11-04 23:34:04,946:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:04,946:INFO:Creating metrics dataframe
2023-11-04 23:34:04,958:INFO:Initializing create_model()
2023-11-04 23:34:04,958:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb61435c250>, estimator=KNeighborsRegressor(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:04,958:INFO:Checking exceptions
2023-11-04 23:34:04,959:INFO:Importing libraries
2023-11-04 23:34:04,960:INFO:Copying training dataset
2023-11-04 23:34:04,961:INFO:Defining folds
2023-11-04 23:34:04,961:INFO:Declaring metric variables
2023-11-04 23:34:04,962:INFO:Importing untrained model
2023-11-04 23:34:04,962:INFO:Declaring custom model
2023-11-04 23:34:04,962:INFO:K Neighbors Regressor Imported successfully
2023-11-04 23:34:04,963:INFO:Cross validation set to False
2023-11-04 23:34:04,963:INFO:Fitting Model
2023-11-04 23:34:04,970:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-04 23:34:04,971:INFO:create_model() successfully completed......................................
2023-11-04 23:34:05,132:INFO:_master_model_container: 20
2023-11-04 23:34:05,132:INFO:_display_container: 2
2023-11-04 23:34:05,133:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-04 23:34:05,133:INFO:compare_models() successfully completed......................................
2023-11-04 23:34:22,732:INFO:PyCaret RegressionExperiment
2023-11-04 23:34:22,732:INFO:Logging name: reg-default-name
2023-11-04 23:34:22,732:INFO:ML Usecase: MLUsecase.REGRESSION
2023-11-04 23:34:22,732:INFO:version 3.1.0
2023-11-04 23:34:22,732:INFO:Initializing setup()
2023-11-04 23:34:22,732:INFO:self.USI: a96d
2023-11-04 23:34:22,732:INFO:self._variable_keys: {'X_test', 'logging_param', 'y_test', 'y_train', 'X_train', 'transform_target_param', 'target_param', 'pipeline', '_available_plots', 'log_plots_param', 'seed', 'exp_id', 'X', 'memory', 'fold_generator', 'fold_groups_param', 'html_param', 'idx', 'gpu_n_jobs_param', 'fold_shuffle_param', 'exp_name_log', 'USI', 'data', 'n_jobs_param', '_ml_usecase', 'gpu_param', 'y'}
2023-11-04 23:34:22,732:INFO:Checking environment
2023-11-04 23:34:22,733:INFO:python_version: 3.9.13
2023-11-04 23:34:22,733:INFO:python_build: ('main', 'Aug 25 2022 18:29:29')
2023-11-04 23:34:22,733:INFO:machine: x86_64
2023-11-04 23:34:22,733:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-11-04 23:34:22,733:INFO:Memory: svmem(total=17179869184, available=1375621120, percent=92.0, used=1859452928, free=15630336, active=1367457792, inactive=1358360576, wired=491995136)
2023-11-04 23:34:22,733:INFO:Physical Core: 8
2023-11-04 23:34:22,733:INFO:Logical Core: 8
2023-11-04 23:34:22,733:INFO:Checking libraries
2023-11-04 23:34:22,733:INFO:System:
2023-11-04 23:34:22,733:INFO:    python: 3.9.13 (main, Aug 25 2022, 18:29:29)  [Clang 12.0.0 ]
2023-11-04 23:34:22,733:INFO:executable: /Users/michal/opt/anaconda3/bin/python
2023-11-04 23:34:22,733:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-11-04 23:34:22,733:INFO:PyCaret required dependencies:
2023-11-04 23:34:22,733:INFO:                 pip: 22.2.2
2023-11-04 23:34:22,733:INFO:          setuptools: 63.4.1
2023-11-04 23:34:22,733:INFO:             pycaret: 3.1.0
2023-11-04 23:34:22,733:INFO:             IPython: 7.31.1
2023-11-04 23:34:22,733:INFO:          ipywidgets: 7.6.5
2023-11-04 23:34:22,733:INFO:                tqdm: 4.64.1
2023-11-04 23:34:22,733:INFO:               numpy: 1.21.5
2023-11-04 23:34:22,733:INFO:              pandas: 1.4.4
2023-11-04 23:34:22,733:INFO:              jinja2: 2.11.3
2023-11-04 23:34:22,733:INFO:               scipy: 1.10.1
2023-11-04 23:34:22,733:INFO:              joblib: 1.2.0
2023-11-04 23:34:22,733:INFO:             sklearn: 1.0.2
2023-11-04 23:34:22,733:INFO:                pyod: 1.1.1
2023-11-04 23:34:22,733:INFO:            imblearn: 0.10.1
2023-11-04 23:34:22,733:INFO:   category_encoders: 2.6.3
2023-11-04 23:34:22,733:INFO:            lightgbm: 3.3.5
2023-11-04 23:34:22,733:INFO:               numba: 0.55.1
2023-11-04 23:34:22,733:INFO:            requests: 2.28.1
2023-11-04 23:34:22,733:INFO:          matplotlib: 3.5.2
2023-11-04 23:34:22,733:INFO:          scikitplot: 0.3.7
2023-11-04 23:34:22,733:INFO:         yellowbrick: 1.5
2023-11-04 23:34:22,733:INFO:              plotly: 5.9.0
2023-11-04 23:34:22,733:INFO:    plotly-resampler: Not installed
2023-11-04 23:34:22,733:INFO:             kaleido: 0.2.1
2023-11-04 23:34:22,733:INFO:           schemdraw: 0.15
2023-11-04 23:34:22,733:INFO:         statsmodels: 0.13.2
2023-11-04 23:34:22,733:INFO:              sktime: 0.21.1
2023-11-04 23:34:22,733:INFO:               tbats: 1.1.3
2023-11-04 23:34:22,733:INFO:            pmdarima: 2.0.4
2023-11-04 23:34:22,733:INFO:              psutil: 5.9.0
2023-11-04 23:34:22,733:INFO:          markupsafe: 2.0.1
2023-11-04 23:34:22,733:INFO:             pickle5: Not installed
2023-11-04 23:34:22,733:INFO:         cloudpickle: 2.0.0
2023-11-04 23:34:22,733:INFO:         deprecation: 2.1.0
2023-11-04 23:34:22,733:INFO:              xxhash: 3.4.1
2023-11-04 23:34:22,733:INFO:           wurlitzer: 3.0.2
2023-11-04 23:34:22,733:INFO:PyCaret optional dependencies:
2023-11-04 23:34:22,733:INFO:                shap: 0.41.0
2023-11-04 23:34:22,733:INFO:           interpret: Not installed
2023-11-04 23:34:22,733:INFO:                umap: 0.5.3
2023-11-04 23:34:22,733:INFO:     ydata_profiling: Not installed
2023-11-04 23:34:22,733:INFO:  explainerdashboard: Not installed
2023-11-04 23:34:22,733:INFO:             autoviz: Not installed
2023-11-04 23:34:22,733:INFO:           fairlearn: Not installed
2023-11-04 23:34:22,734:INFO:          deepchecks: Not installed
2023-11-04 23:34:22,734:INFO:             xgboost: 1.7.4
2023-11-04 23:34:22,734:INFO:            catboost: 1.2
2023-11-04 23:34:22,734:INFO:              kmodes: Not installed
2023-11-04 23:34:22,734:INFO:             mlxtend: 0.21.0
2023-11-04 23:34:22,734:INFO:       statsforecast: Not installed
2023-11-04 23:34:22,734:INFO:        tune_sklearn: Not installed
2023-11-04 23:34:22,734:INFO:                 ray: Not installed
2023-11-04 23:34:22,734:INFO:            hyperopt: Not installed
2023-11-04 23:34:22,734:INFO:              optuna: Not installed
2023-11-04 23:34:22,734:INFO:               skopt: Not installed
2023-11-04 23:34:22,734:INFO:              mlflow: Not installed
2023-11-04 23:34:22,734:INFO:              gradio: Not installed
2023-11-04 23:34:22,734:INFO:             fastapi: Not installed
2023-11-04 23:34:22,734:INFO:             uvicorn: Not installed
2023-11-04 23:34:22,734:INFO:              m2cgen: Not installed
2023-11-04 23:34:22,734:INFO:           evidently: Not installed
2023-11-04 23:34:22,734:INFO:               fugue: Not installed
2023-11-04 23:34:22,734:INFO:           streamlit: Not installed
2023-11-04 23:34:22,734:INFO:             prophet: Not installed
2023-11-04 23:34:22,734:INFO:None
2023-11-04 23:34:22,734:INFO:Set up data.
2023-11-04 23:34:22,735:INFO:Set up folding strategy.
2023-11-04 23:34:22,735:INFO:Set up train/test split.
2023-11-04 23:34:22,737:INFO:Set up index.
2023-11-04 23:34:22,737:INFO:Assigning column types.
2023-11-04 23:34:22,738:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-04 23:34:22,738:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-04 23:34:22,741:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 23:34:22,743:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 23:34:22,776:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:34:22,803:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:34:22,803:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:34:22,805:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:34:22,805:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-04 23:34:22,808:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 23:34:22,810:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 23:34:22,842:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:34:22,868:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:34:22,868:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:34:22,870:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:34:22,870:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-11-04 23:34:22,873:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 23:34:22,875:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 23:34:22,908:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:34:22,934:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:34:22,934:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:34:22,936:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:34:22,939:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 23:34:22,941:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 23:34:22,975:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:34:23,001:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:34:23,001:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:34:23,003:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:34:23,003:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-11-04 23:34:23,008:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 23:34:23,041:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:34:23,067:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:34:23,067:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:34:23,069:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:34:23,074:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 23:34:23,107:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:34:23,133:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:34:23,134:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:34:23,135:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:34:23,135:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-11-04 23:34:23,174:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:34:23,200:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:34:23,200:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:34:23,202:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:34:23,240:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:34:23,266:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:34:23,266:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:34:23,268:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:34:23,268:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-04 23:34:23,307:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:34:23,333:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:34:23,335:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:34:23,373:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:34:23,400:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:34:23,401:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:34:23,404:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-11-04 23:34:23,468:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:34:23,470:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:34:23,535:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:34:23,536:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:34:23,537:INFO:Preparing preprocessing pipeline...
2023-11-04 23:34:23,537:INFO:Set up simple imputation.
2023-11-04 23:34:23,537:INFO:Set up variance threshold.
2023-11-04 23:34:23,537:INFO:Set up removing multicollinearity.
2023-11-04 23:34:23,537:INFO:Set up column name cleaning.
2023-11-04 23:34:23,553:INFO:Finished creating preprocessing pipeline.
2023-11-04 23:34:23,556:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/h9/5_75v3qs13x63s15wwxdrd000000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['sepal length (cm)',
                                             'petal length (cm)',
                                             'petal width (cm)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.1))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-11-04 23:34:23,556:INFO:Creating final display dataframe.
2023-11-04 23:34:23,598:INFO:Setup _display_container:                     Description             Value
0                    Session id              2417
1                        Target  sepal width (cm)
2                   Target type        Regression
3           Original data shape          (150, 4)
4        Transformed data shape          (150, 3)
5   Transformed train set shape          (105, 3)
6    Transformed test set shape           (45, 3)
7              Numeric features                 3
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12       Low variance threshold               0.1
13     Remove multicollinearity              True
14  Multicollinearity threshold              0.95
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              a96d
2023-11-04 23:34:23,667:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:34:23,669:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:34:23,736:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:34:23,737:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:34:23,738:INFO:setup() successfully completed in 1.01s...............
2023-11-04 23:34:23,738:INFO:Initializing compare_models()
2023-11-04 23:34:23,738:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e6a55d30>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fb5e6a55d30>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-11-04 23:34:23,738:INFO:Checking exceptions
2023-11-04 23:34:23,738:INFO:Preparing display monitor
2023-11-04 23:34:23,755:INFO:Initializing Linear Regression
2023-11-04 23:34:23,755:INFO:Total runtime is 3.0676523844401043e-06 minutes
2023-11-04 23:34:23,757:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:23,757:INFO:Initializing create_model()
2023-11-04 23:34:23,757:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e6a55d30>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614be3b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:23,757:INFO:Checking exceptions
2023-11-04 23:34:23,757:INFO:Importing libraries
2023-11-04 23:34:23,757:INFO:Copying training dataset
2023-11-04 23:34:23,759:INFO:Defining folds
2023-11-04 23:34:23,759:INFO:Declaring metric variables
2023-11-04 23:34:23,761:INFO:Importing untrained model
2023-11-04 23:34:23,763:INFO:Linear Regression Imported successfully
2023-11-04 23:34:23,767:INFO:Starting cross validation
2023-11-04 23:34:23,768:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:23,820:INFO:Calculating mean and std
2023-11-04 23:34:23,820:INFO:Creating metrics dataframe
2023-11-04 23:34:23,822:INFO:Uploading results into container
2023-11-04 23:34:23,822:INFO:Uploading model into container now
2023-11-04 23:34:23,822:INFO:_master_model_container: 1
2023-11-04 23:34:23,822:INFO:_display_container: 2
2023-11-04 23:34:23,822:INFO:LinearRegression(n_jobs=-1)
2023-11-04 23:34:23,823:INFO:create_model() successfully completed......................................
2023-11-04 23:34:23,981:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:23,981:INFO:Creating metrics dataframe
2023-11-04 23:34:23,985:INFO:Initializing Lasso Regression
2023-11-04 23:34:23,985:INFO:Total runtime is 0.0038329680760701497 minutes
2023-11-04 23:34:23,987:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:23,987:INFO:Initializing create_model()
2023-11-04 23:34:23,987:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e6a55d30>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614be3b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:23,987:INFO:Checking exceptions
2023-11-04 23:34:23,988:INFO:Importing libraries
2023-11-04 23:34:23,988:INFO:Copying training dataset
2023-11-04 23:34:23,989:INFO:Defining folds
2023-11-04 23:34:23,989:INFO:Declaring metric variables
2023-11-04 23:34:23,991:INFO:Importing untrained model
2023-11-04 23:34:23,992:INFO:Lasso Regression Imported successfully
2023-11-04 23:34:23,995:INFO:Starting cross validation
2023-11-04 23:34:23,996:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:24,044:INFO:Calculating mean and std
2023-11-04 23:34:24,044:INFO:Creating metrics dataframe
2023-11-04 23:34:24,046:INFO:Uploading results into container
2023-11-04 23:34:24,046:INFO:Uploading model into container now
2023-11-04 23:34:24,046:INFO:_master_model_container: 2
2023-11-04 23:34:24,046:INFO:_display_container: 2
2023-11-04 23:34:24,046:INFO:Lasso(random_state=2417)
2023-11-04 23:34:24,046:INFO:create_model() successfully completed......................................
2023-11-04 23:34:24,183:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:24,183:INFO:Creating metrics dataframe
2023-11-04 23:34:24,188:INFO:Initializing Ridge Regression
2023-11-04 23:34:24,188:INFO:Total runtime is 0.007217264175415039 minutes
2023-11-04 23:34:24,190:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:24,190:INFO:Initializing create_model()
2023-11-04 23:34:24,190:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e6a55d30>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614be3b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:24,190:INFO:Checking exceptions
2023-11-04 23:34:24,191:INFO:Importing libraries
2023-11-04 23:34:24,191:INFO:Copying training dataset
2023-11-04 23:34:24,192:INFO:Defining folds
2023-11-04 23:34:24,192:INFO:Declaring metric variables
2023-11-04 23:34:24,193:INFO:Importing untrained model
2023-11-04 23:34:24,195:INFO:Ridge Regression Imported successfully
2023-11-04 23:34:24,198:INFO:Starting cross validation
2023-11-04 23:34:24,199:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:24,249:INFO:Calculating mean and std
2023-11-04 23:34:24,250:INFO:Creating metrics dataframe
2023-11-04 23:34:24,251:INFO:Uploading results into container
2023-11-04 23:34:24,252:INFO:Uploading model into container now
2023-11-04 23:34:24,252:INFO:_master_model_container: 3
2023-11-04 23:34:24,252:INFO:_display_container: 2
2023-11-04 23:34:24,252:INFO:Ridge(random_state=2417)
2023-11-04 23:34:24,252:INFO:create_model() successfully completed......................................
2023-11-04 23:34:24,389:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:24,389:INFO:Creating metrics dataframe
2023-11-04 23:34:24,394:INFO:Initializing Elastic Net
2023-11-04 23:34:24,394:INFO:Total runtime is 0.0106451153755188 minutes
2023-11-04 23:34:24,396:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:24,396:INFO:Initializing create_model()
2023-11-04 23:34:24,396:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e6a55d30>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614be3b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:24,396:INFO:Checking exceptions
2023-11-04 23:34:24,396:INFO:Importing libraries
2023-11-04 23:34:24,396:INFO:Copying training dataset
2023-11-04 23:34:24,398:INFO:Defining folds
2023-11-04 23:34:24,398:INFO:Declaring metric variables
2023-11-04 23:34:24,399:INFO:Importing untrained model
2023-11-04 23:34:24,401:INFO:Elastic Net Imported successfully
2023-11-04 23:34:24,404:INFO:Starting cross validation
2023-11-04 23:34:24,404:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:24,456:INFO:Calculating mean and std
2023-11-04 23:34:24,456:INFO:Creating metrics dataframe
2023-11-04 23:34:24,458:INFO:Uploading results into container
2023-11-04 23:34:24,458:INFO:Uploading model into container now
2023-11-04 23:34:24,458:INFO:_master_model_container: 4
2023-11-04 23:34:24,458:INFO:_display_container: 2
2023-11-04 23:34:24,458:INFO:ElasticNet(random_state=2417)
2023-11-04 23:34:24,458:INFO:create_model() successfully completed......................................
2023-11-04 23:34:24,596:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:24,596:INFO:Creating metrics dataframe
2023-11-04 23:34:24,601:INFO:Initializing Least Angle Regression
2023-11-04 23:34:24,601:INFO:Total runtime is 0.014100682735443116 minutes
2023-11-04 23:34:24,603:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:24,603:INFO:Initializing create_model()
2023-11-04 23:34:24,603:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e6a55d30>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614be3b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:24,604:INFO:Checking exceptions
2023-11-04 23:34:24,604:INFO:Importing libraries
2023-11-04 23:34:24,604:INFO:Copying training dataset
2023-11-04 23:34:24,605:INFO:Defining folds
2023-11-04 23:34:24,605:INFO:Declaring metric variables
2023-11-04 23:34:24,606:INFO:Importing untrained model
2023-11-04 23:34:24,608:INFO:Least Angle Regression Imported successfully
2023-11-04 23:34:24,611:INFO:Starting cross validation
2023-11-04 23:34:24,612:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:24,628:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:24,632:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:24,641:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:24,642:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:24,645:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:24,648:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:24,654:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:24,654:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:24,654:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:24,657:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:24,662:INFO:Calculating mean and std
2023-11-04 23:34:24,662:INFO:Creating metrics dataframe
2023-11-04 23:34:24,664:INFO:Uploading results into container
2023-11-04 23:34:24,664:INFO:Uploading model into container now
2023-11-04 23:34:24,664:INFO:_master_model_container: 5
2023-11-04 23:34:24,664:INFO:_display_container: 2
2023-11-04 23:34:24,665:INFO:Lars(random_state=2417)
2023-11-04 23:34:24,665:INFO:create_model() successfully completed......................................
2023-11-04 23:34:24,803:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:24,803:INFO:Creating metrics dataframe
2023-11-04 23:34:24,808:INFO:Initializing Lasso Least Angle Regression
2023-11-04 23:34:24,808:INFO:Total runtime is 0.01755146582921346 minutes
2023-11-04 23:34:24,810:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:24,810:INFO:Initializing create_model()
2023-11-04 23:34:24,810:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e6a55d30>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614be3b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:24,811:INFO:Checking exceptions
2023-11-04 23:34:24,811:INFO:Importing libraries
2023-11-04 23:34:24,811:INFO:Copying training dataset
2023-11-04 23:34:24,813:INFO:Defining folds
2023-11-04 23:34:24,813:INFO:Declaring metric variables
2023-11-04 23:34:24,815:INFO:Importing untrained model
2023-11-04 23:34:24,816:INFO:Lasso Least Angle Regression Imported successfully
2023-11-04 23:34:24,819:INFO:Starting cross validation
2023-11-04 23:34:24,820:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:24,838:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:34:24,848:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:34:24,850:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:34:24,855:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:34:24,856:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:34:24,860:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:34:24,860:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:34:24,862:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:34:24,866:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:34:24,868:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:34:24,872:INFO:Calculating mean and std
2023-11-04 23:34:24,873:INFO:Creating metrics dataframe
2023-11-04 23:34:24,874:INFO:Uploading results into container
2023-11-04 23:34:24,874:INFO:Uploading model into container now
2023-11-04 23:34:24,875:INFO:_master_model_container: 6
2023-11-04 23:34:24,875:INFO:_display_container: 2
2023-11-04 23:34:24,875:INFO:LassoLars(random_state=2417)
2023-11-04 23:34:24,875:INFO:create_model() successfully completed......................................
2023-11-04 23:34:25,012:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:25,012:INFO:Creating metrics dataframe
2023-11-04 23:34:25,017:INFO:Initializing Orthogonal Matching Pursuit
2023-11-04 23:34:25,017:INFO:Total runtime is 0.021031280358632404 minutes
2023-11-04 23:34:25,019:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:25,019:INFO:Initializing create_model()
2023-11-04 23:34:25,019:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e6a55d30>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614be3b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:25,019:INFO:Checking exceptions
2023-11-04 23:34:25,019:INFO:Importing libraries
2023-11-04 23:34:25,020:INFO:Copying training dataset
2023-11-04 23:34:25,021:INFO:Defining folds
2023-11-04 23:34:25,022:INFO:Declaring metric variables
2023-11-04 23:34:25,023:INFO:Importing untrained model
2023-11-04 23:34:25,025:INFO:Orthogonal Matching Pursuit Imported successfully
2023-11-04 23:34:25,029:INFO:Starting cross validation
2023-11-04 23:34:25,030:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:25,046:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:25,057:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:25,058:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:25,059:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:25,066:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:25,067:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:25,072:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:25,073:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:25,075:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:25,078:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:25,083:INFO:Calculating mean and std
2023-11-04 23:34:25,083:INFO:Creating metrics dataframe
2023-11-04 23:34:25,085:INFO:Uploading results into container
2023-11-04 23:34:25,085:INFO:Uploading model into container now
2023-11-04 23:34:25,085:INFO:_master_model_container: 7
2023-11-04 23:34:25,085:INFO:_display_container: 2
2023-11-04 23:34:25,085:INFO:OrthogonalMatchingPursuit()
2023-11-04 23:34:25,085:INFO:create_model() successfully completed......................................
2023-11-04 23:34:25,222:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:25,222:INFO:Creating metrics dataframe
2023-11-04 23:34:25,228:INFO:Initializing Bayesian Ridge
2023-11-04 23:34:25,228:INFO:Total runtime is 0.024547417958577473 minutes
2023-11-04 23:34:25,230:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:25,230:INFO:Initializing create_model()
2023-11-04 23:34:25,230:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e6a55d30>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614be3b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:25,230:INFO:Checking exceptions
2023-11-04 23:34:25,230:INFO:Importing libraries
2023-11-04 23:34:25,230:INFO:Copying training dataset
2023-11-04 23:34:25,232:INFO:Defining folds
2023-11-04 23:34:25,232:INFO:Declaring metric variables
2023-11-04 23:34:25,234:INFO:Importing untrained model
2023-11-04 23:34:25,236:INFO:Bayesian Ridge Imported successfully
2023-11-04 23:34:25,239:INFO:Starting cross validation
2023-11-04 23:34:25,239:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:25,292:INFO:Calculating mean and std
2023-11-04 23:34:25,292:INFO:Creating metrics dataframe
2023-11-04 23:34:25,294:INFO:Uploading results into container
2023-11-04 23:34:25,294:INFO:Uploading model into container now
2023-11-04 23:34:25,294:INFO:_master_model_container: 8
2023-11-04 23:34:25,294:INFO:_display_container: 2
2023-11-04 23:34:25,295:INFO:BayesianRidge()
2023-11-04 23:34:25,295:INFO:create_model() successfully completed......................................
2023-11-04 23:34:25,434:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:25,434:INFO:Creating metrics dataframe
2023-11-04 23:34:25,440:INFO:Initializing Passive Aggressive Regressor
2023-11-04 23:34:25,440:INFO:Total runtime is 0.028074399630228678 minutes
2023-11-04 23:34:25,441:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:25,442:INFO:Initializing create_model()
2023-11-04 23:34:25,442:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e6a55d30>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614be3b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:25,442:INFO:Checking exceptions
2023-11-04 23:34:25,442:INFO:Importing libraries
2023-11-04 23:34:25,442:INFO:Copying training dataset
2023-11-04 23:34:25,444:INFO:Defining folds
2023-11-04 23:34:25,444:INFO:Declaring metric variables
2023-11-04 23:34:25,446:INFO:Importing untrained model
2023-11-04 23:34:25,448:INFO:Passive Aggressive Regressor Imported successfully
2023-11-04 23:34:25,451:INFO:Starting cross validation
2023-11-04 23:34:25,451:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:25,508:INFO:Calculating mean and std
2023-11-04 23:34:25,509:INFO:Creating metrics dataframe
2023-11-04 23:34:25,511:INFO:Uploading results into container
2023-11-04 23:34:25,511:INFO:Uploading model into container now
2023-11-04 23:34:25,511:INFO:_master_model_container: 9
2023-11-04 23:34:25,511:INFO:_display_container: 2
2023-11-04 23:34:25,511:INFO:PassiveAggressiveRegressor(random_state=2417)
2023-11-04 23:34:25,511:INFO:create_model() successfully completed......................................
2023-11-04 23:34:25,654:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:25,654:INFO:Creating metrics dataframe
2023-11-04 23:34:25,660:INFO:Initializing Huber Regressor
2023-11-04 23:34:25,660:INFO:Total runtime is 0.031752951939900714 minutes
2023-11-04 23:34:25,662:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:25,662:INFO:Initializing create_model()
2023-11-04 23:34:25,663:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e6a55d30>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614be3b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:25,663:INFO:Checking exceptions
2023-11-04 23:34:25,663:INFO:Importing libraries
2023-11-04 23:34:25,663:INFO:Copying training dataset
2023-11-04 23:34:25,665:INFO:Defining folds
2023-11-04 23:34:25,665:INFO:Declaring metric variables
2023-11-04 23:34:25,667:INFO:Importing untrained model
2023-11-04 23:34:25,668:INFO:Huber Regressor Imported successfully
2023-11-04 23:34:25,671:INFO:Starting cross validation
2023-11-04 23:34:25,672:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:25,726:INFO:Calculating mean and std
2023-11-04 23:34:25,726:INFO:Creating metrics dataframe
2023-11-04 23:34:25,728:INFO:Uploading results into container
2023-11-04 23:34:25,729:INFO:Uploading model into container now
2023-11-04 23:34:25,729:INFO:_master_model_container: 10
2023-11-04 23:34:25,729:INFO:_display_container: 2
2023-11-04 23:34:25,729:INFO:HuberRegressor()
2023-11-04 23:34:25,729:INFO:create_model() successfully completed......................................
2023-11-04 23:34:25,867:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:25,867:INFO:Creating metrics dataframe
2023-11-04 23:34:25,873:INFO:Initializing K Neighbors Regressor
2023-11-04 23:34:25,874:INFO:Total runtime is 0.03530574639638265 minutes
2023-11-04 23:34:25,875:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:25,876:INFO:Initializing create_model()
2023-11-04 23:34:25,876:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e6a55d30>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614be3b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:25,876:INFO:Checking exceptions
2023-11-04 23:34:25,876:INFO:Importing libraries
2023-11-04 23:34:25,876:INFO:Copying training dataset
2023-11-04 23:34:25,878:INFO:Defining folds
2023-11-04 23:34:25,878:INFO:Declaring metric variables
2023-11-04 23:34:25,880:INFO:Importing untrained model
2023-11-04 23:34:25,881:INFO:K Neighbors Regressor Imported successfully
2023-11-04 23:34:25,885:INFO:Starting cross validation
2023-11-04 23:34:25,885:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:25,941:INFO:Calculating mean and std
2023-11-04 23:34:25,942:INFO:Creating metrics dataframe
2023-11-04 23:34:25,943:INFO:Uploading results into container
2023-11-04 23:34:25,943:INFO:Uploading model into container now
2023-11-04 23:34:25,944:INFO:_master_model_container: 11
2023-11-04 23:34:25,944:INFO:_display_container: 2
2023-11-04 23:34:25,944:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-04 23:34:25,944:INFO:create_model() successfully completed......................................
2023-11-04 23:34:26,081:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:26,081:INFO:Creating metrics dataframe
2023-11-04 23:34:26,087:INFO:Initializing Decision Tree Regressor
2023-11-04 23:34:26,087:INFO:Total runtime is 0.038866182168324784 minutes
2023-11-04 23:34:26,089:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:26,089:INFO:Initializing create_model()
2023-11-04 23:34:26,089:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e6a55d30>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614be3b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:26,089:INFO:Checking exceptions
2023-11-04 23:34:26,089:INFO:Importing libraries
2023-11-04 23:34:26,090:INFO:Copying training dataset
2023-11-04 23:34:26,092:INFO:Defining folds
2023-11-04 23:34:26,092:INFO:Declaring metric variables
2023-11-04 23:34:26,093:INFO:Importing untrained model
2023-11-04 23:34:26,095:INFO:Decision Tree Regressor Imported successfully
2023-11-04 23:34:26,098:INFO:Starting cross validation
2023-11-04 23:34:26,099:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:26,150:INFO:Calculating mean and std
2023-11-04 23:34:26,151:INFO:Creating metrics dataframe
2023-11-04 23:34:26,152:INFO:Uploading results into container
2023-11-04 23:34:26,153:INFO:Uploading model into container now
2023-11-04 23:34:26,153:INFO:_master_model_container: 12
2023-11-04 23:34:26,153:INFO:_display_container: 2
2023-11-04 23:34:26,153:INFO:DecisionTreeRegressor(random_state=2417)
2023-11-04 23:34:26,153:INFO:create_model() successfully completed......................................
2023-11-04 23:34:26,296:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:26,297:INFO:Creating metrics dataframe
2023-11-04 23:34:26,303:INFO:Initializing Random Forest Regressor
2023-11-04 23:34:26,303:INFO:Total runtime is 0.04246649742126465 minutes
2023-11-04 23:34:26,305:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:26,305:INFO:Initializing create_model()
2023-11-04 23:34:26,305:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e6a55d30>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614be3b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:26,305:INFO:Checking exceptions
2023-11-04 23:34:26,306:INFO:Importing libraries
2023-11-04 23:34:26,306:INFO:Copying training dataset
2023-11-04 23:34:26,308:INFO:Defining folds
2023-11-04 23:34:26,308:INFO:Declaring metric variables
2023-11-04 23:34:26,309:INFO:Importing untrained model
2023-11-04 23:34:26,311:INFO:Random Forest Regressor Imported successfully
2023-11-04 23:34:26,314:INFO:Starting cross validation
2023-11-04 23:34:26,315:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:26,552:INFO:Calculating mean and std
2023-11-04 23:34:26,553:INFO:Creating metrics dataframe
2023-11-04 23:34:26,555:INFO:Uploading results into container
2023-11-04 23:34:26,555:INFO:Uploading model into container now
2023-11-04 23:34:26,556:INFO:_master_model_container: 13
2023-11-04 23:34:26,556:INFO:_display_container: 2
2023-11-04 23:34:26,556:INFO:RandomForestRegressor(n_jobs=-1, random_state=2417)
2023-11-04 23:34:26,556:INFO:create_model() successfully completed......................................
2023-11-04 23:34:26,698:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:26,698:INFO:Creating metrics dataframe
2023-11-04 23:34:26,704:INFO:Initializing Extra Trees Regressor
2023-11-04 23:34:26,704:INFO:Total runtime is 0.04914905230204264 minutes
2023-11-04 23:34:26,706:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:26,706:INFO:Initializing create_model()
2023-11-04 23:34:26,706:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e6a55d30>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614be3b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:26,706:INFO:Checking exceptions
2023-11-04 23:34:26,707:INFO:Importing libraries
2023-11-04 23:34:26,707:INFO:Copying training dataset
2023-11-04 23:34:26,709:INFO:Defining folds
2023-11-04 23:34:26,709:INFO:Declaring metric variables
2023-11-04 23:34:26,710:INFO:Importing untrained model
2023-11-04 23:34:26,712:INFO:Extra Trees Regressor Imported successfully
2023-11-04 23:34:26,715:INFO:Starting cross validation
2023-11-04 23:34:26,716:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:26,913:INFO:Calculating mean and std
2023-11-04 23:34:26,914:INFO:Creating metrics dataframe
2023-11-04 23:34:26,916:INFO:Uploading results into container
2023-11-04 23:34:26,917:INFO:Uploading model into container now
2023-11-04 23:34:26,917:INFO:_master_model_container: 14
2023-11-04 23:34:26,917:INFO:_display_container: 2
2023-11-04 23:34:26,918:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=2417)
2023-11-04 23:34:26,918:INFO:create_model() successfully completed......................................
2023-11-04 23:34:27,057:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:27,057:INFO:Creating metrics dataframe
2023-11-04 23:34:27,063:INFO:Initializing AdaBoost Regressor
2023-11-04 23:34:27,063:INFO:Total runtime is 0.055133279164632155 minutes
2023-11-04 23:34:27,065:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:27,065:INFO:Initializing create_model()
2023-11-04 23:34:27,065:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e6a55d30>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614be3b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:27,065:INFO:Checking exceptions
2023-11-04 23:34:27,065:INFO:Importing libraries
2023-11-04 23:34:27,066:INFO:Copying training dataset
2023-11-04 23:34:27,068:INFO:Defining folds
2023-11-04 23:34:27,068:INFO:Declaring metric variables
2023-11-04 23:34:27,069:INFO:Importing untrained model
2023-11-04 23:34:27,071:INFO:AdaBoost Regressor Imported successfully
2023-11-04 23:34:27,074:INFO:Starting cross validation
2023-11-04 23:34:27,075:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:27,175:INFO:Calculating mean and std
2023-11-04 23:34:27,176:INFO:Creating metrics dataframe
2023-11-04 23:34:27,178:INFO:Uploading results into container
2023-11-04 23:34:27,178:INFO:Uploading model into container now
2023-11-04 23:34:27,178:INFO:_master_model_container: 15
2023-11-04 23:34:27,178:INFO:_display_container: 2
2023-11-04 23:34:27,179:INFO:AdaBoostRegressor(random_state=2417)
2023-11-04 23:34:27,179:INFO:create_model() successfully completed......................................
2023-11-04 23:34:27,316:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:27,316:INFO:Creating metrics dataframe
2023-11-04 23:34:27,323:INFO:Initializing Gradient Boosting Regressor
2023-11-04 23:34:27,323:INFO:Total runtime is 0.05946359634399413 minutes
2023-11-04 23:34:27,325:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:27,325:INFO:Initializing create_model()
2023-11-04 23:34:27,325:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e6a55d30>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614be3b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:27,325:INFO:Checking exceptions
2023-11-04 23:34:27,325:INFO:Importing libraries
2023-11-04 23:34:27,325:INFO:Copying training dataset
2023-11-04 23:34:27,327:INFO:Defining folds
2023-11-04 23:34:27,327:INFO:Declaring metric variables
2023-11-04 23:34:27,329:INFO:Importing untrained model
2023-11-04 23:34:27,331:INFO:Gradient Boosting Regressor Imported successfully
2023-11-04 23:34:27,334:INFO:Starting cross validation
2023-11-04 23:34:27,335:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:27,407:INFO:Calculating mean and std
2023-11-04 23:34:27,407:INFO:Creating metrics dataframe
2023-11-04 23:34:27,409:INFO:Uploading results into container
2023-11-04 23:34:27,409:INFO:Uploading model into container now
2023-11-04 23:34:27,410:INFO:_master_model_container: 16
2023-11-04 23:34:27,410:INFO:_display_container: 2
2023-11-04 23:34:27,410:INFO:GradientBoostingRegressor(random_state=2417)
2023-11-04 23:34:27,410:INFO:create_model() successfully completed......................................
2023-11-04 23:34:27,547:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:27,547:INFO:Creating metrics dataframe
2023-11-04 23:34:27,553:INFO:Initializing Extreme Gradient Boosting
2023-11-04 23:34:27,554:INFO:Total runtime is 0.06330571969350178 minutes
2023-11-04 23:34:27,555:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:27,556:INFO:Initializing create_model()
2023-11-04 23:34:27,556:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e6a55d30>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614be3b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:27,556:INFO:Checking exceptions
2023-11-04 23:34:27,556:INFO:Importing libraries
2023-11-04 23:34:27,556:INFO:Copying training dataset
2023-11-04 23:34:27,558:INFO:Defining folds
2023-11-04 23:34:27,558:INFO:Declaring metric variables
2023-11-04 23:34:27,560:INFO:Importing untrained model
2023-11-04 23:34:27,561:INFO:Extreme Gradient Boosting Imported successfully
2023-11-04 23:34:27,565:INFO:Starting cross validation
2023-11-04 23:34:27,565:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:27,642:INFO:Calculating mean and std
2023-11-04 23:34:27,642:INFO:Creating metrics dataframe
2023-11-04 23:34:27,644:INFO:Uploading results into container
2023-11-04 23:34:27,644:INFO:Uploading model into container now
2023-11-04 23:34:27,644:INFO:_master_model_container: 17
2023-11-04 23:34:27,644:INFO:_display_container: 2
2023-11-04 23:34:27,645:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=2417, ...)
2023-11-04 23:34:27,645:INFO:create_model() successfully completed......................................
2023-11-04 23:34:27,782:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:27,782:INFO:Creating metrics dataframe
2023-11-04 23:34:27,789:INFO:Initializing Light Gradient Boosting Machine
2023-11-04 23:34:27,789:INFO:Total runtime is 0.06723013321558634 minutes
2023-11-04 23:34:27,791:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:27,791:INFO:Initializing create_model()
2023-11-04 23:34:27,791:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e6a55d30>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614be3b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:27,791:INFO:Checking exceptions
2023-11-04 23:34:27,791:INFO:Importing libraries
2023-11-04 23:34:27,791:INFO:Copying training dataset
2023-11-04 23:34:27,793:INFO:Defining folds
2023-11-04 23:34:27,793:INFO:Declaring metric variables
2023-11-04 23:34:27,795:INFO:Importing untrained model
2023-11-04 23:34:27,797:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-04 23:34:27,801:INFO:Starting cross validation
2023-11-04 23:34:27,801:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:27,858:INFO:Calculating mean and std
2023-11-04 23:34:27,858:INFO:Creating metrics dataframe
2023-11-04 23:34:27,860:INFO:Uploading results into container
2023-11-04 23:34:27,860:INFO:Uploading model into container now
2023-11-04 23:34:27,860:INFO:_master_model_container: 18
2023-11-04 23:34:27,860:INFO:_display_container: 2
2023-11-04 23:34:27,860:INFO:LGBMRegressor(random_state=2417)
2023-11-04 23:34:27,860:INFO:create_model() successfully completed......................................
2023-11-04 23:34:27,998:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:27,998:INFO:Creating metrics dataframe
2023-11-04 23:34:28,005:INFO:Initializing CatBoost Regressor
2023-11-04 23:34:28,005:INFO:Total runtime is 0.0708297848701477 minutes
2023-11-04 23:34:28,007:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:28,007:INFO:Initializing create_model()
2023-11-04 23:34:28,007:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e6a55d30>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614be3b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:28,007:INFO:Checking exceptions
2023-11-04 23:34:28,007:INFO:Importing libraries
2023-11-04 23:34:28,007:INFO:Copying training dataset
2023-11-04 23:34:28,010:INFO:Defining folds
2023-11-04 23:34:28,010:INFO:Declaring metric variables
2023-11-04 23:34:28,011:INFO:Importing untrained model
2023-11-04 23:34:28,013:INFO:CatBoost Regressor Imported successfully
2023-11-04 23:34:28,016:INFO:Starting cross validation
2023-11-04 23:34:28,017:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:28,351:INFO:Calculating mean and std
2023-11-04 23:34:28,351:INFO:Creating metrics dataframe
2023-11-04 23:34:28,353:INFO:Uploading results into container
2023-11-04 23:34:28,354:INFO:Uploading model into container now
2023-11-04 23:34:28,354:INFO:_master_model_container: 19
2023-11-04 23:34:28,354:INFO:_display_container: 2
2023-11-04 23:34:28,354:INFO:<catboost.core.CatBoostRegressor object at 0x7fb5e709e610>
2023-11-04 23:34:28,354:INFO:create_model() successfully completed......................................
2023-11-04 23:34:28,505:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:28,505:INFO:Creating metrics dataframe
2023-11-04 23:34:28,513:INFO:Initializing Dummy Regressor
2023-11-04 23:34:28,513:INFO:Total runtime is 0.07930161952972412 minutes
2023-11-04 23:34:28,515:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:28,515:INFO:Initializing create_model()
2023-11-04 23:34:28,515:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e6a55d30>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb614be3b80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:28,515:INFO:Checking exceptions
2023-11-04 23:34:28,516:INFO:Importing libraries
2023-11-04 23:34:28,516:INFO:Copying training dataset
2023-11-04 23:34:28,518:INFO:Defining folds
2023-11-04 23:34:28,518:INFO:Declaring metric variables
2023-11-04 23:34:28,519:INFO:Importing untrained model
2023-11-04 23:34:28,521:INFO:Dummy Regressor Imported successfully
2023-11-04 23:34:28,524:INFO:Starting cross validation
2023-11-04 23:34:28,525:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:28,576:INFO:Calculating mean and std
2023-11-04 23:34:28,577:INFO:Creating metrics dataframe
2023-11-04 23:34:28,578:INFO:Uploading results into container
2023-11-04 23:34:28,579:INFO:Uploading model into container now
2023-11-04 23:34:28,579:INFO:_master_model_container: 20
2023-11-04 23:34:28,579:INFO:_display_container: 2
2023-11-04 23:34:28,579:INFO:DummyRegressor()
2023-11-04 23:34:28,579:INFO:create_model() successfully completed......................................
2023-11-04 23:34:28,730:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:28,730:INFO:Creating metrics dataframe
2023-11-04 23:34:28,743:INFO:Initializing create_model()
2023-11-04 23:34:28,743:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5e6a55d30>, estimator=KNeighborsRegressor(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:28,743:INFO:Checking exceptions
2023-11-04 23:34:28,744:INFO:Importing libraries
2023-11-04 23:34:28,744:INFO:Copying training dataset
2023-11-04 23:34:28,746:INFO:Defining folds
2023-11-04 23:34:28,746:INFO:Declaring metric variables
2023-11-04 23:34:28,746:INFO:Importing untrained model
2023-11-04 23:34:28,746:INFO:Declaring custom model
2023-11-04 23:34:28,746:INFO:K Neighbors Regressor Imported successfully
2023-11-04 23:34:28,747:INFO:Cross validation set to False
2023-11-04 23:34:28,747:INFO:Fitting Model
2023-11-04 23:34:28,755:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-04 23:34:28,755:INFO:create_model() successfully completed......................................
2023-11-04 23:34:28,923:INFO:_master_model_container: 20
2023-11-04 23:34:28,923:INFO:_display_container: 2
2023-11-04 23:34:28,923:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-04 23:34:28,924:INFO:compare_models() successfully completed......................................
2023-11-04 23:34:39,616:INFO:PyCaret RegressionExperiment
2023-11-04 23:34:39,616:INFO:Logging name: reg-default-name
2023-11-04 23:34:39,616:INFO:ML Usecase: MLUsecase.REGRESSION
2023-11-04 23:34:39,617:INFO:version 3.1.0
2023-11-04 23:34:39,617:INFO:Initializing setup()
2023-11-04 23:34:39,617:INFO:self.USI: 967e
2023-11-04 23:34:39,617:INFO:self._variable_keys: {'X_test', 'logging_param', 'y_test', 'y_train', 'X_train', 'transform_target_param', 'target_param', 'pipeline', '_available_plots', 'log_plots_param', 'seed', 'exp_id', 'X', 'memory', 'fold_generator', 'fold_groups_param', 'html_param', 'idx', 'gpu_n_jobs_param', 'fold_shuffle_param', 'exp_name_log', 'USI', 'data', 'n_jobs_param', '_ml_usecase', 'gpu_param', 'y'}
2023-11-04 23:34:39,617:INFO:Checking environment
2023-11-04 23:34:39,617:INFO:python_version: 3.9.13
2023-11-04 23:34:39,617:INFO:python_build: ('main', 'Aug 25 2022 18:29:29')
2023-11-04 23:34:39,617:INFO:machine: x86_64
2023-11-04 23:34:39,617:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-11-04 23:34:39,617:INFO:Memory: svmem(total=17179869184, available=1386958848, percent=91.9, used=1849348096, free=15839232, active=1373982720, inactive=1365905408, wired=475365376)
2023-11-04 23:34:39,617:INFO:Physical Core: 8
2023-11-04 23:34:39,617:INFO:Logical Core: 8
2023-11-04 23:34:39,617:INFO:Checking libraries
2023-11-04 23:34:39,617:INFO:System:
2023-11-04 23:34:39,617:INFO:    python: 3.9.13 (main, Aug 25 2022, 18:29:29)  [Clang 12.0.0 ]
2023-11-04 23:34:39,617:INFO:executable: /Users/michal/opt/anaconda3/bin/python
2023-11-04 23:34:39,617:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-11-04 23:34:39,618:INFO:PyCaret required dependencies:
2023-11-04 23:34:39,618:INFO:                 pip: 22.2.2
2023-11-04 23:34:39,618:INFO:          setuptools: 63.4.1
2023-11-04 23:34:39,618:INFO:             pycaret: 3.1.0
2023-11-04 23:34:39,618:INFO:             IPython: 7.31.1
2023-11-04 23:34:39,618:INFO:          ipywidgets: 7.6.5
2023-11-04 23:34:39,618:INFO:                tqdm: 4.64.1
2023-11-04 23:34:39,618:INFO:               numpy: 1.21.5
2023-11-04 23:34:39,618:INFO:              pandas: 1.4.4
2023-11-04 23:34:39,618:INFO:              jinja2: 2.11.3
2023-11-04 23:34:39,618:INFO:               scipy: 1.10.1
2023-11-04 23:34:39,618:INFO:              joblib: 1.2.0
2023-11-04 23:34:39,618:INFO:             sklearn: 1.0.2
2023-11-04 23:34:39,618:INFO:                pyod: 1.1.1
2023-11-04 23:34:39,618:INFO:            imblearn: 0.10.1
2023-11-04 23:34:39,618:INFO:   category_encoders: 2.6.3
2023-11-04 23:34:39,618:INFO:            lightgbm: 3.3.5
2023-11-04 23:34:39,618:INFO:               numba: 0.55.1
2023-11-04 23:34:39,618:INFO:            requests: 2.28.1
2023-11-04 23:34:39,619:INFO:          matplotlib: 3.5.2
2023-11-04 23:34:39,619:INFO:          scikitplot: 0.3.7
2023-11-04 23:34:39,619:INFO:         yellowbrick: 1.5
2023-11-04 23:34:39,619:INFO:              plotly: 5.9.0
2023-11-04 23:34:39,619:INFO:    plotly-resampler: Not installed
2023-11-04 23:34:39,619:INFO:             kaleido: 0.2.1
2023-11-04 23:34:39,619:INFO:           schemdraw: 0.15
2023-11-04 23:34:39,619:INFO:         statsmodels: 0.13.2
2023-11-04 23:34:39,619:INFO:              sktime: 0.21.1
2023-11-04 23:34:39,619:INFO:               tbats: 1.1.3
2023-11-04 23:34:39,619:INFO:            pmdarima: 2.0.4
2023-11-04 23:34:39,619:INFO:              psutil: 5.9.0
2023-11-04 23:34:39,619:INFO:          markupsafe: 2.0.1
2023-11-04 23:34:39,619:INFO:             pickle5: Not installed
2023-11-04 23:34:39,619:INFO:         cloudpickle: 2.0.0
2023-11-04 23:34:39,619:INFO:         deprecation: 2.1.0
2023-11-04 23:34:39,619:INFO:              xxhash: 3.4.1
2023-11-04 23:34:39,619:INFO:           wurlitzer: 3.0.2
2023-11-04 23:34:39,619:INFO:PyCaret optional dependencies:
2023-11-04 23:34:39,620:INFO:                shap: 0.41.0
2023-11-04 23:34:39,620:INFO:           interpret: Not installed
2023-11-04 23:34:39,620:INFO:                umap: 0.5.3
2023-11-04 23:34:39,620:INFO:     ydata_profiling: Not installed
2023-11-04 23:34:39,620:INFO:  explainerdashboard: Not installed
2023-11-04 23:34:39,620:INFO:             autoviz: Not installed
2023-11-04 23:34:39,620:INFO:           fairlearn: Not installed
2023-11-04 23:34:39,620:INFO:          deepchecks: Not installed
2023-11-04 23:34:39,620:INFO:             xgboost: 1.7.4
2023-11-04 23:34:39,620:INFO:            catboost: 1.2
2023-11-04 23:34:39,620:INFO:              kmodes: Not installed
2023-11-04 23:34:39,620:INFO:             mlxtend: 0.21.0
2023-11-04 23:34:39,620:INFO:       statsforecast: Not installed
2023-11-04 23:34:39,620:INFO:        tune_sklearn: Not installed
2023-11-04 23:34:39,620:INFO:                 ray: Not installed
2023-11-04 23:34:39,620:INFO:            hyperopt: Not installed
2023-11-04 23:34:39,620:INFO:              optuna: Not installed
2023-11-04 23:34:39,620:INFO:               skopt: Not installed
2023-11-04 23:34:39,621:INFO:              mlflow: Not installed
2023-11-04 23:34:39,621:INFO:              gradio: Not installed
2023-11-04 23:34:39,621:INFO:             fastapi: Not installed
2023-11-04 23:34:39,621:INFO:             uvicorn: Not installed
2023-11-04 23:34:39,621:INFO:              m2cgen: Not installed
2023-11-04 23:34:39,621:INFO:           evidently: Not installed
2023-11-04 23:34:39,621:INFO:               fugue: Not installed
2023-11-04 23:34:39,621:INFO:           streamlit: Not installed
2023-11-04 23:34:39,621:INFO:             prophet: Not installed
2023-11-04 23:34:39,621:INFO:None
2023-11-04 23:34:39,621:INFO:Set up data.
2023-11-04 23:34:39,628:INFO:Set up folding strategy.
2023-11-04 23:34:39,628:INFO:Set up train/test split.
2023-11-04 23:34:39,631:INFO:Set up index.
2023-11-04 23:34:39,631:INFO:Assigning column types.
2023-11-04 23:34:39,634:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-04 23:34:39,634:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-04 23:34:39,639:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 23:34:39,644:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 23:34:39,691:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:34:39,717:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:34:39,718:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:34:39,719:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:34:39,720:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-04 23:34:39,722:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 23:34:39,725:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 23:34:39,758:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:34:39,785:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:34:39,785:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:34:39,787:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:34:39,787:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-11-04 23:34:39,790:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 23:34:39,793:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 23:34:39,828:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:34:39,855:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:34:39,855:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:34:39,857:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:34:39,860:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 23:34:39,862:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 23:34:39,896:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:34:39,923:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:34:39,924:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:34:39,925:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:34:39,925:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-11-04 23:34:39,931:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 23:34:39,965:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:34:39,992:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:34:39,993:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:34:39,994:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:34:40,000:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 23:34:40,034:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:34:40,061:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:34:40,061:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:34:40,062:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:34:40,063:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-11-04 23:34:40,102:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:34:40,129:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:34:40,129:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:34:40,131:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:34:40,170:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:34:40,197:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:34:40,197:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:34:40,199:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:34:40,199:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-04 23:34:40,238:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:34:40,265:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:34:40,267:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:34:40,307:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:34:40,334:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:34:40,335:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:34:40,335:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-11-04 23:34:40,401:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:34:40,403:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:34:40,473:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:34:40,475:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:34:40,475:INFO:Preparing preprocessing pipeline...
2023-11-04 23:34:40,475:INFO:Set up simple imputation.
2023-11-04 23:34:40,475:INFO:Set up variance threshold.
2023-11-04 23:34:40,475:INFO:Set up removing multicollinearity.
2023-11-04 23:34:40,476:INFO:Set up column name cleaning.
2023-11-04 23:34:40,492:INFO:Finished creating preprocessing pipeline.
2023-11-04 23:34:40,496:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/h9/5_75v3qs13x63s15wwxdrd000000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['sepal length (cm)',
                                             'petal length (cm)',
                                             'petal width (cm)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.1))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-11-04 23:34:40,496:INFO:Creating final display dataframe.
2023-11-04 23:34:40,539:INFO:Setup _display_container:                     Description             Value
0                    Session id              2657
1                        Target  sepal width (cm)
2                   Target type        Regression
3           Original data shape          (233, 4)
4        Transformed data shape          (233, 3)
5   Transformed train set shape          (163, 3)
6    Transformed test set shape           (70, 3)
7              Numeric features                 3
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12       Low variance threshold               0.1
13     Remove multicollinearity              True
14  Multicollinearity threshold              0.95
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              967e
2023-11-04 23:34:40,612:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:34:40,613:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:34:40,682:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:34:40,683:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:34:40,684:INFO:setup() successfully completed in 1.07s...............
2023-11-04 23:34:40,684:INFO:Initializing compare_models()
2023-11-04 23:34:40,684:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e4f910>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e4f910>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-11-04 23:34:40,684:INFO:Checking exceptions
2023-11-04 23:34:40,685:INFO:Preparing display monitor
2023-11-04 23:34:40,704:INFO:Initializing Linear Regression
2023-11-04 23:34:40,704:INFO:Total runtime is 2.7139981587727863e-06 minutes
2023-11-04 23:34:40,705:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:40,706:INFO:Initializing create_model()
2023-11-04 23:34:40,706:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e4f910>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb61472de80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:40,706:INFO:Checking exceptions
2023-11-04 23:34:40,706:INFO:Importing libraries
2023-11-04 23:34:40,706:INFO:Copying training dataset
2023-11-04 23:34:40,707:INFO:Defining folds
2023-11-04 23:34:40,707:INFO:Declaring metric variables
2023-11-04 23:34:40,709:INFO:Importing untrained model
2023-11-04 23:34:40,711:INFO:Linear Regression Imported successfully
2023-11-04 23:34:40,714:INFO:Starting cross validation
2023-11-04 23:34:40,715:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:40,766:INFO:Calculating mean and std
2023-11-04 23:34:40,766:INFO:Creating metrics dataframe
2023-11-04 23:34:40,768:INFO:Uploading results into container
2023-11-04 23:34:40,768:INFO:Uploading model into container now
2023-11-04 23:34:40,769:INFO:_master_model_container: 1
2023-11-04 23:34:40,769:INFO:_display_container: 2
2023-11-04 23:34:40,769:INFO:LinearRegression(n_jobs=-1)
2023-11-04 23:34:40,769:INFO:create_model() successfully completed......................................
2023-11-04 23:34:40,909:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:40,909:INFO:Creating metrics dataframe
2023-11-04 23:34:40,913:INFO:Initializing Lasso Regression
2023-11-04 23:34:40,913:INFO:Total runtime is 0.003495482603708903 minutes
2023-11-04 23:34:40,915:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:40,915:INFO:Initializing create_model()
2023-11-04 23:34:40,915:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e4f910>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb61472de80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:40,916:INFO:Checking exceptions
2023-11-04 23:34:40,916:INFO:Importing libraries
2023-11-04 23:34:40,916:INFO:Copying training dataset
2023-11-04 23:34:40,917:INFO:Defining folds
2023-11-04 23:34:40,917:INFO:Declaring metric variables
2023-11-04 23:34:40,919:INFO:Importing untrained model
2023-11-04 23:34:40,920:INFO:Lasso Regression Imported successfully
2023-11-04 23:34:40,923:INFO:Starting cross validation
2023-11-04 23:34:40,924:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:40,975:INFO:Calculating mean and std
2023-11-04 23:34:40,975:INFO:Creating metrics dataframe
2023-11-04 23:34:40,977:INFO:Uploading results into container
2023-11-04 23:34:40,977:INFO:Uploading model into container now
2023-11-04 23:34:40,977:INFO:_master_model_container: 2
2023-11-04 23:34:40,977:INFO:_display_container: 2
2023-11-04 23:34:40,978:INFO:Lasso(random_state=2657)
2023-11-04 23:34:40,978:INFO:create_model() successfully completed......................................
2023-11-04 23:34:41,113:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:41,114:INFO:Creating metrics dataframe
2023-11-04 23:34:41,118:INFO:Initializing Ridge Regression
2023-11-04 23:34:41,118:INFO:Total runtime is 0.006914150714874267 minutes
2023-11-04 23:34:41,120:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:41,120:INFO:Initializing create_model()
2023-11-04 23:34:41,121:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e4f910>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb61472de80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:41,121:INFO:Checking exceptions
2023-11-04 23:34:41,121:INFO:Importing libraries
2023-11-04 23:34:41,121:INFO:Copying training dataset
2023-11-04 23:34:41,122:INFO:Defining folds
2023-11-04 23:34:41,122:INFO:Declaring metric variables
2023-11-04 23:34:41,124:INFO:Importing untrained model
2023-11-04 23:34:41,125:INFO:Ridge Regression Imported successfully
2023-11-04 23:34:41,128:INFO:Starting cross validation
2023-11-04 23:34:41,129:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:41,180:INFO:Calculating mean and std
2023-11-04 23:34:41,181:INFO:Creating metrics dataframe
2023-11-04 23:34:41,182:INFO:Uploading results into container
2023-11-04 23:34:41,183:INFO:Uploading model into container now
2023-11-04 23:34:41,183:INFO:_master_model_container: 3
2023-11-04 23:34:41,183:INFO:_display_container: 2
2023-11-04 23:34:41,183:INFO:Ridge(random_state=2657)
2023-11-04 23:34:41,183:INFO:create_model() successfully completed......................................
2023-11-04 23:34:41,318:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:41,318:INFO:Creating metrics dataframe
2023-11-04 23:34:41,323:INFO:Initializing Elastic Net
2023-11-04 23:34:41,323:INFO:Total runtime is 0.01032429536183675 minutes
2023-11-04 23:34:41,325:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:41,325:INFO:Initializing create_model()
2023-11-04 23:34:41,325:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e4f910>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb61472de80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:41,325:INFO:Checking exceptions
2023-11-04 23:34:41,325:INFO:Importing libraries
2023-11-04 23:34:41,325:INFO:Copying training dataset
2023-11-04 23:34:41,327:INFO:Defining folds
2023-11-04 23:34:41,327:INFO:Declaring metric variables
2023-11-04 23:34:41,328:INFO:Importing untrained model
2023-11-04 23:34:41,330:INFO:Elastic Net Imported successfully
2023-11-04 23:34:41,333:INFO:Starting cross validation
2023-11-04 23:34:41,334:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:41,388:INFO:Calculating mean and std
2023-11-04 23:34:41,388:INFO:Creating metrics dataframe
2023-11-04 23:34:41,390:INFO:Uploading results into container
2023-11-04 23:34:41,390:INFO:Uploading model into container now
2023-11-04 23:34:41,390:INFO:_master_model_container: 4
2023-11-04 23:34:41,390:INFO:_display_container: 2
2023-11-04 23:34:41,391:INFO:ElasticNet(random_state=2657)
2023-11-04 23:34:41,391:INFO:create_model() successfully completed......................................
2023-11-04 23:34:41,525:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:41,525:INFO:Creating metrics dataframe
2023-11-04 23:34:41,531:INFO:Initializing Least Angle Regression
2023-11-04 23:34:41,531:INFO:Total runtime is 0.013785330454508462 minutes
2023-11-04 23:34:41,533:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:41,533:INFO:Initializing create_model()
2023-11-04 23:34:41,533:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e4f910>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb61472de80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:41,533:INFO:Checking exceptions
2023-11-04 23:34:41,533:INFO:Importing libraries
2023-11-04 23:34:41,533:INFO:Copying training dataset
2023-11-04 23:34:41,535:INFO:Defining folds
2023-11-04 23:34:41,535:INFO:Declaring metric variables
2023-11-04 23:34:41,536:INFO:Importing untrained model
2023-11-04 23:34:41,538:INFO:Least Angle Regression Imported successfully
2023-11-04 23:34:41,541:INFO:Starting cross validation
2023-11-04 23:34:41,541:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:41,559:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:41,561:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:41,575:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:41,576:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:41,576:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:41,576:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:41,578:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:41,579:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:41,588:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:41,588:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:41,593:INFO:Calculating mean and std
2023-11-04 23:34:41,594:INFO:Creating metrics dataframe
2023-11-04 23:34:41,595:INFO:Uploading results into container
2023-11-04 23:34:41,596:INFO:Uploading model into container now
2023-11-04 23:34:41,596:INFO:_master_model_container: 5
2023-11-04 23:34:41,596:INFO:_display_container: 2
2023-11-04 23:34:41,596:INFO:Lars(random_state=2657)
2023-11-04 23:34:41,596:INFO:create_model() successfully completed......................................
2023-11-04 23:34:41,731:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:41,731:INFO:Creating metrics dataframe
2023-11-04 23:34:41,737:INFO:Initializing Lasso Least Angle Regression
2023-11-04 23:34:41,737:INFO:Total runtime is 0.01721716324488322 minutes
2023-11-04 23:34:41,738:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:41,739:INFO:Initializing create_model()
2023-11-04 23:34:41,739:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e4f910>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb61472de80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:41,739:INFO:Checking exceptions
2023-11-04 23:34:41,739:INFO:Importing libraries
2023-11-04 23:34:41,739:INFO:Copying training dataset
2023-11-04 23:34:41,741:INFO:Defining folds
2023-11-04 23:34:41,741:INFO:Declaring metric variables
2023-11-04 23:34:41,743:INFO:Importing untrained model
2023-11-04 23:34:41,745:INFO:Lasso Least Angle Regression Imported successfully
2023-11-04 23:34:41,748:INFO:Starting cross validation
2023-11-04 23:34:41,749:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:41,766:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:34:41,767:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:34:41,779:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:34:41,779:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:34:41,780:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:34:41,786:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:34:41,789:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:34:41,792:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:34:41,792:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:34:41,798:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:34:41,803:INFO:Calculating mean and std
2023-11-04 23:34:41,803:INFO:Creating metrics dataframe
2023-11-04 23:34:41,804:INFO:Uploading results into container
2023-11-04 23:34:41,805:INFO:Uploading model into container now
2023-11-04 23:34:41,805:INFO:_master_model_container: 6
2023-11-04 23:34:41,805:INFO:_display_container: 2
2023-11-04 23:34:41,805:INFO:LassoLars(random_state=2657)
2023-11-04 23:34:41,805:INFO:create_model() successfully completed......................................
2023-11-04 23:34:41,940:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:41,940:INFO:Creating metrics dataframe
2023-11-04 23:34:41,946:INFO:Initializing Orthogonal Matching Pursuit
2023-11-04 23:34:41,946:INFO:Total runtime is 0.02070219914118449 minutes
2023-11-04 23:34:41,948:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:41,948:INFO:Initializing create_model()
2023-11-04 23:34:41,948:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e4f910>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb61472de80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:41,948:INFO:Checking exceptions
2023-11-04 23:34:41,948:INFO:Importing libraries
2023-11-04 23:34:41,948:INFO:Copying training dataset
2023-11-04 23:34:41,950:INFO:Defining folds
2023-11-04 23:34:41,950:INFO:Declaring metric variables
2023-11-04 23:34:41,952:INFO:Importing untrained model
2023-11-04 23:34:41,954:INFO:Orthogonal Matching Pursuit Imported successfully
2023-11-04 23:34:41,957:INFO:Starting cross validation
2023-11-04 23:34:41,957:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:41,973:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:41,979:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:41,987:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:41,987:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:41,988:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:41,991:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:41,999:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:42,000:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:42,000:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:42,002:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:42,007:INFO:Calculating mean and std
2023-11-04 23:34:42,007:INFO:Creating metrics dataframe
2023-11-04 23:34:42,009:INFO:Uploading results into container
2023-11-04 23:34:42,009:INFO:Uploading model into container now
2023-11-04 23:34:42,009:INFO:_master_model_container: 7
2023-11-04 23:34:42,010:INFO:_display_container: 2
2023-11-04 23:34:42,010:INFO:OrthogonalMatchingPursuit()
2023-11-04 23:34:42,010:INFO:create_model() successfully completed......................................
2023-11-04 23:34:42,147:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:42,147:INFO:Creating metrics dataframe
2023-11-04 23:34:42,152:INFO:Initializing Bayesian Ridge
2023-11-04 23:34:42,152:INFO:Total runtime is 0.02414712905883789 minutes
2023-11-04 23:34:42,155:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:42,155:INFO:Initializing create_model()
2023-11-04 23:34:42,155:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e4f910>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb61472de80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:42,155:INFO:Checking exceptions
2023-11-04 23:34:42,155:INFO:Importing libraries
2023-11-04 23:34:42,155:INFO:Copying training dataset
2023-11-04 23:34:42,157:INFO:Defining folds
2023-11-04 23:34:42,157:INFO:Declaring metric variables
2023-11-04 23:34:42,159:INFO:Importing untrained model
2023-11-04 23:34:42,161:INFO:Bayesian Ridge Imported successfully
2023-11-04 23:34:42,164:INFO:Starting cross validation
2023-11-04 23:34:42,165:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:42,218:INFO:Calculating mean and std
2023-11-04 23:34:42,218:INFO:Creating metrics dataframe
2023-11-04 23:34:42,220:INFO:Uploading results into container
2023-11-04 23:34:42,220:INFO:Uploading model into container now
2023-11-04 23:34:42,220:INFO:_master_model_container: 8
2023-11-04 23:34:42,220:INFO:_display_container: 2
2023-11-04 23:34:42,220:INFO:BayesianRidge()
2023-11-04 23:34:42,220:INFO:create_model() successfully completed......................................
2023-11-04 23:34:42,356:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:42,356:INFO:Creating metrics dataframe
2023-11-04 23:34:42,362:INFO:Initializing Passive Aggressive Regressor
2023-11-04 23:34:42,362:INFO:Total runtime is 0.027646382649739582 minutes
2023-11-04 23:34:42,364:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:42,364:INFO:Initializing create_model()
2023-11-04 23:34:42,364:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e4f910>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb61472de80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:42,365:INFO:Checking exceptions
2023-11-04 23:34:42,365:INFO:Importing libraries
2023-11-04 23:34:42,365:INFO:Copying training dataset
2023-11-04 23:34:42,367:INFO:Defining folds
2023-11-04 23:34:42,367:INFO:Declaring metric variables
2023-11-04 23:34:42,368:INFO:Importing untrained model
2023-11-04 23:34:42,370:INFO:Passive Aggressive Regressor Imported successfully
2023-11-04 23:34:42,373:INFO:Starting cross validation
2023-11-04 23:34:42,374:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:42,423:INFO:Calculating mean and std
2023-11-04 23:34:42,424:INFO:Creating metrics dataframe
2023-11-04 23:34:42,425:INFO:Uploading results into container
2023-11-04 23:34:42,426:INFO:Uploading model into container now
2023-11-04 23:34:42,426:INFO:_master_model_container: 9
2023-11-04 23:34:42,426:INFO:_display_container: 2
2023-11-04 23:34:42,426:INFO:PassiveAggressiveRegressor(random_state=2657)
2023-11-04 23:34:42,426:INFO:create_model() successfully completed......................................
2023-11-04 23:34:42,562:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:42,562:INFO:Creating metrics dataframe
2023-11-04 23:34:42,568:INFO:Initializing Huber Regressor
2023-11-04 23:34:42,568:INFO:Total runtime is 0.031078163782755533 minutes
2023-11-04 23:34:42,570:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:42,570:INFO:Initializing create_model()
2023-11-04 23:34:42,570:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e4f910>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb61472de80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:42,570:INFO:Checking exceptions
2023-11-04 23:34:42,571:INFO:Importing libraries
2023-11-04 23:34:42,571:INFO:Copying training dataset
2023-11-04 23:34:42,573:INFO:Defining folds
2023-11-04 23:34:42,573:INFO:Declaring metric variables
2023-11-04 23:34:42,574:INFO:Importing untrained model
2023-11-04 23:34:42,576:INFO:Huber Regressor Imported successfully
2023-11-04 23:34:42,579:INFO:Starting cross validation
2023-11-04 23:34:42,580:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:42,636:INFO:Calculating mean and std
2023-11-04 23:34:42,636:INFO:Creating metrics dataframe
2023-11-04 23:34:42,638:INFO:Uploading results into container
2023-11-04 23:34:42,638:INFO:Uploading model into container now
2023-11-04 23:34:42,639:INFO:_master_model_container: 10
2023-11-04 23:34:42,639:INFO:_display_container: 2
2023-11-04 23:34:42,639:INFO:HuberRegressor()
2023-11-04 23:34:42,639:INFO:create_model() successfully completed......................................
2023-11-04 23:34:42,774:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:42,774:INFO:Creating metrics dataframe
2023-11-04 23:34:42,780:INFO:Initializing K Neighbors Regressor
2023-11-04 23:34:42,780:INFO:Total runtime is 0.03461318016052246 minutes
2023-11-04 23:34:42,782:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:42,782:INFO:Initializing create_model()
2023-11-04 23:34:42,782:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e4f910>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb61472de80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:42,783:INFO:Checking exceptions
2023-11-04 23:34:42,783:INFO:Importing libraries
2023-11-04 23:34:42,783:INFO:Copying training dataset
2023-11-04 23:34:42,785:INFO:Defining folds
2023-11-04 23:34:42,785:INFO:Declaring metric variables
2023-11-04 23:34:42,787:INFO:Importing untrained model
2023-11-04 23:34:42,788:INFO:K Neighbors Regressor Imported successfully
2023-11-04 23:34:42,791:INFO:Starting cross validation
2023-11-04 23:34:42,792:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:42,856:INFO:Calculating mean and std
2023-11-04 23:34:42,856:INFO:Creating metrics dataframe
2023-11-04 23:34:42,858:INFO:Uploading results into container
2023-11-04 23:34:42,858:INFO:Uploading model into container now
2023-11-04 23:34:42,858:INFO:_master_model_container: 11
2023-11-04 23:34:42,858:INFO:_display_container: 2
2023-11-04 23:34:42,858:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-04 23:34:42,858:INFO:create_model() successfully completed......................................
2023-11-04 23:34:42,993:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:42,993:INFO:Creating metrics dataframe
2023-11-04 23:34:42,999:INFO:Initializing Decision Tree Regressor
2023-11-04 23:34:42,999:INFO:Total runtime is 0.03826441367467244 minutes
2023-11-04 23:34:43,001:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:43,001:INFO:Initializing create_model()
2023-11-04 23:34:43,002:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e4f910>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb61472de80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:43,002:INFO:Checking exceptions
2023-11-04 23:34:43,002:INFO:Importing libraries
2023-11-04 23:34:43,002:INFO:Copying training dataset
2023-11-04 23:34:43,004:INFO:Defining folds
2023-11-04 23:34:43,004:INFO:Declaring metric variables
2023-11-04 23:34:43,005:INFO:Importing untrained model
2023-11-04 23:34:43,007:INFO:Decision Tree Regressor Imported successfully
2023-11-04 23:34:43,010:INFO:Starting cross validation
2023-11-04 23:34:43,011:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:43,060:INFO:Calculating mean and std
2023-11-04 23:34:43,060:INFO:Creating metrics dataframe
2023-11-04 23:34:43,062:INFO:Uploading results into container
2023-11-04 23:34:43,062:INFO:Uploading model into container now
2023-11-04 23:34:43,062:INFO:_master_model_container: 12
2023-11-04 23:34:43,063:INFO:_display_container: 2
2023-11-04 23:34:43,063:INFO:DecisionTreeRegressor(random_state=2657)
2023-11-04 23:34:43,063:INFO:create_model() successfully completed......................................
2023-11-04 23:34:43,198:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:43,198:INFO:Creating metrics dataframe
2023-11-04 23:34:43,204:INFO:Initializing Random Forest Regressor
2023-11-04 23:34:43,205:INFO:Total runtime is 0.04168243010838826 minutes
2023-11-04 23:34:43,206:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:43,206:INFO:Initializing create_model()
2023-11-04 23:34:43,207:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e4f910>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb61472de80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:43,207:INFO:Checking exceptions
2023-11-04 23:34:43,207:INFO:Importing libraries
2023-11-04 23:34:43,207:INFO:Copying training dataset
2023-11-04 23:34:43,209:INFO:Defining folds
2023-11-04 23:34:43,209:INFO:Declaring metric variables
2023-11-04 23:34:43,210:INFO:Importing untrained model
2023-11-04 23:34:43,212:INFO:Random Forest Regressor Imported successfully
2023-11-04 23:34:43,215:INFO:Starting cross validation
2023-11-04 23:34:43,216:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:43,469:INFO:Calculating mean and std
2023-11-04 23:34:43,470:INFO:Creating metrics dataframe
2023-11-04 23:34:43,472:INFO:Uploading results into container
2023-11-04 23:34:43,472:INFO:Uploading model into container now
2023-11-04 23:34:43,472:INFO:_master_model_container: 13
2023-11-04 23:34:43,472:INFO:_display_container: 2
2023-11-04 23:34:43,472:INFO:RandomForestRegressor(n_jobs=-1, random_state=2657)
2023-11-04 23:34:43,472:INFO:create_model() successfully completed......................................
2023-11-04 23:34:43,609:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:43,609:INFO:Creating metrics dataframe
2023-11-04 23:34:43,615:INFO:Initializing Extra Trees Regressor
2023-11-04 23:34:43,615:INFO:Total runtime is 0.048529549439748125 minutes
2023-11-04 23:34:43,617:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:43,617:INFO:Initializing create_model()
2023-11-04 23:34:43,617:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e4f910>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb61472de80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:43,617:INFO:Checking exceptions
2023-11-04 23:34:43,617:INFO:Importing libraries
2023-11-04 23:34:43,618:INFO:Copying training dataset
2023-11-04 23:34:43,620:INFO:Defining folds
2023-11-04 23:34:43,620:INFO:Declaring metric variables
2023-11-04 23:34:43,621:INFO:Importing untrained model
2023-11-04 23:34:43,623:INFO:Extra Trees Regressor Imported successfully
2023-11-04 23:34:43,626:INFO:Starting cross validation
2023-11-04 23:34:43,627:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:43,822:INFO:Calculating mean and std
2023-11-04 23:34:43,823:INFO:Creating metrics dataframe
2023-11-04 23:34:43,824:INFO:Uploading results into container
2023-11-04 23:34:43,825:INFO:Uploading model into container now
2023-11-04 23:34:43,825:INFO:_master_model_container: 14
2023-11-04 23:34:43,825:INFO:_display_container: 2
2023-11-04 23:34:43,826:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=2657)
2023-11-04 23:34:43,826:INFO:create_model() successfully completed......................................
2023-11-04 23:34:43,963:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:43,963:INFO:Creating metrics dataframe
2023-11-04 23:34:43,969:INFO:Initializing AdaBoost Regressor
2023-11-04 23:34:43,969:INFO:Total runtime is 0.05443074703216552 minutes
2023-11-04 23:34:43,971:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:43,971:INFO:Initializing create_model()
2023-11-04 23:34:43,972:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e4f910>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb61472de80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:43,972:INFO:Checking exceptions
2023-11-04 23:34:43,972:INFO:Importing libraries
2023-11-04 23:34:43,972:INFO:Copying training dataset
2023-11-04 23:34:43,974:INFO:Defining folds
2023-11-04 23:34:43,974:INFO:Declaring metric variables
2023-11-04 23:34:43,976:INFO:Importing untrained model
2023-11-04 23:34:43,978:INFO:AdaBoost Regressor Imported successfully
2023-11-04 23:34:43,981:INFO:Starting cross validation
2023-11-04 23:34:43,982:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:44,079:INFO:Calculating mean and std
2023-11-04 23:34:44,080:INFO:Creating metrics dataframe
2023-11-04 23:34:44,082:INFO:Uploading results into container
2023-11-04 23:34:44,082:INFO:Uploading model into container now
2023-11-04 23:34:44,082:INFO:_master_model_container: 15
2023-11-04 23:34:44,082:INFO:_display_container: 2
2023-11-04 23:34:44,083:INFO:AdaBoostRegressor(random_state=2657)
2023-11-04 23:34:44,083:INFO:create_model() successfully completed......................................
2023-11-04 23:34:44,218:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:44,218:INFO:Creating metrics dataframe
2023-11-04 23:34:44,224:INFO:Initializing Gradient Boosting Regressor
2023-11-04 23:34:44,224:INFO:Total runtime is 0.058680367469787595 minutes
2023-11-04 23:34:44,226:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:44,226:INFO:Initializing create_model()
2023-11-04 23:34:44,226:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e4f910>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb61472de80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:44,226:INFO:Checking exceptions
2023-11-04 23:34:44,227:INFO:Importing libraries
2023-11-04 23:34:44,227:INFO:Copying training dataset
2023-11-04 23:34:44,229:INFO:Defining folds
2023-11-04 23:34:44,229:INFO:Declaring metric variables
2023-11-04 23:34:44,231:INFO:Importing untrained model
2023-11-04 23:34:44,232:INFO:Gradient Boosting Regressor Imported successfully
2023-11-04 23:34:44,235:INFO:Starting cross validation
2023-11-04 23:34:44,236:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:44,306:INFO:Calculating mean and std
2023-11-04 23:34:44,307:INFO:Creating metrics dataframe
2023-11-04 23:34:44,308:INFO:Uploading results into container
2023-11-04 23:34:44,308:INFO:Uploading model into container now
2023-11-04 23:34:44,309:INFO:_master_model_container: 16
2023-11-04 23:34:44,309:INFO:_display_container: 2
2023-11-04 23:34:44,309:INFO:GradientBoostingRegressor(random_state=2657)
2023-11-04 23:34:44,309:INFO:create_model() successfully completed......................................
2023-11-04 23:34:44,444:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:44,444:INFO:Creating metrics dataframe
2023-11-04 23:34:44,451:INFO:Initializing Extreme Gradient Boosting
2023-11-04 23:34:44,451:INFO:Total runtime is 0.06245848337809245 minutes
2023-11-04 23:34:44,453:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:44,453:INFO:Initializing create_model()
2023-11-04 23:34:44,453:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e4f910>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb61472de80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:44,453:INFO:Checking exceptions
2023-11-04 23:34:44,453:INFO:Importing libraries
2023-11-04 23:34:44,454:INFO:Copying training dataset
2023-11-04 23:34:44,455:INFO:Defining folds
2023-11-04 23:34:44,456:INFO:Declaring metric variables
2023-11-04 23:34:44,457:INFO:Importing untrained model
2023-11-04 23:34:44,459:INFO:Extreme Gradient Boosting Imported successfully
2023-11-04 23:34:44,462:INFO:Starting cross validation
2023-11-04 23:34:44,463:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:44,553:INFO:Calculating mean and std
2023-11-04 23:34:44,553:INFO:Creating metrics dataframe
2023-11-04 23:34:44,556:INFO:Uploading results into container
2023-11-04 23:34:44,556:INFO:Uploading model into container now
2023-11-04 23:34:44,556:INFO:_master_model_container: 17
2023-11-04 23:34:44,556:INFO:_display_container: 2
2023-11-04 23:34:44,557:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=2657, ...)
2023-11-04 23:34:44,557:INFO:create_model() successfully completed......................................
2023-11-04 23:34:44,692:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:44,692:INFO:Creating metrics dataframe
2023-11-04 23:34:44,699:INFO:Initializing Light Gradient Boosting Machine
2023-11-04 23:34:44,699:INFO:Total runtime is 0.06659131447474162 minutes
2023-11-04 23:34:44,701:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:44,701:INFO:Initializing create_model()
2023-11-04 23:34:44,701:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e4f910>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb61472de80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:44,701:INFO:Checking exceptions
2023-11-04 23:34:44,701:INFO:Importing libraries
2023-11-04 23:34:44,701:INFO:Copying training dataset
2023-11-04 23:34:44,703:INFO:Defining folds
2023-11-04 23:34:44,703:INFO:Declaring metric variables
2023-11-04 23:34:44,704:INFO:Importing untrained model
2023-11-04 23:34:44,706:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-04 23:34:44,710:INFO:Starting cross validation
2023-11-04 23:34:44,711:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:44,769:INFO:Calculating mean and std
2023-11-04 23:34:44,769:INFO:Creating metrics dataframe
2023-11-04 23:34:44,771:INFO:Uploading results into container
2023-11-04 23:34:44,771:INFO:Uploading model into container now
2023-11-04 23:34:44,771:INFO:_master_model_container: 18
2023-11-04 23:34:44,771:INFO:_display_container: 2
2023-11-04 23:34:44,772:INFO:LGBMRegressor(random_state=2657)
2023-11-04 23:34:44,772:INFO:create_model() successfully completed......................................
2023-11-04 23:34:44,907:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:44,908:INFO:Creating metrics dataframe
2023-11-04 23:34:44,915:INFO:Initializing CatBoost Regressor
2023-11-04 23:34:44,915:INFO:Total runtime is 0.07018707990646363 minutes
2023-11-04 23:34:44,917:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:44,917:INFO:Initializing create_model()
2023-11-04 23:34:44,917:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e4f910>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb61472de80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:44,917:INFO:Checking exceptions
2023-11-04 23:34:44,917:INFO:Importing libraries
2023-11-04 23:34:44,917:INFO:Copying training dataset
2023-11-04 23:34:44,919:INFO:Defining folds
2023-11-04 23:34:44,919:INFO:Declaring metric variables
2023-11-04 23:34:44,921:INFO:Importing untrained model
2023-11-04 23:34:44,923:INFO:CatBoost Regressor Imported successfully
2023-11-04 23:34:44,926:INFO:Starting cross validation
2023-11-04 23:34:44,926:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:45,463:INFO:Calculating mean and std
2023-11-04 23:34:45,464:INFO:Creating metrics dataframe
2023-11-04 23:34:45,466:INFO:Uploading results into container
2023-11-04 23:34:45,466:INFO:Uploading model into container now
2023-11-04 23:34:45,466:INFO:_master_model_container: 19
2023-11-04 23:34:45,467:INFO:_display_container: 2
2023-11-04 23:34:45,467:INFO:<catboost.core.CatBoostRegressor object at 0x7fb5e6479040>
2023-11-04 23:34:45,467:INFO:create_model() successfully completed......................................
2023-11-04 23:34:45,609:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:45,609:INFO:Creating metrics dataframe
2023-11-04 23:34:45,616:INFO:Initializing Dummy Regressor
2023-11-04 23:34:45,616:INFO:Total runtime is 0.08187727928161621 minutes
2023-11-04 23:34:45,618:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:45,618:INFO:Initializing create_model()
2023-11-04 23:34:45,618:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e4f910>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb61472de80>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:45,618:INFO:Checking exceptions
2023-11-04 23:34:45,619:INFO:Importing libraries
2023-11-04 23:34:45,619:INFO:Copying training dataset
2023-11-04 23:34:45,621:INFO:Defining folds
2023-11-04 23:34:45,621:INFO:Declaring metric variables
2023-11-04 23:34:45,622:INFO:Importing untrained model
2023-11-04 23:34:45,624:INFO:Dummy Regressor Imported successfully
2023-11-04 23:34:45,627:INFO:Starting cross validation
2023-11-04 23:34:45,628:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:45,681:INFO:Calculating mean and std
2023-11-04 23:34:45,681:INFO:Creating metrics dataframe
2023-11-04 23:34:45,682:INFO:Uploading results into container
2023-11-04 23:34:45,683:INFO:Uploading model into container now
2023-11-04 23:34:45,683:INFO:_master_model_container: 20
2023-11-04 23:34:45,683:INFO:_display_container: 2
2023-11-04 23:34:45,683:INFO:DummyRegressor()
2023-11-04 23:34:45,683:INFO:create_model() successfully completed......................................
2023-11-04 23:34:45,819:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:45,819:INFO:Creating metrics dataframe
2023-11-04 23:34:45,831:INFO:Initializing create_model()
2023-11-04 23:34:45,832:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e4f910>, estimator=KNeighborsRegressor(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:45,832:INFO:Checking exceptions
2023-11-04 23:34:45,833:INFO:Importing libraries
2023-11-04 23:34:45,833:INFO:Copying training dataset
2023-11-04 23:34:45,834:INFO:Defining folds
2023-11-04 23:34:45,834:INFO:Declaring metric variables
2023-11-04 23:34:45,834:INFO:Importing untrained model
2023-11-04 23:34:45,834:INFO:Declaring custom model
2023-11-04 23:34:45,835:INFO:K Neighbors Regressor Imported successfully
2023-11-04 23:34:45,835:INFO:Cross validation set to False
2023-11-04 23:34:45,835:INFO:Fitting Model
2023-11-04 23:34:45,843:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-04 23:34:45,843:INFO:create_model() successfully completed......................................
2023-11-04 23:34:46,001:INFO:_master_model_container: 20
2023-11-04 23:34:46,001:INFO:_display_container: 2
2023-11-04 23:34:46,001:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-04 23:34:46,001:INFO:compare_models() successfully completed......................................
2023-11-04 23:34:54,825:INFO:PyCaret RegressionExperiment
2023-11-04 23:34:54,825:INFO:Logging name: reg-default-name
2023-11-04 23:34:54,825:INFO:ML Usecase: MLUsecase.REGRESSION
2023-11-04 23:34:54,825:INFO:version 3.1.0
2023-11-04 23:34:54,825:INFO:Initializing setup()
2023-11-04 23:34:54,825:INFO:self.USI: 66d3
2023-11-04 23:34:54,825:INFO:self._variable_keys: {'X_test', 'logging_param', 'y_test', 'y_train', 'X_train', 'transform_target_param', 'target_param', 'pipeline', '_available_plots', 'log_plots_param', 'seed', 'exp_id', 'X', 'memory', 'fold_generator', 'fold_groups_param', 'html_param', 'idx', 'gpu_n_jobs_param', 'fold_shuffle_param', 'exp_name_log', 'USI', 'data', 'n_jobs_param', '_ml_usecase', 'gpu_param', 'y'}
2023-11-04 23:34:54,826:INFO:Checking environment
2023-11-04 23:34:54,826:INFO:python_version: 3.9.13
2023-11-04 23:34:54,826:INFO:python_build: ('main', 'Aug 25 2022 18:29:29')
2023-11-04 23:34:54,826:INFO:machine: x86_64
2023-11-04 23:34:54,826:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-11-04 23:34:54,826:INFO:Memory: svmem(total=17179869184, available=1389944832, percent=91.9, used=1846489088, free=27676672, active=1379786752, inactive=1356013568, wired=466702336)
2023-11-04 23:34:54,826:INFO:Physical Core: 8
2023-11-04 23:34:54,826:INFO:Logical Core: 8
2023-11-04 23:34:54,826:INFO:Checking libraries
2023-11-04 23:34:54,826:INFO:System:
2023-11-04 23:34:54,826:INFO:    python: 3.9.13 (main, Aug 25 2022, 18:29:29)  [Clang 12.0.0 ]
2023-11-04 23:34:54,826:INFO:executable: /Users/michal/opt/anaconda3/bin/python
2023-11-04 23:34:54,826:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-11-04 23:34:54,827:INFO:PyCaret required dependencies:
2023-11-04 23:34:54,827:INFO:                 pip: 22.2.2
2023-11-04 23:34:54,827:INFO:          setuptools: 63.4.1
2023-11-04 23:34:54,827:INFO:             pycaret: 3.1.0
2023-11-04 23:34:54,827:INFO:             IPython: 7.31.1
2023-11-04 23:34:54,827:INFO:          ipywidgets: 7.6.5
2023-11-04 23:34:54,827:INFO:                tqdm: 4.64.1
2023-11-04 23:34:54,827:INFO:               numpy: 1.21.5
2023-11-04 23:34:54,827:INFO:              pandas: 1.4.4
2023-11-04 23:34:54,827:INFO:              jinja2: 2.11.3
2023-11-04 23:34:54,827:INFO:               scipy: 1.10.1
2023-11-04 23:34:54,827:INFO:              joblib: 1.2.0
2023-11-04 23:34:54,827:INFO:             sklearn: 1.0.2
2023-11-04 23:34:54,827:INFO:                pyod: 1.1.1
2023-11-04 23:34:54,827:INFO:            imblearn: 0.10.1
2023-11-04 23:34:54,827:INFO:   category_encoders: 2.6.3
2023-11-04 23:34:54,828:INFO:            lightgbm: 3.3.5
2023-11-04 23:34:54,828:INFO:               numba: 0.55.1
2023-11-04 23:34:54,828:INFO:            requests: 2.28.1
2023-11-04 23:34:54,828:INFO:          matplotlib: 3.5.2
2023-11-04 23:34:54,828:INFO:          scikitplot: 0.3.7
2023-11-04 23:34:54,828:INFO:         yellowbrick: 1.5
2023-11-04 23:34:54,828:INFO:              plotly: 5.9.0
2023-11-04 23:34:54,828:INFO:    plotly-resampler: Not installed
2023-11-04 23:34:54,828:INFO:             kaleido: 0.2.1
2023-11-04 23:34:54,828:INFO:           schemdraw: 0.15
2023-11-04 23:34:54,828:INFO:         statsmodels: 0.13.2
2023-11-04 23:34:54,828:INFO:              sktime: 0.21.1
2023-11-04 23:34:54,828:INFO:               tbats: 1.1.3
2023-11-04 23:34:54,828:INFO:            pmdarima: 2.0.4
2023-11-04 23:34:54,828:INFO:              psutil: 5.9.0
2023-11-04 23:34:54,828:INFO:          markupsafe: 2.0.1
2023-11-04 23:34:54,828:INFO:             pickle5: Not installed
2023-11-04 23:34:54,828:INFO:         cloudpickle: 2.0.0
2023-11-04 23:34:54,828:INFO:         deprecation: 2.1.0
2023-11-04 23:34:54,828:INFO:              xxhash: 3.4.1
2023-11-04 23:34:54,828:INFO:           wurlitzer: 3.0.2
2023-11-04 23:34:54,828:INFO:PyCaret optional dependencies:
2023-11-04 23:34:54,829:INFO:                shap: 0.41.0
2023-11-04 23:34:54,829:INFO:           interpret: Not installed
2023-11-04 23:34:54,829:INFO:                umap: 0.5.3
2023-11-04 23:34:54,829:INFO:     ydata_profiling: Not installed
2023-11-04 23:34:54,829:INFO:  explainerdashboard: Not installed
2023-11-04 23:34:54,829:INFO:             autoviz: Not installed
2023-11-04 23:34:54,829:INFO:           fairlearn: Not installed
2023-11-04 23:34:54,829:INFO:          deepchecks: Not installed
2023-11-04 23:34:54,829:INFO:             xgboost: 1.7.4
2023-11-04 23:34:54,829:INFO:            catboost: 1.2
2023-11-04 23:34:54,829:INFO:              kmodes: Not installed
2023-11-04 23:34:54,829:INFO:             mlxtend: 0.21.0
2023-11-04 23:34:54,829:INFO:       statsforecast: Not installed
2023-11-04 23:34:54,829:INFO:        tune_sklearn: Not installed
2023-11-04 23:34:54,829:INFO:                 ray: Not installed
2023-11-04 23:34:54,829:INFO:            hyperopt: Not installed
2023-11-04 23:34:54,829:INFO:              optuna: Not installed
2023-11-04 23:34:54,829:INFO:               skopt: Not installed
2023-11-04 23:34:54,829:INFO:              mlflow: Not installed
2023-11-04 23:34:54,829:INFO:              gradio: Not installed
2023-11-04 23:34:54,829:INFO:             fastapi: Not installed
2023-11-04 23:34:54,829:INFO:             uvicorn: Not installed
2023-11-04 23:34:54,830:INFO:              m2cgen: Not installed
2023-11-04 23:34:54,830:INFO:           evidently: Not installed
2023-11-04 23:34:54,830:INFO:               fugue: Not installed
2023-11-04 23:34:54,830:INFO:           streamlit: Not installed
2023-11-04 23:34:54,830:INFO:             prophet: Not installed
2023-11-04 23:34:54,830:INFO:None
2023-11-04 23:34:54,830:INFO:Set up data.
2023-11-04 23:34:54,835:INFO:Set up folding strategy.
2023-11-04 23:34:54,835:INFO:Set up train/test split.
2023-11-04 23:34:54,839:INFO:Set up index.
2023-11-04 23:34:54,839:INFO:Assigning column types.
2023-11-04 23:34:54,841:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-04 23:34:54,842:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-04 23:34:54,846:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 23:34:54,850:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 23:34:54,887:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:34:54,913:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:34:54,914:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:34:54,915:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:34:54,916:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-04 23:34:54,919:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 23:34:54,921:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 23:34:54,956:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:34:54,983:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:34:54,983:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:34:54,984:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:34:54,985:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-11-04 23:34:54,987:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 23:34:54,990:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 23:34:55,024:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:34:55,050:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:34:55,050:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:34:55,051:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:34:55,054:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-04 23:34:55,057:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 23:34:55,090:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:34:55,116:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:34:55,116:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:34:55,118:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:34:55,118:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-11-04 23:34:55,123:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 23:34:55,156:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:34:55,181:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:34:55,182:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:34:55,183:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:34:55,189:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-04 23:34:55,221:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:34:55,247:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:34:55,247:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:34:55,249:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:34:55,249:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-11-04 23:34:55,286:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:34:55,312:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:34:55,312:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:34:55,314:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:34:55,352:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:34:55,377:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-04 23:34:55,377:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:34:55,379:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:34:55,379:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-04 23:34:55,416:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:34:55,443:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:34:55,444:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:34:55,482:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-04 23:34:55,508:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:34:55,509:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:34:55,509:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-11-04 23:34:55,573:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:34:55,575:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:34:55,642:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:34:55,643:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:34:55,644:INFO:Preparing preprocessing pipeline...
2023-11-04 23:34:55,644:INFO:Set up simple imputation.
2023-11-04 23:34:55,644:INFO:Set up variance threshold.
2023-11-04 23:34:55,644:INFO:Set up removing multicollinearity.
2023-11-04 23:34:55,644:INFO:Set up column name cleaning.
2023-11-04 23:34:55,660:INFO:Finished creating preprocessing pipeline.
2023-11-04 23:34:55,663:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/h9/5_75v3qs13x63s15wwxdrd000000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['sepal length (cm)',
                                             'petal length (cm)',
                                             'petal width (cm)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.1))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-11-04 23:34:55,663:INFO:Creating final display dataframe.
2023-11-04 23:34:55,705:INFO:Setup _display_container:                     Description             Value
0                    Session id               649
1                        Target  sepal width (cm)
2                   Target type        Regression
3           Original data shape          (233, 4)
4        Transformed data shape          (233, 3)
5   Transformed train set shape          (163, 3)
6    Transformed test set shape           (70, 3)
7              Numeric features                 3
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12       Low variance threshold               0.1
13     Remove multicollinearity              True
14  Multicollinearity threshold              0.95
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              66d3
2023-11-04 23:34:55,774:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:34:55,775:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:34:55,841:INFO:Soft dependency imported: xgboost: 1.7.4
2023-11-04 23:34:55,843:INFO:Soft dependency imported: catboost: 1.2
2023-11-04 23:34:55,843:INFO:setup() successfully completed in 1.02s...............
2023-11-04 23:34:55,843:INFO:Initializing compare_models()
2023-11-04 23:34:55,843:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e3c3a0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e3c3a0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-11-04 23:34:55,843:INFO:Checking exceptions
2023-11-04 23:34:55,844:INFO:Preparing display monitor
2023-11-04 23:34:55,860:INFO:Initializing Linear Regression
2023-11-04 23:34:55,860:INFO:Total runtime is 1.7523765563964843e-06 minutes
2023-11-04 23:34:55,862:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:55,862:INFO:Initializing create_model()
2023-11-04 23:34:55,862:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e3c3a0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6149902e0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:55,862:INFO:Checking exceptions
2023-11-04 23:34:55,863:INFO:Importing libraries
2023-11-04 23:34:55,863:INFO:Copying training dataset
2023-11-04 23:34:55,864:INFO:Defining folds
2023-11-04 23:34:55,864:INFO:Declaring metric variables
2023-11-04 23:34:55,866:INFO:Importing untrained model
2023-11-04 23:34:55,868:INFO:Linear Regression Imported successfully
2023-11-04 23:34:55,871:INFO:Starting cross validation
2023-11-04 23:34:55,872:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:55,919:INFO:Calculating mean and std
2023-11-04 23:34:55,920:INFO:Creating metrics dataframe
2023-11-04 23:34:55,921:INFO:Uploading results into container
2023-11-04 23:34:55,922:INFO:Uploading model into container now
2023-11-04 23:34:55,922:INFO:_master_model_container: 1
2023-11-04 23:34:55,922:INFO:_display_container: 2
2023-11-04 23:34:55,922:INFO:LinearRegression(n_jobs=-1)
2023-11-04 23:34:55,922:INFO:create_model() successfully completed......................................
2023-11-04 23:34:56,061:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:56,061:INFO:Creating metrics dataframe
2023-11-04 23:34:56,065:INFO:Initializing Lasso Regression
2023-11-04 23:34:56,066:INFO:Total runtime is 0.0034193833669026695 minutes
2023-11-04 23:34:56,067:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:56,067:INFO:Initializing create_model()
2023-11-04 23:34:56,068:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e3c3a0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6149902e0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:56,068:INFO:Checking exceptions
2023-11-04 23:34:56,068:INFO:Importing libraries
2023-11-04 23:34:56,068:INFO:Copying training dataset
2023-11-04 23:34:56,069:INFO:Defining folds
2023-11-04 23:34:56,069:INFO:Declaring metric variables
2023-11-04 23:34:56,071:INFO:Importing untrained model
2023-11-04 23:34:56,072:INFO:Lasso Regression Imported successfully
2023-11-04 23:34:56,075:INFO:Starting cross validation
2023-11-04 23:34:56,076:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:56,124:INFO:Calculating mean and std
2023-11-04 23:34:56,124:INFO:Creating metrics dataframe
2023-11-04 23:34:56,126:INFO:Uploading results into container
2023-11-04 23:34:56,126:INFO:Uploading model into container now
2023-11-04 23:34:56,127:INFO:_master_model_container: 2
2023-11-04 23:34:56,127:INFO:_display_container: 2
2023-11-04 23:34:56,127:INFO:Lasso(random_state=649)
2023-11-04 23:34:56,127:INFO:create_model() successfully completed......................................
2023-11-04 23:34:56,262:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:56,262:INFO:Creating metrics dataframe
2023-11-04 23:34:56,267:INFO:Initializing Ridge Regression
2023-11-04 23:34:56,267:INFO:Total runtime is 0.00677174727121989 minutes
2023-11-04 23:34:56,268:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:56,269:INFO:Initializing create_model()
2023-11-04 23:34:56,269:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e3c3a0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6149902e0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:56,269:INFO:Checking exceptions
2023-11-04 23:34:56,269:INFO:Importing libraries
2023-11-04 23:34:56,269:INFO:Copying training dataset
2023-11-04 23:34:56,270:INFO:Defining folds
2023-11-04 23:34:56,270:INFO:Declaring metric variables
2023-11-04 23:34:56,272:INFO:Importing untrained model
2023-11-04 23:34:56,273:INFO:Ridge Regression Imported successfully
2023-11-04 23:34:56,276:INFO:Starting cross validation
2023-11-04 23:34:56,277:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:56,324:INFO:Calculating mean and std
2023-11-04 23:34:56,325:INFO:Creating metrics dataframe
2023-11-04 23:34:56,326:INFO:Uploading results into container
2023-11-04 23:34:56,327:INFO:Uploading model into container now
2023-11-04 23:34:56,327:INFO:_master_model_container: 3
2023-11-04 23:34:56,327:INFO:_display_container: 2
2023-11-04 23:34:56,327:INFO:Ridge(random_state=649)
2023-11-04 23:34:56,327:INFO:create_model() successfully completed......................................
2023-11-04 23:34:56,467:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:56,467:INFO:Creating metrics dataframe
2023-11-04 23:34:56,472:INFO:Initializing Elastic Net
2023-11-04 23:34:56,472:INFO:Total runtime is 0.010194532076517743 minutes
2023-11-04 23:34:56,474:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:56,474:INFO:Initializing create_model()
2023-11-04 23:34:56,474:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e3c3a0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6149902e0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:56,474:INFO:Checking exceptions
2023-11-04 23:34:56,474:INFO:Importing libraries
2023-11-04 23:34:56,474:INFO:Copying training dataset
2023-11-04 23:34:56,476:INFO:Defining folds
2023-11-04 23:34:56,476:INFO:Declaring metric variables
2023-11-04 23:34:56,477:INFO:Importing untrained model
2023-11-04 23:34:56,479:INFO:Elastic Net Imported successfully
2023-11-04 23:34:56,482:INFO:Starting cross validation
2023-11-04 23:34:56,483:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:56,532:INFO:Calculating mean and std
2023-11-04 23:34:56,532:INFO:Creating metrics dataframe
2023-11-04 23:34:56,534:INFO:Uploading results into container
2023-11-04 23:34:56,534:INFO:Uploading model into container now
2023-11-04 23:34:56,535:INFO:_master_model_container: 4
2023-11-04 23:34:56,535:INFO:_display_container: 2
2023-11-04 23:34:56,535:INFO:ElasticNet(random_state=649)
2023-11-04 23:34:56,535:INFO:create_model() successfully completed......................................
2023-11-04 23:34:56,677:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:56,677:INFO:Creating metrics dataframe
2023-11-04 23:34:56,683:INFO:Initializing Least Angle Regression
2023-11-04 23:34:56,683:INFO:Total runtime is 0.01370575030644735 minutes
2023-11-04 23:34:56,684:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:56,685:INFO:Initializing create_model()
2023-11-04 23:34:56,685:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e3c3a0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6149902e0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:56,685:INFO:Checking exceptions
2023-11-04 23:34:56,685:INFO:Importing libraries
2023-11-04 23:34:56,685:INFO:Copying training dataset
2023-11-04 23:34:56,687:INFO:Defining folds
2023-11-04 23:34:56,687:INFO:Declaring metric variables
2023-11-04 23:34:56,688:INFO:Importing untrained model
2023-11-04 23:34:56,690:INFO:Least Angle Regression Imported successfully
2023-11-04 23:34:56,692:INFO:Starting cross validation
2023-11-04 23:34:56,693:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:56,710:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:56,717:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:56,720:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:56,725:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:56,729:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:56,729:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:56,732:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:56,737:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:56,739:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:56,741:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:56,746:INFO:Calculating mean and std
2023-11-04 23:34:56,746:INFO:Creating metrics dataframe
2023-11-04 23:34:56,748:INFO:Uploading results into container
2023-11-04 23:34:56,748:INFO:Uploading model into container now
2023-11-04 23:34:56,748:INFO:_master_model_container: 5
2023-11-04 23:34:56,748:INFO:_display_container: 2
2023-11-04 23:34:56,748:INFO:Lars(random_state=649)
2023-11-04 23:34:56,748:INFO:create_model() successfully completed......................................
2023-11-04 23:34:56,889:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:56,890:INFO:Creating metrics dataframe
2023-11-04 23:34:56,895:INFO:Initializing Lasso Least Angle Regression
2023-11-04 23:34:56,895:INFO:Total runtime is 0.017245364189147953 minutes
2023-11-04 23:34:56,897:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:56,897:INFO:Initializing create_model()
2023-11-04 23:34:56,897:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e3c3a0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6149902e0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:56,897:INFO:Checking exceptions
2023-11-04 23:34:56,897:INFO:Importing libraries
2023-11-04 23:34:56,897:INFO:Copying training dataset
2023-11-04 23:34:56,900:INFO:Defining folds
2023-11-04 23:34:56,900:INFO:Declaring metric variables
2023-11-04 23:34:56,901:INFO:Importing untrained model
2023-11-04 23:34:56,903:INFO:Lasso Least Angle Regression Imported successfully
2023-11-04 23:34:56,906:INFO:Starting cross validation
2023-11-04 23:34:56,907:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:56,924:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:34:56,926:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:34:56,928:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:34:56,938:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:34:56,941:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:34:56,942:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:34:56,943:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:34:56,950:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:34:56,951:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:34:56,951:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-04 23:34:56,956:INFO:Calculating mean and std
2023-11-04 23:34:56,957:INFO:Creating metrics dataframe
2023-11-04 23:34:56,958:INFO:Uploading results into container
2023-11-04 23:34:56,959:INFO:Uploading model into container now
2023-11-04 23:34:56,959:INFO:_master_model_container: 6
2023-11-04 23:34:56,959:INFO:_display_container: 2
2023-11-04 23:34:56,959:INFO:LassoLars(random_state=649)
2023-11-04 23:34:56,959:INFO:create_model() successfully completed......................................
2023-11-04 23:34:57,102:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:57,102:INFO:Creating metrics dataframe
2023-11-04 23:34:57,108:INFO:Initializing Orthogonal Matching Pursuit
2023-11-04 23:34:57,108:INFO:Total runtime is 0.020788200696309413 minutes
2023-11-04 23:34:57,109:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:57,110:INFO:Initializing create_model()
2023-11-04 23:34:57,110:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e3c3a0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6149902e0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:57,110:INFO:Checking exceptions
2023-11-04 23:34:57,110:INFO:Importing libraries
2023-11-04 23:34:57,110:INFO:Copying training dataset
2023-11-04 23:34:57,112:INFO:Defining folds
2023-11-04 23:34:57,112:INFO:Declaring metric variables
2023-11-04 23:34:57,114:INFO:Importing untrained model
2023-11-04 23:34:57,116:INFO:Orthogonal Matching Pursuit Imported successfully
2023-11-04 23:34:57,119:INFO:Starting cross validation
2023-11-04 23:34:57,119:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:57,136:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:57,140:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:57,141:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:57,149:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:57,149:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:57,153:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:57,155:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:57,159:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:57,162:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:57,162:WARNING:/Users/michal/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-04 23:34:57,167:INFO:Calculating mean and std
2023-11-04 23:34:57,168:INFO:Creating metrics dataframe
2023-11-04 23:34:57,169:INFO:Uploading results into container
2023-11-04 23:34:57,170:INFO:Uploading model into container now
2023-11-04 23:34:57,170:INFO:_master_model_container: 7
2023-11-04 23:34:57,170:INFO:_display_container: 2
2023-11-04 23:34:57,170:INFO:OrthogonalMatchingPursuit()
2023-11-04 23:34:57,170:INFO:create_model() successfully completed......................................
2023-11-04 23:34:57,309:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:57,309:INFO:Creating metrics dataframe
2023-11-04 23:34:57,315:INFO:Initializing Bayesian Ridge
2023-11-04 23:34:57,315:INFO:Total runtime is 0.024243283271789557 minutes
2023-11-04 23:34:57,317:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:57,317:INFO:Initializing create_model()
2023-11-04 23:34:57,317:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e3c3a0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6149902e0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:57,317:INFO:Checking exceptions
2023-11-04 23:34:57,317:INFO:Importing libraries
2023-11-04 23:34:57,317:INFO:Copying training dataset
2023-11-04 23:34:57,319:INFO:Defining folds
2023-11-04 23:34:57,319:INFO:Declaring metric variables
2023-11-04 23:34:57,321:INFO:Importing untrained model
2023-11-04 23:34:57,323:INFO:Bayesian Ridge Imported successfully
2023-11-04 23:34:57,326:INFO:Starting cross validation
2023-11-04 23:34:57,326:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:57,378:INFO:Calculating mean and std
2023-11-04 23:34:57,378:INFO:Creating metrics dataframe
2023-11-04 23:34:57,380:INFO:Uploading results into container
2023-11-04 23:34:57,380:INFO:Uploading model into container now
2023-11-04 23:34:57,381:INFO:_master_model_container: 8
2023-11-04 23:34:57,381:INFO:_display_container: 2
2023-11-04 23:34:57,381:INFO:BayesianRidge()
2023-11-04 23:34:57,381:INFO:create_model() successfully completed......................................
2023-11-04 23:34:57,516:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:57,517:INFO:Creating metrics dataframe
2023-11-04 23:34:57,522:INFO:Initializing Passive Aggressive Regressor
2023-11-04 23:34:57,522:INFO:Total runtime is 0.027699398994445807 minutes
2023-11-04 23:34:57,524:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:57,524:INFO:Initializing create_model()
2023-11-04 23:34:57,524:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e3c3a0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6149902e0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:57,525:INFO:Checking exceptions
2023-11-04 23:34:57,525:INFO:Importing libraries
2023-11-04 23:34:57,525:INFO:Copying training dataset
2023-11-04 23:34:57,526:INFO:Defining folds
2023-11-04 23:34:57,527:INFO:Declaring metric variables
2023-11-04 23:34:57,528:INFO:Importing untrained model
2023-11-04 23:34:57,530:INFO:Passive Aggressive Regressor Imported successfully
2023-11-04 23:34:57,533:INFO:Starting cross validation
2023-11-04 23:34:57,534:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:57,583:INFO:Calculating mean and std
2023-11-04 23:34:57,583:INFO:Creating metrics dataframe
2023-11-04 23:34:57,585:INFO:Uploading results into container
2023-11-04 23:34:57,585:INFO:Uploading model into container now
2023-11-04 23:34:57,586:INFO:_master_model_container: 9
2023-11-04 23:34:57,586:INFO:_display_container: 2
2023-11-04 23:34:57,586:INFO:PassiveAggressiveRegressor(random_state=649)
2023-11-04 23:34:57,586:INFO:create_model() successfully completed......................................
2023-11-04 23:34:57,721:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:57,721:INFO:Creating metrics dataframe
2023-11-04 23:34:57,727:INFO:Initializing Huber Regressor
2023-11-04 23:34:57,727:INFO:Total runtime is 0.031112198034922288 minutes
2023-11-04 23:34:57,729:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:57,729:INFO:Initializing create_model()
2023-11-04 23:34:57,729:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e3c3a0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6149902e0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:57,729:INFO:Checking exceptions
2023-11-04 23:34:57,729:INFO:Importing libraries
2023-11-04 23:34:57,729:INFO:Copying training dataset
2023-11-04 23:34:57,731:INFO:Defining folds
2023-11-04 23:34:57,732:INFO:Declaring metric variables
2023-11-04 23:34:57,733:INFO:Importing untrained model
2023-11-04 23:34:57,735:INFO:Huber Regressor Imported successfully
2023-11-04 23:34:57,738:INFO:Starting cross validation
2023-11-04 23:34:57,738:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:57,795:INFO:Calculating mean and std
2023-11-04 23:34:57,796:INFO:Creating metrics dataframe
2023-11-04 23:34:57,797:INFO:Uploading results into container
2023-11-04 23:34:57,797:INFO:Uploading model into container now
2023-11-04 23:34:57,798:INFO:_master_model_container: 10
2023-11-04 23:34:57,798:INFO:_display_container: 2
2023-11-04 23:34:57,798:INFO:HuberRegressor()
2023-11-04 23:34:57,798:INFO:create_model() successfully completed......................................
2023-11-04 23:34:57,933:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:57,933:INFO:Creating metrics dataframe
2023-11-04 23:34:57,939:INFO:Initializing K Neighbors Regressor
2023-11-04 23:34:57,939:INFO:Total runtime is 0.03464933236440024 minutes
2023-11-04 23:34:57,941:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:57,941:INFO:Initializing create_model()
2023-11-04 23:34:57,941:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e3c3a0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6149902e0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:57,941:INFO:Checking exceptions
2023-11-04 23:34:57,942:INFO:Importing libraries
2023-11-04 23:34:57,942:INFO:Copying training dataset
2023-11-04 23:34:57,944:INFO:Defining folds
2023-11-04 23:34:57,944:INFO:Declaring metric variables
2023-11-04 23:34:57,945:INFO:Importing untrained model
2023-11-04 23:34:57,947:INFO:K Neighbors Regressor Imported successfully
2023-11-04 23:34:57,950:INFO:Starting cross validation
2023-11-04 23:34:57,951:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:58,013:INFO:Calculating mean and std
2023-11-04 23:34:58,014:INFO:Creating metrics dataframe
2023-11-04 23:34:58,015:INFO:Uploading results into container
2023-11-04 23:34:58,016:INFO:Uploading model into container now
2023-11-04 23:34:58,016:INFO:_master_model_container: 11
2023-11-04 23:34:58,016:INFO:_display_container: 2
2023-11-04 23:34:58,016:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-04 23:34:58,016:INFO:create_model() successfully completed......................................
2023-11-04 23:34:58,152:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:58,152:INFO:Creating metrics dataframe
2023-11-04 23:34:58,158:INFO:Initializing Decision Tree Regressor
2023-11-04 23:34:58,158:INFO:Total runtime is 0.038293564319610604 minutes
2023-11-04 23:34:58,160:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:58,160:INFO:Initializing create_model()
2023-11-04 23:34:58,160:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e3c3a0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6149902e0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:58,160:INFO:Checking exceptions
2023-11-04 23:34:58,160:INFO:Importing libraries
2023-11-04 23:34:58,160:INFO:Copying training dataset
2023-11-04 23:34:58,162:INFO:Defining folds
2023-11-04 23:34:58,162:INFO:Declaring metric variables
2023-11-04 23:34:58,164:INFO:Importing untrained model
2023-11-04 23:34:58,166:INFO:Decision Tree Regressor Imported successfully
2023-11-04 23:34:58,169:INFO:Starting cross validation
2023-11-04 23:34:58,170:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:58,218:INFO:Calculating mean and std
2023-11-04 23:34:58,218:INFO:Creating metrics dataframe
2023-11-04 23:34:58,220:INFO:Uploading results into container
2023-11-04 23:34:58,220:INFO:Uploading model into container now
2023-11-04 23:34:58,220:INFO:_master_model_container: 12
2023-11-04 23:34:58,220:INFO:_display_container: 2
2023-11-04 23:34:58,221:INFO:DecisionTreeRegressor(random_state=649)
2023-11-04 23:34:58,221:INFO:create_model() successfully completed......................................
2023-11-04 23:34:58,360:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:58,360:INFO:Creating metrics dataframe
2023-11-04 23:34:58,367:INFO:Initializing Random Forest Regressor
2023-11-04 23:34:58,367:INFO:Total runtime is 0.0417786995569865 minutes
2023-11-04 23:34:58,369:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:58,369:INFO:Initializing create_model()
2023-11-04 23:34:58,369:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e3c3a0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6149902e0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:58,369:INFO:Checking exceptions
2023-11-04 23:34:58,369:INFO:Importing libraries
2023-11-04 23:34:58,369:INFO:Copying training dataset
2023-11-04 23:34:58,371:INFO:Defining folds
2023-11-04 23:34:58,371:INFO:Declaring metric variables
2023-11-04 23:34:58,373:INFO:Importing untrained model
2023-11-04 23:34:58,375:INFO:Random Forest Regressor Imported successfully
2023-11-04 23:34:58,378:INFO:Starting cross validation
2023-11-04 23:34:58,378:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:58,639:INFO:Calculating mean and std
2023-11-04 23:34:58,640:INFO:Creating metrics dataframe
2023-11-04 23:34:58,642:INFO:Uploading results into container
2023-11-04 23:34:58,643:INFO:Uploading model into container now
2023-11-04 23:34:58,643:INFO:_master_model_container: 13
2023-11-04 23:34:58,643:INFO:_display_container: 2
2023-11-04 23:34:58,643:INFO:RandomForestRegressor(n_jobs=-1, random_state=649)
2023-11-04 23:34:58,643:INFO:create_model() successfully completed......................................
2023-11-04 23:34:58,781:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:58,781:INFO:Creating metrics dataframe
2023-11-04 23:34:58,787:INFO:Initializing Extra Trees Regressor
2023-11-04 23:34:58,787:INFO:Total runtime is 0.04878111680348715 minutes
2023-11-04 23:34:58,789:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:58,789:INFO:Initializing create_model()
2023-11-04 23:34:58,789:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e3c3a0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6149902e0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:58,790:INFO:Checking exceptions
2023-11-04 23:34:58,790:INFO:Importing libraries
2023-11-04 23:34:58,790:INFO:Copying training dataset
2023-11-04 23:34:58,792:INFO:Defining folds
2023-11-04 23:34:58,792:INFO:Declaring metric variables
2023-11-04 23:34:58,793:INFO:Importing untrained model
2023-11-04 23:34:58,795:INFO:Extra Trees Regressor Imported successfully
2023-11-04 23:34:58,798:INFO:Starting cross validation
2023-11-04 23:34:58,799:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:59,017:INFO:Calculating mean and std
2023-11-04 23:34:59,018:INFO:Creating metrics dataframe
2023-11-04 23:34:59,020:INFO:Uploading results into container
2023-11-04 23:34:59,020:INFO:Uploading model into container now
2023-11-04 23:34:59,021:INFO:_master_model_container: 14
2023-11-04 23:34:59,021:INFO:_display_container: 2
2023-11-04 23:34:59,021:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=649)
2023-11-04 23:34:59,021:INFO:create_model() successfully completed......................................
2023-11-04 23:34:59,156:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:59,156:INFO:Creating metrics dataframe
2023-11-04 23:34:59,162:INFO:Initializing AdaBoost Regressor
2023-11-04 23:34:59,162:INFO:Total runtime is 0.05503481626510621 minutes
2023-11-04 23:34:59,164:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:59,164:INFO:Initializing create_model()
2023-11-04 23:34:59,164:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e3c3a0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6149902e0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:59,165:INFO:Checking exceptions
2023-11-04 23:34:59,165:INFO:Importing libraries
2023-11-04 23:34:59,165:INFO:Copying training dataset
2023-11-04 23:34:59,167:INFO:Defining folds
2023-11-04 23:34:59,167:INFO:Declaring metric variables
2023-11-04 23:34:59,168:INFO:Importing untrained model
2023-11-04 23:34:59,170:INFO:AdaBoost Regressor Imported successfully
2023-11-04 23:34:59,173:INFO:Starting cross validation
2023-11-04 23:34:59,174:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:59,257:INFO:Calculating mean and std
2023-11-04 23:34:59,258:INFO:Creating metrics dataframe
2023-11-04 23:34:59,259:INFO:Uploading results into container
2023-11-04 23:34:59,259:INFO:Uploading model into container now
2023-11-04 23:34:59,260:INFO:_master_model_container: 15
2023-11-04 23:34:59,260:INFO:_display_container: 2
2023-11-04 23:34:59,260:INFO:AdaBoostRegressor(random_state=649)
2023-11-04 23:34:59,260:INFO:create_model() successfully completed......................................
2023-11-04 23:34:59,395:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:59,395:INFO:Creating metrics dataframe
2023-11-04 23:34:59,402:INFO:Initializing Gradient Boosting Regressor
2023-11-04 23:34:59,402:INFO:Total runtime is 0.0590217669804891 minutes
2023-11-04 23:34:59,403:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:59,404:INFO:Initializing create_model()
2023-11-04 23:34:59,404:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e3c3a0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6149902e0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:59,404:INFO:Checking exceptions
2023-11-04 23:34:59,404:INFO:Importing libraries
2023-11-04 23:34:59,404:INFO:Copying training dataset
2023-11-04 23:34:59,406:INFO:Defining folds
2023-11-04 23:34:59,406:INFO:Declaring metric variables
2023-11-04 23:34:59,408:INFO:Importing untrained model
2023-11-04 23:34:59,410:INFO:Gradient Boosting Regressor Imported successfully
2023-11-04 23:34:59,413:INFO:Starting cross validation
2023-11-04 23:34:59,413:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:59,489:INFO:Calculating mean and std
2023-11-04 23:34:59,490:INFO:Creating metrics dataframe
2023-11-04 23:34:59,491:INFO:Uploading results into container
2023-11-04 23:34:59,491:INFO:Uploading model into container now
2023-11-04 23:34:59,492:INFO:_master_model_container: 16
2023-11-04 23:34:59,492:INFO:_display_container: 2
2023-11-04 23:34:59,492:INFO:GradientBoostingRegressor(random_state=649)
2023-11-04 23:34:59,492:INFO:create_model() successfully completed......................................
2023-11-04 23:34:59,627:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:59,627:INFO:Creating metrics dataframe
2023-11-04 23:34:59,634:INFO:Initializing Extreme Gradient Boosting
2023-11-04 23:34:59,634:INFO:Total runtime is 0.06289406617482504 minutes
2023-11-04 23:34:59,636:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:59,636:INFO:Initializing create_model()
2023-11-04 23:34:59,636:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e3c3a0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6149902e0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:59,636:INFO:Checking exceptions
2023-11-04 23:34:59,636:INFO:Importing libraries
2023-11-04 23:34:59,636:INFO:Copying training dataset
2023-11-04 23:34:59,638:INFO:Defining folds
2023-11-04 23:34:59,638:INFO:Declaring metric variables
2023-11-04 23:34:59,640:INFO:Importing untrained model
2023-11-04 23:34:59,642:INFO:Extreme Gradient Boosting Imported successfully
2023-11-04 23:34:59,645:INFO:Starting cross validation
2023-11-04 23:34:59,646:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:59,719:INFO:Calculating mean and std
2023-11-04 23:34:59,719:INFO:Creating metrics dataframe
2023-11-04 23:34:59,721:INFO:Uploading results into container
2023-11-04 23:34:59,721:INFO:Uploading model into container now
2023-11-04 23:34:59,721:INFO:_master_model_container: 17
2023-11-04 23:34:59,721:INFO:_display_container: 2
2023-11-04 23:34:59,722:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=649, ...)
2023-11-04 23:34:59,722:INFO:create_model() successfully completed......................................
2023-11-04 23:34:59,858:INFO:SubProcess create_model() end ==================================
2023-11-04 23:34:59,858:INFO:Creating metrics dataframe
2023-11-04 23:34:59,865:INFO:Initializing Light Gradient Boosting Machine
2023-11-04 23:34:59,865:INFO:Total runtime is 0.06674415270487469 minutes
2023-11-04 23:34:59,867:INFO:SubProcess create_model() called ==================================
2023-11-04 23:34:59,867:INFO:Initializing create_model()
2023-11-04 23:34:59,867:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e3c3a0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6149902e0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:34:59,867:INFO:Checking exceptions
2023-11-04 23:34:59,867:INFO:Importing libraries
2023-11-04 23:34:59,867:INFO:Copying training dataset
2023-11-04 23:34:59,869:INFO:Defining folds
2023-11-04 23:34:59,869:INFO:Declaring metric variables
2023-11-04 23:34:59,871:INFO:Importing untrained model
2023-11-04 23:34:59,873:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-04 23:34:59,876:INFO:Starting cross validation
2023-11-04 23:34:59,877:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:34:59,938:INFO:Calculating mean and std
2023-11-04 23:34:59,939:INFO:Creating metrics dataframe
2023-11-04 23:34:59,940:INFO:Uploading results into container
2023-11-04 23:34:59,941:INFO:Uploading model into container now
2023-11-04 23:34:59,941:INFO:_master_model_container: 18
2023-11-04 23:34:59,941:INFO:_display_container: 2
2023-11-04 23:34:59,941:INFO:LGBMRegressor(random_state=649)
2023-11-04 23:34:59,941:INFO:create_model() successfully completed......................................
2023-11-04 23:35:00,076:INFO:SubProcess create_model() end ==================================
2023-11-04 23:35:00,076:INFO:Creating metrics dataframe
2023-11-04 23:35:00,083:INFO:Initializing CatBoost Regressor
2023-11-04 23:35:00,084:INFO:Total runtime is 0.07038748264312746 minutes
2023-11-04 23:35:00,085:INFO:SubProcess create_model() called ==================================
2023-11-04 23:35:00,086:INFO:Initializing create_model()
2023-11-04 23:35:00,086:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e3c3a0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6149902e0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:35:00,086:INFO:Checking exceptions
2023-11-04 23:35:00,086:INFO:Importing libraries
2023-11-04 23:35:00,086:INFO:Copying training dataset
2023-11-04 23:35:00,088:INFO:Defining folds
2023-11-04 23:35:00,088:INFO:Declaring metric variables
2023-11-04 23:35:00,090:INFO:Importing untrained model
2023-11-04 23:35:00,091:INFO:CatBoost Regressor Imported successfully
2023-11-04 23:35:00,094:INFO:Starting cross validation
2023-11-04 23:35:00,095:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:35:00,607:INFO:Calculating mean and std
2023-11-04 23:35:00,608:INFO:Creating metrics dataframe
2023-11-04 23:35:00,610:INFO:Uploading results into container
2023-11-04 23:35:00,611:INFO:Uploading model into container now
2023-11-04 23:35:00,611:INFO:_master_model_container: 19
2023-11-04 23:35:00,611:INFO:_display_container: 2
2023-11-04 23:35:00,611:INFO:<catboost.core.CatBoostRegressor object at 0x7fb614990af0>
2023-11-04 23:35:00,611:INFO:create_model() successfully completed......................................
2023-11-04 23:35:00,762:INFO:SubProcess create_model() end ==================================
2023-11-04 23:35:00,762:INFO:Creating metrics dataframe
2023-11-04 23:35:00,769:INFO:Initializing Dummy Regressor
2023-11-04 23:35:00,770:INFO:Total runtime is 0.08182063102722169 minutes
2023-11-04 23:35:00,771:INFO:SubProcess create_model() called ==================================
2023-11-04 23:35:00,772:INFO:Initializing create_model()
2023-11-04 23:35:00,772:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e3c3a0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6149902e0>, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:35:00,772:INFO:Checking exceptions
2023-11-04 23:35:00,772:INFO:Importing libraries
2023-11-04 23:35:00,772:INFO:Copying training dataset
2023-11-04 23:35:00,774:INFO:Defining folds
2023-11-04 23:35:00,774:INFO:Declaring metric variables
2023-11-04 23:35:00,776:INFO:Importing untrained model
2023-11-04 23:35:00,778:INFO:Dummy Regressor Imported successfully
2023-11-04 23:35:00,781:INFO:Starting cross validation
2023-11-04 23:35:00,781:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-04 23:35:00,832:INFO:Calculating mean and std
2023-11-04 23:35:00,832:INFO:Creating metrics dataframe
2023-11-04 23:35:00,834:INFO:Uploading results into container
2023-11-04 23:35:00,834:INFO:Uploading model into container now
2023-11-04 23:35:00,834:INFO:_master_model_container: 20
2023-11-04 23:35:00,834:INFO:_display_container: 2
2023-11-04 23:35:00,834:INFO:DummyRegressor()
2023-11-04 23:35:00,834:INFO:create_model() successfully completed......................................
2023-11-04 23:35:00,975:INFO:SubProcess create_model() end ==================================
2023-11-04 23:35:00,975:INFO:Creating metrics dataframe
2023-11-04 23:35:00,988:INFO:Initializing create_model()
2023-11-04 23:35:00,988:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb5f0e3c3a0>, estimator=KNeighborsRegressor(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-04 23:35:00,988:INFO:Checking exceptions
2023-11-04 23:35:00,989:INFO:Importing libraries
2023-11-04 23:35:00,989:INFO:Copying training dataset
2023-11-04 23:35:00,991:INFO:Defining folds
2023-11-04 23:35:00,991:INFO:Declaring metric variables
2023-11-04 23:35:00,991:INFO:Importing untrained model
2023-11-04 23:35:00,991:INFO:Declaring custom model
2023-11-04 23:35:00,991:INFO:K Neighbors Regressor Imported successfully
2023-11-04 23:35:00,992:INFO:Cross validation set to False
2023-11-04 23:35:00,992:INFO:Fitting Model
2023-11-04 23:35:01,000:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-04 23:35:01,000:INFO:create_model() successfully completed......................................
2023-11-04 23:35:01,165:INFO:_master_model_container: 20
2023-11-04 23:35:01,165:INFO:_display_container: 2
2023-11-04 23:35:01,165:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-04 23:35:01,166:INFO:compare_models() successfully completed......................................
